Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=122, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_336', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_720_336_FITS_ETTm1_ftM_sl720_ll48_pl336_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=122, out_features=178, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  19457536.0
params:  21894.0
Trainable parameters:  21894
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4177856
	speed: 0.0932s/iter; left time: 1206.5003s
	iters: 200, epoch: 1 | loss: 0.3781857
	speed: 0.0888s/iter; left time: 1140.7724s
Epoch: 1 cost time: 23.99956965446472
Epoch: 1, Steps: 261 | Train Loss: 0.4296281 Vali Loss: 0.7299978 Test Loss: 0.3839052
Validation loss decreased (inf --> 0.729998).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3647776
	speed: 0.3795s/iter; left time: 4815.5654s
	iters: 200, epoch: 2 | loss: 0.3705009
	speed: 0.0850s/iter; left time: 1069.8476s
Epoch: 2 cost time: 22.848057746887207
Epoch: 2, Steps: 261 | Train Loss: 0.3487410 Vali Loss: 0.6881733 Test Loss: 0.3671146
Validation loss decreased (0.729998 --> 0.688173).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3325802
	speed: 0.3557s/iter; left time: 4421.3518s
	iters: 200, epoch: 3 | loss: 0.3648226
	speed: 0.0406s/iter; left time: 500.4336s
Epoch: 3 cost time: 14.523860931396484
Epoch: 3, Steps: 261 | Train Loss: 0.3410006 Vali Loss: 0.6728121 Test Loss: 0.3667621
Validation loss decreased (0.688173 --> 0.672812).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3213712
	speed: 0.3588s/iter; left time: 4366.3183s
	iters: 200, epoch: 4 | loss: 0.3451365
	speed: 0.1120s/iter; left time: 1351.1611s
Epoch: 4 cost time: 28.78744149208069
Epoch: 4, Steps: 261 | Train Loss: 0.3391057 Vali Loss: 0.6666823 Test Loss: 0.3668222
Validation loss decreased (0.672812 --> 0.666682).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3425799
	speed: 0.4863s/iter; left time: 5790.5213s
	iters: 200, epoch: 5 | loss: 0.3284016
	speed: 0.1112s/iter; left time: 1312.9045s
Epoch: 5 cost time: 29.195006847381592
Epoch: 5, Steps: 261 | Train Loss: 0.3380579 Vali Loss: 0.6642931 Test Loss: 0.3667174
Validation loss decreased (0.666682 --> 0.664293).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3214412
	speed: 0.4620s/iter; left time: 5379.9530s
	iters: 200, epoch: 6 | loss: 0.3633335
	speed: 0.1027s/iter; left time: 1186.0098s
Epoch: 6 cost time: 28.063316822052002
Epoch: 6, Steps: 261 | Train Loss: 0.3376251 Vali Loss: 0.6604896 Test Loss: 0.3666087
Validation loss decreased (0.664293 --> 0.660490).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3374561
	speed: 0.5020s/iter; left time: 5715.0822s
	iters: 200, epoch: 7 | loss: 0.3177642
	speed: 0.1110s/iter; left time: 1253.0978s
Epoch: 7 cost time: 30.31014847755432
Epoch: 7, Steps: 261 | Train Loss: 0.3371798 Vali Loss: 0.6590197 Test Loss: 0.3671667
Validation loss decreased (0.660490 --> 0.659020).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3149061
	speed: 0.4801s/iter; left time: 5340.8343s
	iters: 200, epoch: 8 | loss: 0.3334760
	speed: 0.1040s/iter; left time: 1146.1786s
Epoch: 8 cost time: 27.04382848739624
Epoch: 8, Steps: 261 | Train Loss: 0.3369690 Vali Loss: 0.6596074 Test Loss: 0.3667681
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3283785
	speed: 0.4589s/iter; left time: 4984.7008s
	iters: 200, epoch: 9 | loss: 0.3506590
	speed: 0.0996s/iter; left time: 1072.2509s
Epoch: 9 cost time: 26.794594764709473
Epoch: 9, Steps: 261 | Train Loss: 0.3367572 Vali Loss: 0.6569544 Test Loss: 0.3668582
Validation loss decreased (0.659020 --> 0.656954).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3312232
	speed: 0.4360s/iter; left time: 4622.9956s
	iters: 200, epoch: 10 | loss: 0.3321910
	speed: 0.0905s/iter; left time: 950.0735s
Epoch: 10 cost time: 25.0480215549469
Epoch: 10, Steps: 261 | Train Loss: 0.3366466 Vali Loss: 0.6555669 Test Loss: 0.3668841
Validation loss decreased (0.656954 --> 0.655567).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3193859
	speed: 0.4242s/iter; left time: 4386.2289s
	iters: 200, epoch: 11 | loss: 0.3065782
	speed: 0.0942s/iter; left time: 964.8217s
Epoch: 11 cost time: 25.385467052459717
Epoch: 11, Steps: 261 | Train Loss: 0.3364318 Vali Loss: 0.6559220 Test Loss: 0.3668276
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3534079
	speed: 0.4519s/iter; left time: 4555.5152s
	iters: 200, epoch: 12 | loss: 0.3237216
	speed: 0.0875s/iter; left time: 873.1556s
Epoch: 12 cost time: 25.341320514678955
Epoch: 12, Steps: 261 | Train Loss: 0.3363427 Vali Loss: 0.6572066 Test Loss: 0.3668458
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3169149
	speed: 0.4258s/iter; left time: 4181.0545s
	iters: 200, epoch: 13 | loss: 0.3024368
	speed: 0.0929s/iter; left time: 903.2681s
Epoch: 13 cost time: 24.946388483047485
Epoch: 13, Steps: 261 | Train Loss: 0.3362979 Vali Loss: 0.6546744 Test Loss: 0.3668610
Validation loss decreased (0.655567 --> 0.654674).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3238037
	speed: 0.4174s/iter; left time: 3989.3410s
	iters: 200, epoch: 14 | loss: 0.3220273
	speed: 0.0928s/iter; left time: 877.6706s
Epoch: 14 cost time: 25.120033264160156
Epoch: 14, Steps: 261 | Train Loss: 0.3363768 Vali Loss: 0.6558145 Test Loss: 0.3669167
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3108436
	speed: 0.4471s/iter; left time: 4156.5082s
	iters: 200, epoch: 15 | loss: 0.3172451
	speed: 0.1054s/iter; left time: 969.7882s
Epoch: 15 cost time: 28.55512309074402
Epoch: 15, Steps: 261 | Train Loss: 0.3362106 Vali Loss: 0.6549364 Test Loss: 0.3666724
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3386755
	speed: 0.4972s/iter; left time: 4492.6279s
	iters: 200, epoch: 16 | loss: 0.3616447
	speed: 0.1119s/iter; left time: 999.7513s
Epoch: 16 cost time: 30.67705202102661
Epoch: 16, Steps: 261 | Train Loss: 0.3362884 Vali Loss: 0.6547126 Test Loss: 0.3665690
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3502419
	speed: 0.5092s/iter; left time: 4468.5529s
	iters: 200, epoch: 17 | loss: 0.3150362
	speed: 0.1038s/iter; left time: 900.6983s
Epoch: 17 cost time: 28.221335411071777
Epoch: 17, Steps: 261 | Train Loss: 0.3361901 Vali Loss: 0.6544069 Test Loss: 0.3669833
Validation loss decreased (0.654674 --> 0.654407).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3498400
	speed: 0.4305s/iter; left time: 3665.4514s
	iters: 200, epoch: 18 | loss: 0.3547633
	speed: 0.0978s/iter; left time: 822.4826s
Epoch: 18 cost time: 26.32992672920227
Epoch: 18, Steps: 261 | Train Loss: 0.3360985 Vali Loss: 0.6556252 Test Loss: 0.3666846
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3120054
	speed: 0.4185s/iter; left time: 3454.0839s
	iters: 200, epoch: 19 | loss: 0.3550560
	speed: 0.0902s/iter; left time: 735.2480s
Epoch: 19 cost time: 24.82828664779663
Epoch: 19, Steps: 261 | Train Loss: 0.3361133 Vali Loss: 0.6552786 Test Loss: 0.3667164
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3347984
	speed: 0.4065s/iter; left time: 3248.7190s
	iters: 200, epoch: 20 | loss: 0.3801699
	speed: 0.0940s/iter; left time: 742.0029s
Epoch: 20 cost time: 25.311825275421143
Epoch: 20, Steps: 261 | Train Loss: 0.3360657 Vali Loss: 0.6544728 Test Loss: 0.3668538
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3697477
	speed: 0.4140s/iter; left time: 3200.3429s
	iters: 200, epoch: 21 | loss: 0.3209718
	speed: 0.0967s/iter; left time: 738.2837s
Epoch: 21 cost time: 24.957606315612793
Epoch: 21, Steps: 261 | Train Loss: 0.3360903 Vali Loss: 0.6551671 Test Loss: 0.3665349
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4006045
	speed: 0.4187s/iter; left time: 3127.5685s
	iters: 200, epoch: 22 | loss: 0.3651800
	speed: 0.0919s/iter; left time: 677.0505s
Epoch: 22 cost time: 24.702964305877686
Epoch: 22, Steps: 261 | Train Loss: 0.3360123 Vali Loss: 0.6548220 Test Loss: 0.3665671
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3173140
	speed: 0.4209s/iter; left time: 3034.1138s
	iters: 200, epoch: 23 | loss: 0.3769311
	speed: 0.0864s/iter; left time: 614.2365s
Epoch: 23 cost time: 23.75749158859253
Epoch: 23, Steps: 261 | Train Loss: 0.3359856 Vali Loss: 0.6545421 Test Loss: 0.3665891
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3168072
	speed: 0.4128s/iter; left time: 2867.9936s
	iters: 200, epoch: 24 | loss: 0.3744489
	speed: 0.0899s/iter; left time: 615.7135s
Epoch: 24 cost time: 23.839812994003296
Epoch: 24, Steps: 261 | Train Loss: 0.3359750 Vali Loss: 0.6542858 Test Loss: 0.3670845
Validation loss decreased (0.654407 --> 0.654286).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3689095
	speed: 0.4237s/iter; left time: 2833.0928s
	iters: 200, epoch: 25 | loss: 0.3320392
	speed: 0.0895s/iter; left time: 589.2590s
Epoch: 25 cost time: 25.085241079330444
Epoch: 25, Steps: 261 | Train Loss: 0.3359696 Vali Loss: 0.6549739 Test Loss: 0.3669888
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3567066
	speed: 0.4536s/iter; left time: 2914.9674s
	iters: 200, epoch: 26 | loss: 0.3424501
	speed: 0.1145s/iter; left time: 724.2841s
Epoch: 26 cost time: 29.096822261810303
Epoch: 26, Steps: 261 | Train Loss: 0.3360503 Vali Loss: 0.6550238 Test Loss: 0.3667664
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3155763
	speed: 0.5019s/iter; left time: 3094.1964s
	iters: 200, epoch: 27 | loss: 0.3485194
	speed: 0.1287s/iter; left time: 780.4310s
Epoch: 27 cost time: 33.07115817070007
Epoch: 27, Steps: 261 | Train Loss: 0.3360401 Vali Loss: 0.6545245 Test Loss: 0.3666762
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3096341
	speed: 0.5130s/iter; left time: 3028.5383s
	iters: 200, epoch: 28 | loss: 0.3325525
	speed: 0.0973s/iter; left time: 564.7647s
Epoch: 28 cost time: 27.68033504486084
Epoch: 28, Steps: 261 | Train Loss: 0.3359106 Vali Loss: 0.6547635 Test Loss: 0.3666573
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3315791
	speed: 0.4487s/iter; left time: 2532.0861s
	iters: 200, epoch: 29 | loss: 0.3746020
	speed: 0.0988s/iter; left time: 547.4620s
Epoch: 29 cost time: 25.593218564987183
Epoch: 29, Steps: 261 | Train Loss: 0.3357698 Vali Loss: 0.6542001 Test Loss: 0.3668383
Validation loss decreased (0.654286 --> 0.654200).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3205126
	speed: 0.4081s/iter; left time: 2196.5790s
	iters: 200, epoch: 30 | loss: 0.3343173
	speed: 0.0861s/iter; left time: 454.7364s
Epoch: 30 cost time: 24.475204467773438
Epoch: 30, Steps: 261 | Train Loss: 0.3358792 Vali Loss: 0.6542320 Test Loss: 0.3669367
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3368675
	speed: 0.4167s/iter; left time: 2134.1602s
	iters: 200, epoch: 31 | loss: 0.3657919
	speed: 0.0963s/iter; left time: 483.3434s
Epoch: 31 cost time: 26.856778383255005
Epoch: 31, Steps: 261 | Train Loss: 0.3359484 Vali Loss: 0.6537575 Test Loss: 0.3666117
Validation loss decreased (0.654200 --> 0.653757).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3295026
	speed: 0.4220s/iter; left time: 2050.7661s
	iters: 200, epoch: 32 | loss: 0.3318309
	speed: 0.0918s/iter; left time: 437.1673s
Epoch: 32 cost time: 24.9422767162323
Epoch: 32, Steps: 261 | Train Loss: 0.3357310 Vali Loss: 0.6545299 Test Loss: 0.3667648
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3338869
	speed: 0.4230s/iter; left time: 1945.5259s
	iters: 200, epoch: 33 | loss: 0.3425721
	speed: 0.0946s/iter; left time: 425.7087s
Epoch: 33 cost time: 25.458540439605713
Epoch: 33, Steps: 261 | Train Loss: 0.3358864 Vali Loss: 0.6541639 Test Loss: 0.3666351
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3277974
	speed: 0.4165s/iter; left time: 1806.7920s
	iters: 200, epoch: 34 | loss: 0.3411457
	speed: 0.0995s/iter; left time: 421.5159s
Epoch: 34 cost time: 25.52374505996704
Epoch: 34, Steps: 261 | Train Loss: 0.3357881 Vali Loss: 0.6538876 Test Loss: 0.3669138
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3450852
	speed: 0.4192s/iter; left time: 1708.9742s
	iters: 200, epoch: 35 | loss: 0.3448006
	speed: 0.0935s/iter; left time: 371.7066s
Epoch: 35 cost time: 24.937674522399902
Epoch: 35, Steps: 261 | Train Loss: 0.3356857 Vali Loss: 0.6539240 Test Loss: 0.3668084
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.3294889
	speed: 0.4017s/iter; left time: 1532.9315s
	iters: 200, epoch: 36 | loss: 0.3309560
	speed: 0.1012s/iter; left time: 376.0734s
Epoch: 36 cost time: 26.606609582901
Epoch: 36, Steps: 261 | Train Loss: 0.3357633 Vali Loss: 0.6536281 Test Loss: 0.3667643
Validation loss decreased (0.653757 --> 0.653628).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2956782
	speed: 0.4509s/iter; left time: 1603.0056s
	iters: 200, epoch: 37 | loss: 0.3357139
	speed: 0.0964s/iter; left time: 333.1089s
Epoch: 37 cost time: 27.133235931396484
Epoch: 37, Steps: 261 | Train Loss: 0.3356187 Vali Loss: 0.6541800 Test Loss: 0.3666319
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.3581456
	speed: 0.4478s/iter; left time: 1475.0369s
	iters: 200, epoch: 38 | loss: 0.3416666
	speed: 0.0790s/iter; left time: 252.4688s
Epoch: 38 cost time: 24.03847360610962
Epoch: 38, Steps: 261 | Train Loss: 0.3357971 Vali Loss: 0.6544206 Test Loss: 0.3668105
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.3089700
	speed: 0.4129s/iter; left time: 1252.1970s
	iters: 200, epoch: 39 | loss: 0.3492956
	speed: 0.0934s/iter; left time: 274.0066s
Epoch: 39 cost time: 25.382976293563843
Epoch: 39, Steps: 261 | Train Loss: 0.3357215 Vali Loss: 0.6540236 Test Loss: 0.3668340
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.3261408
	speed: 0.4331s/iter; left time: 1200.6076s
	iters: 200, epoch: 40 | loss: 0.3461435
	speed: 0.0999s/iter; left time: 267.0461s
Epoch: 40 cost time: 27.61803364753723
Epoch: 40, Steps: 261 | Train Loss: 0.3358036 Vali Loss: 0.6539652 Test Loss: 0.3667162
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3640097
	speed: 0.4503s/iter; left time: 1130.7255s
	iters: 200, epoch: 41 | loss: 0.3026696
	speed: 0.1043s/iter; left time: 251.4863s
Epoch: 41 cost time: 27.29901933670044
Epoch: 41, Steps: 261 | Train Loss: 0.3357729 Vali Loss: 0.6539737 Test Loss: 0.3666463
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3590693
	speed: 0.4342s/iter; left time: 976.8904s
	iters: 200, epoch: 42 | loss: 0.3334536
	speed: 0.0845s/iter; left time: 181.7824s
Epoch: 42 cost time: 25.259226322174072
Epoch: 42, Steps: 261 | Train Loss: 0.3356891 Vali Loss: 0.6540114 Test Loss: 0.3667437
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.3415465
	speed: 0.4199s/iter; left time: 835.2577s
	iters: 200, epoch: 43 | loss: 0.3667312
	speed: 0.0874s/iter; left time: 165.1873s
Epoch: 43 cost time: 24.022061109542847
Epoch: 43, Steps: 261 | Train Loss: 0.3357570 Vali Loss: 0.6539865 Test Loss: 0.3667266
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.3239528
	speed: 0.4146s/iter; left time: 716.4964s
	iters: 200, epoch: 44 | loss: 0.3224290
	speed: 0.1028s/iter; left time: 167.3016s
Epoch: 44 cost time: 27.02031445503235
Epoch: 44, Steps: 261 | Train Loss: 0.3357287 Vali Loss: 0.6539402 Test Loss: 0.3667733
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.3372263
	speed: 0.4493s/iter; left time: 659.1127s
	iters: 200, epoch: 45 | loss: 0.3558636
	speed: 0.1004s/iter; left time: 137.2433s
Epoch: 45 cost time: 26.271143436431885
Epoch: 45, Steps: 261 | Train Loss: 0.3355726 Vali Loss: 0.6541497 Test Loss: 0.3667955
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.3367542
	speed: 0.4508s/iter; left time: 543.6577s
	iters: 200, epoch: 46 | loss: 0.3529500
	speed: 0.1052s/iter; left time: 116.3541s
Epoch: 46 cost time: 28.613645315170288
Epoch: 46, Steps: 261 | Train Loss: 0.3356394 Vali Loss: 0.6534578 Test Loss: 0.3667628
Validation loss decreased (0.653628 --> 0.653458).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.3433369
	speed: 0.4769s/iter; left time: 450.7067s
	iters: 200, epoch: 47 | loss: 0.3480595
	speed: 0.0957s/iter; left time: 80.8415s
Epoch: 47 cost time: 27.68554973602295
Epoch: 47, Steps: 261 | Train Loss: 0.3356969 Vali Loss: 0.6542071 Test Loss: 0.3667952
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.3630667
	speed: 0.4384s/iter; left time: 299.8360s
	iters: 200, epoch: 48 | loss: 0.3396673
	speed: 0.0866s/iter; left time: 50.5594s
Epoch: 48 cost time: 24.15759253501892
Epoch: 48, Steps: 261 | Train Loss: 0.3357087 Vali Loss: 0.6532457 Test Loss: 0.3667216
Validation loss decreased (0.653458 --> 0.653246).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.3492306
	speed: 0.4163s/iter; left time: 176.0739s
	iters: 200, epoch: 49 | loss: 0.2968321
	speed: 0.0961s/iter; left time: 31.0373s
Epoch: 49 cost time: 25.8543860912323
Epoch: 49, Steps: 261 | Train Loss: 0.3356164 Vali Loss: 0.6535811 Test Loss: 0.3667454
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.3339172
	speed: 0.3674s/iter; left time: 59.5154s
	iters: 200, epoch: 50 | loss: 0.3268798
	speed: 0.0525s/iter; left time: 3.2520s
Epoch: 50 cost time: 15.358889102935791
Epoch: 50, Steps: 261 | Train Loss: 0.3355689 Vali Loss: 0.6541623 Test Loss: 0.3667056
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.0497355408796396e-05
>>>>>>>testing : ETTm1_720_336_FITS_ETTm1_ftM_sl720_ll48_pl336_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.36621522903442383, mae:0.3847183287143707, rse:0.5758594870567322, corr:[0.53948635 0.5462454  0.5485214  0.5496155  0.55138266 0.5536508
 0.55519694 0.55567795 0.5558488  0.5563616  0.55735266 0.5582758
 0.55873173 0.5586361  0.55814326 0.5573869  0.5564799  0.5555458
 0.55454946 0.55347496 0.55226797 0.55084246 0.5492728  0.54789877
 0.5466393  0.5456205  0.5447265  0.5437927  0.5431191  0.5429549
 0.5434541  0.54454947 0.5456852  0.54648143 0.5466323  0.5466137
 0.54653317 0.54650474 0.54640126 0.54600316 0.54553187 0.54515207
 0.5450478  0.5452476  0.5453698  0.5452374  0.5450483  0.5449506
 0.5449115  0.5447752  0.5445594  0.5442522  0.5439947  0.54378456
 0.54368806 0.5436364  0.54353684 0.5433224  0.54315835 0.5430066
 0.5428833  0.54276997 0.54265726 0.54249257 0.54249835 0.5427099
 0.5429339  0.5429927  0.54291093 0.5428173  0.54290915 0.543156
 0.5433499  0.543281   0.5429541  0.54246366 0.5419949  0.5417309
 0.54165936 0.5416511  0.541566   0.5413537  0.5411108  0.5408926
 0.54078573 0.54070616 0.5405896  0.5403821  0.54020035 0.5402731
 0.5406221  0.54111236 0.5415339  0.54173464 0.54166806 0.5414005
 0.5410962  0.5409048  0.5406472  0.54028535 0.5398535  0.53948367
 0.5393159  0.53928703 0.5393566  0.53940296 0.539211   0.5388686
 0.5384622  0.5381842  0.53808993 0.53805333 0.5379545  0.5377648
 0.537504   0.53726053 0.537074   0.53689027 0.53668916 0.53652406
 0.5363949  0.5362934  0.53616333 0.53606576 0.53597665 0.53578657
 0.5354982  0.5352499  0.5351206  0.5351884  0.535306   0.5353306
 0.53525656 0.5351065  0.53491086 0.5348154  0.534922   0.53500915
 0.5350295  0.534993   0.53488034 0.5348434  0.5349682  0.53519833
 0.535405   0.53544116 0.53539765 0.5353554  0.5353986  0.5354206
 0.53534687 0.5352543  0.53516805 0.535109   0.5350544  0.53505254
 0.5350646  0.53504354 0.53507775 0.5350891  0.53514886 0.53520906
 0.53526324 0.5353006  0.53537697 0.53550595 0.5356581  0.535795
 0.53584915 0.53582597 0.53588563 0.5360572  0.5361753  0.5361606
 0.53604406 0.5359484  0.53597265 0.53614277 0.5363174  0.53638923
 0.53627795 0.53607976 0.5359095  0.5359493  0.53619874 0.53651834
 0.5367712  0.53699094 0.53724927 0.5375363  0.53779024 0.53791016
 0.5377936  0.5374927  0.5369896  0.53636146 0.53572476 0.53516054
 0.53460824 0.5340099  0.5333249  0.5326099  0.53192997 0.53133816
 0.5308246  0.5302995  0.52968657 0.52904594 0.5284579  0.52798396
 0.5275917  0.5272347  0.5267617  0.5260967  0.5252253  0.5244219
 0.5239206  0.5236811  0.5235973  0.52345693 0.5232311  0.52307516
 0.5231756  0.523432   0.52378774 0.524114   0.5242575  0.52423185
 0.5241337  0.524071   0.5240842  0.52409554 0.52410454 0.5241479
 0.52422553 0.5243854  0.52447027 0.52461815 0.52477235 0.52497834
 0.52516544 0.5251798  0.52506614 0.5249143  0.52482134 0.5247453
 0.5246741  0.5246469  0.5246178  0.52459836 0.5244777  0.5243219
 0.52408504 0.52394146 0.523856   0.5237966  0.5237647  0.5237575
 0.52377474 0.52384114 0.5239274  0.5240329  0.5241495  0.52433324
 0.52444017 0.5244207  0.5243229  0.5242679  0.5242916  0.5243148
 0.52433467 0.52430284 0.5242567  0.5242844  0.5243775  0.52450186
 0.5245342  0.52451664 0.52440625 0.52433765 0.524314   0.52433306
 0.5244306  0.5245703  0.5246612  0.5246731  0.5245352  0.5241714
 0.5236664  0.5232043  0.5228077  0.5223305  0.52176553 0.5211356
 0.520533   0.51995665 0.5195117  0.5191015  0.5186401  0.5181072
 0.51751465 0.5170025  0.5166894  0.516511   0.5163183  0.51596355
 0.5156146  0.51527935 0.51501065 0.5147755  0.51457757 0.5143328
 0.51409674 0.51402414 0.5140435  0.5140652  0.51397794 0.5138105
 0.5136361  0.5135025  0.51348317 0.51353174 0.51350397 0.5133186
 0.51305604 0.512968   0.51306164 0.51323926 0.5132613  0.5130787
 0.51294434 0.51297665 0.51315403 0.5134142  0.5134089  0.51137155]
