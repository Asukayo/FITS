Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=122, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_336', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_336_FITS_ETTm2_ftM_sl720_ll48_pl336_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=122, out_features=178, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  9728768.0
params:  21894.0
Trainable parameters:  21894
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3181092
	speed: 0.1567s/iter; left time: 4082.5606s
	iters: 200, epoch: 1 | loss: 0.2404301
	speed: 0.1448s/iter; left time: 3757.0046s
	iters: 300, epoch: 1 | loss: 0.1821656
	speed: 0.1326s/iter; left time: 3428.2733s
	iters: 400, epoch: 1 | loss: 0.2640129
	speed: 0.1354s/iter; left time: 3486.2862s
	iters: 500, epoch: 1 | loss: 0.2401063
	speed: 0.1315s/iter; left time: 3371.8335s
Epoch: 1 cost time: 72.94098973274231
Epoch: 1, Steps: 523 | Train Loss: 0.2842561 Vali Loss: 0.2203453 Test Loss: 0.3002445
Validation loss decreased (inf --> 0.220345).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1692939
	speed: 0.7789s/iter; left time: 19884.1061s
	iters: 200, epoch: 2 | loss: 0.1414255
	speed: 0.1079s/iter; left time: 2743.8121s
	iters: 300, epoch: 2 | loss: 0.1039363
	speed: 0.1147s/iter; left time: 2906.0244s
	iters: 400, epoch: 2 | loss: 0.1555768
	speed: 0.1298s/iter; left time: 3274.2143s
	iters: 500, epoch: 2 | loss: 0.0927628
	speed: 0.1270s/iter; left time: 3191.9435s
Epoch: 2 cost time: 63.01770496368408
Epoch: 2, Steps: 523 | Train Loss: 0.1693225 Vali Loss: 0.2060741 Test Loss: 0.2830048
Validation loss decreased (0.220345 --> 0.206074).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2289146
	speed: 0.8100s/iter; left time: 20253.2148s
	iters: 200, epoch: 3 | loss: 0.1556417
	speed: 0.1237s/iter; left time: 3081.9051s
	iters: 300, epoch: 3 | loss: 0.1629287
	speed: 0.1199s/iter; left time: 2972.9835s
	iters: 400, epoch: 3 | loss: 0.1198399
	speed: 0.1153s/iter; left time: 2849.2069s
	iters: 500, epoch: 3 | loss: 0.1560594
	speed: 0.1193s/iter; left time: 2934.5468s
Epoch: 3 cost time: 63.779309034347534
Epoch: 3, Steps: 523 | Train Loss: 0.1419702 Vali Loss: 0.2002255 Test Loss: 0.2764957
Validation loss decreased (0.206074 --> 0.200226).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1645519
	speed: 0.8296s/iter; left time: 20309.1711s
	iters: 200, epoch: 4 | loss: 0.1041054
	speed: 0.1087s/iter; left time: 2649.2014s
	iters: 300, epoch: 4 | loss: 0.1003962
	speed: 0.0961s/iter; left time: 2333.1408s
	iters: 400, epoch: 4 | loss: 0.1256013
	speed: 0.1150s/iter; left time: 2780.4881s
	iters: 500, epoch: 4 | loss: 0.1463348
	speed: 0.1216s/iter; left time: 2929.4157s
Epoch: 4 cost time: 60.0512170791626
Epoch: 4, Steps: 523 | Train Loss: 0.1333859 Vali Loss: 0.1975943 Test Loss: 0.2737701
Validation loss decreased (0.200226 --> 0.197594).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.0912588
	speed: 0.8107s/iter; left time: 19422.5900s
	iters: 200, epoch: 5 | loss: 0.1066334
	speed: 0.1340s/iter; left time: 3196.1165s
	iters: 300, epoch: 5 | loss: 0.1012534
	speed: 0.1240s/iter; left time: 2946.1054s
	iters: 400, epoch: 5 | loss: 0.0685638
	speed: 0.1208s/iter; left time: 2858.0262s
	iters: 500, epoch: 5 | loss: 0.1446654
	speed: 0.1254s/iter; left time: 2955.1974s
Epoch: 5 cost time: 67.50865769386292
Epoch: 5, Steps: 523 | Train Loss: 0.1307247 Vali Loss: 0.1969092 Test Loss: 0.2734002
Validation loss decreased (0.197594 --> 0.196909).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1091009
	speed: 0.9133s/iter; left time: 21404.6019s
	iters: 200, epoch: 6 | loss: 0.0844726
	speed: 0.1292s/iter; left time: 3015.6519s
	iters: 300, epoch: 6 | loss: 0.1764763
	speed: 0.1296s/iter; left time: 3011.5343s
	iters: 400, epoch: 6 | loss: 0.1189160
	speed: 0.1319s/iter; left time: 3051.6815s
	iters: 500, epoch: 6 | loss: 0.1150182
	speed: 0.1338s/iter; left time: 3082.1698s
Epoch: 6 cost time: 69.43532943725586
Epoch: 6, Steps: 523 | Train Loss: 0.1298679 Vali Loss: 0.1966006 Test Loss: 0.2731541
Validation loss decreased (0.196909 --> 0.196601).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1434055
	speed: 0.8921s/iter; left time: 20439.6297s
	iters: 200, epoch: 7 | loss: 0.1182214
	speed: 0.1408s/iter; left time: 3211.6629s
	iters: 300, epoch: 7 | loss: 0.0919017
	speed: 0.1236s/iter; left time: 2808.2235s
	iters: 400, epoch: 7 | loss: 0.1911373
	speed: 0.1249s/iter; left time: 2823.7339s
	iters: 500, epoch: 7 | loss: 0.1343019
	speed: 0.1229s/iter; left time: 2767.0708s
Epoch: 7 cost time: 68.73981523513794
Epoch: 7, Steps: 523 | Train Loss: 0.1294780 Vali Loss: 0.1963922 Test Loss: 0.2728947
Validation loss decreased (0.196601 --> 0.196392).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1557268
	speed: 0.8011s/iter; left time: 17936.0052s
	iters: 200, epoch: 8 | loss: 0.1063299
	speed: 0.1152s/iter; left time: 2566.7907s
	iters: 300, epoch: 8 | loss: 0.2098067
	speed: 0.1144s/iter; left time: 2538.3768s
	iters: 400, epoch: 8 | loss: 0.1163484
	speed: 0.1191s/iter; left time: 2629.8612s
	iters: 500, epoch: 8 | loss: 0.0960357
	speed: 0.1223s/iter; left time: 2689.8013s
Epoch: 8 cost time: 61.64502692222595
Epoch: 8, Steps: 523 | Train Loss: 0.1295337 Vali Loss: 0.1961582 Test Loss: 0.2726487
Validation loss decreased (0.196392 --> 0.196158).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1090175
	speed: 0.8257s/iter; left time: 18054.6921s
	iters: 200, epoch: 9 | loss: 0.1186787
	speed: 0.1383s/iter; left time: 3010.8688s
	iters: 300, epoch: 9 | loss: 0.1444136
	speed: 0.1133s/iter; left time: 2453.8203s
	iters: 400, epoch: 9 | loss: 0.1762365
	speed: 0.1238s/iter; left time: 2670.1162s
	iters: 500, epoch: 9 | loss: 0.1648370
	speed: 0.1194s/iter; left time: 2563.1085s
Epoch: 9 cost time: 66.48115038871765
Epoch: 9, Steps: 523 | Train Loss: 0.1295205 Vali Loss: 0.1961984 Test Loss: 0.2727537
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1685229
	speed: 0.8786s/iter; left time: 18752.1425s
	iters: 200, epoch: 10 | loss: 0.0934034
	speed: 0.1253s/iter; left time: 2662.0306s
	iters: 300, epoch: 10 | loss: 0.1209597
	speed: 0.1211s/iter; left time: 2560.9293s
	iters: 400, epoch: 10 | loss: 0.0847369
	speed: 0.1331s/iter; left time: 2801.4156s
	iters: 500, epoch: 10 | loss: 0.1280611
	speed: 0.1368s/iter; left time: 2865.5774s
Epoch: 10 cost time: 68.01588487625122
Epoch: 10, Steps: 523 | Train Loss: 0.1294686 Vali Loss: 0.1956746 Test Loss: 0.2725981
Validation loss decreased (0.196158 --> 0.195675).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1431267
	speed: 0.8632s/iter; left time: 17973.1634s
	iters: 200, epoch: 11 | loss: 0.0806742
	speed: 0.1158s/iter; left time: 2398.6442s
	iters: 300, epoch: 11 | loss: 0.1573675
	speed: 0.1122s/iter; left time: 2313.2408s
	iters: 400, epoch: 11 | loss: 0.1378378
	speed: 0.1269s/iter; left time: 2604.8001s
	iters: 500, epoch: 11 | loss: 0.1014423
	speed: 0.1231s/iter; left time: 2513.5044s
Epoch: 11 cost time: 63.16070199012756
Epoch: 11, Steps: 523 | Train Loss: 0.1291831 Vali Loss: 0.1960921 Test Loss: 0.2728274
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.0897691
	speed: 0.7736s/iter; left time: 15702.7139s
	iters: 200, epoch: 12 | loss: 0.0939511
	speed: 0.1229s/iter; left time: 2481.8641s
	iters: 300, epoch: 12 | loss: 0.2341460
	speed: 0.1250s/iter; left time: 2513.0000s
	iters: 400, epoch: 12 | loss: 0.1356620
	speed: 0.1287s/iter; left time: 2573.7212s
	iters: 500, epoch: 12 | loss: 0.1330807
	speed: 0.1364s/iter; left time: 2714.3812s
Epoch: 12 cost time: 67.96049952507019
Epoch: 12, Steps: 523 | Train Loss: 0.1294156 Vali Loss: 0.1961673 Test Loss: 0.2725904
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1299071
	speed: 0.8771s/iter; left time: 17344.5326s
	iters: 200, epoch: 13 | loss: 0.0985406
	speed: 0.1384s/iter; left time: 2723.2723s
	iters: 300, epoch: 13 | loss: 0.1565294
	speed: 0.1314s/iter; left time: 2571.3035s
	iters: 400, epoch: 13 | loss: 0.0725309
	speed: 0.1166s/iter; left time: 2270.5030s
	iters: 500, epoch: 13 | loss: 0.1391012
	speed: 0.1237s/iter; left time: 2397.3340s
Epoch: 13 cost time: 68.32154703140259
Epoch: 13, Steps: 523 | Train Loss: 0.1294124 Vali Loss: 0.1961012 Test Loss: 0.2728009
EarlyStopping counter: 3 out of 3
Early stopping
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=122, out_features=178, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  9728768.0
params:  21894.0
Trainable parameters:  21894
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2721896
	speed: 0.1166s/iter; left time: 3036.5407s
	iters: 200, epoch: 1 | loss: 0.3689004
	speed: 0.1080s/iter; left time: 2803.3828s
	iters: 300, epoch: 1 | loss: 0.4903421
	speed: 0.1079s/iter; left time: 2789.0960s
	iters: 400, epoch: 1 | loss: 0.2955160
	speed: 0.1051s/iter; left time: 2705.2684s
	iters: 500, epoch: 1 | loss: 0.2530853
	speed: 0.0974s/iter; left time: 2497.3570s
Epoch: 1 cost time: 56.01188898086548
Epoch: 1, Steps: 523 | Train Loss: 0.3793804 Vali Loss: 0.1935634 Test Loss: 0.2701197
Validation loss decreased (inf --> 0.193563).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3137752
	speed: 0.8083s/iter; left time: 20634.3796s
	iters: 200, epoch: 2 | loss: 0.2716748
	speed: 0.1074s/iter; left time: 2731.5260s
	iters: 300, epoch: 2 | loss: 0.4333216
	speed: 0.1182s/iter; left time: 2993.8323s
	iters: 400, epoch: 2 | loss: 0.3411252
	speed: 0.1174s/iter; left time: 2962.6253s
	iters: 500, epoch: 2 | loss: 0.5873489
	speed: 0.1135s/iter; left time: 2852.9510s
Epoch: 2 cost time: 62.41012167930603
Epoch: 2, Steps: 523 | Train Loss: 0.3770965 Vali Loss: 0.1930950 Test Loss: 0.2695769
Validation loss decreased (0.193563 --> 0.193095).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3653172
	speed: 0.8315s/iter; left time: 20790.6988s
	iters: 200, epoch: 3 | loss: 0.4726338
	speed: 0.1180s/iter; left time: 2939.1613s
	iters: 300, epoch: 3 | loss: 0.5275938
	speed: 0.1242s/iter; left time: 3082.0103s
	iters: 400, epoch: 3 | loss: 0.3155724
	speed: 0.1278s/iter; left time: 3156.8366s
	iters: 500, epoch: 3 | loss: 0.3247726
	speed: 0.1331s/iter; left time: 3275.7152s
Epoch: 3 cost time: 66.57001829147339
Epoch: 3, Steps: 523 | Train Loss: 0.3761897 Vali Loss: 0.1928675 Test Loss: 0.2689974
Validation loss decreased (0.193095 --> 0.192867).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3689821
	speed: 0.8222s/iter; left time: 20129.1884s
	iters: 200, epoch: 4 | loss: 0.5220568
	speed: 0.1168s/iter; left time: 2848.9009s
	iters: 300, epoch: 4 | loss: 0.3309233
	speed: 0.1126s/iter; left time: 2734.3473s
	iters: 400, epoch: 4 | loss: 0.3632276
	speed: 0.1139s/iter; left time: 2753.9984s
	iters: 500, epoch: 4 | loss: 0.2440626
	speed: 0.1136s/iter; left time: 2736.2770s
Epoch: 4 cost time: 62.00608992576599
Epoch: 4, Steps: 523 | Train Loss: 0.3751846 Vali Loss: 0.1929161 Test Loss: 0.2688363
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3210104
	speed: 0.8293s/iter; left time: 19868.1895s
	iters: 200, epoch: 5 | loss: 0.3262073
	speed: 0.1202s/iter; left time: 2868.3164s
	iters: 300, epoch: 5 | loss: 0.3498137
	speed: 0.1118s/iter; left time: 2655.9705s
	iters: 400, epoch: 5 | loss: 0.2752075
	speed: 0.1091s/iter; left time: 2581.0426s
	iters: 500, epoch: 5 | loss: 0.5214995
	speed: 0.1259s/iter; left time: 2965.8439s
Epoch: 5 cost time: 62.48408055305481
Epoch: 5, Steps: 523 | Train Loss: 0.3750891 Vali Loss: 0.1926647 Test Loss: 0.2687984
Validation loss decreased (0.192867 --> 0.192665).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5872504
	speed: 0.8340s/iter; left time: 19545.4139s
	iters: 200, epoch: 6 | loss: 0.3003148
	speed: 0.1304s/iter; left time: 3043.6296s
	iters: 300, epoch: 6 | loss: 0.3635123
	speed: 0.1150s/iter; left time: 2671.3665s
	iters: 400, epoch: 6 | loss: 0.2212135
	speed: 0.1252s/iter; left time: 2897.5036s
	iters: 500, epoch: 6 | loss: 0.3288166
	speed: 0.1226s/iter; left time: 2824.6184s
Epoch: 6 cost time: 66.63457822799683
Epoch: 6, Steps: 523 | Train Loss: 0.3750242 Vali Loss: 0.1921296 Test Loss: 0.2682809
Validation loss decreased (0.192665 --> 0.192130).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4028727
	speed: 0.9091s/iter; left time: 20830.4747s
	iters: 200, epoch: 7 | loss: 0.2698525
	speed: 0.1238s/iter; left time: 2824.2799s
	iters: 300, epoch: 7 | loss: 0.7859774
	speed: 0.1264s/iter; left time: 2870.5221s
	iters: 400, epoch: 7 | loss: 0.4900395
	speed: 0.1349s/iter; left time: 3049.7915s
	iters: 500, epoch: 7 | loss: 0.4295947
	speed: 0.1375s/iter; left time: 3096.3246s
Epoch: 7 cost time: 69.47318625450134
Epoch: 7, Steps: 523 | Train Loss: 0.3748563 Vali Loss: 0.1926438 Test Loss: 0.2686400
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2104551
	speed: 0.8802s/iter; left time: 19706.6479s
	iters: 200, epoch: 8 | loss: 0.5486247
	speed: 0.1322s/iter; left time: 2947.3359s
	iters: 300, epoch: 8 | loss: 0.5610281
	speed: 0.1220s/iter; left time: 2707.2211s
	iters: 400, epoch: 8 | loss: 0.2921796
	speed: 0.1162s/iter; left time: 2566.6211s
	iters: 500, epoch: 8 | loss: 0.3776726
	speed: 0.1209s/iter; left time: 2658.8087s
Epoch: 8 cost time: 66.50662994384766
Epoch: 8, Steps: 523 | Train Loss: 0.3745321 Vali Loss: 0.1925104 Test Loss: 0.2686790
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3770207
	speed: 0.8021s/iter; left time: 17540.4101s
	iters: 200, epoch: 9 | loss: 0.2598360
	speed: 0.0859s/iter; left time: 1869.8623s
	iters: 300, epoch: 9 | loss: 0.2958634
	speed: 0.1153s/iter; left time: 2498.9537s
	iters: 400, epoch: 9 | loss: 0.4428102
	speed: 0.1346s/iter; left time: 2903.8657s
	iters: 500, epoch: 9 | loss: 0.3045719
	speed: 0.1456s/iter; left time: 3125.9768s
Epoch: 9 cost time: 60.821622133255005
Epoch: 9, Steps: 523 | Train Loss: 0.3743412 Vali Loss: 0.1929820 Test Loss: 0.2691999
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_336_FITS_ETTm2_ftM_sl720_ll48_pl336_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.2684774398803711, mae:0.3259713351726532, rse:0.41851839423179626, corr:[0.55809855 0.5611091  0.55783814 0.5555668  0.5557939  0.5568415
 0.5566965  0.5553634  0.5542312  0.5540412  0.55444413 0.5546067
 0.55416703 0.553516   0.55320853 0.55319387 0.55292845 0.55201036
 0.55068856 0.54961187 0.54918855 0.54926676 0.54933923 0.548961
 0.54811764 0.54720575 0.54658216 0.5462652  0.5459982  0.54556584
 0.54496896 0.54439974 0.54393    0.54351246 0.5430285  0.5424045
 0.54164845 0.54087216 0.5401577  0.5395374  0.53899205 0.5384878
 0.53800565 0.5374908  0.53695434 0.5364254  0.5358783  0.5352546
 0.5345325  0.5337444  0.53292996 0.5321448  0.5313538  0.530566
 0.5298406  0.5292769  0.5288649  0.5285541  0.5282921  0.52805394
 0.52786016 0.52775836 0.52769315 0.5275547  0.527305   0.5269985
 0.52669126 0.52647525 0.52634454 0.52621233 0.52599007 0.5256803
 0.525335   0.5250137  0.52468103 0.52431333 0.5238808  0.5233927
 0.5228702  0.5223543  0.5217728  0.5211132  0.52036774 0.51962274
 0.5189981  0.5185251  0.5181287  0.5177534  0.51734424 0.5169074
 0.5165134  0.5161697  0.51577944 0.5152019  0.51427513 0.5129093
 0.51122576 0.5095071  0.5079404  0.5066634  0.50568205 0.5048708
 0.5040592  0.50308216 0.5019591  0.50080365 0.49981716 0.499056
 0.49835628 0.49749705 0.4963691  0.4950141  0.49370056 0.49267885
 0.4920333  0.49160007 0.49105892 0.4901966  0.489128   0.48811346
 0.4875069  0.48724627 0.48705623 0.48663473 0.48588434 0.4848556
 0.48368037 0.4823944  0.48093334 0.4793189  0.47782463 0.4768646
 0.4766561  0.47688335 0.47693104 0.47635382 0.47506228 0.47337562
 0.4717718  0.4706495  0.46996233 0.4694766  0.46905068 0.4686109
 0.4681464  0.46745157 0.46646532 0.46518373 0.4639767  0.4633295
 0.46350116 0.46411365 0.4643789  0.46384722 0.46260962 0.46117675
 0.46005988 0.45945194 0.4590738  0.45861125 0.45786375 0.45700923
 0.456347   0.45613468 0.45634276 0.45679146 0.45727953 0.45771322
 0.45799583 0.45799646 0.45753106 0.45670047 0.45582226 0.4552172
 0.45490205 0.45453808 0.45379892 0.45276132 0.4518738  0.45171028
 0.45218843 0.4527473  0.4528565  0.4522928  0.45127895 0.45031276
 0.44980502 0.44972223 0.44962358 0.44908363 0.44800413 0.4465891
 0.44517082 0.44396907 0.442777   0.44145697 0.44013464 0.43892276
 0.4379427  0.43717113 0.43657345 0.43603846 0.43542975 0.43451956
 0.43308136 0.43105593 0.42878234 0.42705172 0.4265924  0.42728823
 0.42809936 0.42810345 0.4269589  0.4249517  0.42282382 0.42113134
 0.4200242  0.41923344 0.41858637 0.41793877 0.41719982 0.41633418
 0.41528377 0.41416475 0.41332495 0.41292053 0.41291416 0.41280782
 0.41183528 0.40981638 0.4071356  0.40483615 0.40383264 0.4041897
 0.40499818 0.4054098  0.40514353 0.4045425  0.4040689  0.40373707
 0.4032126  0.40211147 0.40066576 0.39961585 0.39924297 0.39937174
 0.39935553 0.39874306 0.39762974 0.39667267 0.3966352  0.397346
 0.39804527 0.3982679  0.39800864 0.39789233 0.3982278  0.39872926
 0.39869118 0.3977655  0.3963913  0.39557308 0.39591742 0.39706203
 0.39791897 0.39769793 0.3966437  0.39559814 0.3952865  0.39569432
 0.39623573 0.39642373 0.39613974 0.39580753 0.39564615 0.39550254
 0.39516482 0.39441866 0.39360318 0.3933527  0.39371192 0.39422056
 0.39423785 0.3936032  0.39273113 0.39217067 0.39198568 0.39153278
 0.39037684 0.3888117  0.3873447  0.38645506 0.38611093 0.38575533
 0.38517314 0.38446924 0.38400272 0.38392025 0.383892   0.38314995
 0.38181335 0.38061205 0.38062716 0.3817304  0.38289908 0.38304287
 0.3819419  0.38014033 0.37895468 0.3790714  0.3797926  0.38014346
 0.3795382  0.3787589  0.3787444  0.3795367  0.3802579  0.3800238
 0.37869498 0.37741387 0.37744322 0.37865338 0.37967816 0.37958583
 0.37845904 0.37749302 0.37769523 0.3784546  0.37868983 0.3777796
 0.37688982 0.37728214 0.37863094 0.37928313 0.37619576 0.36711833]
