Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=512, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_96_FITS_ETTm2_ftM_sl720_ll48_pl96_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=90, out_features=102, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  32901120.0
params:  9282.0
Trainable parameters:  9282
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 12.822100639343262
Epoch: 1, Steps: 65 | Train Loss: 0.3622418 Vali Loss: 0.2241732 Test Loss: 0.2930520
Validation loss decreased (inf --> 0.224173).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 12.565710544586182
Epoch: 2, Steps: 65 | Train Loss: 0.2778618 Vali Loss: 0.1977727 Test Loss: 0.2545773
Validation loss decreased (0.224173 --> 0.197773).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 12.20860505104065
Epoch: 3, Steps: 65 | Train Loss: 0.2312615 Vali Loss: 0.1864244 Test Loss: 0.2378899
Validation loss decreased (0.197773 --> 0.186424).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 13.217966794967651
Epoch: 4, Steps: 65 | Train Loss: 0.2021101 Vali Loss: 0.1801346 Test Loss: 0.2291687
Validation loss decreased (0.186424 --> 0.180135).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 11.736817359924316
Epoch: 5, Steps: 65 | Train Loss: 0.1812199 Vali Loss: 0.1761849 Test Loss: 0.2241432
Validation loss decreased (0.180135 --> 0.176185).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 11.891351461410522
Epoch: 6, Steps: 65 | Train Loss: 0.1658861 Vali Loss: 0.1732448 Test Loss: 0.2205673
Validation loss decreased (0.176185 --> 0.173245).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 12.592427492141724
Epoch: 7, Steps: 65 | Train Loss: 0.1533232 Vali Loss: 0.1711958 Test Loss: 0.2177680
Validation loss decreased (0.173245 --> 0.171196).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 11.319372415542603
Epoch: 8, Steps: 65 | Train Loss: 0.1434274 Vali Loss: 0.1691209 Test Loss: 0.2152790
Validation loss decreased (0.171196 --> 0.169121).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 10.629103422164917
Epoch: 9, Steps: 65 | Train Loss: 0.1347031 Vali Loss: 0.1670534 Test Loss: 0.2130512
Validation loss decreased (0.169121 --> 0.167053).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 10.868153095245361
Epoch: 10, Steps: 65 | Train Loss: 0.1273828 Vali Loss: 0.1653689 Test Loss: 0.2111084
Validation loss decreased (0.167053 --> 0.165369).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 9.98740291595459
Epoch: 11, Steps: 65 | Train Loss: 0.1213765 Vali Loss: 0.1635342 Test Loss: 0.2090959
Validation loss decreased (0.165369 --> 0.163534).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 10.790278911590576
Epoch: 12, Steps: 65 | Train Loss: 0.1161118 Vali Loss: 0.1619422 Test Loss: 0.2075443
Validation loss decreased (0.163534 --> 0.161942).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 12.502540111541748
Epoch: 13, Steps: 65 | Train Loss: 0.1113540 Vali Loss: 0.1601941 Test Loss: 0.2058348
Validation loss decreased (0.161942 --> 0.160194).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 12.217057466506958
Epoch: 14, Steps: 65 | Train Loss: 0.1067142 Vali Loss: 0.1586120 Test Loss: 0.2042070
Validation loss decreased (0.160194 --> 0.158612).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 13.06594729423523
Epoch: 15, Steps: 65 | Train Loss: 0.1029609 Vali Loss: 0.1574749 Test Loss: 0.2028096
Validation loss decreased (0.158612 --> 0.157475).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 9.712124824523926
Epoch: 16, Steps: 65 | Train Loss: 0.0995004 Vali Loss: 0.1560313 Test Loss: 0.2015076
Validation loss decreased (0.157475 --> 0.156031).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 9.608068704605103
Epoch: 17, Steps: 65 | Train Loss: 0.0962601 Vali Loss: 0.1549354 Test Loss: 0.2002137
Validation loss decreased (0.156031 --> 0.154935).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 9.00195026397705
Epoch: 18, Steps: 65 | Train Loss: 0.0938371 Vali Loss: 0.1538157 Test Loss: 0.1990465
Validation loss decreased (0.154935 --> 0.153816).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 8.588671445846558
Epoch: 19, Steps: 65 | Train Loss: 0.0910516 Vali Loss: 0.1527562 Test Loss: 0.1978075
Validation loss decreased (0.153816 --> 0.152756).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 9.294934034347534
Epoch: 20, Steps: 65 | Train Loss: 0.0890262 Vali Loss: 0.1516119 Test Loss: 0.1968146
Validation loss decreased (0.152756 --> 0.151612).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 8.99162745475769
Epoch: 21, Steps: 65 | Train Loss: 0.0866376 Vali Loss: 0.1506965 Test Loss: 0.1958045
Validation loss decreased (0.151612 --> 0.150697).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 8.583636045455933
Epoch: 22, Steps: 65 | Train Loss: 0.0845783 Vali Loss: 0.1498898 Test Loss: 0.1948610
Validation loss decreased (0.150697 --> 0.149890).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 8.502294301986694
Epoch: 23, Steps: 65 | Train Loss: 0.0827249 Vali Loss: 0.1487801 Test Loss: 0.1939857
Validation loss decreased (0.149890 --> 0.148780).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 8.510615348815918
Epoch: 24, Steps: 65 | Train Loss: 0.0810591 Vali Loss: 0.1479056 Test Loss: 0.1931376
Validation loss decreased (0.148780 --> 0.147906).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 8.768176794052124
Epoch: 25, Steps: 65 | Train Loss: 0.0795236 Vali Loss: 0.1473066 Test Loss: 0.1924195
Validation loss decreased (0.147906 --> 0.147307).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 9.230341911315918
Epoch: 26, Steps: 65 | Train Loss: 0.0778811 Vali Loss: 0.1465470 Test Loss: 0.1915870
Validation loss decreased (0.147307 --> 0.146547).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 8.736138343811035
Epoch: 27, Steps: 65 | Train Loss: 0.0766627 Vali Loss: 0.1456806 Test Loss: 0.1909556
Validation loss decreased (0.146547 --> 0.145681).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 8.516033172607422
Epoch: 28, Steps: 65 | Train Loss: 0.0752671 Vali Loss: 0.1453813 Test Loss: 0.1902696
Validation loss decreased (0.145681 --> 0.145381).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 8.79955768585205
Epoch: 29, Steps: 65 | Train Loss: 0.0741203 Vali Loss: 0.1447914 Test Loss: 0.1896736
Validation loss decreased (0.145381 --> 0.144791).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 8.552475452423096
Epoch: 30, Steps: 65 | Train Loss: 0.0729203 Vali Loss: 0.1440341 Test Loss: 0.1891217
Validation loss decreased (0.144791 --> 0.144034).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 8.98682188987732
Epoch: 31, Steps: 65 | Train Loss: 0.0719663 Vali Loss: 0.1436159 Test Loss: 0.1886228
Validation loss decreased (0.144034 --> 0.143616).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 9.619457721710205
Epoch: 32, Steps: 65 | Train Loss: 0.0711607 Vali Loss: 0.1432181 Test Loss: 0.1880763
Validation loss decreased (0.143616 --> 0.143218).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 13.833675861358643
Epoch: 33, Steps: 65 | Train Loss: 0.0701536 Vali Loss: 0.1425658 Test Loss: 0.1875834
Validation loss decreased (0.143218 --> 0.142566).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 15.339525699615479
Epoch: 34, Steps: 65 | Train Loss: 0.0693429 Vali Loss: 0.1422557 Test Loss: 0.1871164
Validation loss decreased (0.142566 --> 0.142256).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 15.326674222946167
Epoch: 35, Steps: 65 | Train Loss: 0.0684943 Vali Loss: 0.1415484 Test Loss: 0.1867171
Validation loss decreased (0.142256 --> 0.141548).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 13.928619146347046
Epoch: 36, Steps: 65 | Train Loss: 0.0678370 Vali Loss: 0.1410554 Test Loss: 0.1863023
Validation loss decreased (0.141548 --> 0.141055).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 14.48026442527771
Epoch: 37, Steps: 65 | Train Loss: 0.0671900 Vali Loss: 0.1409602 Test Loss: 0.1859279
Validation loss decreased (0.141055 --> 0.140960).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 11.334574699401855
Epoch: 38, Steps: 65 | Train Loss: 0.0664345 Vali Loss: 0.1404942 Test Loss: 0.1855412
Validation loss decreased (0.140960 --> 0.140494).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 10.995914459228516
Epoch: 39, Steps: 65 | Train Loss: 0.0657590 Vali Loss: 0.1402477 Test Loss: 0.1852526
Validation loss decreased (0.140494 --> 0.140248).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 11.459713220596313
Epoch: 40, Steps: 65 | Train Loss: 0.0651998 Vali Loss: 0.1399990 Test Loss: 0.1848590
Validation loss decreased (0.140248 --> 0.139999).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 12.595868110656738
Epoch: 41, Steps: 65 | Train Loss: 0.0646704 Vali Loss: 0.1395352 Test Loss: 0.1846134
Validation loss decreased (0.139999 --> 0.139535).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 12.363888502120972
Epoch: 42, Steps: 65 | Train Loss: 0.0641805 Vali Loss: 0.1391999 Test Loss: 0.1842986
Validation loss decreased (0.139535 --> 0.139200).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 12.38900351524353
Epoch: 43, Steps: 65 | Train Loss: 0.0638057 Vali Loss: 0.1391547 Test Loss: 0.1840498
Validation loss decreased (0.139200 --> 0.139155).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 12.670525550842285
Epoch: 44, Steps: 65 | Train Loss: 0.0633279 Vali Loss: 0.1386515 Test Loss: 0.1837699
Validation loss decreased (0.139155 --> 0.138651).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 11.815137147903442
Epoch: 45, Steps: 65 | Train Loss: 0.0628114 Vali Loss: 0.1386283 Test Loss: 0.1834781
Validation loss decreased (0.138651 --> 0.138628).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 12.081478357315063
Epoch: 46, Steps: 65 | Train Loss: 0.0624672 Vali Loss: 0.1383397 Test Loss: 0.1832644
Validation loss decreased (0.138628 --> 0.138340).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 12.045788526535034
Epoch: 47, Steps: 65 | Train Loss: 0.0620880 Vali Loss: 0.1380209 Test Loss: 0.1830339
Validation loss decreased (0.138340 --> 0.138021).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 10.730242013931274
Epoch: 48, Steps: 65 | Train Loss: 0.0616109 Vali Loss: 0.1376465 Test Loss: 0.1828009
Validation loss decreased (0.138021 --> 0.137646).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 10.507300853729248
Epoch: 49, Steps: 65 | Train Loss: 0.0613380 Vali Loss: 0.1373012 Test Loss: 0.1826607
Validation loss decreased (0.137646 --> 0.137301).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 10.170366764068604
Epoch: 50, Steps: 65 | Train Loss: 0.0610468 Vali Loss: 0.1374766 Test Loss: 0.1824718
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.0497355408796396e-05
train 33745
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=90, out_features=102, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  32901120.0
params:  9282.0
Trainable parameters:  9282
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 10.395546674728394
Epoch: 1, Steps: 65 | Train Loss: 0.2307863 Vali Loss: 0.1219511 Test Loss: 0.1669353
Validation loss decreased (inf --> 0.121951).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 11.047294855117798
Epoch: 2, Steps: 65 | Train Loss: 0.2177909 Vali Loss: 0.1184205 Test Loss: 0.1640507
Validation loss decreased (0.121951 --> 0.118421).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 11.177098274230957
Epoch: 3, Steps: 65 | Train Loss: 0.2144219 Vali Loss: 0.1172474 Test Loss: 0.1631538
Validation loss decreased (0.118421 --> 0.117247).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 14.377370595932007
Epoch: 4, Steps: 65 | Train Loss: 0.2123873 Vali Loss: 0.1164777 Test Loss: 0.1626196
Validation loss decreased (0.117247 --> 0.116478).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 13.879793643951416
Epoch: 5, Steps: 65 | Train Loss: 0.2108377 Vali Loss: 0.1162502 Test Loss: 0.1624052
Validation loss decreased (0.116478 --> 0.116250).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 13.546582698822021
Epoch: 6, Steps: 65 | Train Loss: 0.2102765 Vali Loss: 0.1157395 Test Loss: 0.1618465
Validation loss decreased (0.116250 --> 0.115739).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 13.710360050201416
Epoch: 7, Steps: 65 | Train Loss: 0.2097687 Vali Loss: 0.1156470 Test Loss: 0.1617162
Validation loss decreased (0.115739 --> 0.115647).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 7.295245170593262
Epoch: 8, Steps: 65 | Train Loss: 0.2097183 Vali Loss: 0.1157459 Test Loss: 0.1617707
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 8.357730627059937
Epoch: 9, Steps: 65 | Train Loss: 0.2087645 Vali Loss: 0.1154758 Test Loss: 0.1615545
Validation loss decreased (0.115647 --> 0.115476).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 14.890523672103882
Epoch: 10, Steps: 65 | Train Loss: 0.2088108 Vali Loss: 0.1154764 Test Loss: 0.1616313
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 11.755564451217651
Epoch: 11, Steps: 65 | Train Loss: 0.2085082 Vali Loss: 0.1151440 Test Loss: 0.1614541
Validation loss decreased (0.115476 --> 0.115144).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 14.23922348022461
Epoch: 12, Steps: 65 | Train Loss: 0.2085960 Vali Loss: 0.1156258 Test Loss: 0.1614705
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 15.620837211608887
Epoch: 13, Steps: 65 | Train Loss: 0.2084294 Vali Loss: 0.1154550 Test Loss: 0.1613777
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 16.32535195350647
Epoch: 14, Steps: 65 | Train Loss: 0.2082486 Vali Loss: 0.1153792 Test Loss: 0.1612690
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_96_FITS_ETTm2_ftM_sl720_ll48_pl96_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.16366901993751526, mae:0.25493282079696655, rse:0.32800421118736267, corr:[0.5673233  0.5706127  0.5711069  0.5695282  0.5678829  0.56709474
 0.5670391  0.56722564 0.56718254 0.5667298  0.5660305  0.56538385
 0.56499535 0.5648463  0.56483495 0.5646798  0.56424767 0.5635092
 0.562596   0.5616646  0.56087166 0.56023544 0.55975884 0.55937064
 0.5589288  0.5583871  0.5577816  0.5571485  0.5565165  0.5559439
 0.55541086 0.5549763  0.5545429  0.5539535  0.5531915  0.5523735
 0.55157727 0.55089414 0.55032164 0.5498305  0.54935765 0.5488378
 0.54823726 0.54755604 0.54684937 0.5461216  0.54540104 0.54470485
 0.54390824 0.5429544  0.5418906  0.54086447 0.5399347  0.5391082
 0.5383674  0.5377441  0.5371772  0.53664136 0.5361461  0.5357267
 0.5353549  0.5350844  0.53486794 0.5346203  0.5342989  0.53400624
 0.5336887  0.53338283 0.53311163 0.53282595 0.532478   0.5320872
 0.5317271  0.53149194 0.53128684 0.53101265 0.5305356  0.529817
 0.5289036  0.528059   0.5273143  0.52678144 0.52628267 0.52560085
 0.52468747 0.52372026 0.52280676 0.52225494 0.5221386  0.522103
 0.5217619  0.5210087  0.51991326 0.519216   0.51968014 0.5204288 ]
