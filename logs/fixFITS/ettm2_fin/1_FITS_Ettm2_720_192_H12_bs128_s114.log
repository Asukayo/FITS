Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_192_FITS_ETTm2_ftM_sl720_ll48_pl192_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=106, out_features=134, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  25453568.0
params:  14338.0
Trainable parameters:  14338
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4137823
	speed: 0.1514s/iter; left time: 976.8767s
Epoch: 1 cost time: 19.85560417175293
Epoch: 1, Steps: 131 | Train Loss: 0.4316960 Vali Loss: 0.1839105 Test Loss: 0.2501848
Validation loss decreased (inf --> 0.183911).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4439330
	speed: 0.4619s/iter; left time: 2919.4008s
Epoch: 2 cost time: 23.015280961990356
Epoch: 2, Steps: 131 | Train Loss: 0.3416030 Vali Loss: 0.1686589 Test Loss: 0.2339725
Validation loss decreased (0.183911 --> 0.168659).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3151079
	speed: 0.4538s/iter; left time: 2808.3292s
Epoch: 3 cost time: 22.05352234840393
Epoch: 3, Steps: 131 | Train Loss: 0.3232669 Vali Loss: 0.1632879 Test Loss: 0.2281477
Validation loss decreased (0.168659 --> 0.163288).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3215954
	speed: 0.4910s/iter; left time: 2974.5985s
Epoch: 4 cost time: 24.306248426437378
Epoch: 4, Steps: 131 | Train Loss: 0.3139224 Vali Loss: 0.1601718 Test Loss: 0.2251773
Validation loss decreased (0.163288 --> 0.160172).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2738490
	speed: 0.4299s/iter; left time: 2548.2217s
Epoch: 5 cost time: 16.679536819458008
Epoch: 5, Steps: 131 | Train Loss: 0.3083691 Vali Loss: 0.1579681 Test Loss: 0.2229266
Validation loss decreased (0.160172 --> 0.157968).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2856547
	speed: 0.3470s/iter; left time: 2011.0670s
Epoch: 6 cost time: 16.840017795562744
Epoch: 6, Steps: 131 | Train Loss: 0.3039206 Vali Loss: 0.1565718 Test Loss: 0.2215319
Validation loss decreased (0.157968 --> 0.156572).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2879507
	speed: 0.3477s/iter; left time: 1969.6100s
Epoch: 7 cost time: 16.424524068832397
Epoch: 7, Steps: 131 | Train Loss: 0.3016465 Vali Loss: 0.1557956 Test Loss: 0.2204684
Validation loss decreased (0.156572 --> 0.155796).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3278935
	speed: 0.3834s/iter; left time: 2121.7197s
Epoch: 8 cost time: 19.411065101623535
Epoch: 8, Steps: 131 | Train Loss: 0.2995392 Vali Loss: 0.1552599 Test Loss: 0.2199166
Validation loss decreased (0.155796 --> 0.155260).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3361809
	speed: 0.4227s/iter; left time: 2283.6969s
Epoch: 9 cost time: 21.928831338882446
Epoch: 9, Steps: 131 | Train Loss: 0.2979180 Vali Loss: 0.1547306 Test Loss: 0.2191835
Validation loss decreased (0.155260 --> 0.154731).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2309465
	speed: 0.4645s/iter; left time: 2449.0817s
Epoch: 10 cost time: 22.219794750213623
Epoch: 10, Steps: 131 | Train Loss: 0.2966065 Vali Loss: 0.1542358 Test Loss: 0.2185384
Validation loss decreased (0.154731 --> 0.154236).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3032030
	speed: 0.4271s/iter; left time: 2195.8678s
Epoch: 11 cost time: 20.761690139770508
Epoch: 11, Steps: 131 | Train Loss: 0.2962157 Vali Loss: 0.1538102 Test Loss: 0.2183139
Validation loss decreased (0.154236 --> 0.153810).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2594995
	speed: 0.4174s/iter; left time: 2091.2264s
Epoch: 12 cost time: 20.3879554271698
Epoch: 12, Steps: 131 | Train Loss: 0.2940103 Vali Loss: 0.1537406 Test Loss: 0.2180709
Validation loss decreased (0.153810 --> 0.153741).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4725559
	speed: 0.4004s/iter; left time: 1953.4941s
Epoch: 13 cost time: 18.74166512489319
Epoch: 13, Steps: 131 | Train Loss: 0.2940744 Vali Loss: 0.1535292 Test Loss: 0.2178140
Validation loss decreased (0.153741 --> 0.153529).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3322648
	speed: 0.3974s/iter; left time: 1886.7787s
Epoch: 14 cost time: 19.999125003814697
Epoch: 14, Steps: 131 | Train Loss: 0.2939980 Vali Loss: 0.1533310 Test Loss: 0.2176065
Validation loss decreased (0.153529 --> 0.153331).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3137645
	speed: 0.4863s/iter; left time: 2245.4743s
Epoch: 15 cost time: 23.93546485900879
Epoch: 15, Steps: 131 | Train Loss: 0.2937167 Vali Loss: 0.1531636 Test Loss: 0.2173262
Validation loss decreased (0.153331 --> 0.153164).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2740688
	speed: 0.4801s/iter; left time: 2153.7322s
Epoch: 16 cost time: 22.222933053970337
Epoch: 16, Steps: 131 | Train Loss: 0.2928708 Vali Loss: 0.1529707 Test Loss: 0.2171830
Validation loss decreased (0.153164 --> 0.152971).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2442259
	speed: 0.4945s/iter; left time: 2153.3395s
Epoch: 17 cost time: 24.672234535217285
Epoch: 17, Steps: 131 | Train Loss: 0.2927932 Vali Loss: 0.1527005 Test Loss: 0.2170149
Validation loss decreased (0.152971 --> 0.152700).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3041655
	speed: 0.4888s/iter; left time: 2064.7425s
Epoch: 18 cost time: 23.901801109313965
Epoch: 18, Steps: 131 | Train Loss: 0.2922090 Vali Loss: 0.1528032 Test Loss: 0.2169269
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2274688
	speed: 0.4990s/iter; left time: 2042.3343s
Epoch: 19 cost time: 24.029157876968384
Epoch: 19, Steps: 131 | Train Loss: 0.2919589 Vali Loss: 0.1525082 Test Loss: 0.2167721
Validation loss decreased (0.152700 --> 0.152508).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2812205
	speed: 0.5210s/iter; left time: 2064.0923s
Epoch: 20 cost time: 24.382028341293335
Epoch: 20, Steps: 131 | Train Loss: 0.2919523 Vali Loss: 0.1526462 Test Loss: 0.2167475
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3295998
	speed: 0.4408s/iter; left time: 1688.6155s
Epoch: 21 cost time: 20.43429446220398
Epoch: 21, Steps: 131 | Train Loss: 0.2918219 Vali Loss: 0.1524807 Test Loss: 0.2166067
Validation loss decreased (0.152508 --> 0.152481).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3701116
	speed: 0.4436s/iter; left time: 1641.4322s
Epoch: 22 cost time: 21.54578733444214
Epoch: 22, Steps: 131 | Train Loss: 0.2915063 Vali Loss: 0.1525143 Test Loss: 0.2165303
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2836255
	speed: 0.4679s/iter; left time: 1669.8404s
Epoch: 23 cost time: 21.566579818725586
Epoch: 23, Steps: 131 | Train Loss: 0.2911907 Vali Loss: 0.1523564 Test Loss: 0.2165133
Validation loss decreased (0.152481 --> 0.152356).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4007659
	speed: 0.4709s/iter; left time: 1619.0898s
Epoch: 24 cost time: 24.334239721298218
Epoch: 24, Steps: 131 | Train Loss: 0.2911917 Vali Loss: 0.1523736 Test Loss: 0.2164220
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2373227
	speed: 0.5105s/iter; left time: 1688.0853s
Epoch: 25 cost time: 23.051478147506714
Epoch: 25, Steps: 131 | Train Loss: 0.2908445 Vali Loss: 0.1523088 Test Loss: 0.2163457
Validation loss decreased (0.152356 --> 0.152309).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2194317
	speed: 0.4390s/iter; left time: 1394.4152s
Epoch: 26 cost time: 20.713284969329834
Epoch: 26, Steps: 131 | Train Loss: 0.2911229 Vali Loss: 0.1522600 Test Loss: 0.2163068
Validation loss decreased (0.152309 --> 0.152260).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3319635
	speed: 0.4364s/iter; left time: 1328.8234s
Epoch: 27 cost time: 21.05544376373291
Epoch: 27, Steps: 131 | Train Loss: 0.2907968 Vali Loss: 0.1520728 Test Loss: 0.2162707
Validation loss decreased (0.152260 --> 0.152073).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3203679
	speed: 0.4239s/iter; left time: 1235.2663s
Epoch: 28 cost time: 20.390979766845703
Epoch: 28, Steps: 131 | Train Loss: 0.2905403 Vali Loss: 0.1520878 Test Loss: 0.2162676
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2963511
	speed: 0.4869s/iter; left time: 1354.9084s
Epoch: 29 cost time: 24.88182044029236
Epoch: 29, Steps: 131 | Train Loss: 0.2906606 Vali Loss: 0.1522462 Test Loss: 0.2162498
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2348778
	speed: 0.5202s/iter; left time: 1379.6966s
Epoch: 30 cost time: 22.428717851638794
Epoch: 30, Steps: 131 | Train Loss: 0.2906773 Vali Loss: 0.1522568 Test Loss: 0.2161335
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_192_FITS_ETTm2_ftM_sl720_ll48_pl192_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.21796953678131104, mae:0.2924077808856964, rse:0.3779140114784241, corr:[0.5548116  0.56313115 0.56170464 0.55891937 0.5584651  0.5600491
 0.5617572  0.5619328  0.5608455  0.5598148  0.5596545  0.560297
 0.5610607  0.5611466  0.56047505 0.5595132  0.5588242  0.5585627
 0.5585027  0.55823094 0.5575786  0.55668676 0.55589974 0.55543953
 0.5552586  0.55512303 0.554772   0.55412465 0.5533192  0.5525721
 0.55201006 0.5516634  0.5513394  0.5508304  0.550133   0.549387
 0.54868835 0.5480929  0.5475675  0.5470335  0.5464313  0.54575324
 0.5450802  0.5444851  0.54398704 0.54349804 0.5429057  0.54216135
 0.5412399  0.5402417  0.5393539  0.5387344  0.5382855  0.53780425
 0.5371453  0.536368   0.53560466 0.5350436  0.53478974 0.5347328
 0.5346433  0.53441286 0.5340318  0.5336339  0.53336895 0.53332067
 0.5332898  0.53311604 0.5327242  0.5321467  0.5315338  0.5310895
 0.53087807 0.5307769  0.5305515  0.53011745 0.52950597 0.52884454
 0.52826595 0.52782536 0.5273578  0.52675694 0.52600956 0.5252247
 0.52456045 0.52414125 0.5238208  0.5234707  0.52297044 0.52231646
 0.52165204 0.5210966  0.5205747  0.5199802  0.51911527 0.51784676
 0.51628345 0.5147528  0.51346505 0.51245236 0.511545   0.5104815
 0.5091709  0.5076874  0.50624347 0.5051075  0.5043713  0.50390464
 0.50334424 0.5025278  0.5015351  0.5005569  0.49984393 0.49928546
 0.49861684 0.49770132 0.4965758  0.49540833 0.49451956 0.49392483
 0.49353412 0.49299648 0.4922243  0.49123958 0.49024013 0.48949155
 0.48907858 0.48876    0.48817724 0.48715252 0.4858581  0.48466042
 0.48394462 0.48370892 0.48357365 0.48309517 0.48206535 0.48080313
 0.47974852 0.4792646  0.47920707 0.47913992 0.47865787 0.47757545
 0.4761807  0.4748699  0.47417122 0.47393343 0.4737383  0.4731182
 0.47214198 0.47123596 0.47067443 0.47038138 0.47005525 0.46946916
 0.46853217 0.4675434  0.4668507  0.46682826 0.46707132 0.4670855
 0.46641916 0.46523988 0.46416777 0.4638734  0.464311   0.4648637
 0.46486777 0.464163   0.46299416 0.462174   0.46226358 0.46294886
 0.46332496 0.46271503 0.46124735 0.45981392 0.45938575 0.4603251
 0.46123776 0.46070898 0.45864534 0.45608646 0.45504034 0.45661983
 0.45896965 0.45957297 0.45744053 0.45368388 0.45355356 0.45841488]
