Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=74, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_336', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_336_FITS_ETTm2_ftM_sl720_ll48_pl336_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=74, out_features=108, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  14321664.0
params:  8100.0
Trainable parameters:  8100
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4216834
	speed: 0.1449s/iter; left time: 927.4909s
Epoch: 1 cost time: 18.72151255607605
Epoch: 1, Steps: 130 | Train Loss: 0.4930554 Vali Loss: 0.2228292 Test Loss: 0.3042596
Validation loss decreased (inf --> 0.222829).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4369624
	speed: 0.3943s/iter; left time: 2472.5801s
Epoch: 2 cost time: 18.87366771697998
Epoch: 2, Steps: 130 | Train Loss: 0.4185997 Vali Loss: 0.2097484 Test Loss: 0.2879242
Validation loss decreased (0.222829 --> 0.209748).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2954497
	speed: 0.3897s/iter; left time: 2393.2074s
Epoch: 3 cost time: 18.565319538116455
Epoch: 3, Steps: 130 | Train Loss: 0.4044429 Vali Loss: 0.2042139 Test Loss: 0.2820315
Validation loss decreased (0.209748 --> 0.204214).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3415709
	speed: 0.3861s/iter; left time: 2320.5542s
Epoch: 4 cost time: 18.566173315048218
Epoch: 4, Steps: 130 | Train Loss: 0.3973239 Vali Loss: 0.2016955 Test Loss: 0.2784162
Validation loss decreased (0.204214 --> 0.201696).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4232901
	speed: 0.3906s/iter; left time: 2296.9509s
Epoch: 5 cost time: 18.958051443099976
Epoch: 5, Steps: 130 | Train Loss: 0.3923307 Vali Loss: 0.2000792 Test Loss: 0.2764887
Validation loss decreased (0.201696 --> 0.200079).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3465790
	speed: 0.3853s/iter; left time: 2215.6270s
Epoch: 6 cost time: 18.266775131225586
Epoch: 6, Steps: 130 | Train Loss: 0.3901927 Vali Loss: 0.1988693 Test Loss: 0.2749878
Validation loss decreased (0.200079 --> 0.198869).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2723620
	speed: 0.3816s/iter; left time: 2144.7819s
Epoch: 7 cost time: 18.213032007217407
Epoch: 7, Steps: 130 | Train Loss: 0.3870538 Vali Loss: 0.1982084 Test Loss: 0.2739542
Validation loss decreased (0.198869 --> 0.198208).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4391888
	speed: 0.3793s/iter; left time: 2082.8076s
Epoch: 8 cost time: 18.35470175743103
Epoch: 8, Steps: 130 | Train Loss: 0.3852472 Vali Loss: 0.1975818 Test Loss: 0.2731722
Validation loss decreased (0.198208 --> 0.197582).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4044207
	speed: 0.3891s/iter; left time: 2086.1221s
Epoch: 9 cost time: 18.92974066734314
Epoch: 9, Steps: 130 | Train Loss: 0.3853845 Vali Loss: 0.1970863 Test Loss: 0.2726915
Validation loss decreased (0.197582 --> 0.197086).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3668877
	speed: 0.3966s/iter; left time: 2074.5285s
Epoch: 10 cost time: 18.964818477630615
Epoch: 10, Steps: 130 | Train Loss: 0.3838709 Vali Loss: 0.1965531 Test Loss: 0.2721249
Validation loss decreased (0.197086 --> 0.196553).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4230999
	speed: 0.3795s/iter; left time: 1935.9413s
Epoch: 11 cost time: 17.501650094985962
Epoch: 11, Steps: 130 | Train Loss: 0.3832126 Vali Loss: 0.1962194 Test Loss: 0.2717126
Validation loss decreased (0.196553 --> 0.196219).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3064792
	speed: 0.3811s/iter; left time: 1894.3923s
Epoch: 12 cost time: 18.730154752731323
Epoch: 12, Steps: 130 | Train Loss: 0.3824015 Vali Loss: 0.1963336 Test Loss: 0.2714519
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2751790
	speed: 0.3659s/iter; left time: 1771.1922s
Epoch: 13 cost time: 18.751464128494263
Epoch: 13, Steps: 130 | Train Loss: 0.3809666 Vali Loss: 0.1959730 Test Loss: 0.2710269
Validation loss decreased (0.196219 --> 0.195973).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3396625
	speed: 0.4233s/iter; left time: 1994.2861s
Epoch: 14 cost time: 20.025274515151978
Epoch: 14, Steps: 130 | Train Loss: 0.3821572 Vali Loss: 0.1957471 Test Loss: 0.2710408
Validation loss decreased (0.195973 --> 0.195747).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4124451
	speed: 0.3986s/iter; left time: 1825.8867s
Epoch: 15 cost time: 19.413265466690063
Epoch: 15, Steps: 130 | Train Loss: 0.3802173 Vali Loss: 0.1956706 Test Loss: 0.2708459
Validation loss decreased (0.195747 --> 0.195671).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4019902
	speed: 0.3825s/iter; left time: 1702.6666s
Epoch: 16 cost time: 17.975353479385376
Epoch: 16, Steps: 130 | Train Loss: 0.3810964 Vali Loss: 0.1952367 Test Loss: 0.2706083
Validation loss decreased (0.195671 --> 0.195237).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3748150
	speed: 0.3725s/iter; left time: 1609.7179s
Epoch: 17 cost time: 18.801729202270508
Epoch: 17, Steps: 130 | Train Loss: 0.3805359 Vali Loss: 0.1951056 Test Loss: 0.2705894
Validation loss decreased (0.195237 --> 0.195106).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3960744
	speed: 0.3838s/iter; left time: 1608.4229s
Epoch: 18 cost time: 17.98963761329651
Epoch: 18, Steps: 130 | Train Loss: 0.3800140 Vali Loss: 0.1952724 Test Loss: 0.2703917
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3953789
	speed: 0.3729s/iter; left time: 1514.4047s
Epoch: 19 cost time: 17.862483501434326
Epoch: 19, Steps: 130 | Train Loss: 0.3795986 Vali Loss: 0.1955826 Test Loss: 0.2703481
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3692939
	speed: 0.3673s/iter; left time: 1443.8247s
Epoch: 20 cost time: 17.55788779258728
Epoch: 20, Steps: 130 | Train Loss: 0.3785539 Vali Loss: 0.1950458 Test Loss: 0.2700219
Validation loss decreased (0.195106 --> 0.195046).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3519022
	speed: 0.3947s/iter; left time: 1500.3507s
Epoch: 21 cost time: 19.072012424468994
Epoch: 21, Steps: 130 | Train Loss: 0.3790928 Vali Loss: 0.1951817 Test Loss: 0.2700957
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3743342
	speed: 0.3887s/iter; left time: 1426.8150s
Epoch: 22 cost time: 18.339303016662598
Epoch: 22, Steps: 130 | Train Loss: 0.3794270 Vali Loss: 0.1953903 Test Loss: 0.2700076
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.5019339
	speed: 0.4007s/iter; left time: 1418.9097s
Epoch: 23 cost time: 19.480101346969604
Epoch: 23, Steps: 130 | Train Loss: 0.3781168 Vali Loss: 0.1949831 Test Loss: 0.2699734
Validation loss decreased (0.195046 --> 0.194983).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4037002
	speed: 0.4152s/iter; left time: 1416.4134s
Epoch: 24 cost time: 19.588693618774414
Epoch: 24, Steps: 130 | Train Loss: 0.3790242 Vali Loss: 0.1946871 Test Loss: 0.2698409
Validation loss decreased (0.194983 --> 0.194687).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3733256
	speed: 0.4150s/iter; left time: 1361.7280s
Epoch: 25 cost time: 20.343994617462158
Epoch: 25, Steps: 130 | Train Loss: 0.3782870 Vali Loss: 0.1946967 Test Loss: 0.2698394
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3998095
	speed: 0.3764s/iter; left time: 1186.0985s
Epoch: 26 cost time: 17.974984884262085
Epoch: 26, Steps: 130 | Train Loss: 0.3784677 Vali Loss: 0.1948076 Test Loss: 0.2697769
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3424771
	speed: 0.3888s/iter; left time: 1174.5928s
Epoch: 27 cost time: 19.102755069732666
Epoch: 27, Steps: 130 | Train Loss: 0.3782352 Vali Loss: 0.1944945 Test Loss: 0.2696964
Validation loss decreased (0.194687 --> 0.194494).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3841895
	speed: 0.4188s/iter; left time: 1210.7009s
Epoch: 28 cost time: 20.348211526870728
Epoch: 28, Steps: 130 | Train Loss: 0.3789723 Vali Loss: 0.1949339 Test Loss: 0.2696480
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3586312
	speed: 0.4222s/iter; left time: 1165.5697s
Epoch: 29 cost time: 20.013672590255737
Epoch: 29, Steps: 130 | Train Loss: 0.3778315 Vali Loss: 0.1945225 Test Loss: 0.2696408
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3724054
	speed: 0.4204s/iter; left time: 1106.0591s
Epoch: 30 cost time: 20.050297737121582
Epoch: 30, Steps: 130 | Train Loss: 0.3780714 Vali Loss: 0.1943167 Test Loss: 0.2695744
Validation loss decreased (0.194494 --> 0.194317).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.3510774
	speed: 0.4062s/iter; left time: 1016.0222s
Epoch: 31 cost time: 19.084007263183594
Epoch: 31, Steps: 130 | Train Loss: 0.3780005 Vali Loss: 0.1944865 Test Loss: 0.2695681
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3915766
	speed: 0.3900s/iter; left time: 924.5973s
Epoch: 32 cost time: 18.89355707168579
Epoch: 32, Steps: 130 | Train Loss: 0.3780728 Vali Loss: 0.1941846 Test Loss: 0.2694933
Validation loss decreased (0.194317 --> 0.194185).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2938046
	speed: 0.3884s/iter; left time: 870.5000s
Epoch: 33 cost time: 18.431469917297363
Epoch: 33, Steps: 130 | Train Loss: 0.3775483 Vali Loss: 0.1947904 Test Loss: 0.2694659
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4316617
	speed: 0.3878s/iter; left time: 818.5742s
Epoch: 34 cost time: 18.44517183303833
Epoch: 34, Steps: 130 | Train Loss: 0.3776119 Vali Loss: 0.1945572 Test Loss: 0.2694979
EarlyStopping counter: 2 out of 3
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3009515
	speed: 0.3593s/iter; left time: 711.7628s
Epoch: 35 cost time: 17.48905873298645
Epoch: 35, Steps: 130 | Train Loss: 0.3776777 Vali Loss: 0.1944788 Test Loss: 0.2694298
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_336_FITS_ETTm2_ftM_sl720_ll48_pl336_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.27017322182655334, mae:0.3274313807487488, rse:0.4198380708694458, corr:[0.54460394 0.552736   0.5556736  0.5544532  0.552219   0.55077183
 0.55054086 0.55127496 0.5524252  0.55332565 0.55352026 0.5530316
 0.5522364  0.5515095  0.5511143  0.55104256 0.551169   0.5512766
 0.5511227  0.5505783  0.54972863 0.54875803 0.54788625 0.5472683
 0.54690975 0.54673815 0.5466248  0.54642373 0.54603726 0.54546
 0.54475266 0.54405946 0.54344076 0.542891   0.5424003  0.5419712
 0.5415355  0.54105    0.5404734  0.5398102  0.5391057  0.538397
 0.5377327  0.53713346 0.53660786 0.53612506 0.53565335 0.5351436
 0.53452027 0.5337558  0.5328872  0.5320107  0.53117615 0.5304507
 0.529881   0.5295064  0.52926266 0.52906674 0.5288523  0.5285797
 0.5282461  0.5279068  0.5276004  0.52734184 0.527139   0.5269911
 0.52684206 0.5266651  0.5264312  0.52611685 0.5257088  0.5252411
 0.52475256 0.5242905  0.523859   0.5234667  0.5230743  0.5226379
 0.5221128  0.521511   0.52080196 0.5200418  0.51928544 0.5185965
 0.51803166 0.51759404 0.51722795 0.51689065 0.51653016 0.5161039
 0.5155909  0.51496726 0.51418394 0.5132364  0.51213074 0.5108664
 0.50950104 0.508139   0.5067955  0.50549036 0.50425965 0.5031291
 0.50211436 0.501169   0.5002779  0.4993709  0.49844605 0.49750724
 0.49654472 0.49555606 0.49457905 0.4936593  0.49288172 0.49221736
 0.49158853 0.4909473  0.49026403 0.4894771  0.48860607 0.48763797
 0.48666668 0.48572665 0.48490256 0.4841782  0.48348203 0.4827477
 0.48195136 0.48106295 0.48008612 0.47907224 0.47810298 0.47723457
 0.47652063 0.4759495  0.47546855 0.47496885 0.47434998 0.4735928
 0.4726938  0.4717409  0.47080666 0.4699833  0.46933398 0.46878627
 0.4682746  0.4676661  0.46699554 0.46625274 0.4654913  0.4647354
 0.4640576  0.46350914 0.46302268 0.46254516 0.46203452 0.46151438
 0.4609728  0.46041155 0.459828   0.4592984  0.45882243 0.4584077
 0.45803186 0.45768732 0.4573452  0.45699054 0.4565606  0.45604804
 0.45552623 0.45510718 0.45477444 0.4545358  0.45435604 0.4541659
 0.45389393 0.45348597 0.45290947 0.45218235 0.45132387 0.45049247
 0.4497478  0.44913667 0.44871727 0.44843853 0.44818047 0.4478232
 0.4473169  0.44664273 0.44578585 0.4447459  0.4435587  0.44227755
 0.44099903 0.43984365 0.43870962 0.43747592 0.4361349  0.43468165
 0.4332088  0.43180305 0.43055058 0.42947093 0.42854267 0.4277018
 0.42689323 0.4260613  0.4251355  0.4241485  0.42323363 0.42252326
 0.42192268 0.42135006 0.42072886 0.41999725 0.41915715 0.418142
 0.41696146 0.41563666 0.4143211  0.41311797 0.4120451  0.41112825
 0.41033363 0.40959787 0.40888202 0.40801626 0.40697426 0.4058503
 0.40467584 0.4036514  0.40281394 0.402221   0.4017814  0.40140235
 0.4009508  0.40042126 0.39979282 0.39914334 0.39857024 0.3980964
 0.39773735 0.3973728  0.39697868 0.3966376  0.39626163 0.3959074
 0.3956313  0.39548132 0.3954053  0.39534113 0.39534384 0.39535838
 0.3953189  0.39523232 0.39499107 0.39462152 0.39414424 0.3936623
 0.39326537 0.39297554 0.3927831  0.39265594 0.39251703 0.3923624
 0.39214844 0.39182514 0.39147437 0.39115378 0.39086524 0.3905976
 0.39034534 0.39014652 0.38992542 0.38968998 0.3893982  0.38905665
 0.3887972  0.38858145 0.38841957 0.3883789  0.38839683 0.3884103
 0.38827336 0.3879013  0.3872537  0.386347   0.3852738  0.38407004
 0.38292748 0.38211495 0.38157755 0.38111746 0.38057467 0.37979403
 0.37888923 0.3779565  0.37712592 0.37654075 0.3763656  0.3764029
 0.3765774  0.37661898 0.37641758 0.37579077 0.3748718  0.37392142
 0.37328273 0.37300375 0.3731179  0.37348378 0.37381446 0.3740488
 0.3739101  0.37348056 0.37287876 0.37230608 0.37205645 0.37231505
 0.37290153 0.373586   0.37406206 0.37405053 0.37340575 0.37243137
 0.3716303  0.37160745 0.37268087 0.37440848 0.3761581  0.37707904
 0.37683296 0.37511513 0.37246677 0.37080562 0.3721667  0.37587342]
