Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_336', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_336_FITS_ETTm2_ftM_sl720_ll48_pl336_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=90, out_features=132, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  10644480.0
params:  12012.0
Trainable parameters:  12012
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3027245
	speed: 0.1519s/iter; left time: 1966.6433s
	iters: 200, epoch: 1 | loss: 0.2587860
	speed: 0.1515s/iter; left time: 1947.4795s
Epoch: 1 cost time: 39.73093914985657
Epoch: 1, Steps: 261 | Train Loss: 0.3355946 Vali Loss: 0.2394540 Test Loss: 0.3192344
Validation loss decreased (inf --> 0.239454).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2036275
	speed: 0.6709s/iter; left time: 8514.2242s
	iters: 200, epoch: 2 | loss: 0.2141445
	speed: 0.1577s/iter; left time: 1985.7474s
Epoch: 2 cost time: 41.96456956863403
Epoch: 2, Steps: 261 | Train Loss: 0.2142778 Vali Loss: 0.2206656 Test Loss: 0.2958413
Validation loss decreased (0.239454 --> 0.220666).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1388717
	speed: 0.6847s/iter; left time: 8509.6590s
	iters: 200, epoch: 3 | loss: 0.2060600
	speed: 0.1446s/iter; left time: 1782.2702s
Epoch: 3 cost time: 39.0339241027832
Epoch: 3, Steps: 261 | Train Loss: 0.1752556 Vali Loss: 0.2119313 Test Loss: 0.2861855
Validation loss decreased (0.220666 --> 0.211931).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1515087
	speed: 0.6957s/iter; left time: 8465.7737s
	iters: 200, epoch: 4 | loss: 0.1668565
	speed: 0.1712s/iter; left time: 2066.3258s
Epoch: 4 cost time: 45.071682929992676
Epoch: 4, Steps: 261 | Train Loss: 0.1561127 Vali Loss: 0.2064936 Test Loss: 0.2804660
Validation loss decreased (0.211931 --> 0.206494).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1929997
	speed: 0.7745s/iter; left time: 9221.7824s
	iters: 200, epoch: 5 | loss: 0.1359006
	speed: 0.1521s/iter; left time: 1795.7243s
Epoch: 5 cost time: 42.01036095619202
Epoch: 5, Steps: 261 | Train Loss: 0.1457442 Vali Loss: 0.2032499 Test Loss: 0.2772944
Validation loss decreased (0.206494 --> 0.203250).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1312794
	speed: 0.6904s/iter; left time: 8040.5250s
	iters: 200, epoch: 6 | loss: 0.1678249
	speed: 0.1468s/iter; left time: 1695.1169s
Epoch: 6 cost time: 38.36739635467529
Epoch: 6, Steps: 261 | Train Loss: 0.1399097 Vali Loss: 0.2012070 Test Loss: 0.2753277
Validation loss decreased (0.203250 --> 0.201207).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1359336
	speed: 0.6350s/iter; left time: 7228.9123s
	iters: 200, epoch: 7 | loss: 0.1502429
	speed: 0.1431s/iter; left time: 1614.7352s
Epoch: 7 cost time: 37.67678785324097
Epoch: 7, Steps: 261 | Train Loss: 0.1366000 Vali Loss: 0.1996490 Test Loss: 0.2739467
Validation loss decreased (0.201207 --> 0.199649).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1470258
	speed: 0.6230s/iter; left time: 6929.7449s
	iters: 200, epoch: 8 | loss: 0.1663271
	speed: 0.1399s/iter; left time: 1542.8010s
Epoch: 8 cost time: 37.542577505111694
Epoch: 8, Steps: 261 | Train Loss: 0.1347398 Vali Loss: 0.1984735 Test Loss: 0.2732936
Validation loss decreased (0.199649 --> 0.198474).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1302974
	speed: 0.7117s/iter; left time: 7731.5656s
	iters: 200, epoch: 9 | loss: 0.1484512
	speed: 0.1595s/iter; left time: 1716.3749s
Epoch: 9 cost time: 43.296998262405396
Epoch: 9, Steps: 261 | Train Loss: 0.1335411 Vali Loss: 0.1981285 Test Loss: 0.2728699
Validation loss decreased (0.198474 --> 0.198129).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1267043
	speed: 0.6796s/iter; left time: 7204.7842s
	iters: 200, epoch: 10 | loss: 0.1023618
	speed: 0.1474s/iter; left time: 1548.1318s
Epoch: 10 cost time: 40.22068738937378
Epoch: 10, Steps: 261 | Train Loss: 0.1330305 Vali Loss: 0.1977906 Test Loss: 0.2727734
Validation loss decreased (0.198129 --> 0.197791).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1531459
	speed: 0.6274s/iter; left time: 6488.3268s
	iters: 200, epoch: 11 | loss: 0.1611017
	speed: 0.1370s/iter; left time: 1402.9500s
Epoch: 11 cost time: 36.506155014038086
Epoch: 11, Steps: 261 | Train Loss: 0.1327716 Vali Loss: 0.1973424 Test Loss: 0.2725097
Validation loss decreased (0.197791 --> 0.197342).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1390283
	speed: 0.6458s/iter; left time: 6509.6179s
	iters: 200, epoch: 12 | loss: 0.1203101
	speed: 0.1391s/iter; left time: 1388.3413s
Epoch: 12 cost time: 36.84287428855896
Epoch: 12, Steps: 261 | Train Loss: 0.1325514 Vali Loss: 0.1970746 Test Loss: 0.2725556
Validation loss decreased (0.197342 --> 0.197075).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.0876381
	speed: 0.6361s/iter; left time: 6245.7347s
	iters: 200, epoch: 13 | loss: 0.1301348
	speed: 0.1507s/iter; left time: 1464.7466s
Epoch: 13 cost time: 39.557175159454346
Epoch: 13, Steps: 261 | Train Loss: 0.1323605 Vali Loss: 0.1971033 Test Loss: 0.2725323
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1526055
	speed: 0.6594s/iter; left time: 6302.3075s
	iters: 200, epoch: 14 | loss: 0.1909422
	speed: 0.1392s/iter; left time: 1316.1968s
Epoch: 14 cost time: 38.00762414932251
Epoch: 14, Steps: 261 | Train Loss: 0.1322818 Vali Loss: 0.1970544 Test Loss: 0.2723973
Validation loss decreased (0.197075 --> 0.197054).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1168938
	speed: 0.6337s/iter; left time: 5891.6519s
	iters: 200, epoch: 15 | loss: 0.1368186
	speed: 0.1360s/iter; left time: 1251.0872s
Epoch: 15 cost time: 36.297083139419556
Epoch: 15, Steps: 261 | Train Loss: 0.1322326 Vali Loss: 0.1969055 Test Loss: 0.2723481
Validation loss decreased (0.197054 --> 0.196905).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1290139
	speed: 0.6119s/iter; left time: 5528.6823s
	iters: 200, epoch: 16 | loss: 0.1094423
	speed: 0.1324s/iter; left time: 1183.0269s
Epoch: 16 cost time: 36.53481936454773
Epoch: 16, Steps: 261 | Train Loss: 0.1320899 Vali Loss: 0.1968172 Test Loss: 0.2723551
Validation loss decreased (0.196905 --> 0.196817).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1396647
	speed: 0.6411s/iter; left time: 5625.5688s
	iters: 200, epoch: 17 | loss: 0.0924669
	speed: 0.1362s/iter; left time: 1181.4146s
Epoch: 17 cost time: 36.1395103931427
Epoch: 17, Steps: 261 | Train Loss: 0.1320532 Vali Loss: 0.1969951 Test Loss: 0.2722097
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1100647
	speed: 0.5847s/iter; left time: 4977.9686s
	iters: 200, epoch: 18 | loss: 0.0996110
	speed: 0.1284s/iter; left time: 1080.0864s
Epoch: 18 cost time: 34.54301452636719
Epoch: 18, Steps: 261 | Train Loss: 0.1321157 Vali Loss: 0.1968718 Test Loss: 0.2723079
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1746641
	speed: 0.5863s/iter; left time: 4838.7865s
	iters: 200, epoch: 19 | loss: 0.1634078
	speed: 0.1320s/iter; left time: 1076.2664s
Epoch: 19 cost time: 35.306134939193726
Epoch: 19, Steps: 261 | Train Loss: 0.1320774 Vali Loss: 0.1967607 Test Loss: 0.2723593
Validation loss decreased (0.196817 --> 0.196761).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1458954
	speed: 0.6012s/iter; left time: 4804.5782s
	iters: 200, epoch: 20 | loss: 0.1222140
	speed: 0.1364s/iter; left time: 1076.2359s
Epoch: 20 cost time: 37.72452187538147
Epoch: 20, Steps: 261 | Train Loss: 0.1320137 Vali Loss: 0.1966601 Test Loss: 0.2720916
Validation loss decreased (0.196761 --> 0.196660).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1026185
	speed: 0.6385s/iter; left time: 4936.5468s
	iters: 200, epoch: 21 | loss: 0.1772221
	speed: 0.1315s/iter; left time: 1003.6229s
Epoch: 21 cost time: 36.87977480888367
Epoch: 21, Steps: 261 | Train Loss: 0.1319631 Vali Loss: 0.1968450 Test Loss: 0.2721940
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1474552
	speed: 0.6408s/iter; left time: 4786.4958s
	iters: 200, epoch: 22 | loss: 0.1244217
	speed: 0.1231s/iter; left time: 907.5110s
Epoch: 22 cost time: 34.18282866477966
Epoch: 22, Steps: 261 | Train Loss: 0.1319772 Vali Loss: 0.1969212 Test Loss: 0.2722217
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1346820
	speed: 0.5416s/iter; left time: 3904.6433s
	iters: 200, epoch: 23 | loss: 0.1519489
	speed: 0.1107s/iter; left time: 787.1503s
Epoch: 23 cost time: 30.160967588424683
Epoch: 23, Steps: 261 | Train Loss: 0.1320460 Vali Loss: 0.1966632 Test Loss: 0.2721478
EarlyStopping counter: 3 out of 3
Early stopping
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=90, out_features=132, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  10644480.0
params:  12012.0
Trainable parameters:  12012
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4627255
	speed: 0.1305s/iter; left time: 1690.3305s
	iters: 200, epoch: 1 | loss: 0.3919656
	speed: 0.1277s/iter; left time: 1641.0100s
Epoch: 1 cost time: 32.807891607284546
Epoch: 1, Steps: 261 | Train Loss: 0.3807115 Vali Loss: 0.1943772 Test Loss: 0.2696404
Validation loss decreased (inf --> 0.194377).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3528770
	speed: 0.4907s/iter; left time: 6227.5514s
	iters: 200, epoch: 2 | loss: 0.3580768
	speed: 0.1039s/iter; left time: 1307.5829s
Epoch: 2 cost time: 29.487289428710938
Epoch: 2, Steps: 261 | Train Loss: 0.3781449 Vali Loss: 0.1941994 Test Loss: 0.2694007
Validation loss decreased (0.194377 --> 0.194199).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4740430
	speed: 0.5131s/iter; left time: 6377.6886s
	iters: 200, epoch: 3 | loss: 0.4648453
	speed: 0.1352s/iter; left time: 1667.3623s
Epoch: 3 cost time: 32.35879850387573
Epoch: 3, Steps: 261 | Train Loss: 0.3769305 Vali Loss: 0.1936900 Test Loss: 0.2683592
Validation loss decreased (0.194199 --> 0.193690).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3797995
	speed: 0.5424s/iter; left time: 6599.4383s
	iters: 200, epoch: 4 | loss: 0.3393714
	speed: 0.1174s/iter; left time: 1416.5003s
Epoch: 4 cost time: 31.92340397834778
Epoch: 4, Steps: 261 | Train Loss: 0.3761495 Vali Loss: 0.1934952 Test Loss: 0.2681825
Validation loss decreased (0.193690 --> 0.193495).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3006800
	speed: 0.5585s/iter; left time: 6650.5254s
	iters: 200, epoch: 5 | loss: 0.3784645
	speed: 0.1254s/iter; left time: 1480.2654s
Epoch: 5 cost time: 33.63936686515808
Epoch: 5, Steps: 261 | Train Loss: 0.3763215 Vali Loss: 0.1934848 Test Loss: 0.2680779
Validation loss decreased (0.193495 --> 0.193485).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3255900
	speed: 0.5742s/iter; left time: 6687.5177s
	iters: 200, epoch: 6 | loss: 0.3833654
	speed: 0.1315s/iter; left time: 1518.2865s
Epoch: 6 cost time: 34.59090614318848
Epoch: 6, Steps: 261 | Train Loss: 0.3762133 Vali Loss: 0.1931535 Test Loss: 0.2677891
Validation loss decreased (0.193485 --> 0.193153).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3572426
	speed: 0.5528s/iter; left time: 6293.0613s
	iters: 200, epoch: 7 | loss: 0.3406231
	speed: 0.1170s/iter; left time: 1320.0694s
Epoch: 7 cost time: 32.70084357261658
Epoch: 7, Steps: 261 | Train Loss: 0.3753432 Vali Loss: 0.1931947 Test Loss: 0.2678851
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2476333
	speed: 0.6093s/iter; left time: 6778.1845s
	iters: 200, epoch: 8 | loss: 0.2710073
	speed: 0.1393s/iter; left time: 1535.4434s
Epoch: 8 cost time: 37.83525252342224
Epoch: 8, Steps: 261 | Train Loss: 0.3757476 Vali Loss: 0.1933515 Test Loss: 0.2683197
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4506298
	speed: 0.6623s/iter; left time: 7194.8054s
	iters: 200, epoch: 9 | loss: 0.3477335
	speed: 0.1364s/iter; left time: 1467.5859s
Epoch: 9 cost time: 38.869956731796265
Epoch: 9, Steps: 261 | Train Loss: 0.3753705 Vali Loss: 0.1934020 Test Loss: 0.2679930
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_336_FITS_ETTm2_ftM_sl720_ll48_pl336_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.2688157558441162, mae:0.32634979486465454, rse:0.4187820255756378, corr:[0.5545756  0.55905366 0.55950785 0.5574306  0.55550873 0.5548826
 0.5553789  0.556192   0.55647314 0.55588555 0.5547583  0.55370116
 0.55313176 0.5530847  0.5533266  0.5534315  0.553114   0.55238247
 0.5514572  0.5505995  0.5499923  0.5496287  0.5493585  0.54899114
 0.5484056  0.5476546  0.54687655 0.54618067 0.54561746 0.5451986
 0.5448542  0.54450953 0.5440476  0.54341584 0.5426803  0.54196274
 0.54131883 0.5407743  0.54027814 0.53976136 0.5391895  0.5385648
 0.53793204 0.53732276 0.5367663  0.5362552  0.53574574 0.535158
 0.5344005  0.5334948  0.5325378  0.5316538  0.5308765  0.5302334
 0.52970517 0.52926075 0.5288171  0.52834857 0.5279073  0.52757263
 0.52740145 0.5274128  0.52750623 0.52753067 0.5273947  0.52710336
 0.52668095 0.52622396 0.5258072  0.525453   0.5251255  0.52478826
 0.52441406 0.52401906 0.52362096 0.523276   0.5229815  0.5226772
 0.5222758  0.52175134 0.5210558  0.52027166 0.5194951  0.5188299
 0.51833534 0.51796925 0.51761323 0.5171966  0.51669484 0.5161307
 0.5155624  0.5150115  0.51443195 0.5137451  0.5128393  0.5116199
 0.510136   0.508567   0.50703734 0.5056791  0.5045685  0.5036737
 0.50286895 0.5019812  0.500944   0.49976036 0.4985911  0.4976015
 0.49683842 0.49621955 0.4956055  0.49484676 0.49391973 0.49283132
 0.49167395 0.4906388  0.48984504 0.489216   0.48861545 0.4878442
 0.48688146 0.48576275 0.48470488 0.4838798  0.4833377  0.4829771
 0.48260447 0.48198077 0.4809624  0.4795946  0.47809783 0.47676638
 0.4758703  0.4754629  0.4753613  0.47524863 0.47485775 0.4741412
 0.47319388 0.47226784 0.47153774 0.47106743 0.4707454  0.47030178
 0.4695657  0.46846208 0.4672363  0.46612948 0.46536353 0.46494484
 0.46476611 0.46463    0.46428442 0.4636559  0.46285686 0.4621249
 0.4615897  0.46125084 0.46096775 0.46062326 0.4600723  0.45932898
 0.4585136  0.45785785 0.45750406 0.45745596 0.4575272  0.45754558
 0.4574578  0.45734337 0.45724693 0.45726416 0.4573908  0.45748982
 0.45736167 0.45684347 0.45587882 0.4545933  0.45322666 0.4521703
 0.45155555 0.4513068  0.45126212 0.4511768  0.4508742  0.45034888
 0.4497812  0.44936866 0.4491404  0.44893885 0.44852015 0.44766998
 0.4463474  0.4447456  0.4429873  0.44127157 0.43982768 0.43865544
 0.43765497 0.4366436  0.4355277  0.43431804 0.43315664 0.43218607
 0.43144765 0.43079737 0.429979   0.4288431  0.42747417 0.42614433
 0.42501995 0.42430174 0.4240273  0.4240012  0.42391908 0.42338276
 0.4221795  0.4203174  0.41817486 0.41618592 0.4146283  0.41359487
 0.4129199  0.41234365 0.4116871  0.41075456 0.40963492 0.408572
 0.40764812 0.4069763  0.4064202  0.40587038 0.40518516 0.40436772
 0.40348354 0.4027254  0.40215662 0.40178412 0.4015264  0.40124083
 0.40088665 0.40044096 0.40008578 0.40004626 0.40019384 0.4004013
 0.4005118  0.400422   0.40007046 0.39953128 0.39913452 0.39903307
 0.39918548 0.3994715  0.39956564 0.39936236 0.39886993 0.39831448
 0.39792976 0.3978127  0.39786124 0.397851   0.39754254 0.39692008
 0.39612037 0.39538702 0.39509174 0.39535046 0.39592022 0.3963819
 0.39640808 0.39593634 0.3950366  0.39409918 0.39348996 0.39340687
 0.39384    0.3943552  0.3945935  0.39448413 0.394079   0.39363798
 0.3933527  0.39329502 0.39330044 0.3930494  0.39228785 0.3908649
 0.38905936 0.38749138 0.38647833 0.38602734 0.38588133 0.38559803
 0.38501102 0.3840699  0.3829489  0.3819887  0.38155368 0.38147774
 0.38160396 0.38153228 0.3811339  0.3803343  0.37947083 0.37894583
 0.3789687  0.37915903 0.37908778 0.37840074 0.37703648 0.3755267
 0.37435478 0.37415722 0.37495708 0.37617847 0.37711325 0.37730688
 0.37662166 0.37550563 0.3746659  0.37462384 0.37528372 0.37615094
 0.3765206  0.376072   0.37505013 0.3740161  0.37387717 0.3747647
 0.3761578  0.37671813 0.37529352 0.37156928 0.3667788  0.36344782]
