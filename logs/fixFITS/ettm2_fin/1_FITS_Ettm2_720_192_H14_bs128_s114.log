Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=122, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_192_FITS_ETTm2_ftM_sl720_ll48_pl192_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=122, out_features=154, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  33668096.0
params:  18942.0
Trainable parameters:  18942
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3531004
	speed: 0.1008s/iter; left time: 649.9420s
Epoch: 1 cost time: 13.982081651687622
Epoch: 1, Steps: 131 | Train Loss: 0.4175896 Vali Loss: 0.1825550 Test Loss: 0.2478783
Validation loss decreased (inf --> 0.182555).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3397269
	speed: 0.4308s/iter; left time: 2722.4398s
Epoch: 2 cost time: 20.52731966972351
Epoch: 2, Steps: 131 | Train Loss: 0.3388445 Vali Loss: 0.1685543 Test Loss: 0.2333571
Validation loss decreased (0.182555 --> 0.168554).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3512676
	speed: 0.4453s/iter; left time: 2755.9238s
Epoch: 3 cost time: 21.61874294281006
Epoch: 3, Steps: 131 | Train Loss: 0.3215402 Vali Loss: 0.1630764 Test Loss: 0.2277250
Validation loss decreased (0.168554 --> 0.163076).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3219755
	speed: 0.4473s/iter; left time: 2709.8055s
Epoch: 4 cost time: 20.453959226608276
Epoch: 4, Steps: 131 | Train Loss: 0.3126184 Vali Loss: 0.1600316 Test Loss: 0.2247597
Validation loss decreased (0.163076 --> 0.160032).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3165019
	speed: 0.4347s/iter; left time: 2576.7036s
Epoch: 5 cost time: 20.965608835220337
Epoch: 5, Steps: 131 | Train Loss: 0.3073125 Vali Loss: 0.1578548 Test Loss: 0.2226366
Validation loss decreased (0.160032 --> 0.157855).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3385350
	speed: 0.4425s/iter; left time: 2564.8060s
Epoch: 6 cost time: 20.17551350593567
Epoch: 6, Steps: 131 | Train Loss: 0.3034352 Vali Loss: 0.1565602 Test Loss: 0.2213605
Validation loss decreased (0.157855 --> 0.156560).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2732278
	speed: 0.3839s/iter; left time: 2174.7683s
Epoch: 7 cost time: 17.127793312072754
Epoch: 7, Steps: 131 | Train Loss: 0.3011663 Vali Loss: 0.1558838 Test Loss: 0.2203217
Validation loss decreased (0.156560 --> 0.155884).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3731296
	speed: 0.3206s/iter; left time: 1774.3238s
Epoch: 8 cost time: 13.149779796600342
Epoch: 8, Steps: 131 | Train Loss: 0.2994283 Vali Loss: 0.1552113 Test Loss: 0.2197113
Validation loss decreased (0.155884 --> 0.155211).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3316366
	speed: 0.2668s/iter; left time: 1441.5430s
Epoch: 9 cost time: 13.045039415359497
Epoch: 9, Steps: 131 | Train Loss: 0.2974265 Vali Loss: 0.1545559 Test Loss: 0.2191312
Validation loss decreased (0.155211 --> 0.154556).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2531556
	speed: 0.4127s/iter; left time: 2175.7908s
Epoch: 10 cost time: 21.49032425880432
Epoch: 10, Steps: 131 | Train Loss: 0.2966541 Vali Loss: 0.1542254 Test Loss: 0.2185958
Validation loss decreased (0.154556 --> 0.154225).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3114697
	speed: 0.4507s/iter; left time: 2317.0724s
Epoch: 11 cost time: 20.55989122390747
Epoch: 11, Steps: 131 | Train Loss: 0.2955691 Vali Loss: 0.1538740 Test Loss: 0.2181548
Validation loss decreased (0.154225 --> 0.153874).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2126614
	speed: 0.4499s/iter; left time: 2253.8694s
Epoch: 12 cost time: 22.074999570846558
Epoch: 12, Steps: 131 | Train Loss: 0.2947399 Vali Loss: 0.1535976 Test Loss: 0.2177676
Validation loss decreased (0.153874 --> 0.153598).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3478750
	speed: 0.4463s/iter; left time: 2177.5889s
Epoch: 13 cost time: 20.483559131622314
Epoch: 13, Steps: 131 | Train Loss: 0.2943219 Vali Loss: 0.1533860 Test Loss: 0.2176221
Validation loss decreased (0.153598 --> 0.153386).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2603960
	speed: 0.4376s/iter; left time: 2077.6791s
Epoch: 14 cost time: 21.13993215560913
Epoch: 14, Steps: 131 | Train Loss: 0.2931039 Vali Loss: 0.1532740 Test Loss: 0.2175314
Validation loss decreased (0.153386 --> 0.153274).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2439214
	speed: 0.4352s/iter; left time: 2009.1943s
Epoch: 15 cost time: 20.660696506500244
Epoch: 15, Steps: 131 | Train Loss: 0.2933098 Vali Loss: 0.1529522 Test Loss: 0.2171371
Validation loss decreased (0.153274 --> 0.152952).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2658600
	speed: 0.3610s/iter; left time: 1619.6576s
Epoch: 16 cost time: 16.217159509658813
Epoch: 16, Steps: 131 | Train Loss: 0.2928597 Vali Loss: 0.1527325 Test Loss: 0.2169450
Validation loss decreased (0.152952 --> 0.152732).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3041047
	speed: 0.3442s/iter; left time: 1498.7811s
Epoch: 17 cost time: 17.513444900512695
Epoch: 17, Steps: 131 | Train Loss: 0.2922763 Vali Loss: 0.1528936 Test Loss: 0.2169324
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2187082
	speed: 0.3476s/iter; left time: 1468.0937s
Epoch: 18 cost time: 20.02523708343506
Epoch: 18, Steps: 131 | Train Loss: 0.2915634 Vali Loss: 0.1525539 Test Loss: 0.2167166
Validation loss decreased (0.152732 --> 0.152554).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2605271
	speed: 0.4455s/iter; left time: 1823.5111s
Epoch: 19 cost time: 21.269954204559326
Epoch: 19, Steps: 131 | Train Loss: 0.2915315 Vali Loss: 0.1526608 Test Loss: 0.2166936
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2716564
	speed: 0.4341s/iter; left time: 1719.8720s
Epoch: 20 cost time: 21.359412670135498
Epoch: 20, Steps: 131 | Train Loss: 0.2915334 Vali Loss: 0.1524865 Test Loss: 0.2165817
Validation loss decreased (0.152554 --> 0.152487).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2706511
	speed: 0.4468s/iter; left time: 1711.8071s
Epoch: 21 cost time: 20.519036293029785
Epoch: 21, Steps: 131 | Train Loss: 0.2911662 Vali Loss: 0.1524008 Test Loss: 0.2163936
Validation loss decreased (0.152487 --> 0.152401).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2790962
	speed: 0.4433s/iter; left time: 1640.0713s
Epoch: 22 cost time: 21.14932918548584
Epoch: 22, Steps: 131 | Train Loss: 0.2914187 Vali Loss: 0.1524246 Test Loss: 0.2164350
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3417859
	speed: 0.4352s/iter; left time: 1553.3067s
Epoch: 23 cost time: 20.463804721832275
Epoch: 23, Steps: 131 | Train Loss: 0.2908074 Vali Loss: 0.1521980 Test Loss: 0.2162877
Validation loss decreased (0.152401 --> 0.152198).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2910647
	speed: 0.4444s/iter; left time: 1527.7945s
Epoch: 24 cost time: 21.232450485229492
Epoch: 24, Steps: 131 | Train Loss: 0.2906099 Vali Loss: 0.1522404 Test Loss: 0.2162357
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2786737
	speed: 0.4450s/iter; left time: 1471.7339s
Epoch: 25 cost time: 21.045278310775757
Epoch: 25, Steps: 131 | Train Loss: 0.2905445 Vali Loss: 0.1521940 Test Loss: 0.2161758
Validation loss decreased (0.152198 --> 0.152194).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3166777
	speed: 0.4432s/iter; left time: 1407.5076s
Epoch: 26 cost time: 21.220789909362793
Epoch: 26, Steps: 131 | Train Loss: 0.2903235 Vali Loss: 0.1519825 Test Loss: 0.2160997
Validation loss decreased (0.152194 --> 0.151983).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3402035
	speed: 0.4365s/iter; left time: 1329.1691s
Epoch: 27 cost time: 20.90369439125061
Epoch: 27, Steps: 131 | Train Loss: 0.2903977 Vali Loss: 0.1520295 Test Loss: 0.2161023
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3997845
	speed: 0.4467s/iter; left time: 1301.6658s
Epoch: 28 cost time: 21.1572003364563
Epoch: 28, Steps: 131 | Train Loss: 0.2897927 Vali Loss: 0.1520295 Test Loss: 0.2160072
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3017412
	speed: 0.4061s/iter; left time: 1130.2337s
Epoch: 29 cost time: 18.025201082229614
Epoch: 29, Steps: 131 | Train Loss: 0.2902295 Vali Loss: 0.1520300 Test Loss: 0.2159804
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_192_FITS_ETTm2_ftM_sl720_ll48_pl192_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.21783608198165894, mae:0.292146772146225, rse:0.37779831886291504, corr:[0.5568049  0.56401557 0.5596911  0.5577662  0.55953974 0.5616988
 0.56142086 0.5598102  0.5589883  0.5595549  0.5606269  0.5609069
 0.56024724 0.55949205 0.55935323 0.5596936  0.55983055 0.55924684
 0.5581918  0.5572583  0.55680823 0.5566847  0.5564747  0.55594903
 0.5552609  0.554718   0.55443394 0.55420816 0.55375063 0.55301416
 0.55219156 0.5515694  0.551171   0.55081075 0.5503164  0.5496438
 0.54884136 0.5480612  0.54741096 0.54687685 0.54636645 0.54578704
 0.54517454 0.5446062  0.5441019  0.5435738  0.54293734 0.5421527
 0.54124856 0.54041874 0.5397956  0.5393075  0.53871673 0.5379085
 0.5370035  0.53629154 0.5358518  0.5355624  0.53526783 0.5348991
 0.5345329  0.53432685 0.53423154 0.53409046 0.5337779  0.533366
 0.53294617 0.5326615  0.53247476 0.53222466 0.53183085 0.53139764
 0.5310692  0.5308674  0.5305988  0.53014463 0.5295334  0.52892554
 0.528468   0.52813756 0.5276913  0.5270382  0.52626854 0.5255898
 0.5251091  0.5247447  0.5242098  0.5234789  0.5227377  0.5222446
 0.5220722  0.5219749  0.52156174 0.5207427  0.5196171  0.51837116
 0.5171419  0.5159101  0.5145061  0.5129835  0.5116154  0.5105982
 0.50988716 0.50915647 0.508124   0.50683635 0.5055915  0.50463194
 0.50379765 0.5029011  0.5019324  0.5010634  0.50053865 0.50014967
 0.4994589  0.4982645  0.49678463 0.49555215 0.49505237 0.49499026
 0.49480525 0.4939396  0.4925423  0.49117    0.4903869  0.4901754
 0.4899782  0.489217   0.48779204 0.48617378 0.48501316 0.48441017
 0.48395607 0.4832097  0.4822436  0.48154816 0.4814291  0.4817385
 0.48182014 0.48127124 0.48013088 0.4789455  0.4782038  0.47776726
 0.4772294  0.4762268  0.47514376 0.47433996 0.47392187 0.47342724
 0.47259673 0.4716025  0.47078723 0.4703454  0.47007892 0.4696128
 0.4686996  0.46769083 0.4670966  0.46726307 0.4674871  0.4671664
 0.46610644 0.46498218 0.46457678 0.4648675  0.46493578 0.4642009
 0.46305454 0.46272033 0.46361083 0.464795   0.4649364  0.46366066
 0.46192992 0.46135467 0.46230215 0.46319002 0.46249992 0.46067593
 0.45916155 0.4592373  0.46010426 0.4596947  0.45745692 0.45538157
 0.4564249  0.4595453  0.4603723  0.457402   0.45428666 0.45795783]
