Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_192_FITS_ETTm2_ftM_sl720_ll48_pl192_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=90, out_features=114, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  18385920.0
params:  10374.0
Trainable parameters:  10374
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3329704
	speed: 0.2195s/iter; left time: 1416.1757s
Epoch: 1 cost time: 28.668731927871704
Epoch: 1, Steps: 131 | Train Loss: 0.3475123 Vali Loss: 0.2260916 Test Loss: 0.3011651
Validation loss decreased (inf --> 0.226092).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2354146
	speed: 0.6073s/iter; left time: 3837.8260s
Epoch: 2 cost time: 28.585018634796143
Epoch: 2, Steps: 131 | Train Loss: 0.2367799 Vali Loss: 0.2007243 Test Loss: 0.2671214
Validation loss decreased (0.226092 --> 0.200724).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1643352
	speed: 0.6098s/iter; left time: 3774.1287s
Epoch: 3 cost time: 29.24569821357727
Epoch: 3, Steps: 131 | Train Loss: 0.1892817 Vali Loss: 0.1910012 Test Loss: 0.2553948
Validation loss decreased (0.200724 --> 0.191001).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1379581
	speed: 0.6055s/iter; left time: 3667.9873s
Epoch: 4 cost time: 29.126755952835083
Epoch: 4, Steps: 131 | Train Loss: 0.1615682 Vali Loss: 0.1854848 Test Loss: 0.2491629
Validation loss decreased (0.191001 --> 0.185485).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1434299
	speed: 0.6355s/iter; left time: 3766.5462s
Epoch: 5 cost time: 30.663719177246094
Epoch: 5, Steps: 131 | Train Loss: 0.1429543 Vali Loss: 0.1813411 Test Loss: 0.2449485
Validation loss decreased (0.185485 --> 0.181341).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1348385
	speed: 0.6620s/iter; left time: 3837.1543s
Epoch: 6 cost time: 31.908156394958496
Epoch: 6, Steps: 131 | Train Loss: 0.1291215 Vali Loss: 0.1781098 Test Loss: 0.2416241
Validation loss decreased (0.181341 --> 0.178110).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.0997289
	speed: 0.6810s/iter; left time: 3857.6414s
Epoch: 7 cost time: 30.760799169540405
Epoch: 7, Steps: 131 | Train Loss: 0.1190497 Vali Loss: 0.1752833 Test Loss: 0.2387049
Validation loss decreased (0.178110 --> 0.175283).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1106384
	speed: 0.6731s/iter; left time: 3724.9146s
Epoch: 8 cost time: 31.686763763427734
Epoch: 8, Steps: 131 | Train Loss: 0.1110347 Vali Loss: 0.1727923 Test Loss: 0.2361879
Validation loss decreased (0.175283 --> 0.172792).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1046615
	speed: 0.5740s/iter; left time: 3101.3678s
Epoch: 9 cost time: 26.651689052581787
Epoch: 9, Steps: 131 | Train Loss: 0.1046949 Vali Loss: 0.1706329 Test Loss: 0.2340816
Validation loss decreased (0.172792 --> 0.170633).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1086084
	speed: 0.5842s/iter; left time: 3079.8304s
Epoch: 10 cost time: 27.49829936027527
Epoch: 10, Steps: 131 | Train Loss: 0.0996844 Vali Loss: 0.1689285 Test Loss: 0.2323618
Validation loss decreased (0.170633 --> 0.168929).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.0968537
	speed: 0.5740s/iter; left time: 2951.0121s
Epoch: 11 cost time: 27.060229778289795
Epoch: 11, Steps: 131 | Train Loss: 0.0955773 Vali Loss: 0.1672948 Test Loss: 0.2308517
Validation loss decreased (0.168929 --> 0.167295).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.0932387
	speed: 0.5724s/iter; left time: 2867.7910s
Epoch: 12 cost time: 28.056166172027588
Epoch: 12, Steps: 131 | Train Loss: 0.0922200 Vali Loss: 0.1657676 Test Loss: 0.2294306
Validation loss decreased (0.167295 --> 0.165768).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.0786965
	speed: 0.5766s/iter; left time: 2813.0219s
Epoch: 13 cost time: 27.589070081710815
Epoch: 13, Steps: 131 | Train Loss: 0.0895160 Vali Loss: 0.1646294 Test Loss: 0.2283307
Validation loss decreased (0.165768 --> 0.164629).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1131449
	speed: 0.6206s/iter; left time: 2946.4042s
Epoch: 14 cost time: 31.52193570137024
Epoch: 14, Steps: 131 | Train Loss: 0.0873166 Vali Loss: 0.1635366 Test Loss: 0.2273359
Validation loss decreased (0.164629 --> 0.163537).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.0996410
	speed: 0.5358s/iter; left time: 2473.9629s
Epoch: 15 cost time: 17.382001638412476
Epoch: 15, Steps: 131 | Train Loss: 0.0853359 Vali Loss: 0.1625956 Test Loss: 0.2264180
Validation loss decreased (0.163537 --> 0.162596).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.0775505
	speed: 0.4190s/iter; left time: 1879.6515s
Epoch: 16 cost time: 20.620381355285645
Epoch: 16, Steps: 131 | Train Loss: 0.0838624 Vali Loss: 0.1616599 Test Loss: 0.2256007
Validation loss decreased (0.162596 --> 0.161660).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.0721175
	speed: 0.4103s/iter; left time: 1786.9638s
Epoch: 17 cost time: 19.333742141723633
Epoch: 17, Steps: 131 | Train Loss: 0.0824240 Vali Loss: 0.1611190 Test Loss: 0.2250536
Validation loss decreased (0.161660 --> 0.161119).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.0865244
	speed: 0.4131s/iter; left time: 1745.0525s
Epoch: 18 cost time: 20.81487512588501
Epoch: 18, Steps: 131 | Train Loss: 0.0812878 Vali Loss: 0.1603515 Test Loss: 0.2244577
Validation loss decreased (0.161119 --> 0.160352).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.0794993
	speed: 0.4233s/iter; left time: 1732.6035s
Epoch: 19 cost time: 19.343740940093994
Epoch: 19, Steps: 131 | Train Loss: 0.0804569 Vali Loss: 0.1599065 Test Loss: 0.2239911
Validation loss decreased (0.160352 --> 0.159906).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.0979483
	speed: 0.3848s/iter; left time: 1524.4135s
Epoch: 20 cost time: 17.666541814804077
Epoch: 20, Steps: 131 | Train Loss: 0.0796088 Vali Loss: 0.1594177 Test Loss: 0.2236205
Validation loss decreased (0.159906 --> 0.159418).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.0755039
	speed: 0.3646s/iter; left time: 1396.7676s
Epoch: 21 cost time: 17.829246520996094
Epoch: 21, Steps: 131 | Train Loss: 0.0790091 Vali Loss: 0.1590094 Test Loss: 0.2233041
Validation loss decreased (0.159418 --> 0.159009).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.0765567
	speed: 0.3656s/iter; left time: 1352.5595s
Epoch: 22 cost time: 17.647481441497803
Epoch: 22, Steps: 131 | Train Loss: 0.0784178 Vali Loss: 0.1585932 Test Loss: 0.2229283
Validation loss decreased (0.159009 --> 0.158593).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.0749867
	speed: 0.3614s/iter; left time: 1289.9664s
Epoch: 23 cost time: 17.40206241607666
Epoch: 23, Steps: 131 | Train Loss: 0.0779155 Vali Loss: 0.1581403 Test Loss: 0.2226989
Validation loss decreased (0.158593 --> 0.158140).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.0923674
	speed: 0.3635s/iter; left time: 1249.7890s
Epoch: 24 cost time: 17.62428045272827
Epoch: 24, Steps: 131 | Train Loss: 0.0773497 Vali Loss: 0.1580280 Test Loss: 0.2224859
Validation loss decreased (0.158140 --> 0.158028).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.0929249
	speed: 0.3594s/iter; left time: 1188.4427s
Epoch: 25 cost time: 18.62272620201111
Epoch: 25, Steps: 131 | Train Loss: 0.0771409 Vali Loss: 0.1578455 Test Loss: 0.2222043
Validation loss decreased (0.158028 --> 0.157845).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.0753734
	speed: 0.4102s/iter; left time: 1302.7880s
Epoch: 26 cost time: 20.713252782821655
Epoch: 26, Steps: 131 | Train Loss: 0.0768570 Vali Loss: 0.1576086 Test Loss: 0.2220128
Validation loss decreased (0.157845 --> 0.157609).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.0630098
	speed: 0.5340s/iter; left time: 1625.9791s
Epoch: 27 cost time: 28.147446393966675
Epoch: 27, Steps: 131 | Train Loss: 0.0764877 Vali Loss: 0.1573405 Test Loss: 0.2219096
Validation loss decreased (0.157609 --> 0.157340).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.0787515
	speed: 0.7515s/iter; left time: 2189.7587s
Epoch: 28 cost time: 38.47737789154053
Epoch: 28, Steps: 131 | Train Loss: 0.0762994 Vali Loss: 0.1571460 Test Loss: 0.2217181
Validation loss decreased (0.157340 --> 0.157146).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.0778613
	speed: 0.8158s/iter; left time: 2270.2787s
Epoch: 29 cost time: 39.53871440887451
Epoch: 29, Steps: 131 | Train Loss: 0.0761089 Vali Loss: 0.1569263 Test Loss: 0.2215472
Validation loss decreased (0.157146 --> 0.156926).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.0612226
	speed: 0.8174s/iter; left time: 2167.6830s
Epoch: 30 cost time: 38.26476502418518
Epoch: 30, Steps: 131 | Train Loss: 0.0758869 Vali Loss: 0.1569718 Test Loss: 0.2214733
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.0791072
	speed: 0.8532s/iter; left time: 2150.9708s
Epoch: 31 cost time: 40.57604432106018
Epoch: 31, Steps: 131 | Train Loss: 0.0757528 Vali Loss: 0.1569385 Test Loss: 0.2214490
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.0709027
	speed: 0.8280s/iter; left time: 1978.8602s
Epoch: 32 cost time: 36.543739557266235
Epoch: 32, Steps: 131 | Train Loss: 0.0756162 Vali Loss: 0.1567543 Test Loss: 0.2212922
Validation loss decreased (0.156926 --> 0.156754).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.0687805
	speed: 0.7091s/iter; left time: 1601.9332s
Epoch: 33 cost time: 36.41346526145935
Epoch: 33, Steps: 131 | Train Loss: 0.0754493 Vali Loss: 0.1565648 Test Loss: 0.2212365
Validation loss decreased (0.156754 --> 0.156565).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.0812776
	speed: 0.7827s/iter; left time: 1665.5852s
Epoch: 34 cost time: 37.58381772041321
Epoch: 34, Steps: 131 | Train Loss: 0.0753835 Vali Loss: 0.1565269 Test Loss: 0.2211740
Validation loss decreased (0.156565 --> 0.156527).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.0671636
	speed: 0.7674s/iter; left time: 1532.4280s
Epoch: 35 cost time: 35.72232103347778
Epoch: 35, Steps: 131 | Train Loss: 0.0753117 Vali Loss: 0.1563267 Test Loss: 0.2211033
Validation loss decreased (0.156527 --> 0.156327).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.0577784
	speed: 0.7930s/iter; left time: 1479.7569s
Epoch: 36 cost time: 37.0741651058197
Epoch: 36, Steps: 131 | Train Loss: 0.0751782 Vali Loss: 0.1563996 Test Loss: 0.2210548
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.0717610
	speed: 0.7578s/iter; left time: 1314.8518s
Epoch: 37 cost time: 35.073100566864014
Epoch: 37, Steps: 131 | Train Loss: 0.0752062 Vali Loss: 0.1563985 Test Loss: 0.2210370
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.0923720
	speed: 0.6302s/iter; left time: 1010.9194s
Epoch: 38 cost time: 28.83598256111145
Epoch: 38, Steps: 131 | Train Loss: 0.0750625 Vali Loss: 0.1562927 Test Loss: 0.2209631
Validation loss decreased (0.156327 --> 0.156293).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.0680460
	speed: 0.6377s/iter; left time: 939.3046s
Epoch: 39 cost time: 30.30999231338501
Epoch: 39, Steps: 131 | Train Loss: 0.0750886 Vali Loss: 0.1561150 Test Loss: 0.2208995
Validation loss decreased (0.156293 --> 0.156115).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1077466
	speed: 0.6298s/iter; left time: 845.2563s
Epoch: 40 cost time: 28.710076570510864
Epoch: 40, Steps: 131 | Train Loss: 0.0749425 Vali Loss: 0.1561889 Test Loss: 0.2208834
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.0569160
	speed: 0.5886s/iter; left time: 712.8225s
Epoch: 41 cost time: 29.246439456939697
Epoch: 41, Steps: 131 | Train Loss: 0.0748847 Vali Loss: 0.1561266 Test Loss: 0.2208982
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.0589755
	speed: 0.5955s/iter; left time: 643.1202s
Epoch: 42 cost time: 27.205889463424683
Epoch: 42, Steps: 131 | Train Loss: 0.0747555 Vali Loss: 0.1561771 Test Loss: 0.2208625
EarlyStopping counter: 3 out of 3
Early stopping
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=90, out_features=114, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  18385920.0
params:  10374.0
Trainable parameters:  10374
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3494439
	speed: 0.2194s/iter; left time: 1415.1928s
Epoch: 1 cost time: 27.795491456985474
Epoch: 1, Steps: 131 | Train Loss: 0.2964331 Vali Loss: 0.1537470 Test Loss: 0.2178953
Validation loss decreased (inf --> 0.153747).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2540980
	speed: 0.5569s/iter; left time: 3519.4469s
Epoch: 2 cost time: 29.10267925262451
Epoch: 2, Steps: 131 | Train Loss: 0.2941665 Vali Loss: 0.1532545 Test Loss: 0.2171164
Validation loss decreased (0.153747 --> 0.153255).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2387136
	speed: 0.5789s/iter; left time: 3582.8274s
Epoch: 3 cost time: 26.458378791809082
Epoch: 3, Steps: 131 | Train Loss: 0.2927796 Vali Loss: 0.1528978 Test Loss: 0.2170096
Validation loss decreased (0.153255 --> 0.152898).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2220121
	speed: 0.6239s/iter; left time: 3779.4068s
Epoch: 4 cost time: 30.048194646835327
Epoch: 4, Steps: 131 | Train Loss: 0.2919794 Vali Loss: 0.1527374 Test Loss: 0.2167440
Validation loss decreased (0.152898 --> 0.152737).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3236781
	speed: 0.5882s/iter; left time: 3486.0793s
Epoch: 5 cost time: 27.272029638290405
Epoch: 5, Steps: 131 | Train Loss: 0.2913921 Vali Loss: 0.1524876 Test Loss: 0.2163306
Validation loss decreased (0.152737 --> 0.152488).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2364520
	speed: 0.6034s/iter; left time: 3497.1300s
Epoch: 6 cost time: 30.537837028503418
Epoch: 6, Steps: 131 | Train Loss: 0.2909617 Vali Loss: 0.1523532 Test Loss: 0.2161987
Validation loss decreased (0.152488 --> 0.152353).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2867738
	speed: 0.6508s/iter; left time: 3686.5752s
Epoch: 7 cost time: 30.66832733154297
Epoch: 7, Steps: 131 | Train Loss: 0.2904824 Vali Loss: 0.1523308 Test Loss: 0.2159166
Validation loss decreased (0.152353 --> 0.152331).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2491677
	speed: 0.6690s/iter; left time: 3702.0248s
Epoch: 8 cost time: 28.747220993041992
Epoch: 8, Steps: 131 | Train Loss: 0.2898729 Vali Loss: 0.1522616 Test Loss: 0.2158635
Validation loss decreased (0.152331 --> 0.152262).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2901240
	speed: 0.6833s/iter; left time: 3691.8866s
Epoch: 9 cost time: 33.958991050720215
Epoch: 9, Steps: 131 | Train Loss: 0.2900440 Vali Loss: 0.1521273 Test Loss: 0.2158220
Validation loss decreased (0.152262 --> 0.152127).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3234548
	speed: 0.6573s/iter; left time: 3465.1739s
Epoch: 10 cost time: 31.591997385025024
Epoch: 10, Steps: 131 | Train Loss: 0.2884070 Vali Loss: 0.1521730 Test Loss: 0.2156604
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2747391
	speed: 0.6178s/iter; left time: 3175.9495s
Epoch: 11 cost time: 30.339073657989502
Epoch: 11, Steps: 131 | Train Loss: 0.2901035 Vali Loss: 0.1522519 Test Loss: 0.2157852
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3291862
	speed: 0.6500s/iter; left time: 3256.3728s
Epoch: 12 cost time: 29.41622304916382
Epoch: 12, Steps: 131 | Train Loss: 0.2896784 Vali Loss: 0.1522324 Test Loss: 0.2157752
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_192_FITS_ETTm2_ftM_sl720_ll48_pl192_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.21751835942268372, mae:0.2918660640716553, rse:0.37752267718315125, corr:[0.56148463 0.5651428  0.56541413 0.5634988  0.56170315 0.5610504
 0.5613968  0.5620709  0.56233835 0.56190205 0.5610308  0.5602312
 0.55985045 0.5598721  0.56006813 0.5600161  0.5594883  0.5585178
 0.5573863  0.55639005 0.5557336  0.5554     0.5552558  0.5550882
 0.5547229  0.5541347  0.55342287 0.5527132  0.55209744 0.55160743
 0.5511884  0.5508007  0.5503344  0.549714   0.54899025 0.5482852
 0.5476532  0.5471235  0.5466596  0.546196   0.5456757  0.5450634
 0.5443762  0.54364747 0.5429194  0.54220694 0.54152006 0.54086304
 0.5401573  0.5393884  0.53861713 0.5379481  0.5373806  0.5368735
 0.53635836 0.53582597 0.53524023 0.53460866 0.53402245 0.5335898
 0.53337854 0.53340393 0.53351986 0.53355616 0.5333887  0.5330617
 0.5325906  0.5321061  0.53171295 0.53142655 0.53119546 0.53096795
 0.5307089  0.5304301  0.5301343  0.5298467  0.5295364  0.5291395
 0.52861303 0.5279766  0.52721244 0.5264209  0.5257149  0.5251631
 0.52474695 0.5244202  0.52399814 0.52345407 0.5228     0.5221148
 0.5215137  0.5210367  0.520518   0.519844   0.5188925  0.51759887
 0.5160845  0.5146302  0.5133862  0.51238096 0.5115092  0.51057637
 0.5094613  0.5081037  0.5065535  0.5050205  0.50378335 0.5030117
 0.5025112  0.5019971  0.5012291  0.5000819  0.4987337  0.49739105
 0.49630418 0.49566978 0.4954193  0.4952294  0.49485725 0.49407536
 0.49300754 0.49184108 0.4909438  0.49041668 0.4900909  0.4896851
 0.4890106  0.4880014  0.48675147 0.48550907 0.48459184 0.48412105
 0.48401096 0.4839787  0.48376682 0.48322305 0.48231876 0.48134452
 0.4805487  0.48011026 0.47992143 0.47976875 0.47943524 0.47869757
 0.47756863 0.4761718  0.47501287 0.47431305 0.47407776 0.4739582
 0.4737375  0.47334993 0.47275788 0.47200724 0.47124666 0.47065264
 0.47017384 0.46971896 0.46914032 0.46863195 0.46825108 0.46818796
 0.46834582 0.46854967 0.46854973 0.46821126 0.46746174 0.46647787
 0.46564    0.46534517 0.4655085  0.46580908 0.4657964  0.46524376
 0.46426535 0.46321857 0.46254477 0.46240577 0.46238443 0.46215063
 0.46124583 0.45963863 0.45795417 0.45699343 0.45717233 0.4580831
 0.45872742 0.45848945 0.45733678 0.45606253 0.45614183 0.45736605]
