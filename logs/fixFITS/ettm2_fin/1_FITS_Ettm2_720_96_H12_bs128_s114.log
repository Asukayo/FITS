Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_96_FITS_ETTm2_ftM_sl720_ll48_pl96_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=106, out_features=120, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  22794240.0
params:  12840.0
Trainable parameters:  12840
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3244466
	speed: 0.1545s/iter; left time: 996.7417s
Epoch: 1 cost time: 20.616003036499023
Epoch: 1, Steps: 131 | Train Loss: 0.3393525 Vali Loss: 0.1408173 Test Loss: 0.1924005
Validation loss decreased (inf --> 0.140817).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2159438
	speed: 0.4364s/iter; left time: 2758.0080s
Epoch: 2 cost time: 20.834842920303345
Epoch: 2, Steps: 131 | Train Loss: 0.2521400 Vali Loss: 0.1275977 Test Loss: 0.1776424
Validation loss decreased (0.140817 --> 0.127598).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2329534
	speed: 0.4535s/iter; left time: 2807.0104s
Epoch: 3 cost time: 21.90012216567993
Epoch: 3, Steps: 131 | Train Loss: 0.2345679 Vali Loss: 0.1227344 Test Loss: 0.1723935
Validation loss decreased (0.127598 --> 0.122734).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2415640
	speed: 0.4429s/iter; left time: 2683.2962s
Epoch: 4 cost time: 21.40747594833374
Epoch: 4, Steps: 131 | Train Loss: 0.2261729 Vali Loss: 0.1198683 Test Loss: 0.1693113
Validation loss decreased (0.122734 --> 0.119868).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2254923
	speed: 0.4727s/iter; left time: 2801.7955s
Epoch: 5 cost time: 24.617932081222534
Epoch: 5, Steps: 131 | Train Loss: 0.2216524 Vali Loss: 0.1186157 Test Loss: 0.1679057
Validation loss decreased (0.119868 --> 0.118616).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1939861
	speed: 0.5209s/iter; left time: 3019.2718s
Epoch: 6 cost time: 25.261625289916992
Epoch: 6, Steps: 131 | Train Loss: 0.2185162 Vali Loss: 0.1177063 Test Loss: 0.1666247
Validation loss decreased (0.118616 --> 0.117706).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2169813
	speed: 0.5008s/iter; left time: 2836.7766s
Epoch: 7 cost time: 23.62275266647339
Epoch: 7, Steps: 131 | Train Loss: 0.2156902 Vali Loss: 0.1170824 Test Loss: 0.1656049
Validation loss decreased (0.117706 --> 0.117082).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2305242
	speed: 0.4934s/iter; left time: 2730.4518s
Epoch: 8 cost time: 22.36516785621643
Epoch: 8, Steps: 131 | Train Loss: 0.2142545 Vali Loss: 0.1164925 Test Loss: 0.1653645
Validation loss decreased (0.117082 --> 0.116493).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2200659
	speed: 0.4610s/iter; left time: 2490.7923s
Epoch: 9 cost time: 22.092390060424805
Epoch: 9, Steps: 131 | Train Loss: 0.2131543 Vali Loss: 0.1161530 Test Loss: 0.1647373
Validation loss decreased (0.116493 --> 0.116153).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1912588
	speed: 0.4747s/iter; left time: 2502.5448s
Epoch: 10 cost time: 22.193710327148438
Epoch: 10, Steps: 131 | Train Loss: 0.2123012 Vali Loss: 0.1159245 Test Loss: 0.1644865
Validation loss decreased (0.116153 --> 0.115924).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1782487
	speed: 0.4829s/iter; left time: 2482.7547s
Epoch: 11 cost time: 22.607090711593628
Epoch: 11, Steps: 131 | Train Loss: 0.2118049 Vali Loss: 0.1156702 Test Loss: 0.1639701
Validation loss decreased (0.115924 --> 0.115670).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1739955
	speed: 0.4583s/iter; left time: 2296.2546s
Epoch: 12 cost time: 21.420953273773193
Epoch: 12, Steps: 131 | Train Loss: 0.2108434 Vali Loss: 0.1155957 Test Loss: 0.1639797
Validation loss decreased (0.115670 --> 0.115596).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1897224
	speed: 0.5071s/iter; left time: 2474.2324s
Epoch: 13 cost time: 24.841967582702637
Epoch: 13, Steps: 131 | Train Loss: 0.2105439 Vali Loss: 0.1154000 Test Loss: 0.1636031
Validation loss decreased (0.115596 --> 0.115400).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2106096
	speed: 0.5150s/iter; left time: 2445.2450s
Epoch: 14 cost time: 23.50849723815918
Epoch: 14, Steps: 131 | Train Loss: 0.2103679 Vali Loss: 0.1154044 Test Loss: 0.1636949
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2601655
	speed: 0.4844s/iter; left time: 2236.4027s
Epoch: 15 cost time: 23.305254697799683
Epoch: 15, Steps: 131 | Train Loss: 0.2100062 Vali Loss: 0.1152946 Test Loss: 0.1635840
Validation loss decreased (0.115400 --> 0.115295).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1536653
	speed: 0.4768s/iter; left time: 2138.7481s
Epoch: 16 cost time: 22.493485689163208
Epoch: 16, Steps: 131 | Train Loss: 0.2096368 Vali Loss: 0.1152359 Test Loss: 0.1635078
Validation loss decreased (0.115295 --> 0.115236).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1612744
	speed: 0.4553s/iter; left time: 1982.6266s
Epoch: 17 cost time: 22.365822792053223
Epoch: 17, Steps: 131 | Train Loss: 0.2096638 Vali Loss: 0.1152617 Test Loss: 0.1634552
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2494054
	speed: 0.4438s/iter; left time: 1874.6502s
Epoch: 18 cost time: 22.184980869293213
Epoch: 18, Steps: 131 | Train Loss: 0.2091101 Vali Loss: 0.1150866 Test Loss: 0.1632623
Validation loss decreased (0.115236 --> 0.115087).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2098113
	speed: 0.4913s/iter; left time: 2010.7370s
Epoch: 19 cost time: 25.356699466705322
Epoch: 19, Steps: 131 | Train Loss: 0.2091222 Vali Loss: 0.1151760 Test Loss: 0.1632641
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1906765
	speed: 0.4000s/iter; left time: 1584.9109s
Epoch: 20 cost time: 17.895095348358154
Epoch: 20, Steps: 131 | Train Loss: 0.2089346 Vali Loss: 0.1150193 Test Loss: 0.1632009
Validation loss decreased (0.115087 --> 0.115019).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1928023
	speed: 0.4061s/iter; left time: 1555.6802s
Epoch: 21 cost time: 18.616113662719727
Epoch: 21, Steps: 131 | Train Loss: 0.2086328 Vali Loss: 0.1150287 Test Loss: 0.1631850
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1688251
	speed: 0.3323s/iter; left time: 1229.6929s
Epoch: 22 cost time: 16.00905418395996
Epoch: 22, Steps: 131 | Train Loss: 0.2086411 Vali Loss: 0.1149304 Test Loss: 0.1630693
Validation loss decreased (0.115019 --> 0.114930).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2519650
	speed: 0.2952s/iter; left time: 1053.5149s
Epoch: 23 cost time: 9.47448444366455
Epoch: 23, Steps: 131 | Train Loss: 0.2086976 Vali Loss: 0.1149483 Test Loss: 0.1630054
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1917806
	speed: 0.1667s/iter; left time: 573.2241s
Epoch: 24 cost time: 8.928831815719604
Epoch: 24, Steps: 131 | Train Loss: 0.2086124 Vali Loss: 0.1148742 Test Loss: 0.1629550
Validation loss decreased (0.114930 --> 0.114874).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1763092
	speed: 0.2157s/iter; left time: 713.3220s
Epoch: 25 cost time: 10.523730754852295
Epoch: 25, Steps: 131 | Train Loss: 0.2079418 Vali Loss: 0.1147980 Test Loss: 0.1628685
Validation loss decreased (0.114874 --> 0.114798).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2211408
	speed: 0.1841s/iter; left time: 584.6576s
Epoch: 26 cost time: 8.017336368560791
Epoch: 26, Steps: 131 | Train Loss: 0.2084006 Vali Loss: 0.1149069 Test Loss: 0.1629625
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1994698
	speed: 0.2538s/iter; left time: 772.9247s
Epoch: 27 cost time: 17.025083303451538
Epoch: 27, Steps: 131 | Train Loss: 0.2074990 Vali Loss: 0.1148003 Test Loss: 0.1628887
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1875325
	speed: 0.3690s/iter; left time: 1075.1824s
Epoch: 28 cost time: 17.49129605293274
Epoch: 28, Steps: 131 | Train Loss: 0.2080009 Vali Loss: 0.1147107 Test Loss: 0.1627672
Validation loss decreased (0.114798 --> 0.114711).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2245137
	speed: 0.3342s/iter; left time: 930.1639s
Epoch: 29 cost time: 14.536643981933594
Epoch: 29, Steps: 131 | Train Loss: 0.2079917 Vali Loss: 0.1147316 Test Loss: 0.1628362
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2000375
	speed: 0.2642s/iter; left time: 700.6794s
Epoch: 30 cost time: 12.190113067626953
Epoch: 30, Steps: 131 | Train Loss: 0.2076992 Vali Loss: 0.1145546 Test Loss: 0.1627858
Validation loss decreased (0.114711 --> 0.114555).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2110725
	speed: 0.2427s/iter; left time: 611.8264s
Epoch: 31 cost time: 11.098036289215088
Epoch: 31, Steps: 131 | Train Loss: 0.2077114 Vali Loss: 0.1147696 Test Loss: 0.1627837
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1736366
	speed: 0.2417s/iter; left time: 577.7406s
Epoch: 32 cost time: 13.600061655044556
Epoch: 32, Steps: 131 | Train Loss: 0.2080205 Vali Loss: 0.1146579 Test Loss: 0.1627101
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2106244
	speed: 0.3274s/iter; left time: 739.6926s
Epoch: 33 cost time: 17.184176206588745
Epoch: 33, Steps: 131 | Train Loss: 0.2076867 Vali Loss: 0.1150169 Test Loss: 0.1627345
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_96_FITS_ETTm2_ftM_sl720_ll48_pl96_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.16340871155261993, mae:0.2545943856239319, rse:0.3277432918548584, corr:[0.56415707 0.56920403 0.5671193  0.56473523 0.56453305 0.5659135
 0.56706876 0.5667662  0.565548   0.56461275 0.5645475  0.5651385
 0.56567895 0.56551385 0.5647564  0.5638769  0.56331176 0.5630735
 0.56286585 0.5623333  0.5614692  0.56050587 0.55976343 0.55935913
 0.55912805 0.5587985  0.55820495 0.5574219  0.5566467  0.5560593
 0.5556699  0.5554653  0.55517495 0.5545643  0.55374116 0.55295
 0.55230945 0.5518447  0.5513782  0.5507289  0.5498901  0.5489908
 0.5482021  0.5476335  0.54727346 0.54685366 0.5461613  0.5452184
 0.5440932  0.5429891  0.5421696  0.541717   0.5412741  0.5404908
 0.53932804 0.53808063 0.5370794  0.5365979  0.5365382  0.53650105
 0.53615105 0.5355898  0.5350485  0.53477997 0.5348362  0.5349993
 0.53481114 0.53423685 0.5335447  0.53309244 0.5330932  0.5333044
 0.5331983  0.5325254  0.5313763  0.53027004 0.52972794 0.5297997
 0.52986753 0.52939767 0.528085   0.52642125 0.52520293 0.52490443
 0.52502793 0.5246853  0.52329195 0.52129674 0.52001727 0.5204695
 0.521727   0.5218984  0.52009636 0.51758754 0.5187148  0.52339923]
