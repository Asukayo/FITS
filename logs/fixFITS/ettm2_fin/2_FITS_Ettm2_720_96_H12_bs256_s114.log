Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=512, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_96_FITS_ETTm2_ftM_sl720_ll48_pl96_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=106, out_features=120, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  45588480.0
params:  12840.0
Trainable parameters:  12840
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 11.757452249526978
Epoch: 1, Steps: 65 | Train Loss: 0.3594382 Vali Loss: 0.2236757 Test Loss: 0.2926364
Validation loss decreased (inf --> 0.223676).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 11.515433549880981
Epoch: 2, Steps: 65 | Train Loss: 0.2733451 Vali Loss: 0.1962754 Test Loss: 0.2532808
Validation loss decreased (0.223676 --> 0.196275).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 12.65051555633545
Epoch: 3, Steps: 65 | Train Loss: 0.2273415 Vali Loss: 0.1851644 Test Loss: 0.2371419
Validation loss decreased (0.196275 --> 0.185164).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 10.954172372817993
Epoch: 4, Steps: 65 | Train Loss: 0.1986918 Vali Loss: 0.1796371 Test Loss: 0.2294047
Validation loss decreased (0.185164 --> 0.179637).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 11.036002397537231
Epoch: 5, Steps: 65 | Train Loss: 0.1786102 Vali Loss: 0.1765931 Test Loss: 0.2247420
Validation loss decreased (0.179637 --> 0.176593).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 10.768268823623657
Epoch: 6, Steps: 65 | Train Loss: 0.1633951 Vali Loss: 0.1736210 Test Loss: 0.2213637
Validation loss decreased (0.176593 --> 0.173621).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 10.601083755493164
Epoch: 7, Steps: 65 | Train Loss: 0.1513300 Vali Loss: 0.1715861 Test Loss: 0.2185293
Validation loss decreased (0.173621 --> 0.171586).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 10.802744388580322
Epoch: 8, Steps: 65 | Train Loss: 0.1415116 Vali Loss: 0.1692534 Test Loss: 0.2160367
Validation loss decreased (0.171586 --> 0.169253).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 11.377761840820312
Epoch: 9, Steps: 65 | Train Loss: 0.1328878 Vali Loss: 0.1672724 Test Loss: 0.2138478
Validation loss decreased (0.169253 --> 0.167272).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 10.3289475440979
Epoch: 10, Steps: 65 | Train Loss: 0.1259918 Vali Loss: 0.1655925 Test Loss: 0.2119122
Validation loss decreased (0.167272 --> 0.165593).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 9.350438117980957
Epoch: 11, Steps: 65 | Train Loss: 0.1194934 Vali Loss: 0.1637180 Test Loss: 0.2098067
Validation loss decreased (0.165593 --> 0.163718).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 9.89100694656372
Epoch: 12, Steps: 65 | Train Loss: 0.1143886 Vali Loss: 0.1620453 Test Loss: 0.2078955
Validation loss decreased (0.163718 --> 0.162045).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 10.378402709960938
Epoch: 13, Steps: 65 | Train Loss: 0.1095577 Vali Loss: 0.1605976 Test Loss: 0.2061501
Validation loss decreased (0.162045 --> 0.160598).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 10.388938903808594
Epoch: 14, Steps: 65 | Train Loss: 0.1050049 Vali Loss: 0.1585927 Test Loss: 0.2045045
Validation loss decreased (0.160598 --> 0.158593).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 10.100582838058472
Epoch: 15, Steps: 65 | Train Loss: 0.1014254 Vali Loss: 0.1574042 Test Loss: 0.2029602
Validation loss decreased (0.158593 --> 0.157404).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 9.329550981521606
Epoch: 16, Steps: 65 | Train Loss: 0.0977074 Vali Loss: 0.1559254 Test Loss: 0.2016031
Validation loss decreased (0.157404 --> 0.155925).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 9.417677164077759
Epoch: 17, Steps: 65 | Train Loss: 0.0948276 Vali Loss: 0.1546683 Test Loss: 0.2001517
Validation loss decreased (0.155925 --> 0.154668).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 9.603201866149902
Epoch: 18, Steps: 65 | Train Loss: 0.0919449 Vali Loss: 0.1533501 Test Loss: 0.1987677
Validation loss decreased (0.154668 --> 0.153350).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 9.19060206413269
Epoch: 19, Steps: 65 | Train Loss: 0.0892740 Vali Loss: 0.1525065 Test Loss: 0.1977328
Validation loss decreased (0.153350 --> 0.152506).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 9.551497220993042
Epoch: 20, Steps: 65 | Train Loss: 0.0867374 Vali Loss: 0.1512117 Test Loss: 0.1965014
Validation loss decreased (0.152506 --> 0.151212).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 9.661803722381592
Epoch: 21, Steps: 65 | Train Loss: 0.0845986 Vali Loss: 0.1501947 Test Loss: 0.1954323
Validation loss decreased (0.151212 --> 0.150195).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 10.334114074707031
Epoch: 22, Steps: 65 | Train Loss: 0.0823868 Vali Loss: 0.1491627 Test Loss: 0.1943551
Validation loss decreased (0.150195 --> 0.149163).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 10.50844430923462
Epoch: 23, Steps: 65 | Train Loss: 0.0807622 Vali Loss: 0.1483041 Test Loss: 0.1934021
Validation loss decreased (0.149163 --> 0.148304).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 11.168707132339478
Epoch: 24, Steps: 65 | Train Loss: 0.0788525 Vali Loss: 0.1473563 Test Loss: 0.1925694
Validation loss decreased (0.148304 --> 0.147356).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 11.673710107803345
Epoch: 25, Steps: 65 | Train Loss: 0.0771860 Vali Loss: 0.1469397 Test Loss: 0.1918189
Validation loss decreased (0.147356 --> 0.146940).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 11.466197967529297
Epoch: 26, Steps: 65 | Train Loss: 0.0756449 Vali Loss: 0.1459830 Test Loss: 0.1910491
Validation loss decreased (0.146940 --> 0.145983).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 11.126516580581665
Epoch: 27, Steps: 65 | Train Loss: 0.0743672 Vali Loss: 0.1452673 Test Loss: 0.1903958
Validation loss decreased (0.145983 --> 0.145267).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 11.070703983306885
Epoch: 28, Steps: 65 | Train Loss: 0.0730559 Vali Loss: 0.1444681 Test Loss: 0.1896276
Validation loss decreased (0.145267 --> 0.144468).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 10.532034635543823
Epoch: 29, Steps: 65 | Train Loss: 0.0719236 Vali Loss: 0.1441254 Test Loss: 0.1889744
Validation loss decreased (0.144468 --> 0.144125).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 10.321875810623169
Epoch: 30, Steps: 65 | Train Loss: 0.0707040 Vali Loss: 0.1432049 Test Loss: 0.1883875
Validation loss decreased (0.144125 --> 0.143205).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 10.00812554359436
Epoch: 31, Steps: 65 | Train Loss: 0.0696837 Vali Loss: 0.1427035 Test Loss: 0.1878098
Validation loss decreased (0.143205 --> 0.142704).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 9.993848085403442
Epoch: 32, Steps: 65 | Train Loss: 0.0686548 Vali Loss: 0.1423008 Test Loss: 0.1872998
Validation loss decreased (0.142704 --> 0.142301).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 9.96971082687378
Epoch: 33, Steps: 65 | Train Loss: 0.0678566 Vali Loss: 0.1418024 Test Loss: 0.1868508
Validation loss decreased (0.142301 --> 0.141802).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 10.07516860961914
Epoch: 34, Steps: 65 | Train Loss: 0.0668369 Vali Loss: 0.1415052 Test Loss: 0.1863666
Validation loss decreased (0.141802 --> 0.141505).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 10.391136407852173
Epoch: 35, Steps: 65 | Train Loss: 0.0661005 Vali Loss: 0.1407592 Test Loss: 0.1859054
Validation loss decreased (0.141505 --> 0.140759).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 10.392679214477539
Epoch: 36, Steps: 65 | Train Loss: 0.0653510 Vali Loss: 0.1405238 Test Loss: 0.1854749
Validation loss decreased (0.140759 --> 0.140524).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 7.809943914413452
Epoch: 37, Steps: 65 | Train Loss: 0.0647708 Vali Loss: 0.1400603 Test Loss: 0.1851090
Validation loss decreased (0.140524 --> 0.140060).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 9.06694746017456
Epoch: 38, Steps: 65 | Train Loss: 0.0640927 Vali Loss: 0.1395804 Test Loss: 0.1847589
Validation loss decreased (0.140060 --> 0.139580).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 7.710097551345825
Epoch: 39, Steps: 65 | Train Loss: 0.0634260 Vali Loss: 0.1395360 Test Loss: 0.1844013
Validation loss decreased (0.139580 --> 0.139536).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 7.69751763343811
Epoch: 40, Steps: 65 | Train Loss: 0.0628923 Vali Loss: 0.1391128 Test Loss: 0.1840591
Validation loss decreased (0.139536 --> 0.139113).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 9.410438776016235
Epoch: 41, Steps: 65 | Train Loss: 0.0622492 Vali Loss: 0.1387412 Test Loss: 0.1837714
Validation loss decreased (0.139113 --> 0.138741).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 9.912456035614014
Epoch: 42, Steps: 65 | Train Loss: 0.0618170 Vali Loss: 0.1385429 Test Loss: 0.1834732
Validation loss decreased (0.138741 --> 0.138543).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 7.505476713180542
Epoch: 43, Steps: 65 | Train Loss: 0.0613632 Vali Loss: 0.1381650 Test Loss: 0.1831886
Validation loss decreased (0.138543 --> 0.138165).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 9.1852867603302
Epoch: 44, Steps: 65 | Train Loss: 0.0608608 Vali Loss: 0.1380091 Test Loss: 0.1829789
Validation loss decreased (0.138165 --> 0.138009).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 10.144850492477417
Epoch: 45, Steps: 65 | Train Loss: 0.0604796 Vali Loss: 0.1376537 Test Loss: 0.1827358
Validation loss decreased (0.138009 --> 0.137654).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 10.225441932678223
Epoch: 46, Steps: 65 | Train Loss: 0.0597815 Vali Loss: 0.1374486 Test Loss: 0.1824728
Validation loss decreased (0.137654 --> 0.137449).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 10.392332553863525
Epoch: 47, Steps: 65 | Train Loss: 0.0595203 Vali Loss: 0.1370297 Test Loss: 0.1822023
Validation loss decreased (0.137449 --> 0.137030).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 10.945219039916992
Epoch: 48, Steps: 65 | Train Loss: 0.0592192 Vali Loss: 0.1368404 Test Loss: 0.1819906
Validation loss decreased (0.137030 --> 0.136840).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 10.7763991355896
Epoch: 49, Steps: 65 | Train Loss: 0.0590580 Vali Loss: 0.1368367 Test Loss: 0.1817883
Validation loss decreased (0.136840 --> 0.136837).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 12.131771087646484
Epoch: 50, Steps: 65 | Train Loss: 0.0585620 Vali Loss: 0.1365366 Test Loss: 0.1816020
Validation loss decreased (0.136837 --> 0.136537).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
train 33745
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=106, out_features=120, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  45588480.0
params:  12840.0
Trainable parameters:  12840
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 12.237666606903076
Epoch: 1, Steps: 65 | Train Loss: 0.2298397 Vali Loss: 0.1213628 Test Loss: 0.1666591
Validation loss decreased (inf --> 0.121363).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 11.400390863418579
Epoch: 2, Steps: 65 | Train Loss: 0.2165589 Vali Loss: 0.1178693 Test Loss: 0.1638623
Validation loss decreased (0.121363 --> 0.117869).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 10.748192071914673
Epoch: 3, Steps: 65 | Train Loss: 0.2135731 Vali Loss: 0.1165117 Test Loss: 0.1627109
Validation loss decreased (0.117869 --> 0.116512).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 9.834911584854126
Epoch: 4, Steps: 65 | Train Loss: 0.2111848 Vali Loss: 0.1157512 Test Loss: 0.1622054
Validation loss decreased (0.116512 --> 0.115751).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 10.321814775466919
Epoch: 5, Steps: 65 | Train Loss: 0.2097555 Vali Loss: 0.1152085 Test Loss: 0.1616456
Validation loss decreased (0.115751 --> 0.115208).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 9.68867301940918
Epoch: 6, Steps: 65 | Train Loss: 0.2097901 Vali Loss: 0.1153208 Test Loss: 0.1617742
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 9.429579019546509
Epoch: 7, Steps: 65 | Train Loss: 0.2090578 Vali Loss: 0.1149469 Test Loss: 0.1613805
Validation loss decreased (0.115208 --> 0.114947).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 9.19586706161499
Epoch: 8, Steps: 65 | Train Loss: 0.2080220 Vali Loss: 0.1149069 Test Loss: 0.1612700
Validation loss decreased (0.114947 --> 0.114907).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 9.10777497291565
Epoch: 9, Steps: 65 | Train Loss: 0.2080890 Vali Loss: 0.1148365 Test Loss: 0.1611213
Validation loss decreased (0.114907 --> 0.114837).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 10.74215054512024
Epoch: 10, Steps: 65 | Train Loss: 0.2079176 Vali Loss: 0.1146245 Test Loss: 0.1610547
Validation loss decreased (0.114837 --> 0.114624).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 10.359017610549927
Epoch: 11, Steps: 65 | Train Loss: 0.2079498 Vali Loss: 0.1147011 Test Loss: 0.1610476
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 10.201891422271729
Epoch: 12, Steps: 65 | Train Loss: 0.2075910 Vali Loss: 0.1147526 Test Loss: 0.1610548
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 10.174250602722168
Epoch: 13, Steps: 65 | Train Loss: 0.2071978 Vali Loss: 0.1146311 Test Loss: 0.1609087
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_96_FITS_ETTm2_ftM_sl720_ll48_pl96_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.16331380605697632, mae:0.25452905893325806, rse:0.3276480734348297, corr:[0.567587   0.5714628  0.5710199  0.5689611  0.56786305 0.5679377
 0.56831294 0.56807613 0.5671621  0.56625146 0.5658456  0.5659381
 0.56619984 0.5661116  0.56550115 0.5645893  0.563782   0.5631976
 0.5627531  0.5622574  0.56160086 0.5607892  0.56001395 0.5594037
 0.55894315 0.5585796  0.5581864  0.55762655 0.55690366 0.55616486
 0.5554953  0.5550458  0.5547139  0.5542566  0.5535962  0.55281854
 0.5519974  0.55123484 0.550552   0.5499518  0.5494083  0.54885465
 0.5482353  0.5475336  0.54682964 0.5461225  0.5454197  0.5447366
 0.54395854 0.5430573  0.54213214 0.5413488  0.5406593  0.5399408
 0.5391306  0.5383231  0.53757983 0.53699815 0.53659385 0.5363038
 0.5360145  0.5357822  0.53559715 0.5354334  0.53524524 0.5350174
 0.53458303 0.5340216  0.5335115  0.5332111  0.5331464  0.53309274
 0.5327477  0.53205687 0.5311254  0.5303266  0.5299473  0.52992857
 0.52980137 0.5292705  0.52811885 0.526722   0.5255929  0.52500135
 0.5246206  0.5239633  0.52273375 0.5214638  0.52101904 0.52156734
 0.5221526  0.5217367  0.52001774 0.5182519  0.5191394  0.52202576]
