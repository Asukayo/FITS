Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_336', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_336_FITS_ETTm2_ftM_sl720_ll48_pl336_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=90, out_features=132, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  5322240.0
params:  12012.0
Trainable parameters:  12012
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3713412
	speed: 0.1209s/iter; left time: 3150.3107s
	iters: 200, epoch: 1 | loss: 0.3457780
	speed: 0.1177s/iter; left time: 3053.1850s
	iters: 300, epoch: 1 | loss: 0.2246723
	speed: 0.1108s/iter; left time: 2864.0380s
	iters: 400, epoch: 1 | loss: 0.2661968
	speed: 0.1091s/iter; left time: 2809.5010s
	iters: 500, epoch: 1 | loss: 0.1616271
	speed: 0.1056s/iter; left time: 2709.8079s
Epoch: 1 cost time: 58.729254722595215
Epoch: 1, Steps: 523 | Train Loss: 0.2822424 Vali Loss: 0.2220089 Test Loss: 0.2983794
Validation loss decreased (inf --> 0.222009).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1845730
	speed: 0.7587s/iter; left time: 19368.0138s
	iters: 200, epoch: 2 | loss: 0.2063272
	speed: 0.1047s/iter; left time: 2662.2805s
	iters: 300, epoch: 2 | loss: 0.1566684
	speed: 0.1051s/iter; left time: 2660.8345s
	iters: 400, epoch: 2 | loss: 0.0915747
	speed: 0.1204s/iter; left time: 3037.7613s
	iters: 500, epoch: 2 | loss: 0.1356031
	speed: 0.1190s/iter; left time: 2990.5731s
Epoch: 2 cost time: 59.135611057281494
Epoch: 2, Steps: 523 | Train Loss: 0.1675599 Vali Loss: 0.2068628 Test Loss: 0.2816951
Validation loss decreased (0.222009 --> 0.206863).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1495433
	speed: 0.8079s/iter; left time: 20201.6896s
	iters: 200, epoch: 3 | loss: 0.1027071
	speed: 0.1211s/iter; left time: 3016.0963s
	iters: 300, epoch: 3 | loss: 0.1094547
	speed: 0.1190s/iter; left time: 2952.6615s
	iters: 400, epoch: 3 | loss: 0.0898026
	speed: 0.1171s/iter; left time: 2892.3083s
	iters: 500, epoch: 3 | loss: 0.1571930
	speed: 0.1029s/iter; left time: 2530.8563s
Epoch: 3 cost time: 61.66921281814575
Epoch: 3, Steps: 523 | Train Loss: 0.1428484 Vali Loss: 0.2010871 Test Loss: 0.2756123
Validation loss decreased (0.206863 --> 0.201087).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1624201
	speed: 0.8260s/iter; left time: 20222.9381s
	iters: 200, epoch: 4 | loss: 0.0975154
	speed: 0.1361s/iter; left time: 3318.1871s
	iters: 300, epoch: 4 | loss: 0.0843903
	speed: 0.1342s/iter; left time: 3258.0730s
	iters: 400, epoch: 4 | loss: 0.1112917
	speed: 0.1409s/iter; left time: 3406.3134s
	iters: 500, epoch: 4 | loss: 0.1534825
	speed: 0.1228s/iter; left time: 2956.5661s
Epoch: 4 cost time: 69.85048818588257
Epoch: 4, Steps: 523 | Train Loss: 0.1353720 Vali Loss: 0.1987757 Test Loss: 0.2741452
Validation loss decreased (0.201087 --> 0.198776).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1801335
	speed: 0.8350s/iter; left time: 20006.6075s
	iters: 200, epoch: 5 | loss: 0.1869241
	speed: 0.1145s/iter; left time: 2731.4273s
	iters: 300, epoch: 5 | loss: 0.1363574
	speed: 0.0738s/iter; left time: 1752.8246s
	iters: 400, epoch: 5 | loss: 0.1337251
	speed: 0.1109s/iter; left time: 2624.2928s
	iters: 500, epoch: 5 | loss: 0.2093902
	speed: 0.1120s/iter; left time: 2639.2971s
Epoch: 5 cost time: 56.528379917144775
Epoch: 5, Steps: 523 | Train Loss: 0.1333084 Vali Loss: 0.1978721 Test Loss: 0.2738276
Validation loss decreased (0.198776 --> 0.197872).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1129794
	speed: 0.7985s/iter; left time: 18712.6061s
	iters: 200, epoch: 6 | loss: 0.1692220
	speed: 0.1135s/iter; left time: 2649.5937s
	iters: 300, epoch: 6 | loss: 0.1149139
	speed: 0.1180s/iter; left time: 2742.3954s
	iters: 400, epoch: 6 | loss: 0.1087726
	speed: 0.0609s/iter; left time: 1409.5514s
	iters: 500, epoch: 6 | loss: 0.1250703
	speed: 0.0740s/iter; left time: 1704.7163s
Epoch: 6 cost time: 51.17035126686096
Epoch: 6, Steps: 523 | Train Loss: 0.1324933 Vali Loss: 0.1972808 Test Loss: 0.2733167
Validation loss decreased (0.197872 --> 0.197281).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1233228
	speed: 0.7478s/iter; left time: 17133.9151s
	iters: 200, epoch: 7 | loss: 0.1242632
	speed: 0.1133s/iter; left time: 2584.0702s
	iters: 300, epoch: 7 | loss: 0.0773622
	speed: 0.1167s/iter; left time: 2650.5899s
	iters: 400, epoch: 7 | loss: 0.1358949
	speed: 0.1258s/iter; left time: 2844.3943s
	iters: 500, epoch: 7 | loss: 0.1813791
	speed: 0.1225s/iter; left time: 2757.4420s
Epoch: 7 cost time: 62.63285565376282
Epoch: 7, Steps: 523 | Train Loss: 0.1323932 Vali Loss: 0.1970223 Test Loss: 0.2729319
Validation loss decreased (0.197281 --> 0.197022).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1167206
	speed: 0.8587s/iter; left time: 19225.9679s
	iters: 200, epoch: 8 | loss: 0.1565879
	speed: 0.1184s/iter; left time: 2638.2862s
	iters: 300, epoch: 8 | loss: 0.1136930
	speed: 0.1243s/iter; left time: 2758.1487s
	iters: 400, epoch: 8 | loss: 0.1350793
	speed: 0.1134s/iter; left time: 2504.6017s
	iters: 500, epoch: 8 | loss: 0.1586716
	speed: 0.1122s/iter; left time: 2466.7865s
Epoch: 8 cost time: 62.677008390426636
Epoch: 8, Steps: 523 | Train Loss: 0.1322124 Vali Loss: 0.1972861 Test Loss: 0.2733891
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.0943176
	speed: 0.8553s/iter; left time: 18702.8296s
	iters: 200, epoch: 9 | loss: 0.0906600
	speed: 0.1340s/iter; left time: 2917.5302s
	iters: 300, epoch: 9 | loss: 0.1629486
	speed: 0.1231s/iter; left time: 2667.5739s
	iters: 400, epoch: 9 | loss: 0.1196387
	speed: 0.1125s/iter; left time: 2425.5197s
	iters: 500, epoch: 9 | loss: 0.1225478
	speed: 0.1195s/iter; left time: 2564.4013s
Epoch: 9 cost time: 66.0052080154419
Epoch: 9, Steps: 523 | Train Loss: 0.1321747 Vali Loss: 0.1970540 Test Loss: 0.2733849
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1005862
	speed: 0.7660s/iter; left time: 16349.1645s
	iters: 200, epoch: 10 | loss: 0.1429493
	speed: 0.1123s/iter; left time: 2386.4640s
	iters: 300, epoch: 10 | loss: 0.0993403
	speed: 0.1137s/iter; left time: 2404.4139s
	iters: 400, epoch: 10 | loss: 0.1676957
	speed: 0.1107s/iter; left time: 2329.2919s
	iters: 500, epoch: 10 | loss: 0.1865624
	speed: 0.1113s/iter; left time: 2331.5950s
Epoch: 10 cost time: 60.28956723213196
Epoch: 10, Steps: 523 | Train Loss: 0.1321010 Vali Loss: 0.1970022 Test Loss: 0.2732856
Validation loss decreased (0.197022 --> 0.197002).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1259931
	speed: 0.7305s/iter; left time: 15210.2013s
	iters: 200, epoch: 11 | loss: 0.1475123
	speed: 0.1063s/iter; left time: 2201.9774s
	iters: 300, epoch: 11 | loss: 0.1502291
	speed: 0.1084s/iter; left time: 2235.4836s
	iters: 400, epoch: 11 | loss: 0.1277519
	speed: 0.1067s/iter; left time: 2190.3568s
	iters: 500, epoch: 11 | loss: 0.1647206
	speed: 0.1131s/iter; left time: 2309.8354s
Epoch: 11 cost time: 56.75156831741333
Epoch: 11, Steps: 523 | Train Loss: 0.1320928 Vali Loss: 0.1970079 Test Loss: 0.2732928
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1952191
	speed: 0.7477s/iter; left time: 15176.9121s
	iters: 200, epoch: 12 | loss: 0.1300323
	speed: 0.1095s/iter; left time: 2211.4346s
	iters: 300, epoch: 12 | loss: 0.1704023
	speed: 0.1050s/iter; left time: 2111.0362s
	iters: 400, epoch: 12 | loss: 0.1573483
	speed: 0.1184s/iter; left time: 2366.7821s
	iters: 500, epoch: 12 | loss: 0.2727518
	speed: 0.1235s/iter; left time: 2456.4835s
Epoch: 12 cost time: 60.32829689979553
Epoch: 12, Steps: 523 | Train Loss: 0.1321581 Vali Loss: 0.1966751 Test Loss: 0.2730849
Validation loss decreased (0.197002 --> 0.196675).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1890650
	speed: 0.9046s/iter; left time: 17889.2825s
	iters: 200, epoch: 13 | loss: 0.1020637
	speed: 0.1007s/iter; left time: 1981.5769s
	iters: 300, epoch: 13 | loss: 0.1250080
	speed: 0.1407s/iter; left time: 2754.2584s
	iters: 400, epoch: 13 | loss: 0.0871624
	speed: 0.1306s/iter; left time: 2544.2503s
	iters: 500, epoch: 13 | loss: 0.1461554
	speed: 0.1319s/iter; left time: 2555.4073s
Epoch: 13 cost time: 67.15702438354492
Epoch: 13, Steps: 523 | Train Loss: 0.1320877 Vali Loss: 0.1968032 Test Loss: 0.2730717
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1564931
	speed: 0.7775s/iter; left time: 14967.9438s
	iters: 200, epoch: 14 | loss: 0.1239360
	speed: 0.1084s/iter; left time: 2075.1659s
	iters: 300, epoch: 14 | loss: 0.0970014
	speed: 0.1153s/iter; left time: 2196.8934s
	iters: 400, epoch: 14 | loss: 0.1392073
	speed: 0.1139s/iter; left time: 2158.3181s
	iters: 500, epoch: 14 | loss: 0.2283616
	speed: 0.1182s/iter; left time: 2227.8109s
Epoch: 14 cost time: 60.93785762786865
Epoch: 14, Steps: 523 | Train Loss: 0.1319446 Vali Loss: 0.1970933 Test Loss: 0.2732369
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1030073
	speed: 0.8052s/iter; left time: 15081.1769s
	iters: 200, epoch: 15 | loss: 0.0928687
	speed: 0.1131s/iter; left time: 2106.6653s
	iters: 300, epoch: 15 | loss: 0.0841327
	speed: 0.1286s/iter; left time: 2383.3124s
	iters: 400, epoch: 15 | loss: 0.1297946
	speed: 0.1196s/iter; left time: 2204.2317s
	iters: 500, epoch: 15 | loss: 0.1453336
	speed: 0.1186s/iter; left time: 2174.6469s
Epoch: 15 cost time: 62.0455048084259
Epoch: 15, Steps: 523 | Train Loss: 0.1320688 Vali Loss: 0.1967420 Test Loss: 0.2731315
EarlyStopping counter: 3 out of 3
Early stopping
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=90, out_features=132, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  5322240.0
params:  12012.0
Trainable parameters:  12012
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4722992
	speed: 0.1311s/iter; left time: 3416.4975s
	iters: 200, epoch: 1 | loss: 0.4441789
	speed: 0.1349s/iter; left time: 3499.7793s
	iters: 300, epoch: 1 | loss: 0.3421912
	speed: 0.1281s/iter; left time: 3310.2924s
	iters: 400, epoch: 1 | loss: 0.2526877
	speed: 0.1198s/iter; left time: 3084.7511s
	iters: 500, epoch: 1 | loss: 0.4850225
	speed: 0.1225s/iter; left time: 3143.1905s
Epoch: 1 cost time: 66.55939555168152
Epoch: 1, Steps: 523 | Train Loss: 0.3800043 Vali Loss: 0.1947812 Test Loss: 0.2709466
Validation loss decreased (inf --> 0.194781).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3193317
	speed: 0.8010s/iter; left time: 20448.1971s
	iters: 200, epoch: 2 | loss: 0.4812100
	speed: 0.1180s/iter; left time: 3000.2908s
	iters: 300, epoch: 2 | loss: 0.6258603
	speed: 0.1207s/iter; left time: 3058.3408s
	iters: 400, epoch: 2 | loss: 0.2465082
	speed: 0.1189s/iter; left time: 3000.2381s
	iters: 500, epoch: 2 | loss: 0.4671830
	speed: 0.1309s/iter; left time: 3289.0139s
Epoch: 2 cost time: 64.31467342376709
Epoch: 2, Steps: 523 | Train Loss: 0.3780451 Vali Loss: 0.1940251 Test Loss: 0.2695749
Validation loss decreased (0.194781 --> 0.194025).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.6743854
	speed: 1.0022s/iter; left time: 25059.9224s
	iters: 200, epoch: 3 | loss: 0.3270270
	speed: 0.1309s/iter; left time: 3260.4783s
	iters: 300, epoch: 3 | loss: 0.3050454
	speed: 0.1344s/iter; left time: 3334.3763s
	iters: 400, epoch: 3 | loss: 0.2272470
	speed: 0.0872s/iter; left time: 2155.1152s
	iters: 500, epoch: 3 | loss: 0.6422048
	speed: 0.1294s/iter; left time: 3183.8659s
Epoch: 3 cost time: 67.01247501373291
Epoch: 3, Steps: 523 | Train Loss: 0.3768889 Vali Loss: 0.1936274 Test Loss: 0.2695970
Validation loss decreased (0.194025 --> 0.193627).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3087030
	speed: 0.8978s/iter; left time: 21980.2386s
	iters: 200, epoch: 4 | loss: 0.5264273
	speed: 0.1317s/iter; left time: 3211.9653s
	iters: 300, epoch: 4 | loss: 0.3437979
	speed: 0.1294s/iter; left time: 3142.6227s
	iters: 400, epoch: 4 | loss: 0.4900688
	speed: 0.1246s/iter; left time: 3012.0998s
	iters: 500, epoch: 4 | loss: 0.2409179
	speed: 0.1210s/iter; left time: 2914.8974s
Epoch: 4 cost time: 67.64665794372559
Epoch: 4, Steps: 523 | Train Loss: 0.3763664 Vali Loss: 0.1936520 Test Loss: 0.2695653
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3447780
	speed: 0.8437s/iter; left time: 20214.7893s
	iters: 200, epoch: 5 | loss: 0.2991402
	speed: 0.1209s/iter; left time: 2883.5313s
	iters: 300, epoch: 5 | loss: 0.3727946
	speed: 0.1243s/iter; left time: 2952.2080s
	iters: 400, epoch: 5 | loss: 0.3465059
	speed: 0.1377s/iter; left time: 3257.4738s
	iters: 500, epoch: 5 | loss: 0.3896271
	speed: 0.1310s/iter; left time: 3086.3857s
Epoch: 5 cost time: 67.74587726593018
Epoch: 5, Steps: 523 | Train Loss: 0.3757543 Vali Loss: 0.1929466 Test Loss: 0.2685384
Validation loss decreased (0.193627 --> 0.192947).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4601292
	speed: 0.8727s/iter; left time: 20453.4497s
	iters: 200, epoch: 6 | loss: 0.2981580
	speed: 0.1186s/iter; left time: 2768.6010s
	iters: 300, epoch: 6 | loss: 0.5175288
	speed: 0.1174s/iter; left time: 2727.1463s
	iters: 400, epoch: 6 | loss: 0.5364709
	speed: 0.1054s/iter; left time: 2438.0662s
	iters: 500, epoch: 6 | loss: 0.2484742
	speed: 0.1315s/iter; left time: 3028.7205s
Epoch: 6 cost time: 64.55115103721619
Epoch: 6, Steps: 523 | Train Loss: 0.3756811 Vali Loss: 0.1934586 Test Loss: 0.2689137
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3259115
	speed: 0.7341s/iter; left time: 16819.3210s
	iters: 200, epoch: 7 | loss: 0.5385410
	speed: 0.1066s/iter; left time: 2431.7576s
	iters: 300, epoch: 7 | loss: 0.2550551
	speed: 0.1294s/iter; left time: 2939.5563s
	iters: 400, epoch: 7 | loss: 0.4946555
	speed: 0.1328s/iter; left time: 3002.4380s
	iters: 500, epoch: 7 | loss: 0.2629343
	speed: 0.1248s/iter; left time: 2810.0830s
Epoch: 7 cost time: 64.73169589042664
Epoch: 7, Steps: 523 | Train Loss: 0.3754639 Vali Loss: 0.1932564 Test Loss: 0.2686529
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3026640
	speed: 0.8236s/iter; left time: 18441.4131s
	iters: 200, epoch: 8 | loss: 0.3465465
	speed: 0.1125s/iter; left time: 2507.0705s
	iters: 300, epoch: 8 | loss: 0.3791477
	speed: 0.1212s/iter; left time: 2689.2827s
	iters: 400, epoch: 8 | loss: 0.5170992
	speed: 0.1157s/iter; left time: 2555.5311s
	iters: 500, epoch: 8 | loss: 0.2616483
	speed: 0.1425s/iter; left time: 3133.0211s
Epoch: 8 cost time: 65.40487003326416
Epoch: 8, Steps: 523 | Train Loss: 0.3751919 Vali Loss: 0.1931119 Test Loss: 0.2687632
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_336_FITS_ETTm2_ftM_sl720_ll48_pl336_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.26873448491096497, mae:0.3261522352695465, rse:0.41871869564056396, corr:[0.5546713  0.5591672  0.55920625 0.5568803  0.5549536  0.55442756
 0.55505466 0.5559869  0.55637485 0.55592394 0.55500054 0.5541812
 0.5538229  0.55389893 0.55414385 0.5541105  0.55355746 0.5525769
 0.5514691  0.5505442  0.54998034 0.5497274  0.5495913  0.5493464
 0.54885036 0.54815453 0.54741555 0.5467619  0.54624575 0.54584736
 0.5454606  0.545018   0.5444402  0.54373306 0.5429818  0.5422945
 0.5416759  0.54111534 0.5405481  0.5399194  0.53922236 0.5384818
 0.53776914 0.53713053 0.5365913  0.5361306  0.535697   0.53519887
 0.5345309  0.5336998  0.5328014  0.5319574  0.53120804 0.530596
 0.5301288  0.52978766 0.52947754 0.5291475  0.5288165  0.5285064
 0.52822113 0.5279838  0.52776164 0.5274937  0.52716094 0.5268034
 0.52644676 0.5261575  0.5259561  0.52580506 0.5256259  0.52536225
 0.5249828  0.5245103  0.52396846 0.5234204  0.5228881  0.5223741
 0.52186775 0.52138704 0.52088207 0.52038735 0.5199175  0.5194804
 0.5190635  0.51862574 0.51811486 0.51755106 0.51696795 0.51640815
 0.51591843 0.5154826  0.5149996  0.514358   0.5134466  0.5121972
 0.51069677 0.50913477 0.50759447 0.50613666 0.50480425 0.50359476
 0.5024948  0.5014505  0.5004586  0.4995003  0.49864075 0.49791512
 0.49726966 0.4966254  0.49592313 0.4951333  0.4943322  0.49353462
 0.49273986 0.49197856 0.4912374  0.49040446 0.48943356 0.48825595
 0.48699823 0.48580116 0.4849206  0.48444602 0.48426569 0.48414195
 0.48384953 0.48320857 0.48217303 0.48087433 0.47958305 0.47857606
 0.4780304  0.47788176 0.47787902 0.4777267  0.4772039  0.47627592
 0.47501764 0.47367725 0.47250345 0.47168672 0.4712363  0.4709112
 0.47049126 0.46977854 0.4688657  0.4678367  0.4668308  0.46590686
 0.46512064 0.46446794 0.46382993 0.46316507 0.4625155  0.4619885
 0.46159336 0.46128878 0.46097288 0.46061686 0.46016353 0.4596753
 0.45926556 0.45908102 0.45915332 0.45939356 0.4595865  0.4595916
 0.45938972 0.45906454 0.45865467 0.45828587 0.45805082 0.45793864
 0.45784858 0.4576476  0.45723063 0.45657203 0.45568836 0.45476335
 0.4538693  0.45306253 0.4524274  0.4519372  0.45151743 0.4511146
 0.45073283 0.45036256 0.4499016  0.4492114  0.4481824  0.44677958
 0.44511217 0.4434487  0.44187945 0.4404914  0.43940884 0.438577
 0.43790004 0.43719995 0.43634865 0.43524894 0.43391547 0.4324314
 0.4309383  0.42954928 0.4283166  0.42730916 0.42664555 0.42636997
 0.42621547 0.42594603 0.42539328 0.42447197 0.4232407  0.4217376
 0.42008775 0.41843545 0.41702542 0.41593394 0.41506305 0.41431552
 0.41357848 0.41279957 0.41201013 0.41110742 0.4101269  0.40915692
 0.4081342  0.4071282  0.4061029  0.40511653 0.4041889  0.40341148
 0.40282816 0.40252677 0.40245044 0.40254006 0.4027383  0.40295738
 0.40316463 0.40323094 0.40315494 0.40301526 0.40267283 0.40214327
 0.4014975  0.40086174 0.40031856 0.39992893 0.39983088 0.39992434
 0.4000054  0.39996666 0.39963716 0.39912078 0.39857844 0.3982544
 0.39822486 0.39837593 0.39848503 0.39837024 0.39794636 0.39736903
 0.39685485 0.39657652 0.39666617 0.39699122 0.39721984 0.3970696
 0.3964984  0.39574572 0.39505693 0.39473137 0.3947989  0.39506134
 0.39529875 0.39512613 0.39443532 0.39352545 0.39278877 0.39261284
 0.3929888  0.3935985  0.39396825 0.3936903  0.39261496 0.39080158
 0.3887982  0.3874276  0.3869605  0.38713038 0.38740483 0.38725677
 0.3866061  0.3855533  0.38439322 0.38348904 0.3831187  0.38297215
 0.3828095  0.38229117 0.38147223 0.3805169  0.37990385 0.37996134
 0.38062507 0.38125926 0.38135794 0.3806805  0.37934697 0.37804347
 0.37729612 0.3775857  0.37864143 0.3796593  0.37993935 0.37924126
 0.37775517 0.37630993 0.37584877 0.37676394 0.37848628 0.3800405
 0.38050067 0.3795365  0.3775228  0.37542567 0.3747207  0.37585735
 0.37815642 0.38002238 0.37993982 0.37646914 0.36905614 0.3604526 ]
