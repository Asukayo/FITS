Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_192_FITS_ETTm2_ftM_sl720_ll48_pl192_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=90, out_features=114, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  9192960.0
params:  10374.0
Trainable parameters:  10374
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2909343
	speed: 0.1575s/iter; left time: 2047.8984s
	iters: 200, epoch: 1 | loss: 0.2532151
	speed: 0.1438s/iter; left time: 1855.4028s
Epoch: 1 cost time: 39.126381158828735
Epoch: 1, Steps: 262 | Train Loss: 0.2973789 Vali Loss: 0.2012172 Test Loss: 0.2699541
Validation loss decreased (inf --> 0.201217).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1843322
	speed: 0.6545s/iter; left time: 8337.5748s
	iters: 200, epoch: 2 | loss: 0.1525895
	speed: 0.1622s/iter; left time: 2050.6554s
Epoch: 2 cost time: 42.59360980987549
Epoch: 2, Steps: 262 | Train Loss: 0.1778019 Vali Loss: 0.1848782 Test Loss: 0.2500660
Validation loss decreased (0.201217 --> 0.184878).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1334324
	speed: 0.8030s/iter; left time: 10018.9269s
	iters: 200, epoch: 3 | loss: 0.1432640
	speed: 0.1813s/iter; left time: 2244.5357s
Epoch: 3 cost time: 48.40910077095032
Epoch: 3, Steps: 262 | Train Loss: 0.1349315 Vali Loss: 0.1772668 Test Loss: 0.2420241
Validation loss decreased (0.184878 --> 0.177267).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.0833200
	speed: 0.8037s/iter; left time: 9817.4768s
	iters: 200, epoch: 4 | loss: 0.1444259
	speed: 0.1660s/iter; left time: 2011.2391s
Epoch: 4 cost time: 45.18368220329285
Epoch: 4, Steps: 262 | Train Loss: 0.1120590 Vali Loss: 0.1716234 Test Loss: 0.2360899
Validation loss decreased (0.177267 --> 0.171623).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.0963672
	speed: 0.7512s/iter; left time: 8979.4237s
	iters: 200, epoch: 5 | loss: 0.1079001
	speed: 0.1539s/iter; left time: 1824.5207s
Epoch: 5 cost time: 41.65691018104553
Epoch: 5, Steps: 262 | Train Loss: 0.0985017 Vali Loss: 0.1670667 Test Loss: 0.2317063
Validation loss decreased (0.171623 --> 0.167067).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.0835904
	speed: 0.6929s/iter; left time: 8100.9634s
	iters: 200, epoch: 6 | loss: 0.0928786
	speed: 0.1486s/iter; left time: 1722.4065s
Epoch: 6 cost time: 40.52356505393982
Epoch: 6, Steps: 262 | Train Loss: 0.0899446 Vali Loss: 0.1641118 Test Loss: 0.2287151
Validation loss decreased (0.167067 --> 0.164112).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.0768819
	speed: 0.6599s/iter; left time: 7541.5078s
	iters: 200, epoch: 7 | loss: 0.0652674
	speed: 0.1401s/iter; left time: 1586.7510s
Epoch: 7 cost time: 38.243229150772095
Epoch: 7, Steps: 262 | Train Loss: 0.0845369 Vali Loss: 0.1614875 Test Loss: 0.2264727
Validation loss decreased (0.164112 --> 0.161488).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1126928
	speed: 0.8121s/iter; left time: 9068.9102s
	iters: 200, epoch: 8 | loss: 0.0913075
	speed: 0.1436s/iter; left time: 1589.1764s
Epoch: 8 cost time: 41.34380030632019
Epoch: 8, Steps: 262 | Train Loss: 0.0810082 Vali Loss: 0.1594245 Test Loss: 0.2247141
Validation loss decreased (0.161488 --> 0.159424).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.0848721
	speed: 0.7442s/iter; left time: 8115.5457s
	iters: 200, epoch: 9 | loss: 0.0615911
	speed: 0.1608s/iter; left time: 1737.8617s
Epoch: 9 cost time: 42.41662669181824
Epoch: 9, Steps: 262 | Train Loss: 0.0786692 Vali Loss: 0.1587717 Test Loss: 0.2240329
Validation loss decreased (0.159424 --> 0.158772).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1135608
	speed: 0.6638s/iter; left time: 7064.6282s
	iters: 200, epoch: 10 | loss: 0.0836937
	speed: 0.1180s/iter; left time: 1243.6706s
Epoch: 10 cost time: 33.79826045036316
Epoch: 10, Steps: 262 | Train Loss: 0.0771873 Vali Loss: 0.1576265 Test Loss: 0.2230400
Validation loss decreased (0.158772 --> 0.157626).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.0788767
	speed: 0.5560s/iter; left time: 5771.7157s
	iters: 200, epoch: 11 | loss: 0.0931376
	speed: 0.1136s/iter; left time: 1168.3502s
Epoch: 11 cost time: 33.39011478424072
Epoch: 11, Steps: 262 | Train Loss: 0.0762505 Vali Loss: 0.1570683 Test Loss: 0.2226157
Validation loss decreased (0.157626 --> 0.157068).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.0886003
	speed: 0.5067s/iter; left time: 5127.5674s
	iters: 200, epoch: 12 | loss: 0.0707024
	speed: 0.1069s/iter; left time: 1070.7300s
Epoch: 12 cost time: 27.786781072616577
Epoch: 12, Steps: 262 | Train Loss: 0.0756974 Vali Loss: 0.1566287 Test Loss: 0.2222150
Validation loss decreased (0.157068 --> 0.156629).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.0779870
	speed: 0.4803s/iter; left time: 4734.1414s
	iters: 200, epoch: 13 | loss: 0.0741135
	speed: 0.1171s/iter; left time: 1142.1148s
Epoch: 13 cost time: 30.185112953186035
Epoch: 13, Steps: 262 | Train Loss: 0.0753072 Vali Loss: 0.1564902 Test Loss: 0.2223591
Validation loss decreased (0.156629 --> 0.156490).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.0701822
	speed: 0.5059s/iter; left time: 4853.8596s
	iters: 200, epoch: 14 | loss: 0.0622198
	speed: 0.1119s/iter; left time: 1062.1838s
Epoch: 14 cost time: 29.95450234413147
Epoch: 14, Steps: 262 | Train Loss: 0.0750440 Vali Loss: 0.1561880 Test Loss: 0.2218728
Validation loss decreased (0.156490 --> 0.156188).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.0774270
	speed: 0.5063s/iter; left time: 4725.2045s
	iters: 200, epoch: 15 | loss: 0.0632782
	speed: 0.1244s/iter; left time: 1148.3850s
Epoch: 15 cost time: 32.58485221862793
Epoch: 15, Steps: 262 | Train Loss: 0.0748035 Vali Loss: 0.1561545 Test Loss: 0.2218843
Validation loss decreased (0.156188 --> 0.156155).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.0770755
	speed: 0.5477s/iter; left time: 4968.1215s
	iters: 200, epoch: 16 | loss: 0.1018076
	speed: 0.1118s/iter; left time: 1002.7111s
Epoch: 16 cost time: 31.332640171051025
Epoch: 16, Steps: 262 | Train Loss: 0.0746600 Vali Loss: 0.1560123 Test Loss: 0.2216270
Validation loss decreased (0.156155 --> 0.156012).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.0863146
	speed: 0.5659s/iter; left time: 4984.8930s
	iters: 200, epoch: 17 | loss: 0.0725577
	speed: 0.1198s/iter; left time: 1043.2501s
Epoch: 17 cost time: 33.386932611465454
Epoch: 17, Steps: 262 | Train Loss: 0.0747156 Vali Loss: 0.1561503 Test Loss: 0.2218390
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.0681172
	speed: 0.5582s/iter; left time: 4770.9523s
	iters: 200, epoch: 18 | loss: 0.0936761
	speed: 0.1128s/iter; left time: 953.1505s
Epoch: 18 cost time: 30.627779960632324
Epoch: 18, Steps: 262 | Train Loss: 0.0745933 Vali Loss: 0.1558349 Test Loss: 0.2216763
Validation loss decreased (0.156012 --> 0.155835).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.0641334
	speed: 0.5029s/iter; left time: 4166.5050s
	iters: 200, epoch: 19 | loss: 0.0655131
	speed: 0.1134s/iter; left time: 928.2336s
Epoch: 19 cost time: 30.690080404281616
Epoch: 19, Steps: 262 | Train Loss: 0.0745372 Vali Loss: 0.1556730 Test Loss: 0.2216690
Validation loss decreased (0.155835 --> 0.155673).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.0806288
	speed: 0.5305s/iter; left time: 4256.4604s
	iters: 200, epoch: 20 | loss: 0.0727586
	speed: 0.1163s/iter; left time: 921.4537s
Epoch: 20 cost time: 31.467018842697144
Epoch: 20, Steps: 262 | Train Loss: 0.0745795 Vali Loss: 0.1559332 Test Loss: 0.2217363
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.0746471
	speed: 0.5276s/iter; left time: 4094.6655s
	iters: 200, epoch: 21 | loss: 0.0638165
	speed: 0.1186s/iter; left time: 908.2538s
Epoch: 21 cost time: 32.21092939376831
Epoch: 21, Steps: 262 | Train Loss: 0.0746160 Vali Loss: 0.1557197 Test Loss: 0.2217396
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.0505031
	speed: 0.5351s/iter; left time: 4012.5161s
	iters: 200, epoch: 22 | loss: 0.0664511
	speed: 0.1158s/iter; left time: 856.8630s
Epoch: 22 cost time: 31.50769305229187
Epoch: 22, Steps: 262 | Train Loss: 0.0745916 Vali Loss: 0.1558734 Test Loss: 0.2216175
EarlyStopping counter: 3 out of 3
Early stopping
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=90, out_features=114, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  9192960.0
params:  10374.0
Trainable parameters:  10374
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3233368
	speed: 0.1267s/iter; left time: 1646.6271s
	iters: 200, epoch: 1 | loss: 0.2667564
	speed: 0.1241s/iter; left time: 1601.3886s
Epoch: 1 cost time: 32.38343000411987
Epoch: 1, Steps: 262 | Train Loss: 0.2960057 Vali Loss: 0.1534610 Test Loss: 0.2190067
Validation loss decreased (inf --> 0.153461).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2062625
	speed: 0.5484s/iter; left time: 6985.5614s
	iters: 200, epoch: 2 | loss: 0.3956886
	speed: 0.1204s/iter; left time: 1521.8447s
Epoch: 2 cost time: 33.14589715003967
Epoch: 2, Steps: 262 | Train Loss: 0.2927438 Vali Loss: 0.1530860 Test Loss: 0.2184986
Validation loss decreased (0.153461 --> 0.153086).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2467400
	speed: 0.5896s/iter; left time: 7356.3541s
	iters: 200, epoch: 3 | loss: 0.4253970
	speed: 0.1298s/iter; left time: 1606.7923s
Epoch: 3 cost time: 35.8970890045166
Epoch: 3, Steps: 262 | Train Loss: 0.2921908 Vali Loss: 0.1527862 Test Loss: 0.2175577
Validation loss decreased (0.153086 --> 0.152786).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3338980
	speed: 0.5518s/iter; left time: 6739.7815s
	iters: 200, epoch: 4 | loss: 0.3137444
	speed: 0.1006s/iter; left time: 1218.5512s
Epoch: 4 cost time: 26.766780853271484
Epoch: 4, Steps: 262 | Train Loss: 0.2916069 Vali Loss: 0.1524214 Test Loss: 0.2173989
Validation loss decreased (0.152786 --> 0.152421).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2026782
	speed: 0.5786s/iter; left time: 6915.8089s
	iters: 200, epoch: 5 | loss: 0.2206918
	speed: 0.1349s/iter; left time: 1599.3122s
Epoch: 5 cost time: 36.37999510765076
Epoch: 5, Steps: 262 | Train Loss: 0.2907368 Vali Loss: 0.1523727 Test Loss: 0.2172613
Validation loss decreased (0.152421 --> 0.152373).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2571213
	speed: 0.6692s/iter; left time: 7823.1092s
	iters: 200, epoch: 6 | loss: 0.2871888
	speed: 0.1559s/iter; left time: 1806.5702s
Epoch: 6 cost time: 41.976588010787964
Epoch: 6, Steps: 262 | Train Loss: 0.2905217 Vali Loss: 0.1523847 Test Loss: 0.2170670
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3325296
	speed: 0.7096s/iter; left time: 8109.7191s
	iters: 200, epoch: 7 | loss: 0.3272120
	speed: 0.1520s/iter; left time: 1721.5791s
Epoch: 7 cost time: 41.0051474571228
Epoch: 7, Steps: 262 | Train Loss: 0.2903162 Vali Loss: 0.1520988 Test Loss: 0.2169470
Validation loss decreased (0.152373 --> 0.152099).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3213767
	speed: 0.6919s/iter; left time: 7726.3916s
	iters: 200, epoch: 8 | loss: 0.2475925
	speed: 0.1491s/iter; left time: 1650.2459s
Epoch: 8 cost time: 41.073389291763306
Epoch: 8, Steps: 262 | Train Loss: 0.2899284 Vali Loss: 0.1520793 Test Loss: 0.2166777
Validation loss decreased (0.152099 --> 0.152079).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3248211
	speed: 0.7096s/iter; left time: 7738.0418s
	iters: 200, epoch: 9 | loss: 0.2478847
	speed: 0.1440s/iter; left time: 1555.7645s
Epoch: 9 cost time: 39.52796959877014
Epoch: 9, Steps: 262 | Train Loss: 0.2898685 Vali Loss: 0.1522157 Test Loss: 0.2169104
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2478446
	speed: 0.6503s/iter; left time: 6920.9896s
	iters: 200, epoch: 10 | loss: 0.2562610
	speed: 0.1377s/iter; left time: 1451.5378s
Epoch: 10 cost time: 38.0561306476593
Epoch: 10, Steps: 262 | Train Loss: 0.2897141 Vali Loss: 0.1522453 Test Loss: 0.2167091
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3176792
	speed: 0.6703s/iter; left time: 6958.5343s
	iters: 200, epoch: 11 | loss: 0.2605487
	speed: 0.1445s/iter; left time: 1485.3654s
Epoch: 11 cost time: 39.33214521408081
Epoch: 11, Steps: 262 | Train Loss: 0.2894299 Vali Loss: 0.1520846 Test Loss: 0.2168718
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_192_FITS_ETTm2_ftM_sl720_ll48_pl192_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.21726509928703308, mae:0.29133638739585876, rse:0.3773028552532196, corr:[0.5620979  0.565407   0.5651802  0.56308734 0.561375   0.5608796
 0.5613351  0.5619747  0.56207865 0.5614844  0.5605642  0.55980146
 0.559469   0.5594776  0.5595805  0.55938494 0.558761   0.55781335
 0.5568083  0.5559726  0.5554465  0.5551778  0.5550189  0.55477726
 0.55432373 0.5536987  0.5530297  0.5524128  0.55188847 0.55145293
 0.551046   0.55066013 0.55021745 0.5496477  0.5489857  0.5483093
 0.547631   0.54696465 0.54630125 0.5456406  0.54500645 0.5444152
 0.54390216 0.54345906 0.5430533  0.54260516 0.5420586  0.5413959
 0.5405671  0.53959626 0.5385865  0.53768563 0.5369316  0.536302
 0.5357381  0.5352347  0.5347497  0.53427416 0.53385717 0.53356045
 0.53338605 0.5333282  0.5332789  0.5331537  0.5329109  0.5326479
 0.53238493 0.5322056  0.5321192  0.53202933 0.5318199  0.531446
 0.5309211  0.53032535 0.5297235  0.52921116 0.5287974  0.5284121
 0.5279661  0.5274527  0.52684116 0.5262275  0.52569443 0.5252683
 0.52489096 0.5245018  0.523933   0.5232049  0.5223996  0.5216733
 0.5211984  0.52100176 0.5208177  0.52041143 0.51957417 0.51820797
 0.5164386  0.5146079  0.51298857 0.5117495  0.51086056 0.5100941
 0.50924355 0.50816363 0.5068396  0.5054345  0.50422925 0.5034508
 0.5029679  0.502535   0.5019158  0.50097317 0.49984515 0.49869007
 0.49771845 0.49712017 0.49685505 0.4966396  0.49628153 0.49558955
 0.49469116 0.49373668 0.49303812 0.49265894 0.49241605 0.49203563
 0.49133945 0.4902656  0.4888935  0.487457   0.48629272 0.48558202
 0.48529634 0.4851871  0.4849985  0.4845501  0.48375964 0.48284575
 0.48198757 0.4813383  0.48079753 0.48018503 0.47934914 0.47815558
 0.4767507  0.47538897 0.47461858 0.47451586 0.4748311  0.475017
 0.4748081  0.47421503 0.47334155 0.4724261  0.47178203 0.47160223
 0.4716646  0.47164008 0.4711955  0.47043023 0.46944618 0.46868017
 0.46839255 0.46862915 0.4690878  0.4694226  0.46934047 0.468805
 0.46800566 0.46730998 0.46685463 0.46663198 0.46637458 0.46585482
 0.46507967 0.46424776 0.4636938  0.463642   0.46385783 0.46412203
 0.46393973 0.4631386  0.4621023  0.46131048 0.46104655 0.46121094
 0.4613389  0.46110415 0.4603538  0.45946816 0.4593832  0.45978656]
