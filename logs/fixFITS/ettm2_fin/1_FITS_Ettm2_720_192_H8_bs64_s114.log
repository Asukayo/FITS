Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=74, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_192_FITS_ETTm2_ftM_sl720_ll48_pl192_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=74, out_features=93, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6166272.0
params:  6975.0
Trainable parameters:  6975
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2781076
	speed: 0.1381s/iter; left time: 1795.1737s
	iters: 200, epoch: 1 | loss: 0.4754626
	speed: 0.1258s/iter; left time: 1623.1673s
Epoch: 1 cost time: 34.44354462623596
Epoch: 1, Steps: 262 | Train Loss: 0.3864422 Vali Loss: 0.1719189 Test Loss: 0.2372539
Validation loss decreased (inf --> 0.171919).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3821492
	speed: 0.5813s/iter; left time: 7405.4481s
	iters: 200, epoch: 2 | loss: 0.3013872
	speed: 0.1167s/iter; left time: 1475.3022s
Epoch: 2 cost time: 32.78350496292114
Epoch: 2, Steps: 262 | Train Loss: 0.3227801 Vali Loss: 0.1626021 Test Loss: 0.2280501
Validation loss decreased (0.171919 --> 0.162602).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2326044
	speed: 0.5780s/iter; left time: 7211.4042s
	iters: 200, epoch: 3 | loss: 0.2554732
	speed: 0.1284s/iter; left time: 1589.5362s
Epoch: 3 cost time: 34.342658042907715
Epoch: 3, Steps: 262 | Train Loss: 0.3099839 Vali Loss: 0.1588123 Test Loss: 0.2242581
Validation loss decreased (0.162602 --> 0.158812).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3658982
	speed: 0.5916s/iter; left time: 7226.2220s
	iters: 200, epoch: 4 | loss: 0.2029669
	speed: 0.1368s/iter; left time: 1656.9271s
Epoch: 4 cost time: 36.28150463104248
Epoch: 4, Steps: 262 | Train Loss: 0.3042510 Vali Loss: 0.1572957 Test Loss: 0.2228098
Validation loss decreased (0.158812 --> 0.157296).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2863819
	speed: 0.6271s/iter; left time: 7495.8537s
	iters: 200, epoch: 5 | loss: 0.2680883
	speed: 0.1353s/iter; left time: 1603.7516s
Epoch: 5 cost time: 35.796027183532715
Epoch: 5, Steps: 262 | Train Loss: 0.3006198 Vali Loss: 0.1563250 Test Loss: 0.2216453
Validation loss decreased (0.157296 --> 0.156325).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2259035
	speed: 0.5305s/iter; left time: 6201.6253s
	iters: 200, epoch: 6 | loss: 0.2443270
	speed: 0.1410s/iter; left time: 1633.9668s
Epoch: 6 cost time: 37.56308841705322
Epoch: 6, Steps: 262 | Train Loss: 0.2983334 Vali Loss: 0.1553548 Test Loss: 0.2205829
Validation loss decreased (0.156325 --> 0.155355).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2007171
	speed: 0.6694s/iter; left time: 7650.7485s
	iters: 200, epoch: 7 | loss: 0.4038376
	speed: 0.1497s/iter; left time: 1695.6697s
Epoch: 7 cost time: 40.24061441421509
Epoch: 7, Steps: 262 | Train Loss: 0.2968058 Vali Loss: 0.1548605 Test Loss: 0.2199206
Validation loss decreased (0.155355 --> 0.154860).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3287687
	speed: 0.6446s/iter; left time: 7198.1578s
	iters: 200, epoch: 8 | loss: 0.2996421
	speed: 0.1412s/iter; left time: 1562.6908s
Epoch: 8 cost time: 37.73194670677185
Epoch: 8, Steps: 262 | Train Loss: 0.2961548 Vali Loss: 0.1545168 Test Loss: 0.2196343
Validation loss decreased (0.154860 --> 0.154517).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2732484
	speed: 0.6569s/iter; left time: 7163.4272s
	iters: 200, epoch: 9 | loss: 0.2267001
	speed: 0.1457s/iter; left time: 1574.6800s
Epoch: 9 cost time: 38.06082630157471
Epoch: 9, Steps: 262 | Train Loss: 0.2945044 Vali Loss: 0.1544789 Test Loss: 0.2193707
Validation loss decreased (0.154517 --> 0.154479).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3058937
	speed: 0.6288s/iter; left time: 6692.2230s
	iters: 200, epoch: 10 | loss: 0.3676881
	speed: 0.1342s/iter; left time: 1414.5444s
Epoch: 10 cost time: 35.724669456481934
Epoch: 10, Steps: 262 | Train Loss: 0.2944593 Vali Loss: 0.1539809 Test Loss: 0.2190287
Validation loss decreased (0.154479 --> 0.153981).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2747366
	speed: 0.6197s/iter; left time: 6433.4380s
	iters: 200, epoch: 11 | loss: 0.3062795
	speed: 0.1378s/iter; left time: 1416.7593s
Epoch: 11 cost time: 36.38770508766174
Epoch: 11, Steps: 262 | Train Loss: 0.2938010 Vali Loss: 0.1539255 Test Loss: 0.2188494
Validation loss decreased (0.153981 --> 0.153926).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2677146
	speed: 0.6384s/iter; left time: 6459.4684s
	iters: 200, epoch: 12 | loss: 0.2999978
	speed: 0.1305s/iter; left time: 1307.6807s
Epoch: 12 cost time: 36.487738609313965
Epoch: 12, Steps: 262 | Train Loss: 0.2936117 Vali Loss: 0.1538101 Test Loss: 0.2185646
Validation loss decreased (0.153926 --> 0.153810).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3730555
	speed: 0.5838s/iter; left time: 5754.9317s
	iters: 200, epoch: 13 | loss: 0.3147663
	speed: 0.1094s/iter; left time: 1067.7412s
Epoch: 13 cost time: 31.929814100265503
Epoch: 13, Steps: 262 | Train Loss: 0.2933280 Vali Loss: 0.1539414 Test Loss: 0.2184948
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3284916
	speed: 0.6380s/iter; left time: 6121.7489s
	iters: 200, epoch: 14 | loss: 0.2199475
	speed: 0.1401s/iter; left time: 1330.4945s
Epoch: 14 cost time: 38.14900183677673
Epoch: 14, Steps: 262 | Train Loss: 0.2925033 Vali Loss: 0.1535744 Test Loss: 0.2183126
Validation loss decreased (0.153810 --> 0.153574).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1986278
	speed: 0.6284s/iter; left time: 5864.7847s
	iters: 200, epoch: 15 | loss: 0.3456251
	speed: 0.1361s/iter; left time: 1256.4912s
Epoch: 15 cost time: 36.81724834442139
Epoch: 15, Steps: 262 | Train Loss: 0.2927849 Vali Loss: 0.1535977 Test Loss: 0.2182727
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2455463
	speed: 0.6242s/iter; left time: 5662.2233s
	iters: 200, epoch: 16 | loss: 0.3405593
	speed: 0.1391s/iter; left time: 1247.4420s
Epoch: 16 cost time: 36.95581936836243
Epoch: 16, Steps: 262 | Train Loss: 0.2922540 Vali Loss: 0.1536142 Test Loss: 0.2184341
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3510136
	speed: 0.6325s/iter; left time: 5571.3409s
	iters: 200, epoch: 17 | loss: 0.3105485
	speed: 0.1296s/iter; left time: 1128.7247s
Epoch: 17 cost time: 35.51584053039551
Epoch: 17, Steps: 262 | Train Loss: 0.2921385 Vali Loss: 0.1534506 Test Loss: 0.2181320
Validation loss decreased (0.153574 --> 0.153451).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2094860
	speed: 0.6010s/iter; left time: 5136.7846s
	iters: 200, epoch: 18 | loss: 0.2361241
	speed: 0.1353s/iter; left time: 1143.0162s
Epoch: 18 cost time: 35.71706748008728
Epoch: 18, Steps: 262 | Train Loss: 0.2921223 Vali Loss: 0.1533046 Test Loss: 0.2181280
Validation loss decreased (0.153451 --> 0.153305).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2180004
	speed: 0.6061s/iter; left time: 5021.6960s
	iters: 200, epoch: 19 | loss: 0.2650871
	speed: 0.1387s/iter; left time: 1134.9255s
Epoch: 19 cost time: 36.42969107627869
Epoch: 19, Steps: 262 | Train Loss: 0.2917122 Vali Loss: 0.1535564 Test Loss: 0.2181882
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3166485
	speed: 0.6380s/iter; left time: 5118.4477s
	iters: 200, epoch: 20 | loss: 0.2202049
	speed: 0.1342s/iter; left time: 1063.0478s
Epoch: 20 cost time: 36.49516201019287
Epoch: 20, Steps: 262 | Train Loss: 0.2916307 Vali Loss: 0.1534177 Test Loss: 0.2180736
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2899748
	speed: 0.6066s/iter; left time: 4707.8591s
	iters: 200, epoch: 21 | loss: 0.3003779
	speed: 0.1346s/iter; left time: 1030.8834s
Epoch: 21 cost time: 35.83596086502075
Epoch: 21, Steps: 262 | Train Loss: 0.2917435 Vali Loss: 0.1533398 Test Loss: 0.2177510
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_192_FITS_ETTm2_ftM_sl720_ll48_pl192_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.21868707239627838, mae:0.29310593008995056, rse:0.37853553891181946, corr:[0.55527794 0.5614481  0.56298673 0.5615156  0.55951524 0.5582849
 0.55807745 0.55862373 0.5594222  0.5599765  0.55999696 0.5595255
 0.5588489  0.55821383 0.55782443 0.55764437 0.5575949  0.5575023
 0.55721337 0.55665195 0.5559076  0.5550875  0.5543493  0.5537999
 0.5534393  0.5532098  0.5529981  0.55269295 0.5522278  0.551613
 0.55089283 0.5502132  0.5496112  0.5490548  0.5485411  0.5480852
 0.5476277  0.5471307  0.5465653  0.5459326  0.5452558  0.54454815
 0.5438619  0.5432293  0.54267424 0.54216605 0.54167044 0.54115224
 0.5405081  0.5396968  0.5387585  0.53782463 0.5369715  0.5362626
 0.53571784 0.53535783 0.5350944  0.5348309  0.5345176  0.53413945
 0.5336974  0.53327966 0.5329305  0.53267705 0.53249395 0.532395
 0.5322816  0.53214455 0.5319816  0.5317662  0.5314802  0.5311472
 0.5307798  0.53039604 0.5299784  0.529535   0.5290533  0.52851444
 0.5279226  0.5273267  0.5266918  0.526051   0.5254136  0.52478486
 0.5241589  0.52357817 0.522969   0.522374   0.52180696 0.52128357
 0.5208322  0.52044755 0.51996934 0.51933134 0.5184586  0.5172891
 0.51587087 0.51437956 0.51289946 0.5114849  0.51017475 0.5089569
 0.5078392  0.5067629  0.50565517 0.5045031  0.50337213 0.502396
 0.5015512  0.5008199  0.5001696  0.49952456 0.49892548 0.4982886
 0.4975465  0.49673465 0.4959268  0.495143   0.49446833 0.49381804
 0.49321774 0.4925656  0.4918911  0.49113342 0.49022543 0.48917273
 0.48808384 0.4870617  0.486156   0.48534116 0.48458362 0.48379558
 0.48297203 0.48213008 0.48133418 0.4806189  0.47995543 0.47943625
 0.47899982 0.47861242 0.478183   0.4776756  0.4770935  0.47634307
 0.4754307  0.47431567 0.47326282 0.4723587  0.47169167 0.4711288
 0.4706258  0.47014812 0.4695604  0.4687368  0.46769968 0.4666632
 0.4657556  0.46506736 0.4645041  0.46416923 0.46390444 0.4637199
 0.46356836 0.463529   0.4636389  0.463893   0.46409705 0.4640821
 0.46378416 0.46329066 0.46260065 0.46190822 0.4613907  0.46117362
 0.46125945 0.46144494 0.4614664  0.46107948 0.46006778 0.45873192
 0.4573474  0.4563297  0.45610157 0.45652437 0.45699534 0.45687675
 0.45576292 0.4538261  0.45191213 0.4517818  0.45472234 0.4583265 ]
