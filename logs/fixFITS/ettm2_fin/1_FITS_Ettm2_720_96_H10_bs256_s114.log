Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=512, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_96_FITS_ETTm2_ftM_sl720_ll48_pl96_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=90, out_features=102, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  32901120.0
params:  9282.0
Trainable parameters:  9282
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 8.857001304626465
Epoch: 1, Steps: 65 | Train Loss: 0.3881374 Vali Loss: 0.1581378 Test Loss: 0.2100947
Validation loss decreased (inf --> 0.158138).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 9.449309349060059
Epoch: 2, Steps: 65 | Train Loss: 0.2805452 Vali Loss: 0.1390221 Test Loss: 0.1877577
Validation loss decreased (0.158138 --> 0.139022).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 8.766537427902222
Epoch: 3, Steps: 65 | Train Loss: 0.2572698 Vali Loss: 0.1319675 Test Loss: 0.1799154
Validation loss decreased (0.139022 --> 0.131968).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 9.536441326141357
Epoch: 4, Steps: 65 | Train Loss: 0.2446892 Vali Loss: 0.1277764 Test Loss: 0.1753324
Validation loss decreased (0.131968 --> 0.127776).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 9.967837810516357
Epoch: 5, Steps: 65 | Train Loss: 0.2375811 Vali Loss: 0.1249249 Test Loss: 0.1724250
Validation loss decreased (0.127776 --> 0.124925).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 9.279844760894775
Epoch: 6, Steps: 65 | Train Loss: 0.2322530 Vali Loss: 0.1230246 Test Loss: 0.1704838
Validation loss decreased (0.124925 --> 0.123025).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 9.464464902877808
Epoch: 7, Steps: 65 | Train Loss: 0.2282877 Vali Loss: 0.1217822 Test Loss: 0.1690385
Validation loss decreased (0.123025 --> 0.121782).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 9.550359725952148
Epoch: 8, Steps: 65 | Train Loss: 0.2255938 Vali Loss: 0.1209239 Test Loss: 0.1679963
Validation loss decreased (0.121782 --> 0.120924).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 9.219367742538452
Epoch: 9, Steps: 65 | Train Loss: 0.2232736 Vali Loss: 0.1200216 Test Loss: 0.1670759
Validation loss decreased (0.120924 --> 0.120022).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 10.436333417892456
Epoch: 10, Steps: 65 | Train Loss: 0.2216134 Vali Loss: 0.1195176 Test Loss: 0.1665078
Validation loss decreased (0.120022 --> 0.119518).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 9.66561770439148
Epoch: 11, Steps: 65 | Train Loss: 0.2199599 Vali Loss: 0.1191783 Test Loss: 0.1660118
Validation loss decreased (0.119518 --> 0.119178).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 9.445732355117798
Epoch: 12, Steps: 65 | Train Loss: 0.2191627 Vali Loss: 0.1187158 Test Loss: 0.1655707
Validation loss decreased (0.119178 --> 0.118716).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 9.449710130691528
Epoch: 13, Steps: 65 | Train Loss: 0.2180049 Vali Loss: 0.1183783 Test Loss: 0.1652087
Validation loss decreased (0.118716 --> 0.118378).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 10.288045644760132
Epoch: 14, Steps: 65 | Train Loss: 0.2160389 Vali Loss: 0.1179419 Test Loss: 0.1648080
Validation loss decreased (0.118378 --> 0.117942).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 9.944771528244019
Epoch: 15, Steps: 65 | Train Loss: 0.2164893 Vali Loss: 0.1178789 Test Loss: 0.1645283
Validation loss decreased (0.117942 --> 0.117879).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 11.577155590057373
Epoch: 16, Steps: 65 | Train Loss: 0.2150769 Vali Loss: 0.1175897 Test Loss: 0.1643433
Validation loss decreased (0.117879 --> 0.117590).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 11.419320344924927
Epoch: 17, Steps: 65 | Train Loss: 0.2150940 Vali Loss: 0.1175040 Test Loss: 0.1640515
Validation loss decreased (0.117590 --> 0.117504).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 12.47183108329773
Epoch: 18, Steps: 65 | Train Loss: 0.2147681 Vali Loss: 0.1173943 Test Loss: 0.1639407
Validation loss decreased (0.117504 --> 0.117394).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 10.527255773544312
Epoch: 19, Steps: 65 | Train Loss: 0.2143295 Vali Loss: 0.1172793 Test Loss: 0.1636756
Validation loss decreased (0.117394 --> 0.117279).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 9.889804124832153
Epoch: 20, Steps: 65 | Train Loss: 0.2143504 Vali Loss: 0.1169686 Test Loss: 0.1634695
Validation loss decreased (0.117279 --> 0.116969).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 9.017794847488403
Epoch: 21, Steps: 65 | Train Loss: 0.2138975 Vali Loss: 0.1169690 Test Loss: 0.1633984
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 10.639700651168823
Epoch: 22, Steps: 65 | Train Loss: 0.2131272 Vali Loss: 0.1169555 Test Loss: 0.1632415
Validation loss decreased (0.116969 --> 0.116956).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 10.068681716918945
Epoch: 23, Steps: 65 | Train Loss: 0.2130951 Vali Loss: 0.1167573 Test Loss: 0.1632315
Validation loss decreased (0.116956 --> 0.116757).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 9.784545421600342
Epoch: 24, Steps: 65 | Train Loss: 0.2127827 Vali Loss: 0.1165292 Test Loss: 0.1630718
Validation loss decreased (0.116757 --> 0.116529).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 9.23184323310852
Epoch: 25, Steps: 65 | Train Loss: 0.2125967 Vali Loss: 0.1166285 Test Loss: 0.1630133
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 10.173463344573975
Epoch: 26, Steps: 65 | Train Loss: 0.2119390 Vali Loss: 0.1165863 Test Loss: 0.1629194
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 9.568095207214355
Epoch: 27, Steps: 65 | Train Loss: 0.2121257 Vali Loss: 0.1162113 Test Loss: 0.1628269
Validation loss decreased (0.116529 --> 0.116211).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 9.930781126022339
Epoch: 28, Steps: 65 | Train Loss: 0.2117438 Vali Loss: 0.1165014 Test Loss: 0.1627121
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 9.810957431793213
Epoch: 29, Steps: 65 | Train Loss: 0.2116142 Vali Loss: 0.1164662 Test Loss: 0.1626943
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 9.624030828475952
Epoch: 30, Steps: 65 | Train Loss: 0.2112091 Vali Loss: 0.1163127 Test Loss: 0.1626609
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_96_FITS_ETTm2_ftM_sl720_ll48_pl96_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.16509701311588287, mae:0.25637489557266235, rse:0.32943201065063477, corr:[0.5584902  0.56716776 0.56998783 0.56842005 0.5665026  0.5659004
 0.5664743  0.5674728  0.5680588  0.56784695 0.56710327 0.5663506
 0.56592363 0.5658415  0.5659429  0.5659096  0.5655429  0.5648048
 0.5638717  0.56293076 0.56215495 0.561595   0.56122845 0.56093574
 0.56054664 0.55998987 0.55929935 0.5585331  0.5577752  0.5571352
 0.55662626 0.5562505  0.5558729  0.5553168  0.5545405  0.55364466
 0.5527431  0.55197513 0.5513787  0.55091155 0.5504545  0.5498865
 0.5491507  0.54828614 0.54741985 0.5466385  0.545993   0.545451
 0.5448114  0.5439447  0.5428658  0.5417566  0.5407491  0.53993154
 0.53929573 0.53880525 0.53830254 0.53768337 0.53695184 0.536237
 0.53566015 0.53535837 0.5352908  0.53528863 0.5351581  0.53486764
 0.53435904 0.5337797  0.5333053  0.53300196 0.5328347  0.5326956
 0.5324616  0.5320652  0.53145194 0.53072745 0.5299746  0.52929074
 0.52874035 0.52840686 0.5279857  0.527294   0.5261718  0.5246667
 0.5230538  0.5217924  0.5210746  0.5208701  0.520612   0.5196132
 0.51775056 0.515524   0.5138585  0.5141491  0.5155984  0.5132148 ]
