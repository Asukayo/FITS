Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_192_FITS_ETTm2_ftM_sl720_ll48_pl192_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=106, out_features=134, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6363392.0
params:  14338.0
Trainable parameters:  14338
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2663046
	speed: 0.1184s/iter; left time: 3096.6792s
	iters: 200, epoch: 1 | loss: 0.2034301
	speed: 0.1173s/iter; left time: 3056.9740s
	iters: 300, epoch: 1 | loss: 0.2651712
	speed: 0.1126s/iter; left time: 2920.8116s
	iters: 400, epoch: 1 | loss: 0.2632737
	speed: 0.1161s/iter; left time: 3000.8754s
	iters: 500, epoch: 1 | loss: 0.5043935
	speed: 0.1154s/iter; left time: 2972.3832s
Epoch: 1 cost time: 60.904784202575684
Epoch: 1, Steps: 525 | Train Loss: 0.3645290 Vali Loss: 0.1629817 Test Loss: 0.2291249
Validation loss decreased (inf --> 0.162982).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3469081
	speed: 0.7652s/iter; left time: 19609.4963s
	iters: 200, epoch: 2 | loss: 0.3948909
	speed: 0.1075s/iter; left time: 2743.0784s
	iters: 300, epoch: 2 | loss: 0.2957763
	speed: 0.1086s/iter; left time: 2761.4246s
	iters: 400, epoch: 2 | loss: 0.3706112
	speed: 0.0867s/iter; left time: 2196.9847s
	iters: 500, epoch: 2 | loss: 0.1713811
	speed: 0.0478s/iter; left time: 1207.0060s
Epoch: 2 cost time: 46.63177442550659
Epoch: 2, Steps: 525 | Train Loss: 0.3091054 Vali Loss: 0.1567218 Test Loss: 0.2224131
Validation loss decreased (0.162982 --> 0.156722).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2677819
	speed: 0.5580s/iter; left time: 14007.0135s
	iters: 200, epoch: 3 | loss: 0.2095608
	speed: 0.0877s/iter; left time: 2193.2418s
	iters: 300, epoch: 3 | loss: 0.2110887
	speed: 0.0884s/iter; left time: 2200.2711s
	iters: 400, epoch: 3 | loss: 0.4290476
	speed: 0.0906s/iter; left time: 2247.1564s
	iters: 500, epoch: 3 | loss: 0.1860432
	speed: 0.0964s/iter; left time: 2380.7354s
Epoch: 3 cost time: 47.95289063453674
Epoch: 3, Steps: 525 | Train Loss: 0.2999188 Vali Loss: 0.1545392 Test Loss: 0.2203625
Validation loss decreased (0.156722 --> 0.154539).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1791373
	speed: 0.6812s/iter; left time: 16741.4321s
	iters: 200, epoch: 4 | loss: 0.2442624
	speed: 0.1021s/iter; left time: 2498.7634s
	iters: 300, epoch: 4 | loss: 0.2253150
	speed: 0.1016s/iter; left time: 2477.0723s
	iters: 400, epoch: 4 | loss: 0.2884877
	speed: 0.0965s/iter; left time: 2343.6667s
	iters: 500, epoch: 4 | loss: 0.1903365
	speed: 0.0989s/iter; left time: 2390.6470s
Epoch: 4 cost time: 53.16356801986694
Epoch: 4, Steps: 525 | Train Loss: 0.2964525 Vali Loss: 0.1536444 Test Loss: 0.2191436
Validation loss decreased (0.154539 --> 0.153644).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3131010
	speed: 0.5618s/iter; left time: 13512.2538s
	iters: 200, epoch: 5 | loss: 0.3519275
	speed: 0.0989s/iter; left time: 2368.1200s
	iters: 300, epoch: 5 | loss: 0.4497255
	speed: 0.1036s/iter; left time: 2470.6961s
	iters: 400, epoch: 5 | loss: 0.3732264
	speed: 0.0987s/iter; left time: 2343.1269s
	iters: 500, epoch: 5 | loss: 0.2990470
	speed: 0.1006s/iter; left time: 2379.8854s
Epoch: 5 cost time: 53.28593111038208
Epoch: 5, Steps: 525 | Train Loss: 0.2940977 Vali Loss: 0.1530519 Test Loss: 0.2184120
Validation loss decreased (0.153644 --> 0.153052).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5252212
	speed: 0.7349s/iter; left time: 17289.9143s
	iters: 200, epoch: 6 | loss: 0.2724470
	speed: 0.1106s/iter; left time: 2591.5705s
	iters: 300, epoch: 6 | loss: 0.1830561
	speed: 0.1099s/iter; left time: 2563.8396s
	iters: 400, epoch: 6 | loss: 0.2522989
	speed: 0.1103s/iter; left time: 2561.3127s
	iters: 500, epoch: 6 | loss: 0.1782062
	speed: 0.1045s/iter; left time: 2416.6461s
Epoch: 6 cost time: 58.39038968086243
Epoch: 6, Steps: 525 | Train Loss: 0.2928880 Vali Loss: 0.1526163 Test Loss: 0.2179928
Validation loss decreased (0.153052 --> 0.152616).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2763261
	speed: 0.6923s/iter; left time: 15923.1012s
	iters: 200, epoch: 7 | loss: 0.4717153
	speed: 0.0995s/iter; left time: 2279.2015s
	iters: 300, epoch: 7 | loss: 0.3821500
	speed: 0.0954s/iter; left time: 2174.5506s
	iters: 400, epoch: 7 | loss: 0.2735121
	speed: 0.0988s/iter; left time: 2242.5886s
	iters: 500, epoch: 7 | loss: 0.2313550
	speed: 0.0989s/iter; left time: 2235.5925s
Epoch: 7 cost time: 52.80173063278198
Epoch: 7, Steps: 525 | Train Loss: 0.2920078 Vali Loss: 0.1522789 Test Loss: 0.2172853
Validation loss decreased (0.152616 --> 0.152279).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2662005
	speed: 0.7028s/iter; left time: 15797.0902s
	iters: 200, epoch: 8 | loss: 0.1890611
	speed: 0.1028s/iter; left time: 2299.1912s
	iters: 300, epoch: 8 | loss: 0.2736318
	speed: 0.1041s/iter; left time: 2319.2031s
	iters: 400, epoch: 8 | loss: 0.3551902
	speed: 0.1016s/iter; left time: 2252.9517s
	iters: 500, epoch: 8 | loss: 0.3342103
	speed: 0.0997s/iter; left time: 2199.9429s
Epoch: 8 cost time: 54.75911068916321
Epoch: 8, Steps: 525 | Train Loss: 0.2914093 Vali Loss: 0.1522741 Test Loss: 0.2174948
Validation loss decreased (0.152279 --> 0.152274).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2755766
	speed: 0.7198s/iter; left time: 15799.3864s
	iters: 200, epoch: 9 | loss: 0.2092895
	speed: 0.1021s/iter; left time: 2229.9865s
	iters: 300, epoch: 9 | loss: 0.4289564
	speed: 0.1131s/iter; left time: 2460.8983s
	iters: 400, epoch: 9 | loss: 0.3416986
	speed: 0.1017s/iter; left time: 2202.5543s
	iters: 500, epoch: 9 | loss: 0.1259278
	speed: 0.0815s/iter; left time: 1757.1469s
Epoch: 9 cost time: 52.96898627281189
Epoch: 9, Steps: 525 | Train Loss: 0.2904864 Vali Loss: 0.1522310 Test Loss: 0.2174254
Validation loss decreased (0.152274 --> 0.152231).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3163413
	speed: 0.6796s/iter; left time: 14560.0403s
	iters: 200, epoch: 10 | loss: 0.2982313
	speed: 0.0919s/iter; left time: 1958.8930s
	iters: 300, epoch: 10 | loss: 0.1903964
	speed: 0.0936s/iter; left time: 1986.2905s
	iters: 400, epoch: 10 | loss: 0.2287565
	speed: 0.0979s/iter; left time: 2067.6413s
	iters: 500, epoch: 10 | loss: 0.1678294
	speed: 0.0978s/iter; left time: 2057.1804s
Epoch: 10 cost time: 50.16716980934143
Epoch: 10, Steps: 525 | Train Loss: 0.2901811 Vali Loss: 0.1520758 Test Loss: 0.2172808
Validation loss decreased (0.152231 --> 0.152076).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.6222959
	speed: 0.6018s/iter; left time: 12578.3920s
	iters: 200, epoch: 11 | loss: 0.2943694
	speed: 0.0910s/iter; left time: 1893.5725s
	iters: 300, epoch: 11 | loss: 0.3182650
	speed: 0.0918s/iter; left time: 1901.0055s
	iters: 400, epoch: 11 | loss: 0.3722963
	speed: 0.0919s/iter; left time: 1893.6331s
	iters: 500, epoch: 11 | loss: 0.2324719
	speed: 0.1028s/iter; left time: 2107.0244s
Epoch: 11 cost time: 51.07337546348572
Epoch: 11, Steps: 525 | Train Loss: 0.2900284 Vali Loss: 0.1518657 Test Loss: 0.2167998
Validation loss decreased (0.152076 --> 0.151866).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2827184
	speed: 0.6698s/iter; left time: 13647.6866s
	iters: 200, epoch: 12 | loss: 0.2097367
	speed: 0.1005s/iter; left time: 2037.2395s
	iters: 300, epoch: 12 | loss: 0.4325128
	speed: 0.1007s/iter; left time: 2032.3614s
	iters: 400, epoch: 12 | loss: 0.1387810
	speed: 0.0777s/iter; left time: 1559.4841s
	iters: 500, epoch: 12 | loss: 0.2558027
	speed: 0.0795s/iter; left time: 1589.0092s
Epoch: 12 cost time: 48.42980480194092
Epoch: 12, Steps: 525 | Train Loss: 0.2899450 Vali Loss: 0.1518358 Test Loss: 0.2169577
Validation loss decreased (0.151866 --> 0.151836).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2792544
	speed: 0.6903s/iter; left time: 13702.9415s
	iters: 200, epoch: 13 | loss: 0.3266117
	speed: 0.1069s/iter; left time: 2110.9394s
	iters: 300, epoch: 13 | loss: 0.2030420
	speed: 0.0974s/iter; left time: 1913.8144s
	iters: 400, epoch: 13 | loss: 0.2261451
	speed: 0.0939s/iter; left time: 1835.0394s
	iters: 500, epoch: 13 | loss: 0.2488577
	speed: 0.0834s/iter; left time: 1621.5016s
Epoch: 13 cost time: 53.05762553215027
Epoch: 13, Steps: 525 | Train Loss: 0.2896565 Vali Loss: 0.1516092 Test Loss: 0.2166926
Validation loss decreased (0.151836 --> 0.151609).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.5460287
	speed: 0.6818s/iter; left time: 13176.8675s
	iters: 200, epoch: 14 | loss: 0.2026045
	speed: 0.1059s/iter; left time: 2036.5781s
	iters: 300, epoch: 14 | loss: 0.2377986
	speed: 0.1095s/iter; left time: 2093.8068s
	iters: 400, epoch: 14 | loss: 0.1887687
	speed: 0.1115s/iter; left time: 2120.4943s
	iters: 500, epoch: 14 | loss: 0.1844175
	speed: 0.1084s/iter; left time: 2051.3204s
Epoch: 14 cost time: 57.15879726409912
Epoch: 14, Steps: 525 | Train Loss: 0.2894211 Vali Loss: 0.1520570 Test Loss: 0.2170842
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3462026
	speed: 0.7278s/iter; left time: 13683.3872s
	iters: 200, epoch: 15 | loss: 0.1942071
	speed: 0.1088s/iter; left time: 2035.2074s
	iters: 300, epoch: 15 | loss: 0.3394616
	speed: 0.1091s/iter; left time: 2030.0705s
	iters: 400, epoch: 15 | loss: 0.2022776
	speed: 0.1042s/iter; left time: 1927.0157s
	iters: 500, epoch: 15 | loss: 0.2614535
	speed: 0.1001s/iter; left time: 1842.5982s
Epoch: 15 cost time: 56.82682228088379
Epoch: 15, Steps: 525 | Train Loss: 0.2892457 Vali Loss: 0.1517650 Test Loss: 0.2165790
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2502905
	speed: 0.5500s/iter; left time: 10051.0590s
	iters: 200, epoch: 16 | loss: 0.2558751
	speed: 0.0921s/iter; left time: 1673.7596s
	iters: 300, epoch: 16 | loss: 0.2593078
	speed: 0.1021s/iter; left time: 1844.8755s
	iters: 400, epoch: 16 | loss: 0.2753032
	speed: 0.1321s/iter; left time: 2374.8250s
	iters: 500, epoch: 16 | loss: 0.2358945
	speed: 0.1327s/iter; left time: 2372.9501s
Epoch: 16 cost time: 59.082412242889404
Epoch: 16, Steps: 525 | Train Loss: 0.2891874 Vali Loss: 0.1516596 Test Loss: 0.2165194
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_192_FITS_ETTm2_ftM_sl720_ll48_pl192_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.21731173992156982, mae:0.2916874885559082, rse:0.3773433566093445, corr:[0.56139153 0.56503654 0.5615783  0.55903167 0.55900717 0.560281
 0.560923   0.5602601  0.55912274 0.55849993 0.55870694 0.5593261
 0.55967325 0.55936694 0.5587259  0.5581485  0.5579073  0.557891
 0.5577375  0.55717003 0.5563011  0.5554199  0.5548328  0.5545992
 0.5544948  0.5542335  0.55367696 0.55290043 0.55211097 0.55150235
 0.55110234 0.55086184 0.55055726 0.5499927  0.5492272  0.54847014
 0.5478354  0.5473371  0.546866   0.5463281  0.54569596 0.5449972
 0.54433614 0.5437754  0.54328877 0.54272914 0.5420194  0.5412195
 0.54038715 0.53961194 0.5389747  0.5385155  0.53809094 0.5375442
 0.5368414  0.5361273  0.5354537  0.53482723 0.53426737 0.53376126
 0.5332793  0.5329289  0.5327654  0.5327471  0.5327152  0.5325932
 0.53226537 0.53184897 0.531534   0.5314153  0.53141886 0.5313921
 0.5312143  0.5308889  0.5304459  0.5300062  0.52961344 0.5292133
 0.528696   0.5280294  0.5271524  0.5261988  0.5253439  0.5247132
 0.5242897  0.5240038  0.5236625  0.5232712  0.52284974 0.5224267
 0.5220257  0.52160513 0.5209762  0.52013695 0.5191217  0.5179661
 0.51675725 0.5156124  0.51448274 0.5133414  0.51222515 0.51116246
 0.510204   0.5092675  0.5082245  0.50705546 0.5058771  0.50486994
 0.503986   0.50314337 0.5022448  0.5012144  0.50022715 0.4993972
 0.4987582  0.49829474 0.49783438 0.49711967 0.49614006 0.49493194
 0.4938712  0.49311256 0.49270347 0.49230564 0.49152896 0.49025553
 0.48873943 0.48741207 0.48659658 0.48624727 0.4860166  0.4854731
 0.48450845 0.4833214  0.48225445 0.48153174 0.48106432 0.4806913
 0.48011503 0.47930938 0.47844592 0.47788188 0.4778076  0.47796163
 0.47797975 0.4774679  0.47658515 0.47549045 0.47445038 0.47346768
 0.4725867  0.47181213 0.47101602 0.47016105 0.46939844 0.468897
 0.468539   0.4681919  0.46768084 0.46724027 0.4668826  0.466692
 0.46643832 0.4660253  0.46548983 0.46506923 0.4649123  0.4650781
 0.465344   0.4654005  0.4649169  0.46412593 0.4635851  0.46375602
 0.46446696 0.4649818  0.46473467 0.4636672  0.46220183 0.4615039
 0.46178034 0.4621527  0.46172675 0.46015686 0.45809114 0.4572134
 0.4584685  0.46055278 0.46131328 0.45983306 0.45761412 0.45811346]
