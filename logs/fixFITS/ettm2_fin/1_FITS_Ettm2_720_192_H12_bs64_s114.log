Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_192_FITS_ETTm2_ftM_sl720_ll48_pl192_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=106, out_features=134, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  12726784.0
params:  14338.0
Trainable parameters:  14338
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2895135
	speed: 0.1376s/iter; left time: 1788.3786s
	iters: 200, epoch: 1 | loss: 0.3015109
	speed: 0.1294s/iter; left time: 1669.1679s
Epoch: 1 cost time: 34.80707788467407
Epoch: 1, Steps: 262 | Train Loss: 0.3893810 Vali Loss: 0.1702342 Test Loss: 0.2364438
Validation loss decreased (inf --> 0.170234).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2717505
	speed: 0.6638s/iter; left time: 8456.1760s
	iters: 200, epoch: 2 | loss: 0.2732838
	speed: 0.1626s/iter; left time: 2055.6337s
Epoch: 2 cost time: 43.947224617004395
Epoch: 2, Steps: 262 | Train Loss: 0.3215015 Vali Loss: 0.1607043 Test Loss: 0.2269504
Validation loss decreased (0.170234 --> 0.160704).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2450827
	speed: 0.7839s/iter; left time: 9780.6946s
	iters: 200, epoch: 3 | loss: 0.3240099
	speed: 0.1709s/iter; left time: 2115.7116s
Epoch: 3 cost time: 46.999825954437256
Epoch: 3, Steps: 262 | Train Loss: 0.3080516 Vali Loss: 0.1574759 Test Loss: 0.2235180
Validation loss decreased (0.160704 --> 0.157476).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2380189
	speed: 0.7728s/iter; left time: 9439.4280s
	iters: 200, epoch: 4 | loss: 0.2948342
	speed: 0.1557s/iter; left time: 1886.3677s
Epoch: 4 cost time: 42.35378932952881
Epoch: 4, Steps: 262 | Train Loss: 0.3019621 Vali Loss: 0.1556191 Test Loss: 0.2216034
Validation loss decreased (0.157476 --> 0.155619).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2985784
	speed: 0.6859s/iter; left time: 8198.7964s
	iters: 200, epoch: 5 | loss: 0.2730641
	speed: 0.1392s/iter; left time: 1649.8682s
Epoch: 5 cost time: 38.773112297058105
Epoch: 5, Steps: 262 | Train Loss: 0.2987994 Vali Loss: 0.1542789 Test Loss: 0.2202704
Validation loss decreased (0.155619 --> 0.154279).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2421233
	speed: 0.5008s/iter; left time: 5854.9498s
	iters: 200, epoch: 6 | loss: 0.2810380
	speed: 0.0355s/iter; left time: 411.0633s
Epoch: 6 cost time: 14.721290826797485
Epoch: 6, Steps: 262 | Train Loss: 0.2966210 Vali Loss: 0.1538744 Test Loss: 0.2195554
Validation loss decreased (0.154279 --> 0.153874).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2106277
	speed: 0.1761s/iter; left time: 2012.3715s
	iters: 200, epoch: 7 | loss: 0.2877197
	speed: 0.0321s/iter; left time: 364.1058s
Epoch: 7 cost time: 8.698962926864624
Epoch: 7, Steps: 262 | Train Loss: 0.2945132 Vali Loss: 0.1532838 Test Loss: 0.2191184
Validation loss decreased (0.153874 --> 0.153284).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2345518
	speed: 0.1339s/iter; left time: 1495.2581s
	iters: 200, epoch: 8 | loss: 0.2739143
	speed: 0.0382s/iter; left time: 422.2954s
Epoch: 8 cost time: 10.290771484375
Epoch: 8, Steps: 262 | Train Loss: 0.2940132 Vali Loss: 0.1531042 Test Loss: 0.2186430
Validation loss decreased (0.153284 --> 0.153104).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1921609
	speed: 0.1548s/iter; left time: 1688.1673s
	iters: 200, epoch: 9 | loss: 0.3544983
	speed: 0.1395s/iter; left time: 1507.7220s
Epoch: 9 cost time: 28.099759101867676
Epoch: 9, Steps: 262 | Train Loss: 0.2932710 Vali Loss: 0.1528508 Test Loss: 0.2182440
Validation loss decreased (0.153104 --> 0.152851).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1883151
	speed: 0.6676s/iter; left time: 7105.5744s
	iters: 200, epoch: 10 | loss: 0.2124006
	speed: 0.1232s/iter; left time: 1299.0954s
Epoch: 10 cost time: 34.703726291656494
Epoch: 10, Steps: 262 | Train Loss: 0.2920235 Vali Loss: 0.1526156 Test Loss: 0.2179270
Validation loss decreased (0.152851 --> 0.152616).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3928908
	speed: 0.5173s/iter; left time: 5370.5539s
	iters: 200, epoch: 11 | loss: 0.3245309
	speed: 0.1290s/iter; left time: 1326.2112s
Epoch: 11 cost time: 33.5246684551239
Epoch: 11, Steps: 262 | Train Loss: 0.2918661 Vali Loss: 0.1522871 Test Loss: 0.2174681
Validation loss decreased (0.152616 --> 0.152287).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2897946
	speed: 0.5538s/iter; left time: 5604.1727s
	iters: 200, epoch: 12 | loss: 0.4621712
	speed: 0.1249s/iter; left time: 1251.1535s
Epoch: 12 cost time: 33.04309558868408
Epoch: 12, Steps: 262 | Train Loss: 0.2912052 Vali Loss: 0.1523298 Test Loss: 0.2175749
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2610644
	speed: 0.5560s/iter; left time: 5480.7804s
	iters: 200, epoch: 13 | loss: 0.2609456
	speed: 0.1275s/iter; left time: 1244.1427s
Epoch: 13 cost time: 35.34717893600464
Epoch: 13, Steps: 262 | Train Loss: 0.2912431 Vali Loss: 0.1521436 Test Loss: 0.2174604
Validation loss decreased (0.152287 --> 0.152144).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2741571
	speed: 0.7021s/iter; left time: 6736.4783s
	iters: 200, epoch: 14 | loss: 0.3800809
	speed: 0.1402s/iter; left time: 1331.6398s
Epoch: 14 cost time: 39.782777070999146
Epoch: 14, Steps: 262 | Train Loss: 0.2906541 Vali Loss: 0.1521410 Test Loss: 0.2172802
Validation loss decreased (0.152144 --> 0.152141).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4604097
	speed: 0.6065s/iter; left time: 5660.0952s
	iters: 200, epoch: 15 | loss: 0.2602787
	speed: 0.1144s/iter; left time: 1056.3139s
Epoch: 15 cost time: 32.01489543914795
Epoch: 15, Steps: 262 | Train Loss: 0.2903080 Vali Loss: 0.1520009 Test Loss: 0.2170779
Validation loss decreased (0.152141 --> 0.152001).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2354858
	speed: 0.5742s/iter; left time: 5208.2163s
	iters: 200, epoch: 16 | loss: 0.4033228
	speed: 0.1273s/iter; left time: 1141.5999s
Epoch: 16 cost time: 34.144437074661255
Epoch: 16, Steps: 262 | Train Loss: 0.2901120 Vali Loss: 0.1519430 Test Loss: 0.2168945
Validation loss decreased (0.152001 --> 0.151943).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3115229
	speed: 0.5599s/iter; left time: 4932.4226s
	iters: 200, epoch: 17 | loss: 0.4086264
	speed: 0.1235s/iter; left time: 1075.9479s
Epoch: 17 cost time: 33.9748809337616
Epoch: 17, Steps: 262 | Train Loss: 0.2901215 Vali Loss: 0.1518787 Test Loss: 0.2170218
Validation loss decreased (0.151943 --> 0.151879).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2689221
	speed: 0.5553s/iter; left time: 4745.9352s
	iters: 200, epoch: 18 | loss: 0.3303423
	speed: 0.1266s/iter; left time: 1069.6596s
Epoch: 18 cost time: 33.919464349746704
Epoch: 18, Steps: 262 | Train Loss: 0.2900736 Vali Loss: 0.1520675 Test Loss: 0.2171156
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2655317
	speed: 0.5588s/iter; left time: 4629.9098s
	iters: 200, epoch: 19 | loss: 0.2141183
	speed: 0.1130s/iter; left time: 925.1460s
Epoch: 19 cost time: 31.22193932533264
Epoch: 19, Steps: 262 | Train Loss: 0.2897073 Vali Loss: 0.1518607 Test Loss: 0.2170819
Validation loss decreased (0.151879 --> 0.151861).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4078777
	speed: 0.5206s/iter; left time: 4176.7729s
	iters: 200, epoch: 20 | loss: 0.3219531
	speed: 0.1145s/iter; left time: 907.3209s
Epoch: 20 cost time: 30.785305976867676
Epoch: 20, Steps: 262 | Train Loss: 0.2889296 Vali Loss: 0.1518429 Test Loss: 0.2167719
Validation loss decreased (0.151861 --> 0.151843).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2463792
	speed: 0.5156s/iter; left time: 4001.9137s
	iters: 200, epoch: 21 | loss: 0.2340316
	speed: 0.1148s/iter; left time: 879.6953s
Epoch: 21 cost time: 31.493033409118652
Epoch: 21, Steps: 262 | Train Loss: 0.2896479 Vali Loss: 0.1520522 Test Loss: 0.2170542
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3446279
	speed: 0.5199s/iter; left time: 3898.9073s
	iters: 200, epoch: 22 | loss: 0.2976728
	speed: 0.1134s/iter; left time: 838.8515s
Epoch: 22 cost time: 31.259566068649292
Epoch: 22, Steps: 262 | Train Loss: 0.2894491 Vali Loss: 0.1517691 Test Loss: 0.2168614
Validation loss decreased (0.151843 --> 0.151769).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2259130
	speed: 0.5984s/iter; left time: 4330.4036s
	iters: 200, epoch: 23 | loss: 0.2594057
	speed: 0.1405s/iter; left time: 1003.0125s
Epoch: 23 cost time: 38.574627161026
Epoch: 23, Steps: 262 | Train Loss: 0.2893139 Vali Loss: 0.1517138 Test Loss: 0.2167667
Validation loss decreased (0.151769 --> 0.151714).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2463529
	speed: 0.6315s/iter; left time: 4404.4307s
	iters: 200, epoch: 24 | loss: 0.2798674
	speed: 0.1218s/iter; left time: 837.4383s
Epoch: 24 cost time: 33.597163677215576
Epoch: 24, Steps: 262 | Train Loss: 0.2892503 Vali Loss: 0.1516004 Test Loss: 0.2168116
Validation loss decreased (0.151714 --> 0.151600).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2598157
	speed: 0.5417s/iter; left time: 3636.4735s
	iters: 200, epoch: 25 | loss: 0.2586053
	speed: 0.1236s/iter; left time: 817.4274s
Epoch: 25 cost time: 32.78289842605591
Epoch: 25, Steps: 262 | Train Loss: 0.2891864 Vali Loss: 0.1515553 Test Loss: 0.2167433
Validation loss decreased (0.151600 --> 0.151555).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.4025919
	speed: 0.5393s/iter; left time: 3479.1341s
	iters: 200, epoch: 26 | loss: 0.2651821
	speed: 0.1143s/iter; left time: 725.8420s
Epoch: 26 cost time: 32.490885496139526
Epoch: 26, Steps: 262 | Train Loss: 0.2889998 Vali Loss: 0.1515088 Test Loss: 0.2166209
Validation loss decreased (0.151555 --> 0.151509).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3633060
	speed: 0.5651s/iter; left time: 3497.2423s
	iters: 200, epoch: 27 | loss: 0.2403138
	speed: 0.1184s/iter; left time: 720.8246s
Epoch: 27 cost time: 33.18892455101013
Epoch: 27, Steps: 262 | Train Loss: 0.2888751 Vali Loss: 0.1516108 Test Loss: 0.2166362
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2416933
	speed: 0.5669s/iter; left time: 3359.7806s
	iters: 200, epoch: 28 | loss: 0.2303344
	speed: 0.1303s/iter; left time: 759.3847s
Epoch: 28 cost time: 34.4937379360199
Epoch: 28, Steps: 262 | Train Loss: 0.2885472 Vali Loss: 0.1515734 Test Loss: 0.2165273
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3493220
	speed: 0.5447s/iter; left time: 3085.5939s
	iters: 200, epoch: 29 | loss: 0.3055550
	speed: 0.1182s/iter; left time: 658.0414s
Epoch: 29 cost time: 30.640227794647217
Epoch: 29, Steps: 262 | Train Loss: 0.2886913 Vali Loss: 0.1515914 Test Loss: 0.2165974
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_192_FITS_ETTm2_ftM_sl720_ll48_pl192_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.2171950489282608, mae:0.29158976674079895, rse:0.3772420287132263, corr:[0.56150943 0.56453764 0.5610113  0.55863523 0.5588641  0.5603922
 0.5611977  0.5606148  0.5595354  0.5589707  0.5592116  0.55981547
 0.5601257  0.55981106 0.559186   0.558597   0.558282   0.5581167
 0.55778307 0.5570998  0.5562357  0.5554299  0.5549026  0.5546516
 0.5544446  0.5540665  0.5534779  0.55278516 0.5521357  0.55165166
 0.5513036  0.5510239  0.5506271  0.5499999  0.54924893 0.5485644
 0.5480215  0.5475947  0.54713875 0.5465526  0.5458515  0.54512113
 0.5444899  0.5439979  0.5435906  0.5431112  0.542461   0.54165745
 0.54073846 0.539842   0.5390912  0.5385272  0.5380088  0.5373904
 0.53664    0.53591114 0.5353117  0.534898   0.5346514  0.53447145
 0.53423375 0.53395    0.5336361  0.53333706 0.5330564  0.53283685
 0.5325936  0.53238434 0.5322467  0.5321392  0.5319853  0.53172725
 0.53132623 0.53082573 0.5302892  0.52984864 0.5295206  0.5292052
 0.5287755  0.52820677 0.5274428  0.5266167  0.5258764  0.5253137
 0.52490425 0.5245972  0.5242068  0.5237451  0.5232421  0.5227384
 0.5222687  0.52180386 0.52117336 0.520359   0.5193497  0.5181322
 0.516777   0.5154325  0.5140995  0.5128144  0.51164216 0.51058686
 0.5096461  0.50869715 0.50760454 0.50637287 0.5051707  0.5042185
 0.5034451  0.5027191  0.50189537 0.5008707  0.49982643 0.49891546
 0.49824014 0.49781725 0.49746275 0.49688366 0.49603516 0.49492133
 0.4938906  0.4930901  0.4926076  0.4921765  0.49147403 0.49041748
 0.48926476 0.48836422 0.4878472  0.48750767 0.4870264  0.4861538
 0.48498568 0.48387042 0.48318076 0.4829784  0.48289466 0.48259318
 0.48178622 0.48056468 0.47927624 0.47843176 0.47824028 0.478309
 0.47815207 0.4773783  0.4762781  0.4751946  0.4745157  0.47415483
 0.47389618 0.47350892 0.47278357 0.4717609  0.4707702  0.47015938
 0.46985254 0.4696071  0.4690973  0.46849364 0.46786785 0.46745646
 0.4671387  0.46677935 0.46627676 0.46575165 0.46535668 0.46528324
 0.46546105 0.46563056 0.46535373 0.464642   0.46386155 0.46351013
 0.4636828  0.4638705  0.46354464 0.46257925 0.46131685 0.46083355
 0.46125063 0.46166906 0.46124998 0.45971277 0.45770535 0.4568282
 0.45795062 0.45975253 0.4600381  0.45797938 0.45601696 0.4584785 ]
