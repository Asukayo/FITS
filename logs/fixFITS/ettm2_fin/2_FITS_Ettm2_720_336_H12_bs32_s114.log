Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_336', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_336_FITS_ETTm2_ftM_sl720_ll48_pl336_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=106, out_features=155, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  7360640.0
params:  16585.0
Trainable parameters:  16585
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3163498
	speed: 0.1442s/iter; left time: 3756.5212s
	iters: 200, epoch: 1 | loss: 0.2468933
	speed: 0.1495s/iter; left time: 3878.6073s
	iters: 300, epoch: 1 | loss: 0.2555059
	speed: 0.1510s/iter; left time: 3904.1854s
	iters: 400, epoch: 1 | loss: 0.1758936
	speed: 0.1452s/iter; left time: 3738.7709s
	iters: 500, epoch: 1 | loss: 0.2157803
	speed: 0.1392s/iter; left time: 3571.8122s
Epoch: 1 cost time: 76.52316880226135
Epoch: 1, Steps: 523 | Train Loss: 0.2711079 Vali Loss: 0.2188288 Test Loss: 0.2950081
Validation loss decreased (inf --> 0.218829).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1606984
	speed: 0.9403s/iter; left time: 24003.1253s
	iters: 200, epoch: 2 | loss: 0.1169860
	speed: 0.1069s/iter; left time: 2717.5860s
	iters: 300, epoch: 2 | loss: 0.1159063
	speed: 0.1027s/iter; left time: 2601.1072s
	iters: 400, epoch: 2 | loss: 0.1586665
	speed: 0.1073s/iter; left time: 2707.4126s
	iters: 500, epoch: 2 | loss: 0.1003894
	speed: 0.1030s/iter; left time: 2587.9471s
Epoch: 2 cost time: 56.89329671859741
Epoch: 2, Steps: 523 | Train Loss: 0.1637007 Vali Loss: 0.2056427 Test Loss: 0.2798996
Validation loss decreased (0.218829 --> 0.205643).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1380626
	speed: 0.6905s/iter; left time: 17267.1305s
	iters: 200, epoch: 3 | loss: 0.1074902
	speed: 0.1062s/iter; left time: 2644.8359s
	iters: 300, epoch: 3 | loss: 0.1146795
	speed: 0.2276s/iter; left time: 5645.1481s
	iters: 400, epoch: 3 | loss: 0.1148847
	speed: 0.1627s/iter; left time: 4019.4533s
	iters: 500, epoch: 3 | loss: 0.1635016
	speed: 0.1466s/iter; left time: 3608.0070s
Epoch: 3 cost time: 81.23523283004761
Epoch: 3, Steps: 523 | Train Loss: 0.1402175 Vali Loss: 0.2001338 Test Loss: 0.2750279
Validation loss decreased (0.205643 --> 0.200134).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1159937
	speed: 1.2271s/iter; left time: 30041.0206s
	iters: 200, epoch: 4 | loss: 0.1724716
	speed: 0.1450s/iter; left time: 3535.8018s
	iters: 300, epoch: 4 | loss: 0.1854769
	speed: 0.1459s/iter; left time: 3542.1754s
	iters: 400, epoch: 4 | loss: 0.0791756
	speed: 0.1575s/iter; left time: 3808.2204s
	iters: 500, epoch: 4 | loss: 0.1267887
	speed: 0.1411s/iter; left time: 3397.8121s
Epoch: 4 cost time: 78.47722744941711
Epoch: 4, Steps: 523 | Train Loss: 0.1332324 Vali Loss: 0.1977405 Test Loss: 0.2732849
Validation loss decreased (0.200134 --> 0.197740).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1445489
	speed: 1.4353s/iter; left time: 34387.2982s
	iters: 200, epoch: 5 | loss: 0.1317550
	speed: 0.1112s/iter; left time: 2653.9904s
	iters: 300, epoch: 5 | loss: 0.1741990
	speed: 0.1106s/iter; left time: 2626.8629s
	iters: 400, epoch: 5 | loss: 0.0927982
	speed: 0.1151s/iter; left time: 2722.7335s
	iters: 500, epoch: 5 | loss: 0.2043943
	speed: 0.1042s/iter; left time: 2455.2477s
Epoch: 5 cost time: 59.03679370880127
Epoch: 5, Steps: 523 | Train Loss: 0.1314232 Vali Loss: 0.1969040 Test Loss: 0.2730805
Validation loss decreased (0.197740 --> 0.196904).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1366931
	speed: 0.7332s/iter; left time: 17183.5951s
	iters: 200, epoch: 6 | loss: 0.1137979
	speed: 0.1126s/iter; left time: 2626.8969s
	iters: 300, epoch: 6 | loss: 0.0902025
	speed: 0.1099s/iter; left time: 2553.1651s
	iters: 400, epoch: 6 | loss: 0.1242649
	speed: 0.1058s/iter; left time: 2448.0392s
	iters: 500, epoch: 6 | loss: 0.0880670
	speed: 0.1106s/iter; left time: 2548.2039s
Epoch: 6 cost time: 58.64672088623047
Epoch: 6, Steps: 523 | Train Loss: 0.1307440 Vali Loss: 0.1966875 Test Loss: 0.2730048
Validation loss decreased (0.196904 --> 0.196688).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1555671
	speed: 0.7126s/iter; left time: 16327.4169s
	iters: 200, epoch: 7 | loss: 0.1440452
	speed: 0.1357s/iter; left time: 3095.8144s
	iters: 300, epoch: 7 | loss: 0.1678420
	speed: 0.1382s/iter; left time: 3138.0474s
	iters: 400, epoch: 7 | loss: 0.1626816
	speed: 0.1317s/iter; left time: 2979.2184s
	iters: 500, epoch: 7 | loss: 0.1299633
	speed: 0.1318s/iter; left time: 2966.2287s
Epoch: 7 cost time: 68.34098100662231
Epoch: 7, Steps: 523 | Train Loss: 0.1305691 Vali Loss: 0.1964727 Test Loss: 0.2729926
Validation loss decreased (0.196688 --> 0.196473).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2231074
	speed: 0.9409s/iter; left time: 21067.7206s
	iters: 200, epoch: 8 | loss: 0.1364078
	speed: 0.1310s/iter; left time: 2920.6666s
	iters: 300, epoch: 8 | loss: 0.1564070
	speed: 0.1146s/iter; left time: 2542.5530s
	iters: 400, epoch: 8 | loss: 0.1669362
	speed: 0.1233s/iter; left time: 2724.5688s
	iters: 500, epoch: 8 | loss: 0.2417170
	speed: 0.1206s/iter; left time: 2652.3488s
Epoch: 8 cost time: 65.65798735618591
Epoch: 8, Steps: 523 | Train Loss: 0.1305380 Vali Loss: 0.1962238 Test Loss: 0.2729792
Validation loss decreased (0.196473 --> 0.196224).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1460547
	speed: 0.7334s/iter; left time: 16036.9444s
	iters: 200, epoch: 9 | loss: 0.1143876
	speed: 0.1201s/iter; left time: 2614.4110s
	iters: 300, epoch: 9 | loss: 0.1758514
	speed: 0.1135s/iter; left time: 2458.5327s
	iters: 400, epoch: 9 | loss: 0.1499270
	speed: 0.1246s/iter; left time: 2688.2501s
	iters: 500, epoch: 9 | loss: 0.0795892
	speed: 0.1286s/iter; left time: 2760.2584s
Epoch: 9 cost time: 66.0394241809845
Epoch: 9, Steps: 523 | Train Loss: 0.1304775 Vali Loss: 0.1963321 Test Loss: 0.2731687
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1162829
	speed: 0.8257s/iter; left time: 17623.6622s
	iters: 200, epoch: 10 | loss: 0.1276010
	speed: 0.1360s/iter; left time: 2889.6315s
	iters: 300, epoch: 10 | loss: 0.1305481
	speed: 0.1476s/iter; left time: 3120.2975s
	iters: 400, epoch: 10 | loss: 0.0936165
	speed: 0.1484s/iter; left time: 3123.4304s
	iters: 500, epoch: 10 | loss: 0.0696586
	speed: 0.1346s/iter; left time: 2818.0183s
Epoch: 10 cost time: 72.80865287780762
Epoch: 10, Steps: 523 | Train Loss: 0.1302787 Vali Loss: 0.1962777 Test Loss: 0.2729257
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1256934
	speed: 0.8952s/iter; left time: 18639.5033s
	iters: 200, epoch: 11 | loss: 0.1109752
	speed: 0.1365s/iter; left time: 2827.4282s
	iters: 300, epoch: 11 | loss: 0.1045343
	speed: 0.1405s/iter; left time: 2897.2058s
	iters: 400, epoch: 11 | loss: 0.0781031
	speed: 0.1221s/iter; left time: 2506.5788s
	iters: 500, epoch: 11 | loss: 0.1466987
	speed: 0.1192s/iter; left time: 2434.6377s
Epoch: 11 cost time: 70.00882124900818
Epoch: 11, Steps: 523 | Train Loss: 0.1304144 Vali Loss: 0.1963664 Test Loss: 0.2730931
EarlyStopping counter: 3 out of 3
Early stopping
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=106, out_features=155, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  7360640.0
params:  16585.0
Trainable parameters:  16585
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3072366
	speed: 0.1226s/iter; left time: 3193.0680s
	iters: 200, epoch: 1 | loss: 0.4219988
	speed: 0.1302s/iter; left time: 3377.7513s
	iters: 300, epoch: 1 | loss: 0.3269592
	speed: 0.1398s/iter; left time: 3613.0324s
	iters: 400, epoch: 1 | loss: 0.3969497
	speed: 0.1441s/iter; left time: 3710.3425s
	iters: 500, epoch: 1 | loss: 0.4733024
	speed: 0.1444s/iter; left time: 3702.9966s
Epoch: 1 cost time: 71.86052107810974
Epoch: 1, Steps: 523 | Train Loss: 0.3798635 Vali Loss: 0.1938480 Test Loss: 0.2700847
Validation loss decreased (inf --> 0.193848).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2776707
	speed: 1.0572s/iter; left time: 26987.1756s
	iters: 200, epoch: 2 | loss: 0.5215737
	speed: 0.1283s/iter; left time: 3263.2310s
	iters: 300, epoch: 2 | loss: 0.4133046
	speed: 0.1384s/iter; left time: 3506.3614s
	iters: 400, epoch: 2 | loss: 0.2327382
	speed: 0.1383s/iter; left time: 3490.0116s
	iters: 500, epoch: 2 | loss: 0.5482299
	speed: 0.1517s/iter; left time: 3811.6820s
Epoch: 2 cost time: 73.76255297660828
Epoch: 2, Steps: 523 | Train Loss: 0.3776233 Vali Loss: 0.1935625 Test Loss: 0.2697464
Validation loss decreased (0.193848 --> 0.193563).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3355291
	speed: 0.9597s/iter; left time: 23996.1805s
	iters: 200, epoch: 3 | loss: 0.5597392
	speed: 0.1598s/iter; left time: 3979.9859s
	iters: 300, epoch: 3 | loss: 0.4361235
	speed: 0.1534s/iter; left time: 3805.5487s
	iters: 400, epoch: 3 | loss: 0.2689333
	speed: 0.1525s/iter; left time: 3767.0073s
	iters: 500, epoch: 3 | loss: 0.4429506
	speed: 0.1273s/iter; left time: 3132.3103s
Epoch: 3 cost time: 78.10122561454773
Epoch: 3, Steps: 523 | Train Loss: 0.3766296 Vali Loss: 0.1929423 Test Loss: 0.2689957
Validation loss decreased (0.193563 --> 0.192942).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2525471
	speed: 1.0065s/iter; left time: 24641.5090s
	iters: 200, epoch: 4 | loss: 0.6063483
	speed: 0.1253s/iter; left time: 3056.1825s
	iters: 300, epoch: 4 | loss: 0.5024050
	speed: 0.1191s/iter; left time: 2890.9259s
	iters: 400, epoch: 4 | loss: 0.6621556
	speed: 0.1271s/iter; left time: 3073.3187s
	iters: 500, epoch: 4 | loss: 0.3605854
	speed: 0.1216s/iter; left time: 2928.1400s
Epoch: 4 cost time: 67.14397668838501
Epoch: 4, Steps: 523 | Train Loss: 0.3759147 Vali Loss: 0.1929310 Test Loss: 0.2690708
Validation loss decreased (0.192942 --> 0.192931).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3028752
	speed: 0.8088s/iter; left time: 19378.0023s
	iters: 200, epoch: 5 | loss: 0.3833500
	speed: 0.1297s/iter; left time: 3094.1083s
	iters: 300, epoch: 5 | loss: 0.3102112
	speed: 0.1180s/iter; left time: 2802.7996s
	iters: 400, epoch: 5 | loss: 0.3095438
	speed: 0.1295s/iter; left time: 3064.4957s
	iters: 500, epoch: 5 | loss: 0.2931529
	speed: 0.1114s/iter; left time: 2625.2517s
Epoch: 5 cost time: 66.05088996887207
Epoch: 5, Steps: 523 | Train Loss: 0.3755191 Vali Loss: 0.1928998 Test Loss: 0.2688789
Validation loss decreased (0.192931 --> 0.192900).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3226562
	speed: 0.7544s/iter; left time: 17680.6626s
	iters: 200, epoch: 6 | loss: 0.4885862
	speed: 0.1149s/iter; left time: 2681.1908s
	iters: 300, epoch: 6 | loss: 0.5747409
	speed: 0.1152s/iter; left time: 2675.9588s
	iters: 400, epoch: 6 | loss: 0.3597810
	speed: 0.1161s/iter; left time: 2685.6004s
	iters: 500, epoch: 6 | loss: 0.2627922
	speed: 0.1129s/iter; left time: 2601.5345s
Epoch: 6 cost time: 61.43321442604065
Epoch: 6, Steps: 523 | Train Loss: 0.3750915 Vali Loss: 0.1930072 Test Loss: 0.2688353
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2790461
	speed: 0.7136s/iter; left time: 16351.7932s
	iters: 200, epoch: 7 | loss: 0.6375061
	speed: 0.1211s/iter; left time: 2762.3039s
	iters: 300, epoch: 7 | loss: 0.5531481
	speed: 0.1223s/iter; left time: 2777.4620s
	iters: 400, epoch: 7 | loss: 0.4543594
	speed: 0.1151s/iter; left time: 2602.8775s
	iters: 500, epoch: 7 | loss: 0.2847976
	speed: 0.1123s/iter; left time: 2528.7558s
Epoch: 7 cost time: 61.599894523620605
Epoch: 7, Steps: 523 | Train Loss: 0.3749199 Vali Loss: 0.1925297 Test Loss: 0.2683803
Validation loss decreased (0.192900 --> 0.192530).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3906085
	speed: 0.8633s/iter; left time: 19330.2592s
	iters: 200, epoch: 8 | loss: 0.3641668
	speed: 0.1270s/iter; left time: 2831.2648s
	iters: 300, epoch: 8 | loss: 0.6686378
	speed: 0.1286s/iter; left time: 2854.3097s
	iters: 400, epoch: 8 | loss: 0.3060072
	speed: 0.1196s/iter; left time: 2642.0465s
	iters: 500, epoch: 8 | loss: 0.2728541
	speed: 0.1359s/iter; left time: 2988.2121s
Epoch: 8 cost time: 67.47408294677734
Epoch: 8, Steps: 523 | Train Loss: 0.3745856 Vali Loss: 0.1925793 Test Loss: 0.2686205
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3000861
	speed: 0.8970s/iter; left time: 19614.3221s
	iters: 200, epoch: 9 | loss: 0.3124298
	speed: 0.1350s/iter; left time: 2938.1454s
	iters: 300, epoch: 9 | loss: 0.3705199
	speed: 0.1259s/iter; left time: 2727.0445s
	iters: 400, epoch: 9 | loss: 0.4265900
	speed: 0.1195s/iter; left time: 2577.5642s
	iters: 500, epoch: 9 | loss: 0.6225901
	speed: 0.1295s/iter; left time: 2780.8269s
Epoch: 9 cost time: 67.72184133529663
Epoch: 9, Steps: 523 | Train Loss: 0.3745143 Vali Loss: 0.1924762 Test Loss: 0.2684238
Validation loss decreased (0.192530 --> 0.192476).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.7303438
	speed: 0.8892s/iter; left time: 18978.0800s
	iters: 200, epoch: 10 | loss: 0.6056582
	speed: 0.1398s/iter; left time: 2970.4299s
	iters: 300, epoch: 10 | loss: 0.4743565
	speed: 0.1449s/iter; left time: 3063.3023s
	iters: 400, epoch: 10 | loss: 0.3754052
	speed: 0.1553s/iter; left time: 3268.1108s
	iters: 500, epoch: 10 | loss: 0.4535705
	speed: 0.1445s/iter; left time: 3027.4232s
Epoch: 10 cost time: 77.03439331054688
Epoch: 10, Steps: 523 | Train Loss: 0.3743702 Vali Loss: 0.1928181 Test Loss: 0.2689562
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4882458
	speed: 0.8792s/iter; left time: 18305.2875s
	iters: 200, epoch: 11 | loss: 0.4653569
	speed: 0.1184s/iter; left time: 2454.3506s
	iters: 300, epoch: 11 | loss: 0.3737412
	speed: 0.1248s/iter; left time: 2573.8069s
	iters: 400, epoch: 11 | loss: 0.5110450
	speed: 0.1093s/iter; left time: 2242.8784s
	iters: 500, epoch: 11 | loss: 0.3605305
	speed: 0.1248s/iter; left time: 2548.1414s
Epoch: 11 cost time: 64.49120116233826
Epoch: 11, Steps: 523 | Train Loss: 0.3744061 Vali Loss: 0.1922314 Test Loss: 0.2682095
Validation loss decreased (0.192476 --> 0.192231).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1965849
	speed: 0.8492s/iter; left time: 17237.8950s
	iters: 200, epoch: 12 | loss: 0.5543895
	speed: 0.1280s/iter; left time: 2586.2707s
	iters: 300, epoch: 12 | loss: 0.3962655
	speed: 0.1265s/iter; left time: 2542.1621s
	iters: 400, epoch: 12 | loss: 0.3825542
	speed: 0.1242s/iter; left time: 2484.0991s
	iters: 500, epoch: 12 | loss: 0.2377846
	speed: 0.1334s/iter; left time: 2655.3025s
Epoch: 12 cost time: 68.49681186676025
Epoch: 12, Steps: 523 | Train Loss: 0.3742203 Vali Loss: 0.1926178 Test Loss: 0.2686641
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3862050
	speed: 0.9121s/iter; left time: 18037.4313s
	iters: 200, epoch: 13 | loss: 0.3230151
	speed: 0.1511s/iter; left time: 2972.8632s
	iters: 300, epoch: 13 | loss: 0.2849204
	speed: 0.1396s/iter; left time: 2733.5154s
	iters: 400, epoch: 13 | loss: 0.3927253
	speed: 0.1244s/iter; left time: 2423.3421s
	iters: 500, epoch: 13 | loss: 0.1962913
	speed: 0.1391s/iter; left time: 2695.7679s
Epoch: 13 cost time: 72.36930918693542
Epoch: 13, Steps: 523 | Train Loss: 0.3738258 Vali Loss: 0.1922649 Test Loss: 0.2682622
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4878821
	speed: 0.8737s/iter; left time: 16819.6086s
	iters: 200, epoch: 14 | loss: 0.3291247
	speed: 0.1258s/iter; left time: 2409.0797s
	iters: 300, epoch: 14 | loss: 0.3985799
	speed: 0.1230s/iter; left time: 2343.8996s
	iters: 400, epoch: 14 | loss: 0.2979383
	speed: 0.1199s/iter; left time: 2271.4032s
	iters: 500, epoch: 14 | loss: 0.3371602
	speed: 0.1214s/iter; left time: 2289.3552s
Epoch: 14 cost time: 64.2714946269989
Epoch: 14, Steps: 523 | Train Loss: 0.3740894 Vali Loss: 0.1923461 Test Loss: 0.2685303
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_336_FITS_ETTm2_ftM_sl720_ll48_pl336_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.26840394735336304, mae:0.3260165750980377, rse:0.4184611141681671, corr:[0.5582922  0.55955446 0.5566903  0.55454767 0.5543978  0.55535936
 0.5557628  0.55490106 0.55357605 0.5527984  0.5529123  0.5535269
 0.55388546 0.5534774  0.5525921  0.5517206  0.5512057  0.5509857
 0.5506746  0.5499585  0.54892147 0.5479033  0.5472779  0.5471519
 0.5472571  0.5472061  0.5467741  0.54603195 0.5452376  0.54465324
 0.54432976 0.5441754  0.5439022  0.54331136 0.5424995  0.5417191
 0.5411006  0.5406631  0.54025024 0.5397187  0.5390369  0.5382588
 0.5375199  0.5368971  0.5363787  0.53584534 0.53522074 0.53450847
 0.5337213  0.53295475 0.53230333 0.53179437 0.5312649  0.5305678
 0.5296801  0.5287357  0.52785367 0.5271497  0.526699   0.5264741
 0.5263729  0.5263587  0.5263657  0.52633786 0.52625966 0.5261459
 0.52593666 0.5256917  0.52547914 0.5253169  0.5251675  0.5249914
 0.52472717 0.52437    0.5239095  0.5234353  0.5229747  0.52250683
 0.5219606  0.521351   0.5206314  0.5199428  0.51936704 0.51890886
 0.5184806  0.51794183 0.5171795  0.5162946  0.51551276 0.5150683
 0.51502115 0.51514435 0.5150366  0.5144349  0.5132642  0.51164234
 0.50990635 0.5084296  0.5072647  0.5063029  0.50538605 0.50440484
 0.50337243 0.50230485 0.5012611  0.5002299  0.4992413  0.49832347
 0.4974603  0.49666676 0.49595267 0.49524814 0.4945097  0.49363673
 0.49261534 0.49161774 0.49081004 0.4901532  0.48955345 0.48878905
 0.4878656  0.48682246 0.4858907  0.48517507 0.4846007  0.48397315
 0.483135   0.48199853 0.48065886 0.47938037 0.47840998 0.47775847
 0.47726825 0.4767204  0.475998   0.475191   0.47452328 0.47421503
 0.47416633 0.47411326 0.47374684 0.47294647 0.47181556 0.47057128
 0.46954477 0.468801   0.46832147 0.46785173 0.46725565 0.4665218
 0.46585152 0.46542576 0.465107   0.46465144 0.4639394  0.4630799
 0.46223915 0.4615915  0.46111873 0.46071026 0.46006855 0.45910677
 0.4579771  0.4571564  0.45706394 0.45770544 0.45854533 0.45901224
 0.45884135 0.4581781  0.45733306 0.45677245 0.45669565 0.45686918
 0.45685965 0.4563732  0.45545372 0.4544771  0.4538695  0.45392612
 0.4543106  0.4544795  0.45412502 0.4532105  0.4519938  0.45087698
 0.4501649  0.44984245 0.44955984 0.44893205 0.4478213  0.4463981
 0.44505802 0.44419166 0.44366497 0.44315755 0.44244593 0.44135797
 0.43995443 0.43836695 0.43680626 0.43539813 0.43423557 0.43331817
 0.4325626  0.43177798 0.4307356  0.42936137 0.4278805  0.42664915
 0.42575568 0.42521694 0.42489052 0.42451254 0.4238882  0.42286578
 0.4215641  0.4202085  0.4190819  0.41811427 0.41699657 0.4155654
 0.4138744  0.4122593  0.41114023 0.410485   0.41007254 0.40959162
 0.4087401  0.4077183  0.4068812  0.40660775 0.40682167 0.4070829
 0.40678957 0.40565875 0.40377828 0.4018003  0.400617   0.4006164
 0.40145725 0.40223315 0.4023182  0.4017032  0.4006103  0.39967367
 0.3993159  0.39947474 0.39961603 0.3992265  0.39836332 0.39736125
 0.39670688 0.3967652  0.39728796 0.39792013 0.39825338 0.3982409
 0.39805016 0.39791778 0.39793435 0.39799133 0.39783484 0.39735743
 0.3965833  0.39568081 0.395041   0.3948437  0.39498287 0.39520296
 0.39530358 0.39524204 0.39492062 0.39445198 0.39391673 0.39347008
 0.39339203 0.39360344 0.39391053 0.3940979  0.39385346 0.39315218
 0.39216778 0.39131263 0.3909316  0.39099476 0.39106658 0.39045542
 0.3889621  0.38708773 0.38541597 0.38448015 0.3843866  0.3845789
 0.3844688  0.38362965 0.3822074  0.38090575 0.38052875 0.3809723
 0.3817213  0.38188824 0.38112727 0.37958458 0.37822357 0.3779691
 0.37896815 0.38031352 0.38114768 0.3810692  0.38031745 0.3798026
 0.37988624 0.38045287 0.38076103 0.38022074 0.37893412 0.37764952
 0.3771398  0.37769336 0.37870368 0.379253   0.3788105  0.37777427
 0.37701634 0.3772165  0.37812036 0.3786253  0.37802395 0.3762788
 0.37461865 0.3740556  0.37444523 0.37432507 0.3711035  0.36301246]
