Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_192_FITS_ETTm2_ftM_sl720_ll48_pl192_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=106, out_features=134, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6363392.0
params:  14338.0
Trainable parameters:  14338
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2379982
	speed: 0.1486s/iter; left time: 3884.7986s
	iters: 200, epoch: 1 | loss: 0.1867836
	speed: 0.1341s/iter; left time: 3493.3937s
	iters: 300, epoch: 1 | loss: 0.1701245
	speed: 0.1352s/iter; left time: 3509.2715s
	iters: 400, epoch: 1 | loss: 0.1328635
	speed: 0.1109s/iter; left time: 2865.6646s
	iters: 500, epoch: 1 | loss: 0.1827962
	speed: 0.1188s/iter; left time: 3059.6282s
Epoch: 1 cost time: 67.55050134658813
Epoch: 1, Steps: 525 | Train Loss: 0.2341841 Vali Loss: 0.1861277 Test Loss: 0.2513815
Validation loss decreased (inf --> 0.186128).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1638450
	speed: 0.8108s/iter; left time: 20776.8230s
	iters: 200, epoch: 2 | loss: 0.1449643
	speed: 0.1203s/iter; left time: 3071.6239s
	iters: 300, epoch: 2 | loss: 0.1134560
	speed: 0.1100s/iter; left time: 2795.7112s
	iters: 400, epoch: 2 | loss: 0.1241539
	speed: 0.1072s/iter; left time: 2715.7714s
	iters: 500, epoch: 2 | loss: 0.0617232
	speed: 0.1131s/iter; left time: 2853.4029s
Epoch: 2 cost time: 60.30679512023926
Epoch: 2, Steps: 525 | Train Loss: 0.1189011 Vali Loss: 0.1714870 Test Loss: 0.2358741
Validation loss decreased (0.186128 --> 0.171487).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.0821306
	speed: 0.8062s/iter; left time: 20236.1144s
	iters: 200, epoch: 3 | loss: 0.0703169
	speed: 0.1266s/iter; left time: 3164.4428s
	iters: 300, epoch: 3 | loss: 0.0703290
	speed: 0.1148s/iter; left time: 2857.5857s
	iters: 400, epoch: 3 | loss: 0.1161440
	speed: 0.1220s/iter; left time: 3025.0195s
	iters: 500, epoch: 3 | loss: 0.0551580
	speed: 0.1278s/iter; left time: 3157.8645s
Epoch: 3 cost time: 67.0981650352478
Epoch: 3, Steps: 525 | Train Loss: 0.0891512 Vali Loss: 0.1629487 Test Loss: 0.2278741
Validation loss decreased (0.171487 --> 0.162949).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.0508070
	speed: 0.8835s/iter; left time: 21711.6789s
	iters: 200, epoch: 4 | loss: 0.0651393
	speed: 0.1216s/iter; left time: 2976.7200s
	iters: 300, epoch: 4 | loss: 0.0633465
	speed: 0.1221s/iter; left time: 2976.2658s
	iters: 400, epoch: 4 | loss: 0.0775295
	speed: 0.0794s/iter; left time: 1927.0909s
	iters: 500, epoch: 4 | loss: 0.0521271
	speed: 0.0909s/iter; left time: 2198.4455s
Epoch: 4 cost time: 55.814587116241455
Epoch: 4, Steps: 525 | Train Loss: 0.0785085 Vali Loss: 0.1586045 Test Loss: 0.2240216
Validation loss decreased (0.162949 --> 0.158604).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.0799894
	speed: 0.8267s/iter; left time: 19882.7760s
	iters: 200, epoch: 5 | loss: 0.0882713
	speed: 0.1108s/iter; left time: 2654.8484s
	iters: 300, epoch: 5 | loss: 0.1100760
	speed: 0.1190s/iter; left time: 2838.3453s
	iters: 400, epoch: 5 | loss: 0.0927976
	speed: 0.1110s/iter; left time: 2637.1168s
	iters: 500, epoch: 5 | loss: 0.0757832
	speed: 0.1037s/iter; left time: 2453.2682s
Epoch: 5 cost time: 58.830373764038086
Epoch: 5, Steps: 525 | Train Loss: 0.0746034 Vali Loss: 0.1564832 Test Loss: 0.2223327
Validation loss decreased (0.158604 --> 0.156483).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1234328
	speed: 0.7602s/iter; left time: 17884.6470s
	iters: 200, epoch: 6 | loss: 0.0686471
	speed: 0.1442s/iter; left time: 3377.1945s
	iters: 300, epoch: 6 | loss: 0.0487941
	speed: 0.1310s/iter; left time: 3055.5930s
	iters: 400, epoch: 6 | loss: 0.0630403
	speed: 0.1185s/iter; left time: 2752.0116s
	iters: 500, epoch: 6 | loss: 0.0476822
	speed: 0.1176s/iter; left time: 2719.3386s
Epoch: 6 cost time: 67.83329606056213
Epoch: 6, Steps: 525 | Train Loss: 0.0733373 Vali Loss: 0.1556484 Test Loss: 0.2217615
Validation loss decreased (0.156483 --> 0.155648).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.0715669
	speed: 0.8655s/iter; left time: 19908.1223s
	iters: 200, epoch: 7 | loss: 0.1110544
	speed: 0.1189s/iter; left time: 2723.4020s
	iters: 300, epoch: 7 | loss: 0.0933992
	speed: 0.1264s/iter; left time: 2881.7627s
	iters: 400, epoch: 7 | loss: 0.0697269
	speed: 0.1131s/iter; left time: 2566.7155s
	iters: 500, epoch: 7 | loss: 0.0608737
	speed: 0.1238s/iter; left time: 2798.1101s
Epoch: 7 cost time: 64.8419737815857
Epoch: 7, Steps: 525 | Train Loss: 0.0729412 Vali Loss: 0.1552373 Test Loss: 0.2212497
Validation loss decreased (0.155648 --> 0.155237).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.0689545
	speed: 0.7380s/iter; left time: 16587.7711s
	iters: 200, epoch: 8 | loss: 0.0503219
	speed: 0.1083s/iter; left time: 2423.0568s
	iters: 300, epoch: 8 | loss: 0.0680577
	speed: 0.1082s/iter; left time: 2411.2868s
	iters: 400, epoch: 8 | loss: 0.0860833
	speed: 0.1088s/iter; left time: 2412.7205s
	iters: 500, epoch: 8 | loss: 0.0824570
	speed: 0.1023s/iter; left time: 2259.1202s
Epoch: 8 cost time: 58.02470588684082
Epoch: 8, Steps: 525 | Train Loss: 0.0728289 Vali Loss: 0.1552552 Test Loss: 0.2214989
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.0707680
	speed: 0.9061s/iter; left time: 19889.6011s
	iters: 200, epoch: 9 | loss: 0.0573151
	speed: 0.1008s/iter; left time: 2203.3262s
	iters: 300, epoch: 9 | loss: 0.1060793
	speed: 0.1015s/iter; left time: 2206.6957s
	iters: 400, epoch: 9 | loss: 0.0831793
	speed: 0.1011s/iter; left time: 2188.8390s
	iters: 500, epoch: 9 | loss: 0.0362068
	speed: 0.1171s/iter; left time: 2523.4051s
Epoch: 9 cost time: 55.538862228393555
Epoch: 9, Steps: 525 | Train Loss: 0.0726932 Vali Loss: 0.1553308 Test Loss: 0.2215859
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.0795157
	speed: 1.1605s/iter; left time: 24865.5129s
	iters: 200, epoch: 10 | loss: 0.0731185
	speed: 0.1222s/iter; left time: 2605.7654s
	iters: 300, epoch: 10 | loss: 0.0503717
	speed: 0.1661s/iter; left time: 3526.1336s
	iters: 400, epoch: 10 | loss: 0.0606094
	speed: 0.1744s/iter; left time: 3683.3971s
	iters: 500, epoch: 10 | loss: 0.0456829
	speed: 0.1614s/iter; left time: 3393.9552s
Epoch: 10 cost time: 79.2532069683075
Epoch: 10, Steps: 525 | Train Loss: 0.0726902 Vali Loss: 0.1552857 Test Loss: 0.2215694
EarlyStopping counter: 3 out of 3
Early stopping
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=106, out_features=134, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6363392.0
params:  14338.0
Trainable parameters:  14338
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3219008
	speed: 0.1063s/iter; left time: 2779.7960s
	iters: 200, epoch: 1 | loss: 0.3426977
	speed: 0.0983s/iter; left time: 2561.1818s
	iters: 300, epoch: 1 | loss: 0.1909645
	speed: 0.1008s/iter; left time: 2616.3045s
	iters: 400, epoch: 1 | loss: 0.4626060
	speed: 0.0928s/iter; left time: 2397.7400s
	iters: 500, epoch: 1 | loss: 0.1436799
	speed: 0.0928s/iter; left time: 2390.3021s
Epoch: 1 cost time: 51.51361322402954
Epoch: 1, Steps: 525 | Train Loss: 0.2948431 Vali Loss: 0.1524586 Test Loss: 0.2181211
Validation loss decreased (inf --> 0.152459).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2791563
	speed: 1.0313s/iter; left time: 26427.4067s
	iters: 200, epoch: 2 | loss: 0.2060680
	speed: 0.1893s/iter; left time: 4832.4938s
	iters: 300, epoch: 2 | loss: 0.4491131
	speed: 0.1828s/iter; left time: 4647.8595s
	iters: 400, epoch: 2 | loss: 0.4336121
	speed: 0.1917s/iter; left time: 4854.3653s
	iters: 500, epoch: 2 | loss: 0.2917760
	speed: 0.2045s/iter; left time: 5158.2217s
Epoch: 2 cost time: 91.98054647445679
Epoch: 2, Steps: 525 | Train Loss: 0.2920406 Vali Loss: 0.1520351 Test Loss: 0.2178689
Validation loss decreased (0.152459 --> 0.152035).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2556697
	speed: 0.8598s/iter; left time: 21583.0316s
	iters: 200, epoch: 3 | loss: 0.2927101
	speed: 0.1240s/iter; left time: 3101.0340s
	iters: 300, epoch: 3 | loss: 0.2349677
	speed: 0.1268s/iter; left time: 3158.0509s
	iters: 400, epoch: 3 | loss: 0.3311834
	speed: 0.1234s/iter; left time: 3061.1619s
	iters: 500, epoch: 3 | loss: 0.4589426
	speed: 0.1108s/iter; left time: 2737.6022s
Epoch: 3 cost time: 63.8136625289917
Epoch: 3, Steps: 525 | Train Loss: 0.2909793 Vali Loss: 0.1519028 Test Loss: 0.2173480
Validation loss decreased (0.152035 --> 0.151903).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3157602
	speed: 0.4807s/iter; left time: 11812.9279s
	iters: 200, epoch: 4 | loss: 0.2370728
	speed: 0.1037s/iter; left time: 2538.8192s
	iters: 300, epoch: 4 | loss: 0.2996008
	speed: 0.0953s/iter; left time: 2323.2404s
	iters: 400, epoch: 4 | loss: 0.3356366
	speed: 0.1127s/iter; left time: 2736.3005s
	iters: 500, epoch: 4 | loss: 0.1965152
	speed: 0.1073s/iter; left time: 2594.7940s
Epoch: 4 cost time: 55.90307378768921
Epoch: 4, Steps: 525 | Train Loss: 0.2902287 Vali Loss: 0.1517857 Test Loss: 0.2167790
Validation loss decreased (0.151903 --> 0.151786).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2701109
	speed: 0.7121s/iter; left time: 17126.6036s
	iters: 200, epoch: 5 | loss: 0.3319125
	speed: 0.0955s/iter; left time: 2287.8441s
	iters: 300, epoch: 5 | loss: 0.3471429
	speed: 0.0932s/iter; left time: 2223.3924s
	iters: 400, epoch: 5 | loss: 0.2792131
	speed: 0.0996s/iter; left time: 2366.5003s
	iters: 500, epoch: 5 | loss: 0.3240454
	speed: 0.1028s/iter; left time: 2432.2498s
Epoch: 5 cost time: 53.64634037017822
Epoch: 5, Steps: 525 | Train Loss: 0.2898324 Vali Loss: 0.1514707 Test Loss: 0.2166361
Validation loss decreased (0.151786 --> 0.151471).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2765439
	speed: 0.7033s/iter; left time: 16546.0255s
	iters: 200, epoch: 6 | loss: 0.2481908
	speed: 0.1318s/iter; left time: 3087.0204s
	iters: 300, epoch: 6 | loss: 0.2807158
	speed: 0.1422s/iter; left time: 3317.2839s
	iters: 400, epoch: 6 | loss: 0.3333067
	speed: 0.1486s/iter; left time: 3450.4164s
	iters: 500, epoch: 6 | loss: 0.3227134
	speed: 0.1474s/iter; left time: 3409.6926s
Epoch: 6 cost time: 75.7108359336853
Epoch: 6, Steps: 525 | Train Loss: 0.2895416 Vali Loss: 0.1515485 Test Loss: 0.2165328
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2444972
	speed: 0.8251s/iter; left time: 18977.6496s
	iters: 200, epoch: 7 | loss: 0.2226923
	speed: 0.0987s/iter; left time: 2260.7470s
	iters: 300, epoch: 7 | loss: 0.2362045
	speed: 0.0827s/iter; left time: 1885.9292s
	iters: 400, epoch: 7 | loss: 0.2863066
	speed: 0.0871s/iter; left time: 1976.6969s
	iters: 500, epoch: 7 | loss: 0.3259375
	speed: 0.1047s/iter; left time: 2367.2814s
Epoch: 7 cost time: 54.02635383605957
Epoch: 7, Steps: 525 | Train Loss: 0.2892086 Vali Loss: 0.1515297 Test Loss: 0.2167341
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1827894
	speed: 0.7690s/iter; left time: 17285.1577s
	iters: 200, epoch: 8 | loss: 0.3196449
	speed: 0.1043s/iter; left time: 2334.7737s
	iters: 300, epoch: 8 | loss: 0.2267321
	speed: 0.1104s/iter; left time: 2459.2581s
	iters: 400, epoch: 8 | loss: 0.3807147
	speed: 0.1107s/iter; left time: 2455.9008s
	iters: 500, epoch: 8 | loss: 0.2515133
	speed: 0.1111s/iter; left time: 2453.5259s
Epoch: 8 cost time: 58.13270545005798
Epoch: 8, Steps: 525 | Train Loss: 0.2891885 Vali Loss: 0.1516799 Test Loss: 0.2166512
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_192_FITS_ETTm2_ftM_sl720_ll48_pl192_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.21727213263511658, mae:0.29134702682495117, rse:0.3773089647293091, corr:[0.5643633  0.5672031  0.56516993 0.56252855 0.561556   0.56206596
 0.562789   0.56259835 0.5615143  0.5604199  0.5599909  0.5602268
 0.5606058  0.5604812  0.559739   0.5586993  0.55785716 0.55739284
 0.5571398  0.55674964 0.5560497  0.5551189  0.5542834  0.5538057
 0.553698   0.5537476  0.5536251  0.5531237  0.55231893 0.5514707
 0.55078524 0.5503715  0.55007577 0.549652   0.5490279  0.54828835
 0.5475021  0.54673696 0.5460605  0.5455292  0.5451049  0.5446801
 0.54422075 0.5437214  0.5431717  0.5425401  0.5418463  0.5411338
 0.5403643  0.53954405 0.5386949  0.53784424 0.5369663  0.53608376
 0.535263   0.5346426  0.5342578  0.5340435  0.5338878  0.5336923
 0.5334031  0.5330789  0.53274965 0.5325045  0.53239983 0.53245634
 0.5324936  0.53242713 0.53222233 0.53187966 0.53145355 0.5310234
 0.53062564 0.53025746 0.52985066 0.5293927  0.5288782  0.52832633
 0.5277757  0.5272932  0.52683926 0.526435   0.52606654 0.5256968
 0.52527225 0.5247875  0.5241446  0.52341765 0.5227112  0.5221478
 0.5218043  0.5215939  0.52122974 0.5205933  0.5196286  0.51834124
 0.51687807 0.51548874 0.5142509  0.51314247 0.51208746 0.5110015
 0.5099231  0.50889057 0.50791234 0.5069785  0.5060555  0.50510216
 0.5039866  0.5027714  0.50166196 0.5008389  0.5004255  0.50015527
 0.49965507 0.49875438 0.49746314 0.49593538 0.49459648 0.49372458
 0.49348763 0.49356714 0.49364325 0.4933456  0.49245715 0.49104154
 0.48946258 0.4881034  0.48713705 0.48647738 0.48596182 0.48543474
 0.48493585 0.4845842  0.48445496 0.4844647  0.48440787 0.48422152
 0.48378235 0.48312736 0.48234293 0.48161352 0.4810537  0.48051944
 0.47986257 0.47887966 0.47775504 0.47660404 0.47566763 0.4750004
 0.47468626 0.4746459  0.47450298 0.4739338  0.47294688 0.4719079
 0.47112915 0.47081962 0.47080013 0.47090206 0.4706341  0.46987268
 0.4686464  0.46737483 0.46652678 0.4663621  0.46660486 0.46682808
 0.4667359  0.46639013 0.465921   0.46566862 0.46574655 0.4659392
 0.46586767 0.46523347 0.46411785 0.46294275 0.4621062  0.46203285
 0.46221155 0.46191373 0.46099812 0.45979908 0.4589611  0.45897102
 0.4595178  0.4598804  0.45938927 0.45823455 0.4576017  0.45735368]
