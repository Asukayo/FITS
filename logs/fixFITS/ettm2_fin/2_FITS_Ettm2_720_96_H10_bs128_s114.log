Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_96_FITS_ETTm2_ftM_sl720_ll48_pl96_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=90, out_features=102, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  16450560.0
params:  9282.0
Trainable parameters:  9282
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2469318
	speed: 0.2242s/iter; left time: 1446.3294s
Epoch: 1 cost time: 29.682847499847412
Epoch: 1, Steps: 131 | Train Loss: 0.3200127 Vali Loss: 0.1958617 Test Loss: 0.2561122
Validation loss decreased (inf --> 0.195862).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2232328
	speed: 0.6146s/iter; left time: 3884.0928s
Epoch: 2 cost time: 30.04559564590454
Epoch: 2, Steps: 131 | Train Loss: 0.2158523 Vali Loss: 0.1776573 Test Loss: 0.2296341
Validation loss decreased (0.195862 --> 0.177657).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1532305
	speed: 0.6384s/iter; left time: 3950.9491s
Epoch: 3 cost time: 31.026509761810303
Epoch: 3, Steps: 131 | Train Loss: 0.1694468 Vali Loss: 0.1707590 Test Loss: 0.2203618
Validation loss decreased (0.177657 --> 0.170759).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1227172
	speed: 0.6198s/iter; left time: 3755.0388s
Epoch: 4 cost time: 29.184748888015747
Epoch: 4, Steps: 131 | Train Loss: 0.1422736 Vali Loss: 0.1664936 Test Loss: 0.2147527
Validation loss decreased (0.170759 --> 0.166494).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1213562
	speed: 0.5756s/iter; left time: 3411.3407s
Epoch: 5 cost time: 26.87682056427002
Epoch: 5, Steps: 131 | Train Loss: 0.1232011 Vali Loss: 0.1617606 Test Loss: 0.2096616
Validation loss decreased (0.166494 --> 0.161761).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1038460
	speed: 0.5360s/iter; left time: 3106.6549s
Epoch: 6 cost time: 24.878973960876465
Epoch: 6, Steps: 131 | Train Loss: 0.1091909 Vali Loss: 0.1577190 Test Loss: 0.2052366
Validation loss decreased (0.161761 --> 0.157719).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1247225
	speed: 0.5247s/iter; left time: 2972.1500s
Epoch: 7 cost time: 26.18380331993103
Epoch: 7, Steps: 131 | Train Loss: 0.0981681 Vali Loss: 0.1539915 Test Loss: 0.2011963
Validation loss decreased (0.157719 --> 0.153992).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.0819273
	speed: 0.5405s/iter; left time: 2991.3442s
Epoch: 8 cost time: 26.94739866256714
Epoch: 8, Steps: 131 | Train Loss: 0.0893443 Vali Loss: 0.1503754 Test Loss: 0.1976171
Validation loss decreased (0.153992 --> 0.150375).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.0748045
	speed: 0.5438s/iter; left time: 2938.0839s
Epoch: 9 cost time: 26.231656551361084
Epoch: 9, Steps: 131 | Train Loss: 0.0819495 Vali Loss: 0.1471701 Test Loss: 0.1940829
Validation loss decreased (0.150375 --> 0.147170).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.0712785
	speed: 0.5815s/iter; left time: 3065.6760s
Epoch: 10 cost time: 26.72196316719055
Epoch: 10, Steps: 131 | Train Loss: 0.0757526 Vali Loss: 0.1444575 Test Loss: 0.1913638
Validation loss decreased (0.147170 --> 0.144458).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.0698578
	speed: 0.5612s/iter; left time: 2885.1833s
Epoch: 11 cost time: 26.78325581550598
Epoch: 11, Steps: 131 | Train Loss: 0.0706963 Vali Loss: 0.1418108 Test Loss: 0.1886912
Validation loss decreased (0.144458 --> 0.141811).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.0816797
	speed: 0.5202s/iter; left time: 2606.0149s
Epoch: 12 cost time: 24.242798805236816
Epoch: 12, Steps: 131 | Train Loss: 0.0663998 Vali Loss: 0.1396595 Test Loss: 0.1864139
Validation loss decreased (0.141811 --> 0.139659).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.0643012
	speed: 0.5166s/iter; left time: 2520.7011s
Epoch: 13 cost time: 24.20047092437744
Epoch: 13, Steps: 131 | Train Loss: 0.0627951 Vali Loss: 0.1377137 Test Loss: 0.1842808
Validation loss decreased (0.139659 --> 0.137714).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.0519894
	speed: 0.5182s/iter; left time: 2460.2243s
Epoch: 14 cost time: 25.56825065612793
Epoch: 14, Steps: 131 | Train Loss: 0.0595285 Vali Loss: 0.1358783 Test Loss: 0.1823568
Validation loss decreased (0.137714 --> 0.135878).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.0575058
	speed: 0.5645s/iter; left time: 2606.0699s
Epoch: 15 cost time: 28.231618881225586
Epoch: 15, Steps: 131 | Train Loss: 0.0568741 Vali Loss: 0.1341711 Test Loss: 0.1808357
Validation loss decreased (0.135878 --> 0.134171).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.0545005
	speed: 0.5982s/iter; left time: 2683.5039s
Epoch: 16 cost time: 27.731008768081665
Epoch: 16, Steps: 131 | Train Loss: 0.0545428 Vali Loss: 0.1327617 Test Loss: 0.1795540
Validation loss decreased (0.134171 --> 0.132762).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.0461700
	speed: 0.5966s/iter; left time: 2598.3044s
Epoch: 17 cost time: 28.159969091415405
Epoch: 17, Steps: 131 | Train Loss: 0.0525470 Vali Loss: 0.1315234 Test Loss: 0.1781859
Validation loss decreased (0.132762 --> 0.131523).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.0444840
	speed: 0.5201s/iter; left time: 2197.0403s
Epoch: 18 cost time: 24.06710433959961
Epoch: 18, Steps: 131 | Train Loss: 0.0508542 Vali Loss: 0.1305068 Test Loss: 0.1772785
Validation loss decreased (0.131523 --> 0.130507).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.0509905
	speed: 0.5350s/iter; left time: 2189.7788s
Epoch: 19 cost time: 26.311610460281372
Epoch: 19, Steps: 131 | Train Loss: 0.0493144 Vali Loss: 0.1292437 Test Loss: 0.1761315
Validation loss decreased (0.130507 --> 0.129244).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.0419774
	speed: 0.5953s/iter; left time: 2358.5621s
Epoch: 20 cost time: 29.940299034118652
Epoch: 20, Steps: 131 | Train Loss: 0.0480435 Vali Loss: 0.1283663 Test Loss: 0.1753256
Validation loss decreased (0.129244 --> 0.128366).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.0500875
	speed: 0.5784s/iter; left time: 2215.7975s
Epoch: 21 cost time: 26.440747499465942
Epoch: 21, Steps: 131 | Train Loss: 0.0468579 Vali Loss: 0.1276448 Test Loss: 0.1745179
Validation loss decreased (0.128366 --> 0.127645).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.0430103
	speed: 0.5528s/iter; left time: 2045.2948s
Epoch: 22 cost time: 25.974944353103638
Epoch: 22, Steps: 131 | Train Loss: 0.0458631 Vali Loss: 0.1271670 Test Loss: 0.1740136
Validation loss decreased (0.127645 --> 0.127167).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.0432994
	speed: 0.5265s/iter; left time: 1879.1662s
Epoch: 23 cost time: 24.4116427898407
Epoch: 23, Steps: 131 | Train Loss: 0.0450039 Vali Loss: 0.1263030 Test Loss: 0.1734224
Validation loss decreased (0.127167 --> 0.126303).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.0429524
	speed: 0.5231s/iter; left time: 1798.4626s
Epoch: 24 cost time: 25.27999258041382
Epoch: 24, Steps: 131 | Train Loss: 0.0443023 Vali Loss: 0.1258056 Test Loss: 0.1727979
Validation loss decreased (0.126303 --> 0.125806).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.0429369
	speed: 0.5498s/iter; left time: 1818.1799s
Epoch: 25 cost time: 26.238112449645996
Epoch: 25, Steps: 131 | Train Loss: 0.0436392 Vali Loss: 0.1252637 Test Loss: 0.1724292
Validation loss decreased (0.125806 --> 0.125264).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.0444683
	speed: 0.5420s/iter; left time: 1721.3233s
Epoch: 26 cost time: 25.319523811340332
Epoch: 26, Steps: 131 | Train Loss: 0.0430056 Vali Loss: 0.1245615 Test Loss: 0.1719200
Validation loss decreased (0.125264 --> 0.124562).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.0403664
	speed: 0.6299s/iter; left time: 1918.1628s
Epoch: 27 cost time: 30.358739852905273
Epoch: 27, Steps: 131 | Train Loss: 0.0424981 Vali Loss: 0.1241936 Test Loss: 0.1716432
Validation loss decreased (0.124562 --> 0.124194).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.0401958
	speed: 0.6108s/iter; left time: 1779.9660s
Epoch: 28 cost time: 29.22261381149292
Epoch: 28, Steps: 131 | Train Loss: 0.0421138 Vali Loss: 0.1238800 Test Loss: 0.1712418
Validation loss decreased (0.124194 --> 0.123880).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.0507795
	speed: 0.5816s/iter; left time: 1618.6210s
Epoch: 29 cost time: 25.894787311553955
Epoch: 29, Steps: 131 | Train Loss: 0.0416418 Vali Loss: 0.1235530 Test Loss: 0.1709138
Validation loss decreased (0.123880 --> 0.123553).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.0391665
	speed: 0.5389s/iter; left time: 1429.0425s
Epoch: 30 cost time: 25.45806884765625
Epoch: 30, Steps: 131 | Train Loss: 0.0413500 Vali Loss: 0.1232059 Test Loss: 0.1706865
Validation loss decreased (0.123553 --> 0.123206).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.0331670
	speed: 0.5576s/iter; left time: 1405.7757s
Epoch: 31 cost time: 27.093848943710327
Epoch: 31, Steps: 131 | Train Loss: 0.0410305 Vali Loss: 0.1229641 Test Loss: 0.1704624
Validation loss decreased (0.123206 --> 0.122964).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.0396906
	speed: 0.5433s/iter; left time: 1298.4148s
Epoch: 32 cost time: 26.437108993530273
Epoch: 32, Steps: 131 | Train Loss: 0.0407052 Vali Loss: 0.1226530 Test Loss: 0.1702542
Validation loss decreased (0.122964 --> 0.122653).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.0430273
	speed: 0.5494s/iter; left time: 1241.0172s
Epoch: 33 cost time: 25.279510259628296
Epoch: 33, Steps: 131 | Train Loss: 0.0404813 Vali Loss: 0.1225165 Test Loss: 0.1701055
Validation loss decreased (0.122653 --> 0.122517).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.0391518
	speed: 0.5410s/iter; left time: 1151.1781s
Epoch: 34 cost time: 24.97255039215088
Epoch: 34, Steps: 131 | Train Loss: 0.0402455 Vali Loss: 0.1221019 Test Loss: 0.1699094
Validation loss decreased (0.122517 --> 0.122102).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.0490134
	speed: 0.5554s/iter; left time: 1109.1702s
Epoch: 35 cost time: 27.450611352920532
Epoch: 35, Steps: 131 | Train Loss: 0.0399856 Vali Loss: 0.1219821 Test Loss: 0.1696961
Validation loss decreased (0.122102 --> 0.121982).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.0437341
	speed: 0.5524s/iter; left time: 1030.8038s
Epoch: 36 cost time: 26.54206085205078
Epoch: 36, Steps: 131 | Train Loss: 0.0398649 Vali Loss: 0.1216830 Test Loss: 0.1695458
Validation loss decreased (0.121982 --> 0.121683).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.0426294
	speed: 0.5339s/iter; left time: 926.2661s
Epoch: 37 cost time: 24.507789373397827
Epoch: 37, Steps: 131 | Train Loss: 0.0397213 Vali Loss: 0.1214782 Test Loss: 0.1693956
Validation loss decreased (0.121683 --> 0.121478).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.0381369
	speed: 0.4760s/iter; left time: 763.5453s
Epoch: 38 cost time: 24.89361882209778
Epoch: 38, Steps: 131 | Train Loss: 0.0395449 Vali Loss: 0.1214589 Test Loss: 0.1693499
Validation loss decreased (0.121478 --> 0.121459).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.0338852
	speed: 0.5862s/iter; left time: 863.4799s
Epoch: 39 cost time: 29.64719295501709
Epoch: 39, Steps: 131 | Train Loss: 0.0394335 Vali Loss: 0.1213268 Test Loss: 0.1691655
Validation loss decreased (0.121459 --> 0.121327).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.0397645
	speed: 0.6138s/iter; left time: 823.6627s
Epoch: 40 cost time: 29.390655040740967
Epoch: 40, Steps: 131 | Train Loss: 0.0393185 Vali Loss: 0.1212903 Test Loss: 0.1691686
Validation loss decreased (0.121327 --> 0.121290).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.0362173
	speed: 0.5436s/iter; left time: 658.2935s
Epoch: 41 cost time: 22.726555109024048
Epoch: 41, Steps: 131 | Train Loss: 0.0392285 Vali Loss: 0.1210554 Test Loss: 0.1690224
Validation loss decreased (0.121290 --> 0.121055).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.0409357
	speed: 0.5816s/iter; left time: 628.1437s
Epoch: 42 cost time: 30.57863140106201
Epoch: 42, Steps: 131 | Train Loss: 0.0391740 Vali Loss: 0.1208469 Test Loss: 0.1689641
Validation loss decreased (0.121055 --> 0.120847).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.0349678
	speed: 0.5911s/iter; left time: 560.9212s
Epoch: 43 cost time: 27.659308195114136
Epoch: 43, Steps: 131 | Train Loss: 0.0390551 Vali Loss: 0.1206772 Test Loss: 0.1689036
Validation loss decreased (0.120847 --> 0.120677).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.0361594
	speed: 0.5922s/iter; left time: 484.4594s
Epoch: 44 cost time: 26.768158674240112
Epoch: 44, Steps: 131 | Train Loss: 0.0390051 Vali Loss: 0.1205331 Test Loss: 0.1688443
Validation loss decreased (0.120677 --> 0.120533).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.0473976
	speed: 0.5379s/iter; left time: 369.5252s
Epoch: 45 cost time: 25.49849247932434
Epoch: 45, Steps: 131 | Train Loss: 0.0389644 Vali Loss: 0.1207066 Test Loss: 0.1688255
EarlyStopping counter: 1 out of 3
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.0293057
	speed: 0.5521s/iter; left time: 306.9539s
Epoch: 46 cost time: 26.542102575302124
Epoch: 46, Steps: 131 | Train Loss: 0.0389149 Vali Loss: 0.1206369 Test Loss: 0.1687488
EarlyStopping counter: 2 out of 3
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.0391530
	speed: 0.5608s/iter; left time: 238.3552s
Epoch: 47 cost time: 27.379377365112305
Epoch: 47, Steps: 131 | Train Loss: 0.0388506 Vali Loss: 0.1206784 Test Loss: 0.1687557
EarlyStopping counter: 3 out of 3
Early stopping
train 33745
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=90, out_features=102, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  16450560.0
params:  9282.0
Trainable parameters:  9282
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.1978323
	speed: 0.2095s/iter; left time: 1351.8049s
Epoch: 1 cost time: 27.008817672729492
Epoch: 1, Steps: 131 | Train Loss: 0.2152825 Vali Loss: 0.1163167 Test Loss: 0.1647225
Validation loss decreased (inf --> 0.116317).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2245050
	speed: 0.5675s/iter; left time: 3586.7465s
Epoch: 2 cost time: 27.82630205154419
Epoch: 2, Steps: 131 | Train Loss: 0.2119335 Vali Loss: 0.1154358 Test Loss: 0.1640844
Validation loss decreased (0.116317 --> 0.115436).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2054665
	speed: 0.5245s/iter; left time: 3246.0071s
Epoch: 3 cost time: 20.354283332824707
Epoch: 3, Steps: 131 | Train Loss: 0.2101731 Vali Loss: 0.1156388 Test Loss: 0.1636624
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2130427
	speed: 0.3744s/iter; left time: 2268.1025s
Epoch: 4 cost time: 23.569273471832275
Epoch: 4, Steps: 131 | Train Loss: 0.2093009 Vali Loss: 0.1153537 Test Loss: 0.1633333
Validation loss decreased (0.115436 --> 0.115354).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2172858
	speed: 0.5137s/iter; left time: 3044.5017s
Epoch: 5 cost time: 22.970468759536743
Epoch: 5, Steps: 131 | Train Loss: 0.2091723 Vali Loss: 0.1150065 Test Loss: 0.1630447
Validation loss decreased (0.115354 --> 0.115006).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1683742
	speed: 0.5992s/iter; left time: 3472.7223s
Epoch: 6 cost time: 28.659533262252808
Epoch: 6, Steps: 131 | Train Loss: 0.2084938 Vali Loss: 0.1152561 Test Loss: 0.1630232
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2295876
	speed: 0.5619s/iter; left time: 3183.2869s
Epoch: 7 cost time: 26.789642095565796
Epoch: 7, Steps: 131 | Train Loss: 0.2084980 Vali Loss: 0.1153798 Test Loss: 0.1629353
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2768686
	speed: 0.5654s/iter; left time: 3128.7097s
Epoch: 8 cost time: 26.366681337356567
Epoch: 8, Steps: 131 | Train Loss: 0.2078333 Vali Loss: 0.1152450 Test Loss: 0.1628653
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_96_FITS_ETTm2_ftM_sl720_ll48_pl96_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.1636524200439453, mae:0.25468751788139343, rse:0.32798758149147034, corr:[0.567947   0.5712625  0.57184505 0.57014215 0.5680543  0.56677175
 0.56640446 0.56654674 0.566684   0.5664899  0.5659572  0.56533045
 0.56488764 0.56472516 0.5647743  0.5647418  0.5643895  0.56359583
 0.56249386 0.56131345 0.5603002  0.55954736 0.55907565 0.5588061
 0.5585545  0.5581897  0.55767727 0.557038   0.556337   0.5556771
 0.5550991  0.55466276 0.55427843 0.55378973 0.55315095 0.55242246
 0.55164254 0.5508803  0.5501614  0.54950446 0.54890263 0.5483377
 0.5477914  0.54723984 0.5466781  0.54605925 0.54537773 0.5446374
 0.5437513  0.542716   0.54162085 0.54063207 0.5398175  0.5391815
 0.53866464 0.5382315  0.5377693  0.5372144  0.5365785  0.5359439
 0.53536767 0.53497034 0.53474575 0.5346152  0.53449655 0.53441566
 0.53428286 0.534128   0.533984   0.53380954 0.5335562  0.5332026
 0.53276986 0.5323404  0.53192025 0.53154606 0.531154   0.5306794
 0.5300858  0.5294933  0.52879    0.52803767 0.52721465 0.5263327
 0.5254627  0.52473354 0.5240811  0.5235332  0.5229975  0.5223025
 0.52143186 0.520532   0.5197312  0.5195478  0.5200195  0.51971865]
