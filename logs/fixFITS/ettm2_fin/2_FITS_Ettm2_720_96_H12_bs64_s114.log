Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_96_FITS_ETTm2_ftM_sl720_ll48_pl96_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=106, out_features=120, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  11397120.0
params:  12840.0
Trainable parameters:  12840
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3502173
	speed: 0.1666s/iter; left time: 2173.8202s
	iters: 200, epoch: 1 | loss: 0.1825163
	speed: 0.1797s/iter; left time: 2326.8965s
Epoch: 1 cost time: 45.8942551612854
Epoch: 1, Steps: 263 | Train Loss: 0.2669322 Vali Loss: 0.1763310 Test Loss: 0.2294131
Validation loss decreased (inf --> 0.176331).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1377304
	speed: 0.7655s/iter; left time: 9789.3574s
	iters: 200, epoch: 2 | loss: 0.1347338
	speed: 0.1598s/iter; left time: 2027.3873s
Epoch: 2 cost time: 42.32687973976135
Epoch: 2, Steps: 263 | Train Loss: 0.1536281 Vali Loss: 0.1644139 Test Loss: 0.2136158
Validation loss decreased (0.176331 --> 0.164414).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1096119
	speed: 0.7283s/iter; left time: 9122.3237s
	iters: 200, epoch: 3 | loss: 0.1074295
	speed: 0.1728s/iter; left time: 2147.0893s
Epoch: 3 cost time: 46.411529779434204
Epoch: 3, Steps: 263 | Train Loss: 0.1115967 Vali Loss: 0.1553069 Test Loss: 0.2032160
Validation loss decreased (0.164414 --> 0.155307).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.0925946
	speed: 0.8551s/iter; left time: 10485.4405s
	iters: 200, epoch: 4 | loss: 0.0947259
	speed: 0.1478s/iter; left time: 1797.0939s
Epoch: 4 cost time: 43.585134506225586
Epoch: 4, Steps: 263 | Train Loss: 0.0871718 Vali Loss: 0.1469837 Test Loss: 0.1943005
Validation loss decreased (0.155307 --> 0.146984).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.0736765
	speed: 0.5800s/iter; left time: 6959.5226s
	iters: 200, epoch: 5 | loss: 0.0519325
	speed: 0.1339s/iter; left time: 1593.8557s
Epoch: 5 cost time: 36.683770179748535
Epoch: 5, Steps: 263 | Train Loss: 0.0709832 Vali Loss: 0.1401381 Test Loss: 0.1871451
Validation loss decreased (0.146984 --> 0.140138).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.0630428
	speed: 0.5787s/iter; left time: 6791.1968s
	iters: 200, epoch: 6 | loss: 0.0460554
	speed: 0.1209s/iter; left time: 1407.2915s
Epoch: 6 cost time: 33.02241921424866
Epoch: 6, Steps: 263 | Train Loss: 0.0599289 Vali Loss: 0.1346869 Test Loss: 0.1816004
Validation loss decreased (0.140138 --> 0.134687).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.0614136
	speed: 0.5645s/iter; left time: 6476.7649s
	iters: 200, epoch: 7 | loss: 0.0575772
	speed: 0.1249s/iter; left time: 1420.5049s
Epoch: 7 cost time: 32.47632455825806
Epoch: 7, Steps: 263 | Train Loss: 0.0523486 Vali Loss: 0.1304844 Test Loss: 0.1774257
Validation loss decreased (0.134687 --> 0.130484).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.0423288
	speed: 0.5675s/iter; left time: 6361.6933s
	iters: 200, epoch: 8 | loss: 0.0493350
	speed: 0.1229s/iter; left time: 1365.1210s
Epoch: 8 cost time: 32.2653124332428
Epoch: 8, Steps: 263 | Train Loss: 0.0471173 Vali Loss: 0.1275726 Test Loss: 0.1747749
Validation loss decreased (0.130484 --> 0.127573).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.0302645
	speed: 0.5629s/iter; left time: 6161.5491s
	iters: 200, epoch: 9 | loss: 0.0543027
	speed: 0.1261s/iter; left time: 1367.3774s
Epoch: 9 cost time: 33.488951206207275
Epoch: 9, Steps: 263 | Train Loss: 0.0435163 Vali Loss: 0.1250530 Test Loss: 0.1724788
Validation loss decreased (0.127573 --> 0.125053).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.0338705
	speed: 0.6496s/iter; left time: 6940.1708s
	iters: 200, epoch: 10 | loss: 0.0380810
	speed: 0.1470s/iter; left time: 1556.3447s
Epoch: 10 cost time: 37.93805003166199
Epoch: 10, Steps: 263 | Train Loss: 0.0410597 Vali Loss: 0.1237256 Test Loss: 0.1712304
Validation loss decreased (0.125053 --> 0.123726).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.0399189
	speed: 0.6542s/iter; left time: 6817.3551s
	iters: 200, epoch: 11 | loss: 0.0389023
	speed: 0.1469s/iter; left time: 1516.3984s
Epoch: 11 cost time: 39.373011350631714
Epoch: 11, Steps: 263 | Train Loss: 0.0393848 Vali Loss: 0.1221630 Test Loss: 0.1701677
Validation loss decreased (0.123726 --> 0.122163).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.0457011
	speed: 0.7100s/iter; left time: 7212.1906s
	iters: 200, epoch: 12 | loss: 0.0344573
	speed: 0.1670s/iter; left time: 1679.6820s
Epoch: 12 cost time: 43.87752175331116
Epoch: 12, Steps: 263 | Train Loss: 0.0382842 Vali Loss: 0.1211255 Test Loss: 0.1694335
Validation loss decreased (0.122163 --> 0.121126).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.0325085
	speed: 0.7147s/iter; left time: 7071.8906s
	iters: 200, epoch: 13 | loss: 0.0319280
	speed: 0.1647s/iter; left time: 1613.1373s
Epoch: 13 cost time: 41.466540813446045
Epoch: 13, Steps: 263 | Train Loss: 0.0375509 Vali Loss: 0.1206533 Test Loss: 0.1691308
Validation loss decreased (0.121126 --> 0.120653).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.0341844
	speed: 0.7071s/iter; left time: 6810.5322s
	iters: 200, epoch: 14 | loss: 0.0385107
	speed: 0.1623s/iter; left time: 1547.3588s
Epoch: 14 cost time: 43.380234479904175
Epoch: 14, Steps: 263 | Train Loss: 0.0370726 Vali Loss: 0.1198033 Test Loss: 0.1684711
Validation loss decreased (0.120653 --> 0.119803).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.0335701
	speed: 0.7751s/iter; left time: 7262.1891s
	iters: 200, epoch: 15 | loss: 0.0353311
	speed: 0.1780s/iter; left time: 1649.4512s
Epoch: 15 cost time: 47.47363591194153
Epoch: 15, Steps: 263 | Train Loss: 0.0367662 Vali Loss: 0.1193497 Test Loss: 0.1681415
Validation loss decreased (0.119803 --> 0.119350).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.0433667
	speed: 0.7298s/iter; left time: 6645.5025s
	iters: 200, epoch: 16 | loss: 0.0490424
	speed: 0.1567s/iter; left time: 1411.3124s
Epoch: 16 cost time: 42.635266065597534
Epoch: 16, Steps: 263 | Train Loss: 0.0365867 Vali Loss: 0.1192069 Test Loss: 0.1679669
Validation loss decreased (0.119350 --> 0.119207).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.0400334
	speed: 0.7425s/iter; left time: 6566.0140s
	iters: 200, epoch: 17 | loss: 0.0463900
	speed: 0.1540s/iter; left time: 1346.6793s
Epoch: 17 cost time: 43.221131563186646
Epoch: 17, Steps: 263 | Train Loss: 0.0364547 Vali Loss: 0.1189496 Test Loss: 0.1678429
Validation loss decreased (0.119207 --> 0.118950).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.0313657
	speed: 0.6996s/iter; left time: 6002.4705s
	iters: 200, epoch: 18 | loss: 0.0438676
	speed: 0.1523s/iter; left time: 1291.3584s
Epoch: 18 cost time: 41.98237109184265
Epoch: 18, Steps: 263 | Train Loss: 0.0363912 Vali Loss: 0.1188399 Test Loss: 0.1678579
Validation loss decreased (0.118950 --> 0.118840).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.0317921
	speed: 0.7088s/iter; left time: 5895.3196s
	iters: 200, epoch: 19 | loss: 0.0287658
	speed: 0.1615s/iter; left time: 1327.4464s
Epoch: 19 cost time: 44.93590235710144
Epoch: 19, Steps: 263 | Train Loss: 0.0363409 Vali Loss: 0.1186829 Test Loss: 0.1677610
Validation loss decreased (0.118840 --> 0.118683).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.0375446
	speed: 0.7620s/iter; left time: 6136.8538s
	iters: 200, epoch: 20 | loss: 0.0643687
	speed: 0.1815s/iter; left time: 1443.4760s
Epoch: 20 cost time: 48.723634481430054
Epoch: 20, Steps: 263 | Train Loss: 0.0362478 Vali Loss: 0.1186223 Test Loss: 0.1678058
Validation loss decreased (0.118683 --> 0.118622).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.0313439
	speed: 0.7521s/iter; left time: 5859.9656s
	iters: 200, epoch: 21 | loss: 0.0301441
	speed: 0.1542s/iter; left time: 1186.0291s
Epoch: 21 cost time: 42.97343897819519
Epoch: 21, Steps: 263 | Train Loss: 0.0362490 Vali Loss: 0.1185627 Test Loss: 0.1678759
Validation loss decreased (0.118622 --> 0.118563).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.0337013
	speed: 0.5653s/iter; left time: 4255.8411s
	iters: 200, epoch: 22 | loss: 0.0348176
	speed: 0.1206s/iter; left time: 896.1756s
Epoch: 22 cost time: 29.584535598754883
Epoch: 22, Steps: 263 | Train Loss: 0.0362645 Vali Loss: 0.1186259 Test Loss: 0.1678752
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.0311533
	speed: 0.5991s/iter; left time: 4352.3559s
	iters: 200, epoch: 23 | loss: 0.0471542
	speed: 0.1271s/iter; left time: 910.6866s
Epoch: 23 cost time: 32.72176647186279
Epoch: 23, Steps: 263 | Train Loss: 0.0362678 Vali Loss: 0.1187804 Test Loss: 0.1678635
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.0365981
	speed: 0.5512s/iter; left time: 3859.4818s
	iters: 200, epoch: 24 | loss: 0.0476362
	speed: 0.1220s/iter; left time: 842.2941s
Epoch: 24 cost time: 32.502898931503296
Epoch: 24, Steps: 263 | Train Loss: 0.0362432 Vali Loss: 0.1185927 Test Loss: 0.1678616
EarlyStopping counter: 3 out of 3
Early stopping
train 33745
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=106, out_features=120, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  11397120.0
params:  12840.0
Trainable parameters:  12840
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2157926
	speed: 0.1267s/iter; left time: 1653.5576s
	iters: 200, epoch: 1 | loss: 0.1590967
	speed: 0.1129s/iter; left time: 1462.8029s
Epoch: 1 cost time: 32.424660205841064
Epoch: 1, Steps: 263 | Train Loss: 0.2133084 Vali Loss: 0.1151758 Test Loss: 0.1642886
Validation loss decreased (inf --> 0.115176).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1739530
	speed: 0.5503s/iter; left time: 7036.7383s
	iters: 200, epoch: 2 | loss: 0.2282493
	speed: 0.0676s/iter; left time: 858.2724s
Epoch: 2 cost time: 24.104689836502075
Epoch: 2, Steps: 263 | Train Loss: 0.2103317 Vali Loss: 0.1150272 Test Loss: 0.1636540
Validation loss decreased (0.115176 --> 0.115027).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2846651
	speed: 0.4899s/iter; left time: 6135.7329s
	iters: 200, epoch: 3 | loss: 0.1913680
	speed: 0.1084s/iter; left time: 1346.8871s
Epoch: 3 cost time: 28.47617793083191
Epoch: 3, Steps: 263 | Train Loss: 0.2086451 Vali Loss: 0.1145075 Test Loss: 0.1631136
Validation loss decreased (0.115027 --> 0.114507).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2208259
	speed: 0.5105s/iter; left time: 6260.3474s
	iters: 200, epoch: 4 | loss: 0.1817895
	speed: 0.1103s/iter; left time: 1341.7029s
Epoch: 4 cost time: 30.870354652404785
Epoch: 4, Steps: 263 | Train Loss: 0.2081267 Vali Loss: 0.1143764 Test Loss: 0.1623141
Validation loss decreased (0.114507 --> 0.114376).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2060539
	speed: 0.5497s/iter; left time: 6596.1122s
	iters: 200, epoch: 5 | loss: 0.2366185
	speed: 0.1063s/iter; left time: 1264.5151s
Epoch: 5 cost time: 29.861400604248047
Epoch: 5, Steps: 263 | Train Loss: 0.2078589 Vali Loss: 0.1144849 Test Loss: 0.1627444
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1631597
	speed: 0.5370s/iter; left time: 6302.2982s
	iters: 200, epoch: 6 | loss: 0.2364617
	speed: 0.1196s/iter; left time: 1391.9582s
Epoch: 6 cost time: 34.272438287734985
Epoch: 6, Steps: 263 | Train Loss: 0.2074091 Vali Loss: 0.1144529 Test Loss: 0.1626135
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2000524
	speed: 0.4719s/iter; left time: 5414.2914s
	iters: 200, epoch: 7 | loss: 0.1861505
	speed: 0.0893s/iter; left time: 1016.1427s
Epoch: 7 cost time: 24.444881439208984
Epoch: 7, Steps: 263 | Train Loss: 0.2073367 Vali Loss: 0.1148196 Test Loss: 0.1628733
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_96_FITS_ETTm2_ftM_sl720_ll48_pl96_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.16277718544006348, mae:0.2539527118206024, rse:0.32710933685302734, corr:[0.56811494 0.5714291  0.57073504 0.5684108  0.56699795 0.5669183
 0.5673673  0.5673953  0.5667055  0.5657794  0.5651961  0.5651268
 0.5653088  0.56524295 0.56469816 0.56381524 0.56296235 0.562316
 0.56183904 0.5613327  0.56066376 0.5598412  0.55906564 0.5585233
 0.5582268  0.5580646  0.55783707 0.5573736  0.5566689  0.5558778
 0.5551435  0.5546471  0.554307   0.5538879  0.553294   0.55259496
 0.55186963 0.5511942  0.5505535  0.5499285  0.5493085  0.5486898
 0.54807484 0.5474578  0.5468514  0.54620546 0.54550016 0.5447528
 0.5439071  0.5430136  0.54220426 0.54158473 0.5410122  0.5403122
 0.53943425 0.53852135 0.5376799  0.537035   0.53661186 0.5363155
 0.53597546 0.5356122  0.53525645 0.534965   0.53476745 0.53466034
 0.5344229  0.53404206 0.5336697  0.5334903  0.5335678  0.53371876
 0.5336181  0.53311896 0.53225213 0.5313456  0.53073066 0.53048724
 0.53029215 0.5298296  0.52875996 0.5273729  0.52619964 0.5256856
 0.525721   0.525793   0.52531546 0.524335   0.5233103  0.5226702
 0.522421   0.52211523 0.5212001  0.5201313  0.520247   0.52082485]
