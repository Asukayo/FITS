Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_96_FITS_ETTm2_ftM_sl720_ll48_pl96_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=90, out_features=102, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  8225280.0
params:  9282.0
Trainable parameters:  9282
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4092803
	speed: 0.0967s/iter; left time: 1261.6830s
	iters: 200, epoch: 1 | loss: 0.2027498
	speed: 0.0922s/iter; left time: 1194.4132s
Epoch: 1 cost time: 24.561723709106445
Epoch: 1, Steps: 263 | Train Loss: 0.3039528 Vali Loss: 0.1304194 Test Loss: 0.1808510
Validation loss decreased (inf --> 0.130419).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3049994
	speed: 0.3866s/iter; left time: 4943.4090s
	iters: 200, epoch: 2 | loss: 0.2325357
	speed: 0.1020s/iter; left time: 1294.3349s
Epoch: 2 cost time: 27.96411156654358
Epoch: 2, Steps: 263 | Train Loss: 0.2360003 Vali Loss: 0.1218738 Test Loss: 0.1713719
Validation loss decreased (0.130419 --> 0.121874).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2640305
	speed: 0.4351s/iter; left time: 5449.4410s
	iters: 200, epoch: 3 | loss: 0.2923995
	speed: 0.0978s/iter; left time: 1214.7649s
Epoch: 3 cost time: 25.6262047290802
Epoch: 3, Steps: 263 | Train Loss: 0.2236869 Vali Loss: 0.1189179 Test Loss: 0.1680036
Validation loss decreased (0.121874 --> 0.118918).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2164309
	speed: 0.4467s/iter; left time: 5477.1729s
	iters: 200, epoch: 4 | loss: 0.2107121
	speed: 0.0893s/iter; left time: 1086.2207s
Epoch: 4 cost time: 26.813541889190674
Epoch: 4, Steps: 263 | Train Loss: 0.2185349 Vali Loss: 0.1176447 Test Loss: 0.1664944
Validation loss decreased (0.118918 --> 0.117645).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2140257
	speed: 0.4415s/iter; left time: 5297.5227s
	iters: 200, epoch: 5 | loss: 0.1672977
	speed: 0.0943s/iter; left time: 1121.7191s
Epoch: 5 cost time: 25.137734413146973
Epoch: 5, Steps: 263 | Train Loss: 0.2154446 Vali Loss: 0.1169565 Test Loss: 0.1658431
Validation loss decreased (0.117645 --> 0.116956).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1927605
	speed: 0.4583s/iter; left time: 5378.2722s
	iters: 200, epoch: 6 | loss: 0.1867158
	speed: 0.1078s/iter; left time: 1254.9215s
Epoch: 6 cost time: 29.166250467300415
Epoch: 6, Steps: 263 | Train Loss: 0.2133363 Vali Loss: 0.1164962 Test Loss: 0.1651866
Validation loss decreased (0.116956 --> 0.116496).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2460884
	speed: 0.4704s/iter; left time: 5397.3019s
	iters: 200, epoch: 7 | loss: 0.1713753
	speed: 0.1108s/iter; left time: 1260.2641s
Epoch: 7 cost time: 29.758161783218384
Epoch: 7, Steps: 263 | Train Loss: 0.2122981 Vali Loss: 0.1161233 Test Loss: 0.1643794
Validation loss decreased (0.116496 --> 0.116123).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1654372
	speed: 0.4558s/iter; left time: 5109.0940s
	iters: 200, epoch: 8 | loss: 0.2063618
	speed: 0.0622s/iter; left time: 691.4788s
Epoch: 8 cost time: 18.924967050552368
Epoch: 8, Steps: 263 | Train Loss: 0.2112895 Vali Loss: 0.1161470 Test Loss: 0.1642151
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1615069
	speed: 0.3330s/iter; left time: 3644.9670s
	iters: 200, epoch: 9 | loss: 0.2559523
	speed: 0.0912s/iter; left time: 989.5608s
Epoch: 9 cost time: 21.5156192779541
Epoch: 9, Steps: 263 | Train Loss: 0.2106175 Vali Loss: 0.1158414 Test Loss: 0.1638268
Validation loss decreased (0.116123 --> 0.115841).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2008460
	speed: 0.2328s/iter; left time: 2486.8291s
	iters: 200, epoch: 10 | loss: 0.2046283
	speed: 0.0544s/iter; left time: 575.7672s
Epoch: 10 cost time: 17.44760036468506
Epoch: 10, Steps: 263 | Train Loss: 0.2100117 Vali Loss: 0.1157332 Test Loss: 0.1637038
Validation loss decreased (0.115841 --> 0.115733).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2057712
	speed: 0.4347s/iter; left time: 4529.9995s
	iters: 200, epoch: 11 | loss: 0.1950020
	speed: 0.1027s/iter; left time: 1059.8914s
Epoch: 11 cost time: 26.95228362083435
Epoch: 11, Steps: 263 | Train Loss: 0.2095551 Vali Loss: 0.1157446 Test Loss: 0.1637459
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2753107
	speed: 0.3912s/iter; left time: 3973.9458s
	iters: 200, epoch: 12 | loss: 0.1434233
	speed: 0.0921s/iter; left time: 926.3823s
Epoch: 12 cost time: 25.362172842025757
Epoch: 12, Steps: 263 | Train Loss: 0.2093961 Vali Loss: 0.1155816 Test Loss: 0.1636098
Validation loss decreased (0.115733 --> 0.115582).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1910036
	speed: 0.4377s/iter; left time: 4330.6239s
	iters: 200, epoch: 13 | loss: 0.1660490
	speed: 0.0958s/iter; left time: 938.2153s
Epoch: 13 cost time: 27.408581495285034
Epoch: 13, Steps: 263 | Train Loss: 0.2092293 Vali Loss: 0.1158055 Test Loss: 0.1635727
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2074308
	speed: 0.4500s/iter; left time: 4334.5343s
	iters: 200, epoch: 14 | loss: 0.2765465
	speed: 0.1027s/iter; left time: 979.0068s
Epoch: 14 cost time: 27.492912769317627
Epoch: 14, Steps: 263 | Train Loss: 0.2091024 Vali Loss: 0.1157274 Test Loss: 0.1634335
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1793326
	speed: 0.4342s/iter; left time: 4068.1924s
	iters: 200, epoch: 15 | loss: 0.2310134
	speed: 0.1086s/iter; left time: 1006.9532s
Epoch: 15 cost time: 28.240354537963867
Epoch: 15, Steps: 263 | Train Loss: 0.2084840 Vali Loss: 0.1155691 Test Loss: 0.1634544
Validation loss decreased (0.115582 --> 0.115569).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2733103
	speed: 0.4800s/iter; left time: 4371.1243s
	iters: 200, epoch: 16 | loss: 0.1840952
	speed: 0.0792s/iter; left time: 712.9960s
Epoch: 16 cost time: 24.81895089149475
Epoch: 16, Steps: 263 | Train Loss: 0.2087650 Vali Loss: 0.1154912 Test Loss: 0.1633119
Validation loss decreased (0.115569 --> 0.115491).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3262484
	speed: 0.3148s/iter; left time: 2784.0156s
	iters: 200, epoch: 17 | loss: 0.2167875
	speed: 0.0931s/iter; left time: 814.0993s
Epoch: 17 cost time: 23.6548113822937
Epoch: 17, Steps: 263 | Train Loss: 0.2085812 Vali Loss: 0.1154611 Test Loss: 0.1630657
Validation loss decreased (0.115491 --> 0.115461).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2313135
	speed: 0.3968s/iter; left time: 3404.3875s
	iters: 200, epoch: 18 | loss: 0.1941473
	speed: 0.0934s/iter; left time: 791.6941s
Epoch: 18 cost time: 25.742484092712402
Epoch: 18, Steps: 263 | Train Loss: 0.2083853 Vali Loss: 0.1153908 Test Loss: 0.1632513
Validation loss decreased (0.115461 --> 0.115391).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1638597
	speed: 0.4720s/iter; left time: 3925.8342s
	iters: 200, epoch: 19 | loss: 0.3183887
	speed: 0.0987s/iter; left time: 811.0374s
Epoch: 19 cost time: 28.194035053253174
Epoch: 19, Steps: 263 | Train Loss: 0.2081820 Vali Loss: 0.1154276 Test Loss: 0.1631088
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1748230
	speed: 0.4911s/iter; left time: 3955.6250s
	iters: 200, epoch: 20 | loss: 0.2100231
	speed: 0.1096s/iter; left time: 871.5643s
Epoch: 20 cost time: 29.551304578781128
Epoch: 20, Steps: 263 | Train Loss: 0.2082293 Vali Loss: 0.1155628 Test Loss: 0.1631805
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1657835
	speed: 0.4695s/iter; left time: 3658.1355s
	iters: 200, epoch: 21 | loss: 0.2567618
	speed: 0.0882s/iter; left time: 677.9679s
Epoch: 21 cost time: 26.435529708862305
Epoch: 21, Steps: 263 | Train Loss: 0.2082053 Vali Loss: 0.1154151 Test Loss: 0.1631354
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_96_FITS_ETTm2_ftM_sl720_ll48_pl96_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.16370584070682526, mae:0.254868745803833, rse:0.32804110646247864, corr:[0.5640761  0.5688087  0.5676314  0.5651253  0.56385016 0.5641138
 0.5651539  0.56585354 0.565628   0.5647863  0.5639771  0.5636125
 0.5637733  0.56417304 0.56441045 0.5640892  0.5632935  0.56229264
 0.5613625  0.5606383  0.56016624 0.5597916  0.5593735  0.5588514
 0.5582316  0.55762917 0.5571479  0.5568062  0.55653954 0.5562484
 0.555803   0.5552886  0.5547372  0.55410355 0.5534313  0.5528097
 0.5522057  0.55156046 0.55081594 0.55001074 0.5492207  0.5485154
 0.5479546  0.54752594 0.54713964 0.5466086  0.54585946 0.54493475
 0.54383415 0.5426671  0.5416342  0.5409022  0.5403739  0.53983843
 0.53913575 0.5383055  0.53742313 0.53666836 0.5361965  0.5360035
 0.53587955 0.53571004 0.5353668  0.5347879  0.5340872  0.5336335
 0.53353184 0.53369707 0.53386015 0.5337496  0.5332628  0.5324966
 0.5317543  0.53140867 0.531444   0.5315573  0.53133667 0.5305892
 0.52935416 0.52806693 0.5270782  0.5266914  0.5265594  0.52611524
 0.5250992  0.52367055 0.5222015  0.5215645  0.52215356 0.52309024
 0.52321506 0.52215356 0.5199411  0.5178446  0.51904255 0.5228542 ]
