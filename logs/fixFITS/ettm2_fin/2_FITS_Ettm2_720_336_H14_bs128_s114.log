Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=122, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_336', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_336_FITS_ETTm2_ftM_sl720_ll48_pl336_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=122, out_features=178, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  38915072.0
params:  21894.0
Trainable parameters:  21894
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3537803
	speed: 0.1765s/iter; left time: 1129.7063s
Epoch: 1 cost time: 22.7604022026062
Epoch: 1, Steps: 130 | Train Loss: 0.3938219 Vali Loss: 0.2613070 Test Loss: 0.3502366
Validation loss decreased (inf --> 0.261307).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2649288
	speed: 0.4683s/iter; left time: 2936.8541s
Epoch: 2 cost time: 21.86827826499939
Epoch: 2, Steps: 130 | Train Loss: 0.2778605 Vali Loss: 0.2361779 Test Loss: 0.3186959
Validation loss decreased (0.261307 --> 0.236178).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1931974
	speed: 0.4617s/iter; left time: 2835.4121s
Epoch: 3 cost time: 21.745619297027588
Epoch: 3, Steps: 130 | Train Loss: 0.2317793 Vali Loss: 0.2256785 Test Loss: 0.3063181
Validation loss decreased (0.236178 --> 0.225678).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1272654
	speed: 0.4464s/iter; left time: 2683.2182s
Epoch: 4 cost time: 20.035993576049805
Epoch: 4, Steps: 130 | Train Loss: 0.2058097 Vali Loss: 0.2197294 Test Loss: 0.2989951
Validation loss decreased (0.225678 --> 0.219729).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1597839
	speed: 0.4278s/iter; left time: 2515.8099s
Epoch: 5 cost time: 20.718289613723755
Epoch: 5, Steps: 130 | Train Loss: 0.1873644 Vali Loss: 0.2155208 Test Loss: 0.2939495
Validation loss decreased (0.219729 --> 0.215521).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1716955
	speed: 0.4154s/iter; left time: 2389.1990s
Epoch: 6 cost time: 19.480271577835083
Epoch: 6, Steps: 130 | Train Loss: 0.1743996 Vali Loss: 0.2121451 Test Loss: 0.2897578
Validation loss decreased (0.215521 --> 0.212145).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1625344
	speed: 0.4060s/iter; left time: 2282.2748s
Epoch: 7 cost time: 20.069640398025513
Epoch: 7, Steps: 130 | Train Loss: 0.1643408 Vali Loss: 0.2091838 Test Loss: 0.2866077
Validation loss decreased (0.212145 --> 0.209184).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1491050
	speed: 0.4259s/iter; left time: 2338.5272s
Epoch: 8 cost time: 20.47188639640808
Epoch: 8, Steps: 130 | Train Loss: 0.1569793 Vali Loss: 0.2074525 Test Loss: 0.2839241
Validation loss decreased (0.209184 --> 0.207453).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1399294
	speed: 0.4230s/iter; left time: 2267.4653s
Epoch: 9 cost time: 20.4255473613739
Epoch: 9, Steps: 130 | Train Loss: 0.1513788 Vali Loss: 0.2055347 Test Loss: 0.2817869
Validation loss decreased (0.207453 --> 0.205535).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1343753
	speed: 0.4207s/iter; left time: 2200.5103s
Epoch: 10 cost time: 19.531895399093628
Epoch: 10, Steps: 130 | Train Loss: 0.1468851 Vali Loss: 0.2041778 Test Loss: 0.2800859
Validation loss decreased (0.205535 --> 0.204178).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1326931
	speed: 0.4216s/iter; left time: 2150.4680s
Epoch: 11 cost time: 20.750603914260864
Epoch: 11, Steps: 130 | Train Loss: 0.1430586 Vali Loss: 0.2027470 Test Loss: 0.2787208
Validation loss decreased (0.204178 --> 0.202747).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1133701
	speed: 0.4176s/iter; left time: 2076.0263s
Epoch: 12 cost time: 20.937676906585693
Epoch: 12, Steps: 130 | Train Loss: 0.1406304 Vali Loss: 0.2015414 Test Loss: 0.2773961
Validation loss decreased (0.202747 --> 0.201541).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1507891
	speed: 0.4738s/iter; left time: 2293.5597s
Epoch: 13 cost time: 23.27133870124817
Epoch: 13, Steps: 130 | Train Loss: 0.1386815 Vali Loss: 0.2010846 Test Loss: 0.2765675
Validation loss decreased (0.201541 --> 0.201085).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1793080
	speed: 0.4475s/iter; left time: 2108.2614s
Epoch: 14 cost time: 21.691354990005493
Epoch: 14, Steps: 130 | Train Loss: 0.1369646 Vali Loss: 0.2001894 Test Loss: 0.2757712
Validation loss decreased (0.201085 --> 0.200189).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1808771
	speed: 0.4409s/iter; left time: 2019.7563s
Epoch: 15 cost time: 21.571693420410156
Epoch: 15, Steps: 130 | Train Loss: 0.1353115 Vali Loss: 0.1995816 Test Loss: 0.2752440
Validation loss decreased (0.200189 --> 0.199582).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1154201
	speed: 0.4485s/iter; left time: 1996.0892s
Epoch: 16 cost time: 20.354235887527466
Epoch: 16, Steps: 130 | Train Loss: 0.1345594 Vali Loss: 0.1991360 Test Loss: 0.2746888
Validation loss decreased (0.199582 --> 0.199136).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1226823
	speed: 0.4191s/iter; left time: 1810.8184s
Epoch: 17 cost time: 20.801300048828125
Epoch: 17, Steps: 130 | Train Loss: 0.1336532 Vali Loss: 0.1985751 Test Loss: 0.2742262
Validation loss decreased (0.199136 --> 0.198575).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1195792
	speed: 0.4376s/iter; left time: 1834.0042s
Epoch: 18 cost time: 20.899216175079346
Epoch: 18, Steps: 130 | Train Loss: 0.1324652 Vali Loss: 0.1980145 Test Loss: 0.2738781
Validation loss decreased (0.198575 --> 0.198014).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1449403
	speed: 0.4382s/iter; left time: 1779.5954s
Epoch: 19 cost time: 20.625398635864258
Epoch: 19, Steps: 130 | Train Loss: 0.1322480 Vali Loss: 0.1979575 Test Loss: 0.2735448
Validation loss decreased (0.198014 --> 0.197958).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1176518
	speed: 0.4423s/iter; left time: 1738.6457s
Epoch: 20 cost time: 21.6059308052063
Epoch: 20, Steps: 130 | Train Loss: 0.1319458 Vali Loss: 0.1974590 Test Loss: 0.2732955
Validation loss decreased (0.197958 --> 0.197459).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1746688
	speed: 0.4348s/iter; left time: 1652.6067s
Epoch: 21 cost time: 19.083421230316162
Epoch: 21, Steps: 130 | Train Loss: 0.1314940 Vali Loss: 0.1972801 Test Loss: 0.2731608
Validation loss decreased (0.197459 --> 0.197280).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1227276
	speed: 0.3930s/iter; left time: 1442.7474s
Epoch: 22 cost time: 21.717092752456665
Epoch: 22, Steps: 130 | Train Loss: 0.1308097 Vali Loss: 0.1971695 Test Loss: 0.2729616
Validation loss decreased (0.197280 --> 0.197170).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1269900
	speed: 0.4703s/iter; left time: 1665.3534s
Epoch: 23 cost time: 22.92703413963318
Epoch: 23, Steps: 130 | Train Loss: 0.1306268 Vali Loss: 0.1970609 Test Loss: 0.2728653
Validation loss decreased (0.197170 --> 0.197061).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1409641
	speed: 0.4092s/iter; left time: 1395.7448s
Epoch: 24 cost time: 22.134198427200317
Epoch: 24, Steps: 130 | Train Loss: 0.1303907 Vali Loss: 0.1968259 Test Loss: 0.2727685
Validation loss decreased (0.197061 --> 0.196826).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1250791
	speed: 0.4724s/iter; left time: 1549.9616s
Epoch: 25 cost time: 22.717363834381104
Epoch: 25, Steps: 130 | Train Loss: 0.1304633 Vali Loss: 0.1967608 Test Loss: 0.2726362
Validation loss decreased (0.196826 --> 0.196761).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1401385
	speed: 0.4620s/iter; left time: 1455.7624s
Epoch: 26 cost time: 22.325493574142456
Epoch: 26, Steps: 130 | Train Loss: 0.1302363 Vali Loss: 0.1966529 Test Loss: 0.2725942
Validation loss decreased (0.196761 --> 0.196653).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1456863
	speed: 0.4616s/iter; left time: 1394.5295s
Epoch: 27 cost time: 22.575621366500854
Epoch: 27, Steps: 130 | Train Loss: 0.1298836 Vali Loss: 0.1966652 Test Loss: 0.2724980
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1227726
	speed: 0.4698s/iter; left time: 1358.1250s
Epoch: 28 cost time: 22.28552222251892
Epoch: 28, Steps: 130 | Train Loss: 0.1302318 Vali Loss: 0.1964821 Test Loss: 0.2724868
Validation loss decreased (0.196653 --> 0.196482).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1182615
	speed: 0.4803s/iter; left time: 1325.9772s
Epoch: 29 cost time: 23.387303113937378
Epoch: 29, Steps: 130 | Train Loss: 0.1297351 Vali Loss: 0.1963506 Test Loss: 0.2724780
Validation loss decreased (0.196482 --> 0.196351).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1682419
	speed: 0.4646s/iter; left time: 1222.3220s
Epoch: 30 cost time: 23.423351764678955
Epoch: 30, Steps: 130 | Train Loss: 0.1298148 Vali Loss: 0.1965482 Test Loss: 0.2724084
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1169908
	speed: 0.4479s/iter; left time: 1120.1382s
Epoch: 31 cost time: 20.85645890235901
Epoch: 31, Steps: 130 | Train Loss: 0.1295270 Vali Loss: 0.1961031 Test Loss: 0.2723593
Validation loss decreased (0.196351 --> 0.196103).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1230936
	speed: 0.3805s/iter; left time: 902.1278s
Epoch: 32 cost time: 17.80697274208069
Epoch: 32, Steps: 130 | Train Loss: 0.1296453 Vali Loss: 0.1961397 Test Loss: 0.2723809
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1083574
	speed: 0.3432s/iter; left time: 769.0080s
Epoch: 33 cost time: 15.697533369064331
Epoch: 33, Steps: 130 | Train Loss: 0.1294658 Vali Loss: 0.1962716 Test Loss: 0.2722796
EarlyStopping counter: 2 out of 3
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.0972513
	speed: 0.3378s/iter; left time: 713.1848s
Epoch: 34 cost time: 16.135128498077393
Epoch: 34, Steps: 130 | Train Loss: 0.1294340 Vali Loss: 0.1961885 Test Loss: 0.2722614
EarlyStopping counter: 3 out of 3
Early stopping
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=122, out_features=178, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  38915072.0
params:  21894.0
Trainable parameters:  21894
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3753833
	speed: 0.1240s/iter; left time: 793.8522s
Epoch: 1 cost time: 15.847513914108276
Epoch: 1, Steps: 130 | Train Loss: 0.3798423 Vali Loss: 0.1945208 Test Loss: 0.2701167
Validation loss decreased (inf --> 0.194521).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4561071
	speed: 0.3310s/iter; left time: 2075.6451s
Epoch: 2 cost time: 15.944607973098755
Epoch: 2, Steps: 130 | Train Loss: 0.3776047 Vali Loss: 0.1934106 Test Loss: 0.2693785
Validation loss decreased (0.194521 --> 0.193411).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4250922
	speed: 0.3458s/iter; left time: 2123.4626s
Epoch: 3 cost time: 15.65333867073059
Epoch: 3, Steps: 130 | Train Loss: 0.3770719 Vali Loss: 0.1929358 Test Loss: 0.2690460
Validation loss decreased (0.193411 --> 0.192936).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2738228
	speed: 0.3375s/iter; left time: 2028.6805s
Epoch: 4 cost time: 15.759038925170898
Epoch: 4, Steps: 130 | Train Loss: 0.3768121 Vali Loss: 0.1929932 Test Loss: 0.2688188
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3596557
	speed: 0.3374s/iter; left time: 1984.4408s
Epoch: 5 cost time: 16.311412811279297
Epoch: 5, Steps: 130 | Train Loss: 0.3762199 Vali Loss: 0.1931075 Test Loss: 0.2687261
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3959487
	speed: 0.3509s/iter; left time: 2018.2771s
Epoch: 6 cost time: 17.533146619796753
Epoch: 6, Steps: 130 | Train Loss: 0.3747111 Vali Loss: 0.1932083 Test Loss: 0.2682703
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_336_FITS_ETTm2_ftM_sl720_ll48_pl336_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.26969805359840393, mae:0.3272877037525177, rse:0.4194687008857727, corr:[0.555478   0.5615101  0.56130046 0.5584731  0.55728716 0.5578702
 0.55864084 0.558307   0.55707526 0.55608755 0.55590725 0.5562116
 0.5563095  0.55585396 0.5550818  0.5544385  0.5540186  0.55358285
 0.55291134 0.55207497 0.5513564  0.5509198  0.55064845 0.55028737
 0.5496719  0.54889125 0.5481686  0.5476088  0.54715353 0.54666466
 0.54606384 0.5453792  0.5446702  0.54401475 0.5434071  0.54276407
 0.5420185  0.54119176 0.5403797  0.53971326 0.5392275  0.53880954
 0.5383158  0.5376603  0.5368659  0.5360954  0.5354818  0.53494203
 0.5343221  0.5335693  0.5327377  0.5319513  0.5312867  0.5307302
 0.5301895  0.5296234  0.5290481  0.528581   0.5283203  0.528215
 0.52815455 0.5280584  0.5279046  0.5277545  0.5276675  0.5275854
 0.5274304  0.5271831  0.5268326  0.52640676 0.5259595  0.5255134
 0.5250466  0.52454066 0.52401483 0.5235563  0.5231644  0.52273107
 0.5221532  0.5214417  0.5206951  0.52009416 0.5196521  0.51921487
 0.5186337  0.5178671  0.51708746 0.51655996 0.5163126  0.5161095
 0.5157103  0.51498526 0.51400346 0.5129934  0.51206297 0.5110442
 0.5097491  0.50815976 0.5064627  0.5050439  0.50412446 0.5034885
 0.50271636 0.5015636  0.50021327 0.4990488  0.49835825 0.49798766
 0.49757525 0.49689844 0.49597934 0.49497434 0.4940258  0.49307415
 0.49203002 0.4909483  0.48998418 0.48923957 0.48864067 0.4879056
 0.4868926  0.48562735 0.4843677  0.48335063 0.48265174 0.48208255
 0.48133513 0.48022547 0.47887427 0.47761676 0.47667906 0.47596148
 0.47518247 0.4741407  0.4729279  0.47186497 0.47119907 0.47089747
 0.4706443  0.4701939  0.46945894 0.46858832 0.46780697 0.46720335
 0.4667637  0.4663523  0.46593902 0.46543396 0.4648187  0.4641033
 0.46337605 0.4627067  0.46206746 0.46148968 0.46097526 0.4604659
 0.4598772  0.45924595 0.45870176 0.45845038 0.45849994 0.4586687
 0.4586545  0.45827976 0.45750147 0.45648596 0.4555942  0.4552308
 0.45547205 0.45597678 0.45619723 0.4558533  0.45505312 0.4542278
 0.4538035  0.45383823 0.4539911  0.45384803 0.45322746 0.452384
 0.45160678 0.4510908  0.45079172 0.4504229  0.44980854 0.44905803
 0.44848442 0.4482129  0.4479547  0.44720897 0.44566202 0.44345802
 0.4412382  0.43969664 0.4388448  0.43822458 0.43738207 0.43606997
 0.4344699  0.4329667  0.43188342 0.43118006 0.430625   0.42999566
 0.42921776 0.42829016 0.4272059  0.4260158  0.4248521  0.4238569
 0.42299944 0.4223395  0.42186862 0.4214374  0.42085844 0.4199578
 0.41877767 0.417429   0.41614786 0.41498557 0.41390216 0.41293213
 0.4120743  0.41128337 0.41047403 0.40944242 0.40831402 0.40739527
 0.40676078 0.40635592 0.4058496  0.40506357 0.40400758 0.40302512
 0.40246773 0.40242758 0.40247497 0.40213832 0.4012655  0.40009147
 0.39912513 0.39853388 0.3981321  0.397582   0.3965651  0.39545992
 0.3950064  0.3956375  0.39687255 0.39777988 0.39790705 0.3973569
 0.39680597 0.39699072 0.39777368 0.39846286 0.3982761  0.39709118
 0.3954408  0.39420825 0.3939231  0.39433998 0.39470527 0.39454436
 0.3938852  0.39314482 0.3928472  0.3929952  0.39320838 0.3932201
 0.3931776  0.39344734 0.39401817 0.39462036 0.3947754  0.39432737
 0.39364898 0.39307353 0.39280054 0.39272133 0.3923882  0.39159533
 0.390465   0.3894625  0.3889301  0.38875416 0.38851923 0.38781187
 0.3868091  0.38607195 0.3856627  0.38523564 0.3843762  0.38291827
 0.38137823 0.38033262 0.3800219  0.38017783 0.38034454 0.37994066
 0.3790745  0.37796992 0.37702045 0.37615258 0.3754246  0.37500864
 0.37519622 0.37584367 0.37665066 0.37711614 0.37688902 0.3762807
 0.37557596 0.3752404  0.37512895 0.37476406 0.37397498 0.37318414
 0.37296048 0.3736646  0.37480327 0.37545848 0.37512577 0.37443396
 0.37439767 0.3754647  0.3770404  0.37796703 0.37804496 0.37789372
 0.37872905 0.3801757  0.38091177 0.3798654  0.37710658 0.37490484]
