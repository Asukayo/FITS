Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=74, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_192_FITS_ETTm2_ftM_sl720_ll48_pl192_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=74, out_features=93, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  12332544.0
params:  6975.0
Trainable parameters:  6975
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3479196
	speed: 0.0526s/iter; left time: 339.3304s
Epoch: 1 cost time: 5.863358974456787
Epoch: 1, Steps: 131 | Train Loss: 0.3372851 Vali Loss: 0.2225948 Test Loss: 0.2934006
Validation loss decreased (inf --> 0.222595).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2137422
	speed: 0.1317s/iter; left time: 832.2837s
Epoch: 2 cost time: 7.813266277313232
Epoch: 2, Steps: 131 | Train Loss: 0.2348987 Vali Loss: 0.1987311 Test Loss: 0.2627066
Validation loss decreased (0.222595 --> 0.198731).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1945550
	speed: 0.1567s/iter; left time: 969.5447s
Epoch: 3 cost time: 8.366004228591919
Epoch: 3, Steps: 131 | Train Loss: 0.1907219 Vali Loss: 0.1902418 Test Loss: 0.2530784
Validation loss decreased (0.198731 --> 0.190242).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2196275
	speed: 0.1710s/iter; left time: 1035.9187s
Epoch: 4 cost time: 8.252965688705444
Epoch: 4, Steps: 131 | Train Loss: 0.1643754 Vali Loss: 0.1856411 Test Loss: 0.2485325
Validation loss decreased (0.190242 --> 0.185641).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1448419
	speed: 0.1620s/iter; left time: 960.3145s
Epoch: 5 cost time: 7.814604759216309
Epoch: 5, Steps: 131 | Train Loss: 0.1464507 Vali Loss: 0.1819289 Test Loss: 0.2449272
Validation loss decreased (0.185641 --> 0.181929).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1281380
	speed: 0.1716s/iter; left time: 994.8547s
Epoch: 6 cost time: 8.185964584350586
Epoch: 6, Steps: 131 | Train Loss: 0.1331334 Vali Loss: 0.1788588 Test Loss: 0.2419777
Validation loss decreased (0.181929 --> 0.178859).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1047291
	speed: 0.1923s/iter; left time: 1089.2804s
Epoch: 7 cost time: 9.672970294952393
Epoch: 7, Steps: 131 | Train Loss: 0.1229148 Vali Loss: 0.1761781 Test Loss: 0.2394458
Validation loss decreased (0.178859 --> 0.176178).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1041642
	speed: 0.1993s/iter; left time: 1102.9437s
Epoch: 8 cost time: 9.268014430999756
Epoch: 8, Steps: 131 | Train Loss: 0.1146964 Vali Loss: 0.1740845 Test Loss: 0.2373518
Validation loss decreased (0.176178 --> 0.174085).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1035787
	speed: 0.1843s/iter; left time: 995.6611s
Epoch: 9 cost time: 8.897525548934937
Epoch: 9, Steps: 131 | Train Loss: 0.1083204 Vali Loss: 0.1717535 Test Loss: 0.2350809
Validation loss decreased (0.174085 --> 0.171753).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1130160
	speed: 0.1899s/iter; left time: 1001.2661s
Epoch: 10 cost time: 9.668185472488403
Epoch: 10, Steps: 131 | Train Loss: 0.1031087 Vali Loss: 0.1698039 Test Loss: 0.2332834
Validation loss decreased (0.171753 --> 0.169804).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1131040
	speed: 0.1973s/iter; left time: 1014.4023s
Epoch: 11 cost time: 10.100281000137329
Epoch: 11, Steps: 131 | Train Loss: 0.0988112 Vali Loss: 0.1682943 Test Loss: 0.2316813
Validation loss decreased (0.169804 --> 0.168294).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1093858
	speed: 0.1655s/iter; left time: 829.3486s
Epoch: 12 cost time: 8.450050592422485
Epoch: 12, Steps: 131 | Train Loss: 0.0954949 Vali Loss: 0.1667326 Test Loss: 0.2301783
Validation loss decreased (0.168294 --> 0.166733).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.0880174
	speed: 0.1565s/iter; left time: 763.6410s
Epoch: 13 cost time: 7.448306322097778
Epoch: 13, Steps: 131 | Train Loss: 0.0925743 Vali Loss: 0.1654094 Test Loss: 0.2289173
Validation loss decreased (0.166733 --> 0.165409).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.0881534
	speed: 0.1476s/iter; left time: 700.7489s
Epoch: 14 cost time: 7.65945291519165
Epoch: 14, Steps: 131 | Train Loss: 0.0902980 Vali Loss: 0.1643509 Test Loss: 0.2279375
Validation loss decreased (0.165409 --> 0.164351).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.0877211
	speed: 0.1703s/iter; left time: 786.3464s
Epoch: 15 cost time: 7.725109100341797
Epoch: 15, Steps: 131 | Train Loss: 0.0883588 Vali Loss: 0.1635452 Test Loss: 0.2271218
Validation loss decreased (0.164351 --> 0.163545).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.0881217
	speed: 0.1509s/iter; left time: 677.1283s
Epoch: 16 cost time: 7.871613502502441
Epoch: 16, Steps: 131 | Train Loss: 0.0867084 Vali Loss: 0.1625445 Test Loss: 0.2263173
Validation loss decreased (0.163545 --> 0.162545).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1040837
	speed: 0.1726s/iter; left time: 751.5229s
Epoch: 17 cost time: 7.827272176742554
Epoch: 17, Steps: 131 | Train Loss: 0.0852384 Vali Loss: 0.1617919 Test Loss: 0.2256176
Validation loss decreased (0.162545 --> 0.161792).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.0925439
	speed: 0.1195s/iter; left time: 504.9276s
Epoch: 18 cost time: 5.883361339569092
Epoch: 18, Steps: 131 | Train Loss: 0.0840911 Vali Loss: 0.1611504 Test Loss: 0.2249168
Validation loss decreased (0.161792 --> 0.161150).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.0874411
	speed: 0.1168s/iter; left time: 477.9063s
Epoch: 19 cost time: 5.894917249679565
Epoch: 19, Steps: 131 | Train Loss: 0.0830977 Vali Loss: 0.1604657 Test Loss: 0.2243619
Validation loss decreased (0.161150 --> 0.160466).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.0845984
	speed: 0.1006s/iter; left time: 398.3870s
Epoch: 20 cost time: 5.238030672073364
Epoch: 20, Steps: 131 | Train Loss: 0.0824498 Vali Loss: 0.1600797 Test Loss: 0.2240502
Validation loss decreased (0.160466 --> 0.160080).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.0814333
	speed: 0.0947s/iter; left time: 362.8054s
Epoch: 21 cost time: 5.133654832839966
Epoch: 21, Steps: 131 | Train Loss: 0.0816955 Vali Loss: 0.1595777 Test Loss: 0.2237477
Validation loss decreased (0.160080 --> 0.159578).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.0784139
	speed: 0.1191s/iter; left time: 440.6712s
Epoch: 22 cost time: 6.1223180294036865
Epoch: 22, Steps: 131 | Train Loss: 0.0811023 Vali Loss: 0.1593172 Test Loss: 0.2233408
Validation loss decreased (0.159578 --> 0.159317).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.0654586
	speed: 0.1119s/iter; left time: 399.2509s
Epoch: 23 cost time: 5.919176816940308
Epoch: 23, Steps: 131 | Train Loss: 0.0805980 Vali Loss: 0.1591262 Test Loss: 0.2231330
Validation loss decreased (0.159317 --> 0.159126).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.0698125
	speed: 0.1172s/iter; left time: 403.0909s
Epoch: 24 cost time: 5.844886302947998
Epoch: 24, Steps: 131 | Train Loss: 0.0802146 Vali Loss: 0.1589341 Test Loss: 0.2229284
Validation loss decreased (0.159126 --> 0.158934).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.0654825
	speed: 0.1038s/iter; left time: 343.2452s
Epoch: 25 cost time: 5.240375757217407
Epoch: 25, Steps: 131 | Train Loss: 0.0798298 Vali Loss: 0.1585791 Test Loss: 0.2226714
Validation loss decreased (0.158934 --> 0.158579).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.0796648
	speed: 0.1244s/iter; left time: 395.0088s
Epoch: 26 cost time: 7.80655312538147
Epoch: 26, Steps: 131 | Train Loss: 0.0794281 Vali Loss: 0.1582364 Test Loss: 0.2225281
Validation loss decreased (0.158579 --> 0.158236).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.0880691
	speed: 0.1842s/iter; left time: 561.0183s
Epoch: 27 cost time: 8.524024963378906
Epoch: 27, Steps: 131 | Train Loss: 0.0792306 Vali Loss: 0.1581374 Test Loss: 0.2223989
Validation loss decreased (0.158236 --> 0.158137).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.0703251
	speed: 0.1718s/iter; left time: 500.5746s
Epoch: 28 cost time: 8.152998685836792
Epoch: 28, Steps: 131 | Train Loss: 0.0789999 Vali Loss: 0.1579638 Test Loss: 0.2222965
Validation loss decreased (0.158137 --> 0.157964).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.0728169
	speed: 0.1675s/iter; left time: 466.2242s
Epoch: 29 cost time: 8.835358142852783
Epoch: 29, Steps: 131 | Train Loss: 0.0789077 Vali Loss: 0.1579173 Test Loss: 0.2221207
Validation loss decreased (0.157964 --> 0.157917).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.0772507
	speed: 0.1736s/iter; left time: 460.3910s
Epoch: 30 cost time: 7.7022387981414795
Epoch: 30, Steps: 131 | Train Loss: 0.0786480 Vali Loss: 0.1577183 Test Loss: 0.2219928
Validation loss decreased (0.157917 --> 0.157718).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.0874734
	speed: 0.1740s/iter; left time: 438.7185s
Epoch: 31 cost time: 3.63863205909729
Epoch: 31, Steps: 131 | Train Loss: 0.0785777 Vali Loss: 0.1574798 Test Loss: 0.2219024
Validation loss decreased (0.157718 --> 0.157480).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.0705122
	speed: 0.0692s/iter; left time: 165.2840s
Epoch: 32 cost time: 3.52917218208313
Epoch: 32, Steps: 131 | Train Loss: 0.0784261 Vali Loss: 0.1575011 Test Loss: 0.2218278
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.0763057
	speed: 0.0568s/iter; left time: 128.3412s
Epoch: 33 cost time: 2.38753604888916
Epoch: 33, Steps: 131 | Train Loss: 0.0783518 Vali Loss: 0.1572263 Test Loss: 0.2217962
Validation loss decreased (0.157480 --> 0.157226).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.0653530
	speed: 0.1269s/iter; left time: 270.0702s
Epoch: 34 cost time: 4.515085697174072
Epoch: 34, Steps: 131 | Train Loss: 0.0782369 Vali Loss: 0.1572705 Test Loss: 0.2217599
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.0807596
	speed: 0.0560s/iter; left time: 111.8609s
Epoch: 35 cost time: 3.0622270107269287
Epoch: 35, Steps: 131 | Train Loss: 0.0781154 Vali Loss: 0.1572338 Test Loss: 0.2217455
EarlyStopping counter: 2 out of 3
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.0772148
	speed: 0.0728s/iter; left time: 135.8120s
Epoch: 36 cost time: 3.585089921951294
Epoch: 36, Steps: 131 | Train Loss: 0.0780579 Vali Loss: 0.1573061 Test Loss: 0.2216653
EarlyStopping counter: 3 out of 3
Early stopping
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=74, out_features=93, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  12332544.0
params:  6975.0
Trainable parameters:  6975
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2782914
	speed: 0.0308s/iter; left time: 198.9722s
Epoch: 1 cost time: 3.7134017944335938
Epoch: 1, Steps: 131 | Train Loss: 0.2982320 Vali Loss: 0.1546134 Test Loss: 0.2190835
Validation loss decreased (inf --> 0.154613).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2581866
	speed: 0.0834s/iter; left time: 527.1445s
Epoch: 2 cost time: 4.270128011703491
Epoch: 2, Steps: 131 | Train Loss: 0.2956259 Vali Loss: 0.1541482 Test Loss: 0.2181808
Validation loss decreased (0.154613 --> 0.154148).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2874554
	speed: 0.0709s/iter; left time: 439.0803s
Epoch: 3 cost time: 3.780137300491333
Epoch: 3, Steps: 131 | Train Loss: 0.2940679 Vali Loss: 0.1537295 Test Loss: 0.2177952
Validation loss decreased (0.154148 --> 0.153730).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3466159
	speed: 0.0724s/iter; left time: 438.3608s
Epoch: 4 cost time: 3.77799391746521
Epoch: 4, Steps: 131 | Train Loss: 0.2933745 Vali Loss: 0.1535619 Test Loss: 0.2174450
Validation loss decreased (0.153730 --> 0.153562).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2837786
	speed: 0.0901s/iter; left time: 533.7488s
Epoch: 5 cost time: 3.800565242767334
Epoch: 5, Steps: 131 | Train Loss: 0.2927185 Vali Loss: 0.1533237 Test Loss: 0.2171683
Validation loss decreased (0.153562 --> 0.153324).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2398297
	speed: 0.0780s/iter; left time: 452.2314s
Epoch: 6 cost time: 5.484168291091919
Epoch: 6, Steps: 131 | Train Loss: 0.2926832 Vali Loss: 0.1532580 Test Loss: 0.2169189
Validation loss decreased (0.153324 --> 0.153258).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2196457
	speed: 0.0834s/iter; left time: 472.2908s
Epoch: 7 cost time: 4.105071067810059
Epoch: 7, Steps: 131 | Train Loss: 0.2917189 Vali Loss: 0.1530083 Test Loss: 0.2166792
Validation loss decreased (0.153258 --> 0.153008).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3932115
	speed: 0.0771s/iter; left time: 426.7658s
Epoch: 8 cost time: 3.945336103439331
Epoch: 8, Steps: 131 | Train Loss: 0.2920570 Vali Loss: 0.1530374 Test Loss: 0.2167350
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3004283
	speed: 0.0569s/iter; left time: 307.2749s
Epoch: 9 cost time: 2.303589105606079
Epoch: 9, Steps: 131 | Train Loss: 0.2917168 Vali Loss: 0.1530891 Test Loss: 0.2165184
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2805782
	speed: 0.0657s/iter; left time: 346.4093s
Epoch: 10 cost time: 4.4558234214782715
Epoch: 10, Steps: 131 | Train Loss: 0.2909195 Vali Loss: 0.1530347 Test Loss: 0.2166981
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_192_FITS_ETTm2_ftM_sl720_ll48_pl192_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.21839489042758942, mae:0.2925766110420227, rse:0.3782826066017151, corr:[0.56083703 0.5641858  0.5659378  0.56552696 0.5638551  0.56216276
 0.5610978  0.5607584  0.56094277 0.56134343 0.5616127  0.56150514
 0.5610048  0.5602515  0.55949306 0.5588509  0.5583808  0.5580165
 0.5576624  0.5571951  0.5565738  0.555797   0.55496335 0.5542022
 0.55359155 0.5531484  0.5528315  0.5525609  0.5522526  0.551843
 0.5512963  0.5506817  0.5500229  0.5493209  0.54861814 0.5479786
 0.547401   0.546876   0.54636043 0.5458138  0.5452156  0.54455847
 0.5438678  0.5431698  0.54249287 0.541843   0.5412333  0.54065496
 0.5400144  0.53924716 0.53835076 0.53739685 0.53642434 0.53549474
 0.5346842  0.53410846 0.5337728  0.5336147  0.5335455  0.5334666
 0.5333004  0.5330624  0.5327572  0.5324163  0.5320649  0.53180325
 0.53162134 0.53153706 0.53150487 0.5314278  0.53122824 0.53090125
 0.5304627  0.5299662  0.52945226 0.5289898  0.52860045 0.52824557
 0.52786064 0.5274028  0.52677464 0.52598196 0.5250712  0.52413565
 0.5232797  0.522643   0.5221903  0.52191925 0.52173996 0.52154076
 0.52124035 0.52078307 0.520039   0.5190218  0.5177781  0.5163744
 0.51494133 0.51365215 0.5125311  0.5115318  0.51060694 0.5096908
 0.50877464 0.507828   0.5068088  0.5057272  0.5046418  0.50363964
 0.50266504 0.50169945 0.5007449  0.4998013  0.4989882  0.4982732
 0.49760288 0.4969451  0.49626943 0.4954984  0.49465623 0.49368656
 0.49270535 0.49176517 0.4910366  0.49053484 0.49017096 0.48982158
 0.48939583 0.48881075 0.48801428 0.48698345 0.48579597 0.48455882
 0.48347065 0.48268685 0.48227862 0.48214427 0.48205027 0.48189443
 0.4815211  0.4809106  0.48007733 0.47914854 0.47829753 0.47756445
 0.4769696  0.4763797  0.4758529  0.47529948 0.4747161  0.47401872
 0.4732913  0.4726552  0.47210366 0.47158    0.47104758 0.47058
 0.47015694 0.46977043 0.46932277 0.46894473 0.46856222 0.46825036
 0.46797746 0.46777934 0.46763164 0.46750328 0.46725145 0.46679664
 0.4661673  0.46552095 0.4648947  0.46442842 0.46415746 0.46403208
 0.46396548 0.4638144  0.46348926 0.46294573 0.46211693 0.46127787
 0.46048173 0.45976195 0.45921654 0.45873195 0.45807543 0.45711994
 0.4559289  0.4549505  0.4546722  0.45529574 0.45626912 0.4561855 ]
