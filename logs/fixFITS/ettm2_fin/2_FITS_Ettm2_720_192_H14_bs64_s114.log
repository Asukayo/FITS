Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=122, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=5, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_720_192_FITS_ETTm2_ftM_sl720_ll48_pl192_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=122, out_features=154, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  16834048.0
params:  18942.0
Trainable parameters:  18942
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2755005
	speed: 0.1218s/iter; left time: 1584.0515s
	iters: 200, epoch: 1 | loss: 0.2159140
	speed: 0.1026s/iter; left time: 1324.2313s
Epoch: 1 cost time: 27.093051195144653
Epoch: 1, Steps: 262 | Train Loss: 0.2958422 Vali Loss: 0.2019973 Test Loss: 0.2694095
Validation loss decreased (inf --> 0.201997).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1662026
	speed: 0.6048s/iter; left time: 7704.3438s
	iters: 200, epoch: 2 | loss: 0.1742362
	speed: 0.1566s/iter; left time: 1979.0087s
Epoch: 2 cost time: 42.213388442993164
Epoch: 2, Steps: 262 | Train Loss: 0.1798908 Vali Loss: 0.1871109 Test Loss: 0.2529759
Validation loss decreased (0.201997 --> 0.187111).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1408906
	speed: 0.5573s/iter; left time: 6952.8398s
	iters: 200, epoch: 3 | loss: 0.1662539
	speed: 0.0509s/iter; left time: 630.4566s
Epoch: 3 cost time: 15.342485904693604
Epoch: 3, Steps: 262 | Train Loss: 0.1372672 Vali Loss: 0.1793358 Test Loss: 0.2449402
Validation loss decreased (0.187111 --> 0.179336).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1291565
	speed: 0.3326s/iter; left time: 4062.7107s
	iters: 200, epoch: 4 | loss: 0.1612616
	speed: 0.1228s/iter; left time: 1487.6676s
Epoch: 4 cost time: 33.75710725784302
Epoch: 4, Steps: 262 | Train Loss: 0.1135836 Vali Loss: 0.1733647 Test Loss: 0.2385675
Validation loss decreased (0.179336 --> 0.173365).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1273163
	speed: 0.4717s/iter; left time: 5638.4338s
	iters: 200, epoch: 5 | loss: 0.0924124
	speed: 0.1357s/iter; left time: 1608.1644s
Epoch: 5 cost time: 35.43089199066162
Epoch: 5, Steps: 262 | Train Loss: 0.0988206 Vali Loss: 0.1683659 Test Loss: 0.2336590
Validation loss decreased (0.173365 --> 0.168366).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1272064
	speed: 0.6111s/iter; left time: 7144.0109s
	iters: 200, epoch: 6 | loss: 0.1014319
	speed: 0.1306s/iter; left time: 1513.5371s
Epoch: 6 cost time: 35.595048666000366
Epoch: 6, Steps: 262 | Train Loss: 0.0892634 Vali Loss: 0.1645834 Test Loss: 0.2300748
Validation loss decreased (0.168366 --> 0.164583).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.0687054
	speed: 0.6029s/iter; left time: 6890.8910s
	iters: 200, epoch: 7 | loss: 0.0655147
	speed: 0.1423s/iter; left time: 1611.7700s
Epoch: 7 cost time: 37.815990686416626
Epoch: 7, Steps: 262 | Train Loss: 0.0830793 Vali Loss: 0.1621642 Test Loss: 0.2273822
Validation loss decreased (0.164583 --> 0.162164).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.0603232
	speed: 0.6616s/iter; left time: 7388.1443s
	iters: 200, epoch: 8 | loss: 0.0837682
	speed: 0.1410s/iter; left time: 1560.9396s
Epoch: 8 cost time: 35.73983192443848
Epoch: 8, Steps: 262 | Train Loss: 0.0789985 Vali Loss: 0.1597517 Test Loss: 0.2253238
Validation loss decreased (0.162164 --> 0.159752).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1088160
	speed: 0.5021s/iter; left time: 5475.5600s
	iters: 200, epoch: 9 | loss: 0.0809665
	speed: 0.1328s/iter; left time: 1435.0596s
Epoch: 9 cost time: 36.43294954299927
Epoch: 9, Steps: 262 | Train Loss: 0.0763060 Vali Loss: 0.1584775 Test Loss: 0.2240645
Validation loss decreased (0.159752 --> 0.158478).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.0777502
	speed: 0.6113s/iter; left time: 6505.5433s
	iters: 200, epoch: 10 | loss: 0.0803844
	speed: 0.1278s/iter; left time: 1347.3886s
Epoch: 10 cost time: 35.183473110198975
Epoch: 10, Steps: 262 | Train Loss: 0.0746059 Vali Loss: 0.1574376 Test Loss: 0.2233552
Validation loss decreased (0.158478 --> 0.157438).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.0646767
	speed: 0.5413s/iter; left time: 5619.1852s
	iters: 200, epoch: 11 | loss: 0.0651787
	speed: 0.1344s/iter; left time: 1382.2507s
Epoch: 11 cost time: 35.25148272514343
Epoch: 11, Steps: 262 | Train Loss: 0.0734666 Vali Loss: 0.1566059 Test Loss: 0.2225611
Validation loss decreased (0.157438 --> 0.156606).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.0645642
	speed: 0.6134s/iter; left time: 6206.4920s
	iters: 200, epoch: 12 | loss: 0.0650322
	speed: 0.1548s/iter; left time: 1550.5639s
Epoch: 12 cost time: 39.53954076766968
Epoch: 12, Steps: 262 | Train Loss: 0.0725051 Vali Loss: 0.1558290 Test Loss: 0.2218791
Validation loss decreased (0.156606 --> 0.155829).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.0755958
	speed: 0.6899s/iter; left time: 6800.5173s
	iters: 200, epoch: 13 | loss: 0.0614391
	speed: 0.1348s/iter; left time: 1315.2319s
Epoch: 13 cost time: 37.63757514953613
Epoch: 13, Steps: 262 | Train Loss: 0.0723036 Vali Loss: 0.1555350 Test Loss: 0.2216522
Validation loss decreased (0.155829 --> 0.155535).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.0651326
	speed: 0.5744s/iter; left time: 5511.6802s
	iters: 200, epoch: 14 | loss: 0.0570440
	speed: 0.1039s/iter; left time: 986.6366s
Epoch: 14 cost time: 29.31803822517395
Epoch: 14, Steps: 262 | Train Loss: 0.0718610 Vali Loss: 0.1555300 Test Loss: 0.2216800
Validation loss decreased (0.155535 --> 0.155530).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.0782549
	speed: 0.5596s/iter; left time: 5223.1219s
	iters: 200, epoch: 15 | loss: 0.0760598
	speed: 0.1361s/iter; left time: 1256.3798s
Epoch: 15 cost time: 35.89205312728882
Epoch: 15, Steps: 262 | Train Loss: 0.0717813 Vali Loss: 0.1552664 Test Loss: 0.2214461
Validation loss decreased (0.155530 --> 0.155266).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.0695529
	speed: 0.6218s/iter; left time: 5640.3619s
	iters: 200, epoch: 16 | loss: 0.0923426
	speed: 0.1332s/iter; left time: 1195.3206s
Epoch: 16 cost time: 36.35954523086548
Epoch: 16, Steps: 262 | Train Loss: 0.0716159 Vali Loss: 0.1551629 Test Loss: 0.2214189
Validation loss decreased (0.155266 --> 0.155163).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.0560853
	speed: 0.6274s/iter; left time: 5527.0365s
	iters: 200, epoch: 17 | loss: 0.0575303
	speed: 0.1314s/iter; left time: 1144.0608s
Epoch: 17 cost time: 35.27436399459839
Epoch: 17, Steps: 262 | Train Loss: 0.0715954 Vali Loss: 0.1548878 Test Loss: 0.2211163
Validation loss decreased (0.155163 --> 0.154888).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.0665522
	speed: 0.5162s/iter; left time: 4412.1778s
	iters: 200, epoch: 18 | loss: 0.0711185
	speed: 0.1507s/iter; left time: 1272.6745s
Epoch: 18 cost time: 40.6878924369812
Epoch: 18, Steps: 262 | Train Loss: 0.0715466 Vali Loss: 0.1549236 Test Loss: 0.2210773
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.0827640
	speed: 0.6564s/iter; left time: 5438.1801s
	iters: 200, epoch: 19 | loss: 0.0882961
	speed: 0.1345s/iter; left time: 1100.9167s
Epoch: 19 cost time: 36.4497287273407
Epoch: 19, Steps: 262 | Train Loss: 0.0715200 Vali Loss: 0.1549507 Test Loss: 0.2212073
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.0872350
	speed: 0.5408s/iter; left time: 4338.9639s
	iters: 200, epoch: 20 | loss: 0.0652403
	speed: 0.0389s/iter; left time: 308.5107s
Epoch: 20 cost time: 17.896907806396484
Epoch: 20, Steps: 262 | Train Loss: 0.0714741 Vali Loss: 0.1550405 Test Loss: 0.2211335
EarlyStopping counter: 3 out of 3
Early stopping
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=122, out_features=154, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  16834048.0
params:  18942.0
Trainable parameters:  18942
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4601300
	speed: 0.1531s/iter; left time: 1990.9718s
	iters: 200, epoch: 1 | loss: 0.2474328
	speed: 0.1393s/iter; left time: 1797.7031s
Epoch: 1 cost time: 38.03569960594177
Epoch: 1, Steps: 262 | Train Loss: 0.2946143 Vali Loss: 0.1528720 Test Loss: 0.2184654
Validation loss decreased (inf --> 0.152872).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3360547
	speed: 0.6586s/iter; left time: 8390.5046s
	iters: 200, epoch: 2 | loss: 0.3014445
	speed: 0.1580s/iter; left time: 1997.0968s
Epoch: 2 cost time: 43.00914645195007
Epoch: 2, Steps: 262 | Train Loss: 0.2925228 Vali Loss: 0.1521299 Test Loss: 0.2175585
Validation loss decreased (0.152872 --> 0.152130).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2286593
	speed: 0.7188s/iter; left time: 8968.9320s
	iters: 200, epoch: 3 | loss: 0.3987497
	speed: 0.1407s/iter; left time: 1740.9905s
Epoch: 3 cost time: 38.27673053741455
Epoch: 3, Steps: 262 | Train Loss: 0.2909020 Vali Loss: 0.1518808 Test Loss: 0.2172855
Validation loss decreased (0.152130 --> 0.151881).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3404908
	speed: 0.6271s/iter; left time: 7659.6799s
	iters: 200, epoch: 4 | loss: 0.2315214
	speed: 0.1359s/iter; left time: 1646.6417s
Epoch: 4 cost time: 36.920873403549194
Epoch: 4, Steps: 262 | Train Loss: 0.2901646 Vali Loss: 0.1516650 Test Loss: 0.2168974
Validation loss decreased (0.151881 --> 0.151665).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2898461
	speed: 0.5440s/iter; left time: 6502.4660s
	iters: 200, epoch: 5 | loss: 0.2721084
	speed: 0.1365s/iter; left time: 1618.2921s
Epoch: 5 cost time: 35.64178967475891
Epoch: 5, Steps: 262 | Train Loss: 0.2897192 Vali Loss: 0.1516093 Test Loss: 0.2169781
Validation loss decreased (0.151665 --> 0.151609).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2099789
	speed: 0.6429s/iter; left time: 7516.5074s
	iters: 200, epoch: 6 | loss: 0.3187278
	speed: 0.1336s/iter; left time: 1547.9857s
Epoch: 6 cost time: 37.124380588531494
Epoch: 6, Steps: 262 | Train Loss: 0.2892282 Vali Loss: 0.1513405 Test Loss: 0.2167261
Validation loss decreased (0.151609 --> 0.151340).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3851872
	speed: 0.6771s/iter; left time: 7738.5763s
	iters: 200, epoch: 7 | loss: 0.3898068
	speed: 0.1611s/iter; left time: 1824.5490s
Epoch: 7 cost time: 42.286022901535034
Epoch: 7, Steps: 262 | Train Loss: 0.2892288 Vali Loss: 0.1513539 Test Loss: 0.2165491
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2034906
	speed: 0.6868s/iter; left time: 7669.8189s
	iters: 200, epoch: 8 | loss: 0.4597122
	speed: 0.1391s/iter; left time: 1539.6320s
Epoch: 8 cost time: 36.692768573760986
Epoch: 8, Steps: 262 | Train Loss: 0.2884478 Vali Loss: 0.1512855 Test Loss: 0.2164046
Validation loss decreased (0.151340 --> 0.151286).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2639932
	speed: 0.6918s/iter; left time: 7544.1456s
	iters: 200, epoch: 9 | loss: 0.3001087
	speed: 0.1468s/iter; left time: 1586.5738s
Epoch: 9 cost time: 43.1471381187439
Epoch: 9, Steps: 262 | Train Loss: 0.2888148 Vali Loss: 0.1514850 Test Loss: 0.2164460
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2456484
	speed: 0.8146s/iter; left time: 8670.0212s
	iters: 200, epoch: 10 | loss: 0.2674194
	speed: 0.1819s/iter; left time: 1917.9379s
Epoch: 10 cost time: 48.376800775527954
Epoch: 10, Steps: 262 | Train Loss: 0.2889789 Vali Loss: 0.1512388 Test Loss: 0.2163440
Validation loss decreased (0.151286 --> 0.151239).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2796676
	speed: 0.8499s/iter; left time: 8823.1097s
	iters: 200, epoch: 11 | loss: 0.2836767
	speed: 0.1795s/iter; left time: 1845.3093s
Epoch: 11 cost time: 48.612261056900024
Epoch: 11, Steps: 262 | Train Loss: 0.2887335 Vali Loss: 0.1512265 Test Loss: 0.2162619
Validation loss decreased (0.151239 --> 0.151226).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2593647
	speed: 0.7867s/iter; left time: 7960.4336s
	iters: 200, epoch: 12 | loss: 0.3973961
	speed: 0.1345s/iter; left time: 1347.0670s
Epoch: 12 cost time: 38.629634141922
Epoch: 12, Steps: 262 | Train Loss: 0.2887913 Vali Loss: 0.1512378 Test Loss: 0.2162273
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2245813
	speed: 0.7134s/iter; left time: 7031.9024s
	iters: 200, epoch: 13 | loss: 0.2231158
	speed: 0.1589s/iter; left time: 1549.9104s
Epoch: 13 cost time: 42.83268427848816
Epoch: 13, Steps: 262 | Train Loss: 0.2886350 Vali Loss: 0.1513726 Test Loss: 0.2164168
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3397512
	speed: 0.7141s/iter; left time: 6851.3939s
	iters: 200, epoch: 14 | loss: 0.3634262
	speed: 0.1501s/iter; left time: 1425.2888s
Epoch: 14 cost time: 40.091657876968384
Epoch: 14, Steps: 262 | Train Loss: 0.2883602 Vali Loss: 0.1512267 Test Loss: 0.2161465
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_192_FITS_ETTm2_ftM_sl720_ll48_pl192_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.21683622896671295, mae:0.29134711623191833, rse:0.376930296421051, corr:[0.5654362  0.56657183 0.5635227  0.56177586 0.56199706 0.56254005
 0.5620019  0.56080854 0.5600766  0.5601776  0.5605683  0.560471
 0.5598292  0.5591673  0.5589747  0.5590872  0.5590147  0.5584055
 0.5574485  0.556616   0.5561789  0.5559292  0.55550724 0.5547699
 0.55393124 0.5533134  0.55298525 0.55271196 0.5522054  0.5514358
 0.55061406 0.5500429  0.5497007  0.54935277 0.548857   0.54825294
 0.54764473 0.5471421  0.5466788  0.5461309  0.5454687  0.54476005
 0.54415584 0.5437159  0.54333967 0.54281014 0.5420479  0.5411323
 0.5401803  0.5393753  0.53876406 0.53822273 0.53754383 0.5367157
 0.5359021  0.53532314 0.53492624 0.5345135  0.5339913  0.53344184
 0.5330453  0.5329871  0.53310966 0.53310037 0.5327817  0.5323037
 0.53184134 0.5316321  0.5316439  0.5316104  0.5313427  0.5309027
 0.53047156 0.5302045  0.52998406 0.5296314  0.52904415 0.52831537
 0.5276643  0.52726907 0.5269552  0.526565   0.52601427 0.52536833
 0.5247231  0.52414185 0.5234786  0.5227576  0.5221017  0.52169365
 0.52160364 0.52160776 0.5212269  0.5202665  0.5188045  0.51715577
 0.51572937 0.51471466 0.513819   0.51275814 0.5115328  0.51033133
 0.509372   0.508557   0.5075982  0.5063464  0.5050156  0.5040506
 0.5035478  0.5032972  0.50289065 0.5020184  0.50080675 0.49952006
 0.49847114 0.4978333  0.49739656 0.4967592  0.49583757 0.49466786
 0.49361286 0.49277982 0.49224275 0.49176756 0.49109912 0.4901494
 0.48901427 0.48774004 0.4863212  0.48480257 0.48337713 0.48221943
 0.4814851  0.48117796 0.48121887 0.48143667 0.48155874 0.48147696
 0.48103768 0.48027885 0.479343   0.47859833 0.47831148 0.47830194
 0.47825876 0.4778088  0.47708505 0.47616726 0.47525775 0.4743491
 0.47360492 0.47321033 0.4730853  0.47297812 0.47264543 0.4720219
 0.47112364 0.47028258 0.46977934 0.46984607 0.46991873 0.46952808
 0.46842533 0.4670811  0.4663122  0.46659046 0.46732125 0.4676376
 0.46718135 0.46634245 0.4656619  0.4655506  0.46571207 0.4656029
 0.4650833  0.4644247  0.46396068 0.46357402 0.46269614 0.461358
 0.45986262 0.45894572 0.4590459  0.45950386 0.45952928 0.45914683
 0.4589802  0.4593642  0.45934325 0.4579777  0.45612028 0.45618877]
