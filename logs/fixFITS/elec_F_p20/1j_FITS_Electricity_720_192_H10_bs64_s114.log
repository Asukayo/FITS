Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=320, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=4, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_720_j192_H10', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:4
>>>>>>>start training : Electricity_720_j192_H10_FITS_custom_ftM_sl720_ll48_pl192_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17501
val 2441
test 5069
Model(
  (freq_upsampler): Linear(in_features=320, out_features=405, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  5325004800.0
params:  130005.0
Trainable parameters:  130005
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3663308
	speed: 0.3792s/iter; left time: 2541.2240s
Epoch: 1 cost time: 50.360567808151245
Epoch: 1, Steps: 136 | Train Loss: 0.5605721 Vali Loss: 0.2384217 Test Loss: 0.2876537
Validation loss decreased (inf --> 0.238422).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1947405
	speed: 0.8349s/iter; left time: 5480.8577s
Epoch: 2 cost time: 52.32001996040344
Epoch: 2, Steps: 136 | Train Loss: 0.2117124 Vali Loss: 0.1386990 Test Loss: 0.1699839
Validation loss decreased (0.238422 --> 0.138699).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1583138
	speed: 0.8654s/iter; left time: 5563.8995s
Epoch: 3 cost time: 53.91784429550171
Epoch: 3, Steps: 136 | Train Loss: 0.1600525 Vali Loss: 0.1283269 Test Loss: 0.1561435
Validation loss decreased (0.138699 --> 0.128327).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1591530
	speed: 0.8192s/iter; left time: 5155.1546s
Epoch: 4 cost time: 49.53029799461365
Epoch: 4, Steps: 136 | Train Loss: 0.1540054 Vali Loss: 0.1271500 Test Loss: 0.1543038
Validation loss decreased (0.128327 --> 0.127150).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1537805
	speed: 0.8099s/iter; left time: 4986.6785s
Epoch: 5 cost time: 51.082892179489136
Epoch: 5, Steps: 136 | Train Loss: 0.1527953 Vali Loss: 0.1267007 Test Loss: 0.1536825
Validation loss decreased (0.127150 --> 0.126701).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1549111
	speed: 0.8155s/iter; left time: 4909.9553s
Epoch: 6 cost time: 50.34092712402344
Epoch: 6, Steps: 136 | Train Loss: 0.1520603 Vali Loss: 0.1263235 Test Loss: 0.1532919
Validation loss decreased (0.126701 --> 0.126324).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1492247
	speed: 0.8170s/iter; left time: 4808.0421s
Epoch: 7 cost time: 50.56261610984802
Epoch: 7, Steps: 136 | Train Loss: 0.1516546 Vali Loss: 0.1262316 Test Loss: 0.1530851
Validation loss decreased (0.126324 --> 0.126232).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1491908
	speed: 0.8335s/iter; left time: 4791.7455s
Epoch: 8 cost time: 53.12065649032593
Epoch: 8, Steps: 136 | Train Loss: 0.1513985 Vali Loss: 0.1261067 Test Loss: 0.1529091
Validation loss decreased (0.126232 --> 0.126107).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1584432
	speed: 0.9115s/iter; left time: 5115.9733s
Epoch: 9 cost time: 57.16046142578125
Epoch: 9, Steps: 136 | Train Loss: 0.1511205 Vali Loss: 0.1259168 Test Loss: 0.1527378
Validation loss decreased (0.126107 --> 0.125917).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1605521
	speed: 0.8181s/iter; left time: 4480.6430s
Epoch: 10 cost time: 47.54960918426514
Epoch: 10, Steps: 136 | Train Loss: 0.1509265 Vali Loss: 0.1258931 Test Loss: 0.1526569
Validation loss decreased (0.125917 --> 0.125893).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1625321
	speed: 0.7331s/iter; left time: 3915.2531s
Epoch: 11 cost time: 44.146241188049316
Epoch: 11, Steps: 136 | Train Loss: 0.1507627 Vali Loss: 0.1258539 Test Loss: 0.1525820
Validation loss decreased (0.125893 --> 0.125854).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1497782
	speed: 0.7698s/iter; left time: 4006.8075s
Epoch: 12 cost time: 48.55008578300476
Epoch: 12, Steps: 136 | Train Loss: 0.1506812 Vali Loss: 0.1257607 Test Loss: 0.1525584
Validation loss decreased (0.125854 --> 0.125761).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1469118
	speed: 0.7755s/iter; left time: 3931.1013s
Epoch: 13 cost time: 45.43841505050659
Epoch: 13, Steps: 136 | Train Loss: 0.1506199 Vali Loss: 0.1257057 Test Loss: 0.1524499
Validation loss decreased (0.125761 --> 0.125706).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1496736
	speed: 0.8097s/iter; left time: 3994.1467s
Epoch: 14 cost time: 49.10894560813904
Epoch: 14, Steps: 136 | Train Loss: 0.1505319 Vali Loss: 0.1256806 Test Loss: 0.1524412
Validation loss decreased (0.125706 --> 0.125681).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1627796
	speed: 0.7927s/iter; left time: 3802.7842s
Epoch: 15 cost time: 47.60896921157837
Epoch: 15, Steps: 136 | Train Loss: 0.1505334 Vali Loss: 0.1256020 Test Loss: 0.1523704
Validation loss decreased (0.125681 --> 0.125602).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1448064
	speed: 0.8231s/iter; left time: 3836.4036s
Epoch: 16 cost time: 53.573384046554565
Epoch: 16, Steps: 136 | Train Loss: 0.1504316 Vali Loss: 0.1255924 Test Loss: 0.1523037
Validation loss decreased (0.125602 --> 0.125592).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1456109
	speed: 0.8396s/iter; left time: 3799.3340s
Epoch: 17 cost time: 48.07498526573181
Epoch: 17, Steps: 136 | Train Loss: 0.1503549 Vali Loss: 0.1256068 Test Loss: 0.1523455
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1391965
	speed: 0.7257s/iter; left time: 3184.9294s
Epoch: 18 cost time: 44.10712695121765
Epoch: 18, Steps: 136 | Train Loss: 0.1504065 Vali Loss: 0.1255193 Test Loss: 0.1523029
Validation loss decreased (0.125592 --> 0.125519).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1475557
	speed: 0.6608s/iter; left time: 2810.3886s
Epoch: 19 cost time: 41.402583360672
Epoch: 19, Steps: 136 | Train Loss: 0.1503281 Vali Loss: 0.1256027 Test Loss: 0.1522921
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1563723
	speed: 0.6714s/iter; left time: 2764.1715s
Epoch: 20 cost time: 40.31239914894104
Epoch: 20, Steps: 136 | Train Loss: 0.1502520 Vali Loss: 0.1255679 Test Loss: 0.1522674
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1544440
	speed: 0.6726s/iter; left time: 2677.6449s
Epoch: 21 cost time: 42.34932827949524
Epoch: 21, Steps: 136 | Train Loss: 0.1503236 Vali Loss: 0.1255093 Test Loss: 0.1522729
Validation loss decreased (0.125519 --> 0.125509).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1579686
	speed: 0.6883s/iter; left time: 2646.6437s
Epoch: 22 cost time: 41.15503144264221
Epoch: 22, Steps: 136 | Train Loss: 0.1502697 Vali Loss: 0.1255029 Test Loss: 0.1522559
Validation loss decreased (0.125509 --> 0.125503).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1461715
	speed: 0.6835s/iter; left time: 2534.9587s
Epoch: 23 cost time: 42.71849298477173
Epoch: 23, Steps: 136 | Train Loss: 0.1502592 Vali Loss: 0.1255220 Test Loss: 0.1522087
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1421712
	speed: 0.7346s/iter; left time: 2624.7713s
Epoch: 24 cost time: 44.07322883605957
Epoch: 24, Steps: 136 | Train Loss: 0.1501432 Vali Loss: 0.1254721 Test Loss: 0.1522153
Validation loss decreased (0.125503 --> 0.125472).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1432084
	speed: 0.6933s/iter; left time: 2382.7257s
Epoch: 25 cost time: 41.723151206970215
Epoch: 25, Steps: 136 | Train Loss: 0.1501662 Vali Loss: 0.1255157 Test Loss: 0.1522100
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1454143
	speed: 0.6389s/iter; left time: 2109.0876s
Epoch: 26 cost time: 40.55990386009216
Epoch: 26, Steps: 136 | Train Loss: 0.1501710 Vali Loss: 0.1255236 Test Loss: 0.1522199
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1497026
	speed: 0.6495s/iter; left time: 2055.6738s
Epoch: 27 cost time: 38.72841238975525
Epoch: 27, Steps: 136 | Train Loss: 0.1501622 Vali Loss: 0.1254605 Test Loss: 0.1521755
Validation loss decreased (0.125472 --> 0.125460).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1540311
	speed: 0.6318s/iter; left time: 1913.5797s
Epoch: 28 cost time: 38.82757759094238
Epoch: 28, Steps: 136 | Train Loss: 0.1501485 Vali Loss: 0.1253721 Test Loss: 0.1521782
Validation loss decreased (0.125460 --> 0.125372).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1428828
	speed: 0.6037s/iter; left time: 1746.6439s
Epoch: 29 cost time: 36.76099443435669
Epoch: 29, Steps: 136 | Train Loss: 0.1500531 Vali Loss: 0.1254573 Test Loss: 0.1521237
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1438818
	speed: 0.5894s/iter; left time: 1624.8397s
Epoch: 30 cost time: 36.67146873474121
Epoch: 30, Steps: 136 | Train Loss: 0.1501814 Vali Loss: 0.1254339 Test Loss: 0.1521488
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1460288
	speed: 0.6063s/iter; left time: 1589.2191s
Epoch: 31 cost time: 36.7167067527771
Epoch: 31, Steps: 136 | Train Loss: 0.1501106 Vali Loss: 0.1254574 Test Loss: 0.1521268
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1622786
	speed: 0.6230s/iter; left time: 1548.2073s
Epoch: 32 cost time: 39.62090611457825
Epoch: 32, Steps: 136 | Train Loss: 0.1501705 Vali Loss: 0.1253844 Test Loss: 0.1521704
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1543322
	speed: 0.6364s/iter; left time: 1494.8334s
Epoch: 33 cost time: 37.66350293159485
Epoch: 33, Steps: 136 | Train Loss: 0.1500474 Vali Loss: 0.1255061 Test Loss: 0.1521401
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1579383
	speed: 0.5669s/iter; left time: 1254.4596s
Epoch: 34 cost time: 34.121582984924316
Epoch: 34, Steps: 136 | Train Loss: 0.1500443 Vali Loss: 0.1255202 Test Loss: 0.1521131
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1551987
	speed: 0.5494s/iter; left time: 1141.1384s
Epoch: 35 cost time: 35.17232060432434
Epoch: 35, Steps: 136 | Train Loss: 0.1500377 Vali Loss: 0.1254634 Test Loss: 0.1521229
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1679611
	speed: 0.6009s/iter; left time: 1166.2549s
Epoch: 36 cost time: 37.36593055725098
Epoch: 36, Steps: 136 | Train Loss: 0.1500386 Vali Loss: 0.1254484 Test Loss: 0.1521265
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1409132
	speed: 0.6111s/iter; left time: 1102.9794s
Epoch: 37 cost time: 36.377023458480835
Epoch: 37, Steps: 136 | Train Loss: 0.1500687 Vali Loss: 0.1253959 Test Loss: 0.1521284
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1441987
	speed: 0.5882s/iter; left time: 981.6344s
Epoch: 38 cost time: 36.68692088127136
Epoch: 38, Steps: 136 | Train Loss: 0.1501126 Vali Loss: 0.1254408 Test Loss: 0.1521037
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1547071
	speed: 0.6113s/iter; left time: 937.1856s
Epoch: 39 cost time: 37.205991983413696
Epoch: 39, Steps: 136 | Train Loss: 0.1500726 Vali Loss: 0.1253860 Test Loss: 0.1521014
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1456300
	speed: 0.6116s/iter; left time: 854.4345s
Epoch: 40 cost time: 38.556697368621826
Epoch: 40, Steps: 136 | Train Loss: 0.1500628 Vali Loss: 0.1253975 Test Loss: 0.1521083
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1454445
	speed: 0.6088s/iter; left time: 767.7298s
Epoch: 41 cost time: 37.861626863479614
Epoch: 41, Steps: 136 | Train Loss: 0.1501005 Vali Loss: 0.1254727 Test Loss: 0.1520912
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1508026
	speed: 0.6152s/iter; left time: 692.0769s
Epoch: 42 cost time: 37.55144429206848
Epoch: 42, Steps: 136 | Train Loss: 0.1500430 Vali Loss: 0.1254252 Test Loss: 0.1521014
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1443753
	speed: 0.6357s/iter; left time: 628.6825s
Epoch: 43 cost time: 39.02899169921875
Epoch: 43, Steps: 136 | Train Loss: 0.1500127 Vali Loss: 0.1253753 Test Loss: 0.1520937
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1603630
	speed: 0.5824s/iter; left time: 496.7850s
Epoch: 44 cost time: 35.360286235809326
Epoch: 44, Steps: 136 | Train Loss: 0.1500190 Vali Loss: 0.1253316 Test Loss: 0.1520859
Validation loss decreased (0.125372 --> 0.125332).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1519583
	speed: 0.6197s/iter; left time: 444.3457s
Epoch: 45 cost time: 39.08311867713928
Epoch: 45, Steps: 136 | Train Loss: 0.1500368 Vali Loss: 0.1253107 Test Loss: 0.1520846
Validation loss decreased (0.125332 --> 0.125311).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1558755
	speed: 0.6639s/iter; left time: 385.7448s
Epoch: 46 cost time: 38.74977087974548
Epoch: 46, Steps: 136 | Train Loss: 0.1499896 Vali Loss: 0.1254214 Test Loss: 0.1520946
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1635579
	speed: 0.6354s/iter; left time: 282.7507s
Epoch: 47 cost time: 40.331194162368774
Epoch: 47, Steps: 136 | Train Loss: 0.1500531 Vali Loss: 0.1253906 Test Loss: 0.1520852
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1623961
	speed: 0.6157s/iter; left time: 190.2521s
Epoch: 48 cost time: 37.27922058105469
Epoch: 48, Steps: 136 | Train Loss: 0.1499543 Vali Loss: 0.1253848 Test Loss: 0.1520693
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1410539
	speed: 0.6002s/iter; left time: 103.8336s
Epoch: 49 cost time: 36.79382538795471
Epoch: 49, Steps: 136 | Train Loss: 0.1500010 Vali Loss: 0.1252789 Test Loss: 0.1520691
Validation loss decreased (0.125311 --> 0.125279).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1433251
	speed: 0.6326s/iter; left time: 23.4062s
Epoch: 50 cost time: 39.29993152618408
Epoch: 50, Steps: 136 | Train Loss: 0.1500529 Vali Loss: 0.1253637 Test Loss: 0.1520785
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
>>>>>>>testing : Electricity_720_j192_H10_FITS_custom_ftM_sl720_ll48_pl192_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5069
mse:0.14918364584445953, mae:0.2441718876361847, rse:0.3840280771255493, corr:[0.46391383 0.46652293 0.46681812 0.46805075 0.46804464 0.4686211
 0.46843395 0.46850783 0.46839175 0.4682789  0.46822318 0.46799898
 0.4681323  0.4680098  0.46806854 0.4681398  0.4680146  0.4680815
 0.46789852 0.46769652 0.4676543  0.46759924 0.4677763  0.4679627
 0.46828124 0.4684291  0.46859077 0.46864444 0.4684161  0.46840945
 0.4681826  0.46809667 0.46798736 0.4678182  0.46774277 0.46756315
 0.46754074 0.4674746  0.4674583  0.46738452 0.46713108 0.46705034
 0.46689114 0.46669748 0.4666787  0.4665393  0.4665906  0.46674633
 0.46687236 0.4670712  0.46708122 0.46710643 0.4670391  0.46692672
 0.46691477 0.4667639  0.4667119  0.46665016 0.46659723 0.46658266
 0.46654513 0.46654552 0.4665219  0.46656206 0.46653968 0.46649826
 0.46649355 0.46627688 0.46616527 0.46615013 0.46617746 0.4663532
 0.46635428 0.4664866  0.46654186 0.4664702  0.4664717  0.46631798
 0.4662728  0.46616882 0.46610686 0.46608284 0.46595463 0.46601042
 0.46595272 0.46593666 0.46600318 0.4659552  0.46595713 0.46593592
 0.4659005  0.4657176  0.46555206 0.46556425 0.46551377 0.4656676
 0.46580294 0.4658033  0.4659229  0.46586856 0.46583462 0.46583614
 0.46565825 0.465615   0.46553007 0.46548197 0.46545395 0.46536413
 0.46536937 0.4653367  0.46538457 0.46531993 0.46526614 0.46531573
 0.46527597 0.4653641  0.46541414 0.4654661  0.46555743 0.46572945
 0.46604946 0.4661263  0.46608204 0.46606952 0.46604568 0.46601877
 0.4659729  0.46585178 0.46582392 0.46574798 0.4656458  0.46553272
 0.46554735 0.46551663 0.46548954 0.465546   0.46544567 0.46561623
 0.46556476 0.4653707  0.46526957 0.46520254 0.46529627 0.46526107
 0.46536982 0.4654645  0.46554798 0.46559554 0.46551764 0.46544752
 0.46537536 0.46528736 0.4652718  0.46516976 0.46506676 0.46501222
 0.4649352  0.46508586 0.46501827 0.4651333  0.46515152 0.46517858
 0.46524838 0.46488687 0.46487325 0.4646904  0.46466368 0.46475437
 0.46465042 0.46479392 0.4648233  0.464665   0.4645106  0.46438158
 0.46417117 0.46400577 0.4639176  0.46374896 0.46355253 0.4636999
 0.46358278 0.46378475 0.46376303 0.46372753 0.4637693  0.463478
 0.463705   0.46303764 0.46343306 0.46305773 0.46403608 0.46374148]
