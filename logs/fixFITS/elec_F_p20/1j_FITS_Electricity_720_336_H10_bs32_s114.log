Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=320, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=4, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_720_j336_H10', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:4
>>>>>>>start training : Electricity_720_j336_H10_FITS_custom_ftM_sl720_ll48_pl336_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17357
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=320, out_features=469, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3083243520.0
params:  150549.0
Trainable parameters:  150549
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4651595
	speed: 0.2862s/iter; left time: 3849.3865s
	iters: 200, epoch: 1 | loss: 0.2729471
	speed: 0.2575s/iter; left time: 3437.6746s
Epoch: 1 cost time: 75.05183911323547
Epoch: 1, Steps: 271 | Train Loss: 0.4430832 Vali Loss: 0.1799658 Test Loss: 0.2166807
Validation loss decreased (inf --> 0.179966).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1935141
	speed: 0.9323s/iter; left time: 12288.0387s
	iters: 200, epoch: 2 | loss: 0.1692801
	speed: 0.2454s/iter; left time: 3210.1424s
Epoch: 2 cost time: 71.14790844917297
Epoch: 2, Steps: 271 | Train Loss: 0.1898662 Vali Loss: 0.1436833 Test Loss: 0.1692444
Validation loss decreased (0.179966 --> 0.143683).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1820504
	speed: 0.8813s/iter; left time: 11376.4788s
	iters: 200, epoch: 3 | loss: 0.1804622
	speed: 0.2525s/iter; left time: 3234.8273s
Epoch: 3 cost time: 69.78326296806335
Epoch: 3, Steps: 271 | Train Loss: 0.1753467 Vali Loss: 0.1423309 Test Loss: 0.1666203
Validation loss decreased (0.143683 --> 0.142331).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1836685
	speed: 0.8606s/iter; left time: 10876.0947s
	iters: 200, epoch: 4 | loss: 0.1566189
	speed: 0.2580s/iter; left time: 3234.4806s
Epoch: 4 cost time: 70.58993363380432
Epoch: 4, Steps: 271 | Train Loss: 0.1740768 Vali Loss: 0.1420314 Test Loss: 0.1661115
Validation loss decreased (0.142331 --> 0.142031).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1706410
	speed: 0.8436s/iter; left time: 10433.2949s
	iters: 200, epoch: 5 | loss: 0.1775988
	speed: 0.2322s/iter; left time: 2848.5321s
Epoch: 5 cost time: 66.80310702323914
Epoch: 5, Steps: 271 | Train Loss: 0.1735367 Vali Loss: 0.1418787 Test Loss: 0.1658538
Validation loss decreased (0.142031 --> 0.141879).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1606413
	speed: 0.8551s/iter; left time: 10343.1690s
	iters: 200, epoch: 6 | loss: 0.1766655
	speed: 0.2729s/iter; left time: 3273.5770s
Epoch: 6 cost time: 73.10127449035645
Epoch: 6, Steps: 271 | Train Loss: 0.1732061 Vali Loss: 0.1416375 Test Loss: 0.1656918
Validation loss decreased (0.141879 --> 0.141637).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1571745
	speed: 0.8982s/iter; left time: 10620.9141s
	iters: 200, epoch: 7 | loss: 0.1689482
	speed: 0.2303s/iter; left time: 2700.2631s
Epoch: 7 cost time: 67.13277864456177
Epoch: 7, Steps: 271 | Train Loss: 0.1730239 Vali Loss: 0.1415992 Test Loss: 0.1656213
Validation loss decreased (0.141637 --> 0.141599).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1831798
	speed: 0.7986s/iter; left time: 9226.7164s
	iters: 200, epoch: 8 | loss: 0.1860490
	speed: 0.2266s/iter; left time: 2595.7277s
Epoch: 8 cost time: 63.72120761871338
Epoch: 8, Steps: 271 | Train Loss: 0.1728539 Vali Loss: 0.1415271 Test Loss: 0.1656570
Validation loss decreased (0.141599 --> 0.141527).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1667543
	speed: 0.8014s/iter; left time: 9042.2790s
	iters: 200, epoch: 9 | loss: 0.1695793
	speed: 0.2431s/iter; left time: 2718.5978s
Epoch: 9 cost time: 65.99917221069336
Epoch: 9, Steps: 271 | Train Loss: 0.1727687 Vali Loss: 0.1415166 Test Loss: 0.1654979
Validation loss decreased (0.141527 --> 0.141517).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1872940
	speed: 0.8553s/iter; left time: 9418.7311s
	iters: 200, epoch: 10 | loss: 0.1754482
	speed: 0.2356s/iter; left time: 2571.3790s
Epoch: 10 cost time: 66.7358570098877
Epoch: 10, Steps: 271 | Train Loss: 0.1727068 Vali Loss: 0.1415678 Test Loss: 0.1654648
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1644669
	speed: 0.8041s/iter; left time: 8636.8227s
	iters: 200, epoch: 11 | loss: 0.1715447
	speed: 0.2305s/iter; left time: 2452.9396s
Epoch: 11 cost time: 65.28432250022888
Epoch: 11, Steps: 271 | Train Loss: 0.1726537 Vali Loss: 0.1417061 Test Loss: 0.1655086
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1795303
	speed: 0.9158s/iter; left time: 9588.3056s
	iters: 200, epoch: 12 | loss: 0.1828772
	speed: 0.2787s/iter; left time: 2889.9612s
Epoch: 12 cost time: 77.41004276275635
Epoch: 12, Steps: 271 | Train Loss: 0.1725897 Vali Loss: 0.1414421 Test Loss: 0.1654681
Validation loss decreased (0.141517 --> 0.141442).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1874043
	speed: 0.8846s/iter; left time: 9022.1880s
	iters: 200, epoch: 13 | loss: 0.1852631
	speed: 0.2325s/iter; left time: 2348.3577s
Epoch: 13 cost time: 65.11999225616455
Epoch: 13, Steps: 271 | Train Loss: 0.1725540 Vali Loss: 0.1414631 Test Loss: 0.1654341
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1525115
	speed: 0.8062s/iter; left time: 8003.8382s
	iters: 200, epoch: 14 | loss: 0.1653229
	speed: 0.2508s/iter; left time: 2465.2882s
Epoch: 14 cost time: 67.67997670173645
Epoch: 14, Steps: 271 | Train Loss: 0.1725124 Vali Loss: 0.1412003 Test Loss: 0.1654587
Validation loss decreased (0.141442 --> 0.141200).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1719143
	speed: 0.8362s/iter; left time: 8075.4039s
	iters: 200, epoch: 15 | loss: 0.1709081
	speed: 0.2408s/iter; left time: 2301.2281s
Epoch: 15 cost time: 66.57254934310913
Epoch: 15, Steps: 271 | Train Loss: 0.1724768 Vali Loss: 0.1414819 Test Loss: 0.1654000
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1764101
	speed: 0.7932s/iter; left time: 7445.0503s
	iters: 200, epoch: 16 | loss: 0.1741727
	speed: 0.2403s/iter; left time: 2231.2866s
Epoch: 16 cost time: 66.41909790039062
Epoch: 16, Steps: 271 | Train Loss: 0.1724612 Vali Loss: 0.1414896 Test Loss: 0.1653706
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1801510
	speed: 0.8459s/iter; left time: 7710.5317s
	iters: 200, epoch: 17 | loss: 0.1815139
	speed: 0.2597s/iter; left time: 2341.2829s
Epoch: 17 cost time: 71.46336245536804
Epoch: 17, Steps: 271 | Train Loss: 0.1724109 Vali Loss: 0.1413022 Test Loss: 0.1653488
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1650444
	speed: 0.8751s/iter; left time: 7739.4934s
	iters: 200, epoch: 18 | loss: 0.1562024
	speed: 0.2464s/iter; left time: 2154.7276s
Epoch: 18 cost time: 69.5889368057251
Epoch: 18, Steps: 271 | Train Loss: 0.1723979 Vali Loss: 0.1414060 Test Loss: 0.1653711
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1558733
	speed: 0.8742s/iter; left time: 7494.2620s
	iters: 200, epoch: 19 | loss: 0.1782023
	speed: 0.2555s/iter; left time: 2165.0480s
Epoch: 19 cost time: 70.12502551078796
Epoch: 19, Steps: 271 | Train Loss: 0.1723729 Vali Loss: 0.1413357 Test Loss: 0.1653023
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1618931
	speed: 0.9092s/iter; left time: 7547.9277s
	iters: 200, epoch: 20 | loss: 0.1738906
	speed: 0.2393s/iter; left time: 1962.5845s
Epoch: 20 cost time: 69.30965852737427
Epoch: 20, Steps: 271 | Train Loss: 0.1723672 Vali Loss: 0.1412709 Test Loss: 0.1652357
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1802959
	speed: 0.8380s/iter; left time: 6730.0552s
	iters: 200, epoch: 21 | loss: 0.1862090
	speed: 0.2466s/iter; left time: 1955.6189s
Epoch: 21 cost time: 68.36279201507568
Epoch: 21, Steps: 271 | Train Loss: 0.1723246 Vali Loss: 0.1412041 Test Loss: 0.1652980
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1851401
	speed: 0.9110s/iter; left time: 7069.3514s
	iters: 200, epoch: 22 | loss: 0.1686471
	speed: 0.2646s/iter; left time: 2026.6490s
Epoch: 22 cost time: 73.1992416381836
Epoch: 22, Steps: 271 | Train Loss: 0.1723395 Vali Loss: 0.1412354 Test Loss: 0.1653251
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1760271
	speed: 0.8083s/iter; left time: 6053.3159s
	iters: 200, epoch: 23 | loss: 0.1812497
	speed: 0.2228s/iter; left time: 1646.0848s
Epoch: 23 cost time: 62.15919756889343
Epoch: 23, Steps: 271 | Train Loss: 0.1723083 Vali Loss: 0.1412459 Test Loss: 0.1652676
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1587646
	speed: 0.8640s/iter; left time: 6236.5288s
	iters: 200, epoch: 24 | loss: 0.1697200
	speed: 0.2701s/iter; left time: 1922.4214s
Epoch: 24 cost time: 72.35929155349731
Epoch: 24, Steps: 271 | Train Loss: 0.1722900 Vali Loss: 0.1413715 Test Loss: 0.1651979
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1672175
	speed: 0.8232s/iter; left time: 5719.0874s
	iters: 200, epoch: 25 | loss: 0.1851316
	speed: 0.2125s/iter; left time: 1455.0911s
Epoch: 25 cost time: 60.17320656776428
Epoch: 25, Steps: 271 | Train Loss: 0.1722569 Vali Loss: 0.1412304 Test Loss: 0.1652872
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1652917
	speed: 0.7347s/iter; left time: 4904.6075s
	iters: 200, epoch: 26 | loss: 0.1623202
	speed: 0.2373s/iter; left time: 1560.2618s
Epoch: 26 cost time: 65.91136527061462
Epoch: 26, Steps: 271 | Train Loss: 0.1722646 Vali Loss: 0.1413461 Test Loss: 0.1652637
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1669736
	speed: 0.8304s/iter; left time: 5318.5927s
	iters: 200, epoch: 27 | loss: 0.1574281
	speed: 0.2484s/iter; left time: 1566.4443s
Epoch: 27 cost time: 68.86323142051697
Epoch: 27, Steps: 271 | Train Loss: 0.1722613 Vali Loss: 0.1411215 Test Loss: 0.1652754
Validation loss decreased (0.141200 --> 0.141121).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1604470
	speed: 0.8559s/iter; left time: 5249.8645s
	iters: 200, epoch: 28 | loss: 0.1721122
	speed: 0.2337s/iter; left time: 1410.1522s
Epoch: 28 cost time: 63.33124279975891
Epoch: 28, Steps: 271 | Train Loss: 0.1722525 Vali Loss: 0.1409689 Test Loss: 0.1652749
Validation loss decreased (0.141121 --> 0.140969).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1700939
	speed: 0.7822s/iter; left time: 4586.2305s
	iters: 200, epoch: 29 | loss: 0.1775530
	speed: 0.2313s/iter; left time: 1332.9972s
Epoch: 29 cost time: 65.27736163139343
Epoch: 29, Steps: 271 | Train Loss: 0.1722325 Vali Loss: 0.1411947 Test Loss: 0.1652326
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1670211
	speed: 0.8938s/iter; left time: 4997.9538s
	iters: 200, epoch: 30 | loss: 0.1752959
	speed: 0.2841s/iter; left time: 1560.2408s
Epoch: 30 cost time: 75.07470965385437
Epoch: 30, Steps: 271 | Train Loss: 0.1722182 Vali Loss: 0.1412873 Test Loss: 0.1652110
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1578500
	speed: 0.8396s/iter; left time: 4467.5999s
	iters: 200, epoch: 31 | loss: 0.1655751
	speed: 0.2302s/iter; left time: 1201.7098s
Epoch: 31 cost time: 63.68336248397827
Epoch: 31, Steps: 271 | Train Loss: 0.1721931 Vali Loss: 0.1412009 Test Loss: 0.1652785
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1739922
	speed: 0.7951s/iter; left time: 4015.1850s
	iters: 200, epoch: 32 | loss: 0.1646234
	speed: 0.2311s/iter; left time: 1144.0477s
Epoch: 32 cost time: 63.379425048828125
Epoch: 32, Steps: 271 | Train Loss: 0.1722173 Vali Loss: 0.1410037 Test Loss: 0.1652287
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1706496
	speed: 0.7748s/iter; left time: 3702.5837s
	iters: 200, epoch: 33 | loss: 0.1737518
	speed: 0.2078s/iter; left time: 972.4890s
Epoch: 33 cost time: 59.03605318069458
Epoch: 33, Steps: 271 | Train Loss: 0.1721856 Vali Loss: 0.1412213 Test Loss: 0.1652331
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1828064
	speed: 0.7396s/iter; left time: 3334.1759s
	iters: 200, epoch: 34 | loss: 0.1592597
	speed: 0.2184s/iter; left time: 962.6888s
Epoch: 34 cost time: 60.837785482406616
Epoch: 34, Steps: 271 | Train Loss: 0.1721790 Vali Loss: 0.1411804 Test Loss: 0.1652347
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1616632
	speed: 0.8058s/iter; left time: 3414.3362s
	iters: 200, epoch: 35 | loss: 0.1709798
	speed: 0.2638s/iter; left time: 1091.2209s
Epoch: 35 cost time: 71.44062924385071
Epoch: 35, Steps: 271 | Train Loss: 0.1721651 Vali Loss: 0.1410592 Test Loss: 0.1652018
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1801260
	speed: 0.9233s/iter; left time: 3661.7621s
	iters: 200, epoch: 36 | loss: 0.1812585
	speed: 0.2736s/iter; left time: 1057.7351s
Epoch: 36 cost time: 75.53202700614929
Epoch: 36, Steps: 271 | Train Loss: 0.1721604 Vali Loss: 0.1410946 Test Loss: 0.1652542
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1779732
	speed: 0.9531s/iter; left time: 3521.6372s
	iters: 200, epoch: 37 | loss: 0.1777574
	speed: 0.2486s/iter; left time: 893.7362s
Epoch: 37 cost time: 72.50100779533386
Epoch: 37, Steps: 271 | Train Loss: 0.1721850 Vali Loss: 0.1410395 Test Loss: 0.1652013
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1838482
	speed: 0.9355s/iter; left time: 3203.2573s
	iters: 200, epoch: 38 | loss: 0.1758391
	speed: 0.2643s/iter; left time: 878.4437s
Epoch: 38 cost time: 73.13812685012817
Epoch: 38, Steps: 271 | Train Loss: 0.1721416 Vali Loss: 0.1411630 Test Loss: 0.1652300
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1779406
	speed: 0.8705s/iter; left time: 2744.7120s
	iters: 200, epoch: 39 | loss: 0.1606152
	speed: 0.2606s/iter; left time: 795.4781s
Epoch: 39 cost time: 71.7653419971466
Epoch: 39, Steps: 271 | Train Loss: 0.1721062 Vali Loss: 0.1409981 Test Loss: 0.1652179
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1681222
	speed: 0.9522s/iter; left time: 2744.3074s
	iters: 200, epoch: 40 | loss: 0.1796063
	speed: 0.2810s/iter; left time: 781.6145s
Epoch: 40 cost time: 77.19811081886292
Epoch: 40, Steps: 271 | Train Loss: 0.1721211 Vali Loss: 0.1410771 Test Loss: 0.1651928
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1795771
	speed: 0.8709s/iter; left time: 2274.0445s
	iters: 200, epoch: 41 | loss: 0.1720114
	speed: 0.2602s/iter; left time: 653.3522s
Epoch: 41 cost time: 70.12785029411316
Epoch: 41, Steps: 271 | Train Loss: 0.1721179 Vali Loss: 0.1411370 Test Loss: 0.1651903
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1728452
	speed: 0.9023s/iter; left time: 2111.3148s
	iters: 200, epoch: 42 | loss: 0.1619303
	speed: 0.2888s/iter; left time: 646.8176s
Epoch: 42 cost time: 75.05821180343628
Epoch: 42, Steps: 271 | Train Loss: 0.1721201 Vali Loss: 0.1411783 Test Loss: 0.1652130
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1669877
	speed: 0.9259s/iter; left time: 1915.7522s
	iters: 200, epoch: 43 | loss: 0.1791438
	speed: 0.2467s/iter; left time: 485.8046s
Epoch: 43 cost time: 71.11790180206299
Epoch: 43, Steps: 271 | Train Loss: 0.1721269 Vali Loss: 0.1411678 Test Loss: 0.1651683
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1536988
	speed: 0.8354s/iter; left time: 1502.0751s
	iters: 200, epoch: 44 | loss: 0.1673295
	speed: 0.2357s/iter; left time: 400.2578s
Epoch: 44 cost time: 67.697190284729
Epoch: 44, Steps: 271 | Train Loss: 0.1720869 Vali Loss: 0.1411893 Test Loss: 0.1652146
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1797755
	speed: 0.9061s/iter; left time: 1383.5462s
	iters: 200, epoch: 45 | loss: 0.1749396
	speed: 0.2469s/iter; left time: 352.3775s
Epoch: 45 cost time: 69.20381188392639
Epoch: 45, Steps: 271 | Train Loss: 0.1721220 Vali Loss: 0.1411761 Test Loss: 0.1652081
EarlyStopping counter: 17 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1464086
	speed: 0.8434s/iter; left time: 1059.2660s
	iters: 200, epoch: 46 | loss: 0.1696356
	speed: 0.2364s/iter; left time: 273.2366s
Epoch: 46 cost time: 66.2126042842865
Epoch: 46, Steps: 271 | Train Loss: 0.1721149 Vali Loss: 0.1412360 Test Loss: 0.1651916
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1955061
	speed: 0.8305s/iter; left time: 818.0917s
	iters: 200, epoch: 47 | loss: 0.1812702
	speed: 0.2617s/iter; left time: 231.5801s
Epoch: 47 cost time: 72.34004235267639
Epoch: 47, Steps: 271 | Train Loss: 0.1721025 Vali Loss: 0.1410022 Test Loss: 0.1652027
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1947221
	speed: 0.9882s/iter; left time: 705.5590s
	iters: 200, epoch: 48 | loss: 0.1754577
	speed: 0.2858s/iter; left time: 175.4704s
Epoch: 48 cost time: 79.36636853218079
Epoch: 48, Steps: 271 | Train Loss: 0.1720879 Vali Loss: 0.1410934 Test Loss: 0.1651915
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : Electricity_720_j336_H10_FITS_custom_ftM_sl720_ll48_pl336_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4925
mse:0.16517449915409088, mae:0.26046693325042725, rse:0.40449464321136475, corr:[0.45934924 0.46220228 0.4622464  0.46355212 0.463364   0.4640126
 0.4638319  0.46398836 0.46362484 0.4636374  0.46353996 0.46344283
 0.46336696 0.4632798  0.46322414 0.4632405  0.46334642 0.46342006
 0.4633503  0.4633306  0.46325037 0.4630942  0.46326926 0.46333233
 0.46368694 0.4639082  0.46406922 0.46406814 0.4639773  0.46386343
 0.46364662 0.46353614 0.46322173 0.46315446 0.46315035 0.46311516
 0.46297443 0.46310169 0.4632035  0.46313044 0.463125   0.46293554
 0.462961   0.463007   0.46277678 0.46252596 0.46278757 0.46284693
 0.46296284 0.46323866 0.4631461  0.46313226 0.46291625 0.46286982
 0.46280482 0.46274048 0.46280894 0.46269134 0.4626511  0.46266964
 0.46260524 0.46258226 0.46267375 0.4626616  0.46276549 0.46273535
 0.46261123 0.46246824 0.46229994 0.46221632 0.4620956  0.46224567
 0.46232325 0.46245316 0.4623671  0.4622471  0.4622457  0.4620495
 0.46201822 0.4618853  0.46175808 0.461749   0.46176872 0.46186748
 0.46188533 0.4617723  0.46182647 0.46190074 0.46192777 0.46191958
 0.46187374 0.46196792 0.46184853 0.46185303 0.4618536  0.46189207
 0.46209747 0.46210098 0.46211284 0.4619685  0.46190637 0.46188974
 0.46182212 0.4617849  0.4616746  0.46157333 0.46157324 0.461605
 0.46149912 0.4615006  0.46157414 0.46167335 0.4616296  0.46168685
 0.46180555 0.46167797 0.4616352  0.4615509  0.46154684 0.461705
 0.46190292 0.4618611  0.46187973 0.46189654 0.4618217  0.46186197
 0.4618445  0.46177462 0.46161604 0.46153918 0.46157172 0.46151814
 0.46143785 0.46146777 0.4615358  0.46154234 0.46158007 0.46165243
 0.46175456 0.46158004 0.46136305 0.46127546 0.46118304 0.46119055
 0.46117935 0.46129212 0.4613521  0.46128252 0.4612416  0.46124023
 0.46128142 0.46122435 0.46113852 0.4611438  0.46109745 0.46098098
 0.46091413 0.46090707 0.46096054 0.460951   0.46104077 0.46116954
 0.4611314  0.46092132 0.46076968 0.46082982 0.4607643  0.46077785
 0.4608489  0.46078163 0.46079984 0.46084663 0.46079418 0.4606055
 0.46053737 0.46042907 0.4602633  0.4602002  0.46012375 0.45999956
 0.45978957 0.4596738  0.45959342 0.45945385 0.4593399  0.45923662
 0.45913756 0.45897573 0.4587667  0.4587463  0.4586735  0.45873168
 0.45896444 0.4589856  0.45913404 0.45925158 0.45919597 0.45906165
 0.45897573 0.45894173 0.45874164 0.45868096 0.45869356 0.45851463
 0.45832992 0.45828876 0.45826438 0.45824227 0.4581767  0.45818865
 0.45819408 0.45802647 0.4579946  0.45789227 0.45789394 0.45803767
 0.45821586 0.4584749  0.45859936 0.45869836 0.45860898 0.4585294
 0.45857787 0.4584434  0.45836    0.4584099  0.45829433 0.45818457
 0.45810553 0.45799187 0.45803556 0.4579909  0.45794436 0.45798224
 0.45802492 0.4577858  0.45752978 0.45754844 0.45760477 0.45770216
 0.45776373 0.4579539  0.4580306  0.45802048 0.45803222 0.45797175
 0.45801243 0.45807323 0.45791546 0.4577463  0.45782763 0.45778567
 0.4577172  0.45771053 0.4576745  0.45757988 0.45760757 0.45764577
 0.45748976 0.457469   0.4574019  0.4574499  0.45744434 0.45754603
 0.45778987 0.45783442 0.4577999  0.45773274 0.45779544 0.45772478
 0.45764926 0.45761126 0.45750678 0.45738754 0.45741543 0.45742655
 0.45725653 0.45729014 0.45730796 0.45738742 0.45726305 0.45723048
 0.45744464 0.4573813  0.45725128 0.4571837  0.45742235 0.45753574
 0.45772597 0.45774707 0.4576836  0.45768154 0.45776    0.45772925
 0.45755756 0.45753765 0.45730674 0.45719123 0.45720682 0.45718578
 0.45714217 0.4571991  0.45722583 0.4571976  0.45729437 0.4572613
 0.45723185 0.45703098 0.45682475 0.4565851  0.45667735 0.45677984
 0.45683256 0.4569779  0.45680827 0.45681852 0.4567177  0.45665133
 0.45653078 0.4564542  0.45626655 0.45625818 0.45634106 0.45627844
 0.45631263 0.4564944  0.45662132 0.45650822 0.45666462 0.4563917
 0.45673904 0.4561765  0.4563471  0.45604575 0.45659408 0.45642626]
