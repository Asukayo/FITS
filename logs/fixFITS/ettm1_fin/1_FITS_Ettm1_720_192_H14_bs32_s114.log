Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=122, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTm1_720_192_FITS_ETTm1_ftM_sl720_ll48_pl192_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=122, out_features=154, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  8417024.0
params:  18942.0
Trainable parameters:  18942
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3555220
	speed: 0.1483s/iter; left time: 3876.9386s
	iters: 200, epoch: 1 | loss: 0.2961979
	speed: 0.1507s/iter; left time: 3925.4641s
	iters: 300, epoch: 1 | loss: 0.2978157
	speed: 0.1572s/iter; left time: 4080.0898s
	iters: 400, epoch: 1 | loss: 0.3059319
	speed: 0.1515s/iter; left time: 3917.4615s
	iters: 500, epoch: 1 | loss: 0.2623745
	speed: 0.1537s/iter; left time: 3956.7654s
Epoch: 1 cost time: 79.98923301696777
Epoch: 1, Steps: 525 | Train Loss: 0.3415540 Vali Loss: 0.5425400 Test Loss: 0.3400419
Validation loss decreased (inf --> 0.542540).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3140669
	speed: 1.0675s/iter; left time: 27355.9120s
	iters: 200, epoch: 2 | loss: 0.2673275
	speed: 0.1537s/iter; left time: 3922.1784s
	iters: 300, epoch: 2 | loss: 0.3012135
	speed: 0.1533s/iter; left time: 3896.6969s
	iters: 400, epoch: 2 | loss: 0.2927123
	speed: 0.1551s/iter; left time: 3928.5172s
	iters: 500, epoch: 2 | loss: 0.2559352
	speed: 0.1489s/iter; left time: 3756.9111s
Epoch: 2 cost time: 81.51601791381836
Epoch: 2, Steps: 525 | Train Loss: 0.3022564 Vali Loss: 0.5251278 Test Loss: 0.3392439
Validation loss decreased (0.542540 --> 0.525128).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3266562
	speed: 1.0753s/iter; left time: 26990.7793s
	iters: 200, epoch: 3 | loss: 0.3521882
	speed: 0.1530s/iter; left time: 3826.3134s
	iters: 300, epoch: 3 | loss: 0.3257088
	speed: 0.1244s/iter; left time: 3097.7116s
	iters: 400, epoch: 3 | loss: 0.2903703
	speed: 0.1449s/iter; left time: 3593.3699s
	iters: 500, epoch: 3 | loss: 0.2934777
	speed: 0.1517s/iter; left time: 3747.7712s
Epoch: 3 cost time: 76.8155767917633
Epoch: 3, Steps: 525 | Train Loss: 0.2998577 Vali Loss: 0.5182385 Test Loss: 0.3381582
Validation loss decreased (0.525128 --> 0.518239).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2623153
	speed: 1.0154s/iter; left time: 24954.4338s
	iters: 200, epoch: 4 | loss: 0.3145550
	speed: 0.1523s/iter; left time: 3727.0249s
	iters: 300, epoch: 4 | loss: 0.2705604
	speed: 0.1553s/iter; left time: 3786.2828s
	iters: 400, epoch: 4 | loss: 0.3281320
	speed: 0.1577s/iter; left time: 3827.3643s
	iters: 500, epoch: 4 | loss: 0.2917486
	speed: 0.1505s/iter; left time: 3638.1132s
Epoch: 4 cost time: 81.13692283630371
Epoch: 4, Steps: 525 | Train Loss: 0.2988977 Vali Loss: 0.5184444 Test Loss: 0.3385468
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2861859
	speed: 1.0621s/iter; left time: 25545.1336s
	iters: 200, epoch: 5 | loss: 0.3232341
	speed: 0.1453s/iter; left time: 3480.8358s
	iters: 300, epoch: 5 | loss: 0.3634395
	speed: 0.1545s/iter; left time: 3686.0676s
	iters: 400, epoch: 5 | loss: 0.3012958
	speed: 0.1162s/iter; left time: 2760.7670s
	iters: 500, epoch: 5 | loss: 0.2724047
	speed: 0.1175s/iter; left time: 2778.4100s
Epoch: 5 cost time: 73.22401571273804
Epoch: 5, Steps: 525 | Train Loss: 0.2984623 Vali Loss: 0.5137609 Test Loss: 0.3383611
Validation loss decreased (0.518239 --> 0.513761).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3089706
	speed: 1.0793s/iter; left time: 25390.8882s
	iters: 200, epoch: 6 | loss: 0.3195059
	speed: 0.1510s/iter; left time: 3538.4753s
	iters: 300, epoch: 6 | loss: 0.2484868
	speed: 0.1506s/iter; left time: 3513.9597s
	iters: 400, epoch: 6 | loss: 0.3406565
	speed: 0.1520s/iter; left time: 3529.9324s
	iters: 500, epoch: 6 | loss: 0.2694831
	speed: 0.1512s/iter; left time: 3497.7830s
Epoch: 6 cost time: 80.01562142372131
Epoch: 6, Steps: 525 | Train Loss: 0.2981222 Vali Loss: 0.5117077 Test Loss: 0.3389092
Validation loss decreased (0.513761 --> 0.511708).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3500567
	speed: 1.0595s/iter; left time: 24369.6227s
	iters: 200, epoch: 7 | loss: 0.3404385
	speed: 0.1409s/iter; left time: 3227.4423s
	iters: 300, epoch: 7 | loss: 0.2789270
	speed: 0.1449s/iter; left time: 3303.7897s
	iters: 400, epoch: 7 | loss: 0.2900629
	speed: 0.1471s/iter; left time: 3338.6780s
	iters: 500, epoch: 7 | loss: 0.2583658
	speed: 0.1438s/iter; left time: 3250.4081s
Epoch: 7 cost time: 76.41876554489136
Epoch: 7, Steps: 525 | Train Loss: 0.2980418 Vali Loss: 0.5126638 Test Loss: 0.3385868
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3613147
	speed: 1.0262s/iter; left time: 23064.7703s
	iters: 200, epoch: 8 | loss: 0.2557845
	speed: 0.1479s/iter; left time: 3308.9191s
	iters: 300, epoch: 8 | loss: 0.2935785
	speed: 0.1451s/iter; left time: 3231.1512s
	iters: 400, epoch: 8 | loss: 0.3621952
	speed: 0.1426s/iter; left time: 3162.4641s
	iters: 500, epoch: 8 | loss: 0.3386747
	speed: 0.1446s/iter; left time: 3191.5744s
Epoch: 8 cost time: 74.98822498321533
Epoch: 8, Steps: 525 | Train Loss: 0.2978816 Vali Loss: 0.5151002 Test Loss: 0.3378569
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3074079
	speed: 1.0040s/iter; left time: 22039.8923s
	iters: 200, epoch: 9 | loss: 0.2994007
	speed: 0.1475s/iter; left time: 3222.2197s
	iters: 300, epoch: 9 | loss: 0.3394860
	speed: 0.1493s/iter; left time: 3248.3904s
	iters: 400, epoch: 9 | loss: 0.3173570
	speed: 0.1395s/iter; left time: 3019.6778s
	iters: 500, epoch: 9 | loss: 0.2396319
	speed: 0.1369s/iter; left time: 2949.8467s
Epoch: 9 cost time: 75.96705412864685
Epoch: 9, Steps: 525 | Train Loss: 0.2977665 Vali Loss: 0.5114775 Test Loss: 0.3391030
Validation loss decreased (0.511708 --> 0.511477).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2863815
	speed: 0.9801s/iter; left time: 21000.5840s
	iters: 200, epoch: 10 | loss: 0.2970375
	speed: 0.1441s/iter; left time: 3072.7856s
	iters: 300, epoch: 10 | loss: 0.3066095
	speed: 0.1470s/iter; left time: 3120.4993s
	iters: 400, epoch: 10 | loss: 0.3379822
	speed: 0.1437s/iter; left time: 3035.9118s
	iters: 500, epoch: 10 | loss: 0.2916398
	speed: 0.1389s/iter; left time: 2921.1576s
Epoch: 10 cost time: 75.57538890838623
Epoch: 10, Steps: 525 | Train Loss: 0.2977582 Vali Loss: 0.5131925 Test Loss: 0.3386289
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2821671
	speed: 0.9546s/iter; left time: 19952.8092s
	iters: 200, epoch: 11 | loss: 0.3240709
	speed: 0.1339s/iter; left time: 2785.8201s
	iters: 300, epoch: 11 | loss: 0.3161363
	speed: 0.1330s/iter; left time: 2752.2877s
	iters: 400, epoch: 11 | loss: 0.2917396
	speed: 0.1360s/iter; left time: 2802.0186s
	iters: 500, epoch: 11 | loss: 0.2547555
	speed: 0.1394s/iter; left time: 2858.5691s
Epoch: 11 cost time: 71.85887742042542
Epoch: 11, Steps: 525 | Train Loss: 0.2974923 Vali Loss: 0.5125316 Test Loss: 0.3388475
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2832986
	speed: 0.9684s/iter; left time: 19732.9375s
	iters: 200, epoch: 12 | loss: 0.3217133
	speed: 0.1446s/iter; left time: 2932.9154s
	iters: 300, epoch: 12 | loss: 0.2942464
	speed: 0.1374s/iter; left time: 2771.3103s
	iters: 400, epoch: 12 | loss: 0.3217139
	speed: 0.1326s/iter; left time: 2662.9976s
	iters: 500, epoch: 12 | loss: 0.3799874
	speed: 0.1361s/iter; left time: 2717.8584s
Epoch: 12 cost time: 72.94576168060303
Epoch: 12, Steps: 525 | Train Loss: 0.2976053 Vali Loss: 0.5117943 Test Loss: 0.3383522
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_720_192_FITS_ETTm1_ftM_sl720_ll48_pl192_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.33906951546669006, mae:0.3686325252056122, rse:0.5543012619018555, corr:[0.54267275 0.5524884  0.55513    0.5554532  0.55700445 0.5599616
 0.5625549  0.5637644  0.564011   0.56397635 0.56407905 0.5642644
 0.5644416  0.56444967 0.56412196 0.56328577 0.56201977 0.5607017
 0.5596084  0.5587328  0.5577664  0.55632967 0.5545042  0.55294067
 0.55188847 0.5514469  0.551178   0.55050266 0.54954416 0.54879755
 0.54883593 0.54981637 0.5511091  0.55208826 0.5522443  0.5519767
 0.55152965 0.55118686 0.55091834 0.550513   0.55015033 0.5499783
 0.55017024 0.5506958  0.55107385 0.55102324 0.5507091  0.55035794
 0.550062   0.54981923 0.5497241  0.549771   0.5499875  0.550177
 0.55019647 0.54990953 0.5493407  0.54867035 0.5483808  0.5485074
 0.54888    0.5492022  0.54930633 0.5491142  0.54895234 0.54902476
 0.54925025 0.5494387  0.5495224  0.54954183 0.5496458  0.54979455
 0.54981226 0.54954374 0.54904    0.54839563 0.5477833  0.54737425
 0.54721296 0.5472795  0.54751116 0.5477782  0.54797924 0.54793614
 0.54764336 0.5471598  0.54672235 0.5465109  0.54662746 0.5470249
 0.5474023  0.5474747  0.547206   0.54681116 0.5465469  0.5465393
 0.54677296 0.54705876 0.5469755  0.5464312  0.5456123  0.5448959
 0.54458827 0.54468507 0.5450451  0.54536957 0.54527706 0.5448016
 0.54412866 0.54361826 0.5434113  0.5433258  0.54312867 0.54271007
 0.5421307  0.5416578  0.54153323 0.5416796  0.54186803 0.54193574
 0.5418071  0.5415798  0.54137766 0.54131556 0.541246   0.54086137
 0.5401329  0.5393983  0.5389763  0.53900874 0.53922707 0.53931564
 0.5392117  0.5390452  0.5389472  0.5390552  0.53939146 0.53963906
 0.53980035 0.54002106 0.5403098  0.5406637  0.54095274 0.54105765
 0.5409698  0.5407352  0.54053223 0.5403541  0.5401587  0.539857
 0.53957313 0.53961015 0.5399389  0.5402664  0.54027796 0.5400186
 0.5397161  0.53959185 0.5397718  0.5399164  0.5398367  0.5394319
 0.538995   0.53884465 0.53908926 0.53951263 0.5398135  0.53986126
 0.53977835 0.53977776 0.5400229  0.5403482  0.54035246 0.5399685
 0.53946644 0.53922176 0.53930986 0.53948975 0.53935045 0.5388844
 0.53832763 0.5380487  0.5380817  0.5383035  0.538432   0.5384031
 0.5383103  0.5384904  0.5389917  0.53956974 0.53975725 0.53858745]
