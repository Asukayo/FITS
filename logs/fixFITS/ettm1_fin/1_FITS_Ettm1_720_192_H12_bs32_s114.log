Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTm1_720_192_FITS_ETTm1_ftM_sl720_ll48_pl192_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=106, out_features=134, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6363392.0
params:  14338.0
Trainable parameters:  14338
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3452000
	speed: 0.1624s/iter; left time: 4245.8125s
	iters: 200, epoch: 1 | loss: 0.3561321
	speed: 0.1294s/iter; left time: 3370.7951s
	iters: 300, epoch: 1 | loss: 0.3094089
	speed: 0.1281s/iter; left time: 3324.2076s
	iters: 400, epoch: 1 | loss: 0.2938878
	speed: 0.1512s/iter; left time: 3907.8660s
	iters: 500, epoch: 1 | loss: 0.2543834
	speed: 0.1586s/iter; left time: 4084.1898s
Epoch: 1 cost time: 77.32393264770508
Epoch: 1, Steps: 525 | Train Loss: 0.3475633 Vali Loss: 0.5430126 Test Loss: 0.3403309
Validation loss decreased (inf --> 0.543013).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2842607
	speed: 1.2152s/iter; left time: 31139.6693s
	iters: 200, epoch: 2 | loss: 0.2656893
	speed: 0.1553s/iter; left time: 3963.7279s
	iters: 300, epoch: 2 | loss: 0.3123577
	speed: 0.1521s/iter; left time: 3867.4556s
	iters: 400, epoch: 2 | loss: 0.3510819
	speed: 0.1536s/iter; left time: 3890.9523s
	iters: 500, epoch: 2 | loss: 0.2979945
	speed: 0.1562s/iter; left time: 3939.6048s
Epoch: 2 cost time: 82.67571973800659
Epoch: 2, Steps: 525 | Train Loss: 0.3023669 Vali Loss: 0.5236149 Test Loss: 0.3390972
Validation loss decreased (0.543013 --> 0.523615).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3257628
	speed: 1.0651s/iter; left time: 26734.2649s
	iters: 200, epoch: 3 | loss: 0.2828498
	speed: 0.1142s/iter; left time: 2855.4545s
	iters: 300, epoch: 3 | loss: 0.2585654
	speed: 0.1158s/iter; left time: 2882.6046s
	iters: 400, epoch: 3 | loss: 0.2903122
	speed: 0.1170s/iter; left time: 2900.7804s
	iters: 500, epoch: 3 | loss: 0.3290116
	speed: 0.1391s/iter; left time: 3436.7395s
Epoch: 3 cost time: 67.44480633735657
Epoch: 3, Steps: 525 | Train Loss: 0.2999865 Vali Loss: 0.5224266 Test Loss: 0.3382953
Validation loss decreased (0.523615 --> 0.522427).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3006981
	speed: 0.9777s/iter; left time: 24028.6985s
	iters: 200, epoch: 4 | loss: 0.2639835
	speed: 0.1592s/iter; left time: 3895.9964s
	iters: 300, epoch: 4 | loss: 0.3163460
	speed: 0.1630s/iter; left time: 3972.1773s
	iters: 400, epoch: 4 | loss: 0.2896675
	speed: 0.1514s/iter; left time: 3674.7914s
	iters: 500, epoch: 4 | loss: 0.3250304
	speed: 0.1555s/iter; left time: 3760.5568s
Epoch: 4 cost time: 84.01904201507568
Epoch: 4, Steps: 525 | Train Loss: 0.2991740 Vali Loss: 0.5168031 Test Loss: 0.3380618
Validation loss decreased (0.522427 --> 0.516803).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3103144
	speed: 1.0662s/iter; left time: 25642.9708s
	iters: 200, epoch: 5 | loss: 0.2659501
	speed: 0.1198s/iter; left time: 2868.5559s
	iters: 300, epoch: 5 | loss: 0.2813409
	speed: 0.1039s/iter; left time: 2477.0312s
	iters: 400, epoch: 5 | loss: 0.2988279
	speed: 0.1312s/iter; left time: 3115.0688s
	iters: 500, epoch: 5 | loss: 0.2721774
	speed: 0.1581s/iter; left time: 3738.0666s
Epoch: 5 cost time: 70.28316235542297
Epoch: 5, Steps: 525 | Train Loss: 0.2987725 Vali Loss: 0.5172894 Test Loss: 0.3390025
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2771960
	speed: 1.0859s/iter; left time: 25546.4670s
	iters: 200, epoch: 6 | loss: 0.2767617
	speed: 0.1532s/iter; left time: 3589.2081s
	iters: 300, epoch: 6 | loss: 0.2681852
	speed: 0.1506s/iter; left time: 3512.2765s
	iters: 400, epoch: 6 | loss: 0.3012035
	speed: 0.1473s/iter; left time: 3420.7135s
	iters: 500, epoch: 6 | loss: 0.2695729
	speed: 0.1606s/iter; left time: 3714.7906s
Epoch: 6 cost time: 82.06969499588013
Epoch: 6, Steps: 525 | Train Loss: 0.2984323 Vali Loss: 0.5144679 Test Loss: 0.3389575
Validation loss decreased (0.516803 --> 0.514468).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3358616
	speed: 1.0733s/iter; left time: 24686.6668s
	iters: 200, epoch: 7 | loss: 0.3154583
	speed: 0.1547s/iter; left time: 3541.6774s
	iters: 300, epoch: 7 | loss: 0.2803723
	speed: 0.1535s/iter; left time: 3499.7179s
	iters: 400, epoch: 7 | loss: 0.3102627
	speed: 0.1490s/iter; left time: 3382.8657s
	iters: 500, epoch: 7 | loss: 0.3184344
	speed: 0.1466s/iter; left time: 3314.1111s
Epoch: 7 cost time: 79.07954740524292
Epoch: 7, Steps: 525 | Train Loss: 0.2982040 Vali Loss: 0.5162521 Test Loss: 0.3392633
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2721635
	speed: 0.9082s/iter; left time: 20413.0100s
	iters: 200, epoch: 8 | loss: 0.2513658
	speed: 0.1361s/iter; left time: 3044.6515s
	iters: 300, epoch: 8 | loss: 0.3192686
	speed: 0.1424s/iter; left time: 3171.7368s
	iters: 400, epoch: 8 | loss: 0.3490664
	speed: 0.1542s/iter; left time: 3420.3911s
	iters: 500, epoch: 8 | loss: 0.3116559
	speed: 0.1562s/iter; left time: 3449.3186s
Epoch: 8 cost time: 76.75894093513489
Epoch: 8, Steps: 525 | Train Loss: 0.2981407 Vali Loss: 0.5114847 Test Loss: 0.3385109
Validation loss decreased (0.514468 --> 0.511485).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3226158
	speed: 1.0293s/iter; left time: 22593.3850s
	iters: 200, epoch: 9 | loss: 0.2916738
	speed: 0.1360s/iter; left time: 2971.0936s
	iters: 300, epoch: 9 | loss: 0.3248138
	speed: 0.1388s/iter; left time: 3019.3431s
	iters: 400, epoch: 9 | loss: 0.2866929
	speed: 0.1336s/iter; left time: 2892.4942s
	iters: 500, epoch: 9 | loss: 0.2659576
	speed: 0.1287s/iter; left time: 2773.6515s
Epoch: 9 cost time: 71.28604650497437
Epoch: 9, Steps: 525 | Train Loss: 0.2979920 Vali Loss: 0.5119525 Test Loss: 0.3396598
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2768330
	speed: 0.8922s/iter; left time: 19116.3969s
	iters: 200, epoch: 10 | loss: 0.3215990
	speed: 0.1274s/iter; left time: 2716.5337s
	iters: 300, epoch: 10 | loss: 0.2769733
	speed: 0.1325s/iter; left time: 2811.6657s
	iters: 400, epoch: 10 | loss: 0.3468748
	speed: 0.1212s/iter; left time: 2560.2723s
	iters: 500, epoch: 10 | loss: 0.2597053
	speed: 0.1316s/iter; left time: 2767.8042s
Epoch: 10 cost time: 67.92077875137329
Epoch: 10, Steps: 525 | Train Loss: 0.2979802 Vali Loss: 0.5118639 Test Loss: 0.3378208
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3003373
	speed: 1.0323s/iter; left time: 21576.3249s
	iters: 200, epoch: 11 | loss: 0.2817507
	speed: 0.1636s/iter; left time: 3403.0545s
	iters: 300, epoch: 11 | loss: 0.2605410
	speed: 0.1650s/iter; left time: 3415.5353s
	iters: 400, epoch: 11 | loss: 0.2730283
	speed: 0.1369s/iter; left time: 2819.3425s
	iters: 500, epoch: 11 | loss: 0.3043878
	speed: 0.1295s/iter; left time: 2655.2717s
Epoch: 11 cost time: 81.15954303741455
Epoch: 11, Steps: 525 | Train Loss: 0.2978832 Vali Loss: 0.5124711 Test Loss: 0.3386327
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_720_192_FITS_ETTm1_ftM_sl720_ll48_pl192_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.3385232388973236, mae:0.3688013255596161, rse:0.5538545846939087, corr:[0.54240793 0.5516366  0.55586284 0.5567693  0.55739063 0.5590069
 0.5611215  0.5628128  0.5637058  0.5640651  0.56443185 0.56488127
 0.56525636 0.5652163  0.56459135 0.56351316 0.5622557  0.5609822
 0.5596399  0.55826145 0.55695325 0.55567807 0.5544079  0.5533141
 0.55225044 0.55128765 0.5504869  0.54988414 0.5496928  0.5498998
 0.55037165 0.55093056 0.5512384  0.5512921  0.55113375 0.5511613
 0.5512308  0.55118316 0.5508498  0.550131   0.5493818  0.54890007
 0.5489093  0.5494175  0.5500135  0.5503603  0.55042875 0.5502798
 0.549981   0.5496079  0.5492737  0.5489252  0.54858583 0.54823774
 0.5480156  0.5479839  0.5480552  0.5479674  0.54768413 0.5471622
 0.5466558  0.54646885 0.54673827 0.5472349  0.54779565 0.5482053
 0.548328   0.5482172  0.54806846 0.5479793  0.54798937 0.5479779
 0.54782677 0.5475228  0.54719716 0.5469125  0.54672116 0.54666895
 0.546752   0.54692304 0.54706776 0.5470461  0.54685736 0.546527
 0.5462268  0.54605424 0.54609543 0.5462732  0.54649866 0.5467327
 0.5468827  0.5468866  0.5467717  0.5466193  0.546497   0.5463877
 0.54628474 0.54618967 0.5459444  0.5455936  0.5452489  0.5450458
 0.54505545 0.5451538  0.5452722  0.5453342  0.545165   0.5448318
 0.5444037  0.5440382  0.5438085  0.54365444 0.54349583 0.5432949
 0.5430381  0.54279923 0.54265356 0.5425854  0.54258645 0.5426578
 0.54269254 0.54260516 0.54232186 0.54194826 0.5415435  0.54106414
 0.5405449  0.5400893  0.5396943  0.5393758  0.5390254  0.53862065
 0.53830564 0.53820866 0.53834736 0.53875864 0.53940433 0.53991735
 0.54021305 0.54031277 0.54023397 0.54017353 0.5402521  0.54046506
 0.54068905 0.5407099  0.54053766 0.54026794 0.5401131  0.54007417
 0.54005706 0.54004294 0.53995156 0.5398079  0.5396877  0.53974175
 0.5399371  0.54008    0.5401125  0.5399042  0.53967476 0.539582
 0.53973013 0.5399991  0.54025364 0.5403945  0.54041535 0.54038066
 0.54034686 0.5403368  0.5404676  0.54070956 0.54081655 0.54066277
 0.5402383  0.539667   0.53912205 0.53881913 0.53881717 0.5391542
 0.539643   0.5400487  0.54008716 0.5398354  0.5395117  0.53938025
 0.53947854 0.53990114 0.54061127 0.54136294 0.5414313  0.53972983]
