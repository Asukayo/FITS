Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=122, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTm1_720_192_FITS_ETTm1_ftM_sl720_ll48_pl192_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=122, out_features=154, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  33668096.0
params:  18942.0
Trainable parameters:  18942
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3500021
	speed: 0.0975s/iter; left time: 628.8951s
Epoch: 1 cost time: 13.743664741516113
Epoch: 1, Steps: 131 | Train Loss: 0.4154038 Vali Loss: 0.6235268 Test Loss: 0.3657407
Validation loss decreased (inf --> 0.623527).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3249012
	speed: 0.3645s/iter; left time: 2303.7773s
Epoch: 2 cost time: 18.63703465461731
Epoch: 2, Steps: 131 | Train Loss: 0.3206428 Vali Loss: 0.5667517 Test Loss: 0.3445676
Validation loss decreased (0.623527 --> 0.566752).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3148364
	speed: 0.3640s/iter; left time: 2252.8479s
Epoch: 3 cost time: 17.470775604248047
Epoch: 3, Steps: 131 | Train Loss: 0.3084294 Vali Loss: 0.5478739 Test Loss: 0.3408663
Validation loss decreased (0.566752 --> 0.547874).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2829506
	speed: 0.3166s/iter; left time: 1917.8922s
Epoch: 4 cost time: 14.481105327606201
Epoch: 4, Steps: 131 | Train Loss: 0.3041614 Vali Loss: 0.5373854 Test Loss: 0.3393425
Validation loss decreased (0.547874 --> 0.537385).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2882503
	speed: 0.3650s/iter; left time: 2163.2340s
Epoch: 5 cost time: 17.43950366973877
Epoch: 5, Steps: 131 | Train Loss: 0.3018062 Vali Loss: 0.5315613 Test Loss: 0.3384053
Validation loss decreased (0.537385 --> 0.531561).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2978984
	speed: 0.3691s/iter; left time: 2139.3428s
Epoch: 6 cost time: 18.91326665878296
Epoch: 6, Steps: 131 | Train Loss: 0.3007048 Vali Loss: 0.5281333 Test Loss: 0.3380828
Validation loss decreased (0.531561 --> 0.528133).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2987006
	speed: 0.3755s/iter; left time: 2127.0725s
Epoch: 7 cost time: 17.343310117721558
Epoch: 7, Steps: 131 | Train Loss: 0.2998184 Vali Loss: 0.5253574 Test Loss: 0.3384701
Validation loss decreased (0.528133 --> 0.525357).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2981271
	speed: 0.3706s/iter; left time: 2050.8689s
Epoch: 8 cost time: 17.52665400505066
Epoch: 8, Steps: 131 | Train Loss: 0.2994589 Vali Loss: 0.5225682 Test Loss: 0.3382055
Validation loss decreased (0.525357 --> 0.522568).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3174891
	speed: 0.3825s/iter; left time: 2066.6549s
Epoch: 9 cost time: 19.085193157196045
Epoch: 9, Steps: 131 | Train Loss: 0.2990638 Vali Loss: 0.5201883 Test Loss: 0.3382503
Validation loss decreased (0.522568 --> 0.520188).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2871982
	speed: 0.3686s/iter; left time: 1943.1905s
Epoch: 10 cost time: 18.183005809783936
Epoch: 10, Steps: 131 | Train Loss: 0.2987348 Vali Loss: 0.5197735 Test Loss: 0.3379222
Validation loss decreased (0.520188 --> 0.519774).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2856699
	speed: 0.3720s/iter; left time: 1912.6791s
Epoch: 11 cost time: 17.534297943115234
Epoch: 11, Steps: 131 | Train Loss: 0.2985161 Vali Loss: 0.5191550 Test Loss: 0.3378982
Validation loss decreased (0.519774 --> 0.519155).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2982097
	speed: 0.3653s/iter; left time: 1830.3849s
Epoch: 12 cost time: 16.922268390655518
Epoch: 12, Steps: 131 | Train Loss: 0.2982291 Vali Loss: 0.5178149 Test Loss: 0.3383155
Validation loss decreased (0.519155 --> 0.517815).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3025956
	speed: 0.3785s/iter; left time: 1846.8493s
Epoch: 13 cost time: 18.995343446731567
Epoch: 13, Steps: 131 | Train Loss: 0.2980245 Vali Loss: 0.5168353 Test Loss: 0.3381874
Validation loss decreased (0.517815 --> 0.516835).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2870019
	speed: 0.3448s/iter; left time: 1637.3352s
Epoch: 14 cost time: 17.341371059417725
Epoch: 14, Steps: 131 | Train Loss: 0.2979562 Vali Loss: 0.5152495 Test Loss: 0.3380557
Validation loss decreased (0.516835 --> 0.515249).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2918624
	speed: 0.3738s/iter; left time: 1725.6926s
Epoch: 15 cost time: 18.665128469467163
Epoch: 15, Steps: 131 | Train Loss: 0.2978747 Vali Loss: 0.5160607 Test Loss: 0.3382573
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3380191
	speed: 0.3916s/iter; left time: 1756.7631s
Epoch: 16 cost time: 18.196380138397217
Epoch: 16, Steps: 131 | Train Loss: 0.2978024 Vali Loss: 0.5146590 Test Loss: 0.3377999
Validation loss decreased (0.515249 --> 0.514659).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2824183
	speed: 0.3770s/iter; left time: 1642.0133s
Epoch: 17 cost time: 18.6776123046875
Epoch: 17, Steps: 131 | Train Loss: 0.2977860 Vali Loss: 0.5152149 Test Loss: 0.3381388
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2789239
	speed: 0.3599s/iter; left time: 1520.4268s
Epoch: 18 cost time: 15.076385498046875
Epoch: 18, Steps: 131 | Train Loss: 0.2974948 Vali Loss: 0.5147219 Test Loss: 0.3379380
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2818310
	speed: 0.3244s/iter; left time: 1327.7370s
Epoch: 19 cost time: 16.19835376739502
Epoch: 19, Steps: 131 | Train Loss: 0.2974015 Vali Loss: 0.5143716 Test Loss: 0.3377964
Validation loss decreased (0.514659 --> 0.514372).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2743388
	speed: 0.2529s/iter; left time: 1002.0662s
Epoch: 20 cost time: 7.675460338592529
Epoch: 20, Steps: 131 | Train Loss: 0.2974889 Vali Loss: 0.5139859 Test Loss: 0.3379650
Validation loss decreased (0.514372 --> 0.513986).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2920822
	speed: 0.2161s/iter; left time: 827.8948s
Epoch: 21 cost time: 11.662750005722046
Epoch: 21, Steps: 131 | Train Loss: 0.2974777 Vali Loss: 0.5141124 Test Loss: 0.3376664
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3074753
	speed: 0.3457s/iter; left time: 1278.9705s
Epoch: 22 cost time: 18.396507740020752
Epoch: 22, Steps: 131 | Train Loss: 0.2974090 Vali Loss: 0.5145559 Test Loss: 0.3378725
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3227943
	speed: 0.3740s/iter; left time: 1334.7025s
Epoch: 23 cost time: 17.489705801010132
Epoch: 23, Steps: 131 | Train Loss: 0.2974149 Vali Loss: 0.5137395 Test Loss: 0.3378887
Validation loss decreased (0.513986 --> 0.513740).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3051318
	speed: 0.3814s/iter; left time: 1311.2600s
Epoch: 24 cost time: 18.75234842300415
Epoch: 24, Steps: 131 | Train Loss: 0.2973179 Vali Loss: 0.5131574 Test Loss: 0.3380477
Validation loss decreased (0.513740 --> 0.513157).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2910183
	speed: 0.3503s/iter; left time: 1158.6022s
Epoch: 25 cost time: 16.04951286315918
Epoch: 25, Steps: 131 | Train Loss: 0.2973646 Vali Loss: 0.5135014 Test Loss: 0.3379572
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2736636
	speed: 0.3235s/iter; left time: 1027.4908s
Epoch: 26 cost time: 16.165772438049316
Epoch: 26, Steps: 131 | Train Loss: 0.2970701 Vali Loss: 0.5124565 Test Loss: 0.3378138
Validation loss decreased (0.513157 --> 0.512456).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2885731
	speed: 0.3268s/iter; left time: 995.1105s
Epoch: 27 cost time: 13.977306842803955
Epoch: 27, Steps: 131 | Train Loss: 0.2971299 Vali Loss: 0.5119238 Test Loss: 0.3378529
Validation loss decreased (0.512456 --> 0.511924).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2986400
	speed: 0.3740s/iter; left time: 1089.8504s
Epoch: 28 cost time: 19.13988947868347
Epoch: 28, Steps: 131 | Train Loss: 0.2972358 Vali Loss: 0.5129321 Test Loss: 0.3379947
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2930864
	speed: 0.4018s/iter; left time: 1118.2756s
Epoch: 29 cost time: 19.107542276382446
Epoch: 29, Steps: 131 | Train Loss: 0.2972273 Vali Loss: 0.5136237 Test Loss: 0.3378572
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2799688
	speed: 0.4030s/iter; left time: 1068.6347s
Epoch: 30 cost time: 19.3724422454834
Epoch: 30, Steps: 131 | Train Loss: 0.2970822 Vali Loss: 0.5131916 Test Loss: 0.3377280
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_720_192_FITS_ETTm1_ftM_sl720_ll48_pl192_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.3378429710865021, mae:0.36810529232025146, rse:0.5532978177070618, corr:[0.5415055  0.5515372  0.5549861  0.55584604 0.55739284 0.5599197
 0.56200516 0.56288946 0.56311345 0.5634235  0.5641035  0.5647846
 0.5651671  0.56512827 0.5646849  0.5638912  0.5628641  0.5618128
 0.5608314  0.55988145 0.5587752  0.5573043  0.55554193 0.55397695
 0.5527326  0.5519005  0.5511988  0.55030876 0.5495263  0.5492484
 0.5497329  0.55084294 0.5518764  0.55237466 0.55211824 0.5517506
 0.5515691  0.5516752  0.55178124 0.55151844 0.5510507  0.5505892
 0.5503556  0.55036104 0.55022246 0.5498153  0.5494739  0.5494703
 0.54971254 0.5498768  0.54981446 0.54950494 0.54919994 0.5490458
 0.5490814  0.54909146 0.5488833  0.54841423 0.5480423  0.5479241
 0.5481182  0.54841447 0.54858667 0.54846096 0.54831713 0.5483447
 0.5484879  0.5485735  0.54852194 0.548359   0.5482836  0.54834074
 0.5484436  0.548454   0.5483572  0.5481208  0.5478207  0.54759544
 0.5475045  0.5475143  0.54751563 0.5473817  0.5471295  0.54678124
 0.54646915 0.54622567 0.54608357 0.545978   0.54592884 0.5460508
 0.5463324  0.5466969  0.54704815 0.5472817  0.5472943  0.5470385
 0.54662925 0.54625523 0.5458789  0.5455484  0.54526526 0.5450318
 0.54484826 0.5446426  0.54449683 0.5444588  0.544377   0.5442838
 0.5441562  0.5440656  0.5439947  0.5438148  0.5434595  0.5429894
 0.5425313  0.54224885 0.54220086 0.54223746 0.5421929  0.5419968
 0.54162806 0.5412043  0.5408618  0.5407577  0.5408081  0.5407404
 0.5404474  0.5401169  0.53996634 0.54010946 0.5402917  0.5402453
 0.5399646  0.5396036  0.53932935 0.53934026 0.53965604 0.53991544
 0.5400664  0.5401863  0.54028434 0.5404532  0.5406494  0.5407615
 0.5407555  0.5406629  0.5406643  0.5407659  0.5409092  0.54089063
 0.5406794  0.5405056  0.5404624  0.540497   0.5404749  0.54042184
 0.5403666  0.5403244  0.5403967  0.5404266  0.5404551  0.54046166
 0.5405261  0.5406515  0.5408026  0.5408809  0.5408454  0.5407731
 0.5407578  0.54081625 0.540974   0.5410945  0.54089963 0.5404446
 0.53999805 0.53980005 0.5398193  0.5398665  0.5396822  0.53937787
 0.53912455 0.5390342  0.5389118  0.53870445 0.53848594 0.5385261
 0.5389151  0.53965616 0.5404364  0.5410255  0.5411732  0.5396416 ]
