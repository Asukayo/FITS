Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTm1_720_96_FITS_ETTm1_ftM_sl720_ll48_pl96_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=106, out_features=120, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  22794240.0
params:  12840.0
Trainable parameters:  12840
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3068984
	speed: 0.1537s/iter; left time: 991.5714s
Epoch: 1 cost time: 20.59557294845581
Epoch: 1, Steps: 131 | Train Loss: 0.3593801 Vali Loss: 0.4719992 Test Loss: 0.3208267
Validation loss decreased (inf --> 0.471999).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2716952
	speed: 0.4894s/iter; left time: 3092.9507s
Epoch: 2 cost time: 24.117534160614014
Epoch: 2, Steps: 131 | Train Loss: 0.2781114 Vali Loss: 0.4319279 Test Loss: 0.3130270
Validation loss decreased (0.471999 --> 0.431928).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2484603
	speed: 0.5623s/iter; left time: 3480.1001s
Epoch: 3 cost time: 27.96948742866516
Epoch: 3, Steps: 131 | Train Loss: 0.2706842 Vali Loss: 0.4185131 Test Loss: 0.3113573
Validation loss decreased (0.431928 --> 0.418513).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2504844
	speed: 0.5788s/iter; left time: 3506.3667s
Epoch: 4 cost time: 27.98992395401001
Epoch: 4, Steps: 131 | Train Loss: 0.2678138 Vali Loss: 0.4115276 Test Loss: 0.3110511
Validation loss decreased (0.418513 --> 0.411528).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2589210
	speed: 0.5161s/iter; left time: 3059.0412s
Epoch: 5 cost time: 21.907907724380493
Epoch: 5, Steps: 131 | Train Loss: 0.2660910 Vali Loss: 0.4066840 Test Loss: 0.3102297
Validation loss decreased (0.411528 --> 0.406684).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2772032
	speed: 0.3724s/iter; left time: 2158.1698s
Epoch: 6 cost time: 17.595890522003174
Epoch: 6, Steps: 131 | Train Loss: 0.2651720 Vali Loss: 0.4058175 Test Loss: 0.3098914
Validation loss decreased (0.406684 --> 0.405818).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2609475
	speed: 0.3628s/iter; left time: 2055.5215s
Epoch: 7 cost time: 17.108545064926147
Epoch: 7, Steps: 131 | Train Loss: 0.2643542 Vali Loss: 0.4033546 Test Loss: 0.3096297
Validation loss decreased (0.405818 --> 0.403355).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2557449
	speed: 0.2993s/iter; left time: 1656.5881s
Epoch: 8 cost time: 13.382836103439331
Epoch: 8, Steps: 131 | Train Loss: 0.2637412 Vali Loss: 0.3999235 Test Loss: 0.3101718
Validation loss decreased (0.403355 --> 0.399924).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2620333
	speed: 0.3466s/iter; left time: 1872.7016s
Epoch: 9 cost time: 16.68086075782776
Epoch: 9, Steps: 131 | Train Loss: 0.2634415 Vali Loss: 0.4009272 Test Loss: 0.3099099
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2631012
	speed: 0.3542s/iter; left time: 1867.1784s
Epoch: 10 cost time: 17.007256984710693
Epoch: 10, Steps: 131 | Train Loss: 0.2634049 Vali Loss: 0.4013509 Test Loss: 0.3092655
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2800649
	speed: 0.3524s/iter; left time: 1811.9046s
Epoch: 11 cost time: 17.026288270950317
Epoch: 11, Steps: 131 | Train Loss: 0.2630779 Vali Loss: 0.4009344 Test Loss: 0.3091256
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_720_96_FITS_ETTm1_ftM_sl720_ll48_pl96_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.3102918267250061, mae:0.3525509536266327, rse:0.5300502777099609, corr:[0.54407096 0.556672   0.5637817  0.56542546 0.56537056 0.56586057
 0.56710064 0.568531   0.569537   0.56997895 0.57019466 0.57026726
 0.5701253  0.5696463  0.5688135  0.5678248  0.56695473 0.5662219
 0.5653291  0.56414753 0.5628163  0.5614676  0.56027573 0.5594316
 0.5586049  0.5575958  0.5563354  0.5550082  0.55421025 0.55429155
 0.55515873 0.55633336 0.5571339  0.5573008  0.5568397  0.55635005
 0.5560628  0.55601597 0.5559499  0.5554928  0.5547299  0.5538706
 0.553301   0.5533174  0.5536724  0.554049   0.554339   0.55449015
 0.55448693 0.5543536  0.55422187 0.5540578  0.553874   0.5536154
 0.5534201  0.553389   0.5534953  0.5535394  0.5534985  0.55325323
 0.5529315  0.5527041  0.552658   0.55262643 0.5526284  0.55263174
 0.55259126 0.5525466  0.5526052  0.55272347 0.55286294 0.5529187
 0.552825   0.5525692  0.55224824 0.55183375 0.5513422  0.55088204
 0.5505442  0.55035245 0.55023587 0.5500082  0.5495855  0.54882866
 0.5478646  0.546877   0.5461276  0.5456379  0.5453604  0.5452639
 0.54512566 0.544992   0.5452289  0.5459683  0.5463819  0.54399484]
