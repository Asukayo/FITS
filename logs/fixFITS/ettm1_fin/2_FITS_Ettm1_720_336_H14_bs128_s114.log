Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=122, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_336', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTm1_720_336_FITS_ETTm1_ftM_sl720_ll48_pl336_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=122, out_features=178, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  38915072.0
params:  21894.0
Trainable parameters:  21894
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4233887
	speed: 0.1689s/iter; left time: 1080.9879s
Epoch: 1 cost time: 22.15560221672058
Epoch: 1, Steps: 130 | Train Loss: 0.5032132 Vali Loss: 1.0995343 Test Loss: 0.6581999
Validation loss decreased (inf --> 1.099534).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3239821
	speed: 0.4758s/iter; left time: 2983.5748s
Epoch: 2 cost time: 22.736923694610596
Epoch: 2, Steps: 130 | Train Loss: 0.3408042 Vali Loss: 0.9451294 Test Loss: 0.5590672
Validation loss decreased (1.099534 --> 0.945129).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2509229
	speed: 0.4772s/iter; left time: 2930.2284s
Epoch: 3 cost time: 23.626773595809937
Epoch: 3, Steps: 130 | Train Loss: 0.2743797 Vali Loss: 0.8688624 Test Loss: 0.5100679
Validation loss decreased (0.945129 --> 0.868862).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2160810
	speed: 0.4204s/iter; left time: 2527.2775s
Epoch: 4 cost time: 17.48110866546631
Epoch: 4, Steps: 130 | Train Loss: 0.2353156 Vali Loss: 0.8235610 Test Loss: 0.4768544
Validation loss decreased (0.868862 --> 0.823561).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2011305
	speed: 0.3971s/iter; left time: 2335.1288s
Epoch: 5 cost time: 23.09091567993164
Epoch: 5, Steps: 130 | Train Loss: 0.2096145 Vali Loss: 0.7956698 Test Loss: 0.4574897
Validation loss decreased (0.823561 --> 0.795670).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1821768
	speed: 0.4627s/iter; left time: 2661.2198s
Epoch: 6 cost time: 21.86963176727295
Epoch: 6, Steps: 130 | Train Loss: 0.1914246 Vali Loss: 0.7716124 Test Loss: 0.4407518
Validation loss decreased (0.795670 --> 0.771612).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1692912
	speed: 0.4376s/iter; left time: 2459.8334s
Epoch: 7 cost time: 20.69740343093872
Epoch: 7, Steps: 130 | Train Loss: 0.1781156 Vali Loss: 0.7559339 Test Loss: 0.4285026
Validation loss decreased (0.771612 --> 0.755934).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1645551
	speed: 0.4485s/iter; left time: 2462.9639s
Epoch: 8 cost time: 21.063876390457153
Epoch: 8, Steps: 130 | Train Loss: 0.1679560 Vali Loss: 0.7436374 Test Loss: 0.4189394
Validation loss decreased (0.755934 --> 0.743637).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1588645
	speed: 0.4192s/iter; left time: 2247.3334s
Epoch: 9 cost time: 18.087913751602173
Epoch: 9, Steps: 130 | Train Loss: 0.1599906 Vali Loss: 0.7324224 Test Loss: 0.4114744
Validation loss decreased (0.743637 --> 0.732422).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1681290
	speed: 0.3552s/iter; left time: 1857.8001s
Epoch: 10 cost time: 17.110475540161133
Epoch: 10, Steps: 130 | Train Loss: 0.1536318 Vali Loss: 0.7222881 Test Loss: 0.4043041
Validation loss decreased (0.732422 --> 0.722288).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1515383
	speed: 0.3233s/iter; left time: 1649.3923s
Epoch: 11 cost time: 13.39539098739624
Epoch: 11, Steps: 130 | Train Loss: 0.1485178 Vali Loss: 0.7149643 Test Loss: 0.3995959
Validation loss decreased (0.722288 --> 0.714964).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1407180
	speed: 0.3288s/iter; left time: 1634.2596s
Epoch: 12 cost time: 18.36143469810486
Epoch: 12, Steps: 130 | Train Loss: 0.1442633 Vali Loss: 0.7091079 Test Loss: 0.3942908
Validation loss decreased (0.714964 --> 0.709108).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1392176
	speed: 0.3939s/iter; left time: 1906.6948s
Epoch: 13 cost time: 18.91462016105652
Epoch: 13, Steps: 130 | Train Loss: 0.1408863 Vali Loss: 0.7042033 Test Loss: 0.3905748
Validation loss decreased (0.709108 --> 0.704203).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1423295
	speed: 0.3686s/iter; left time: 1736.3066s
Epoch: 14 cost time: 14.320593357086182
Epoch: 14, Steps: 130 | Train Loss: 0.1380781 Vali Loss: 0.6991768 Test Loss: 0.3871862
Validation loss decreased (0.704203 --> 0.699177).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1321880
	speed: 0.2579s/iter; left time: 1181.3114s
Epoch: 15 cost time: 17.806731700897217
Epoch: 15, Steps: 130 | Train Loss: 0.1356884 Vali Loss: 0.6974644 Test Loss: 0.3849093
Validation loss decreased (0.699177 --> 0.697464).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1356277
	speed: 0.3707s/iter; left time: 1649.9922s
Epoch: 16 cost time: 17.809008598327637
Epoch: 16, Steps: 130 | Train Loss: 0.1336061 Vali Loss: 0.6933552 Test Loss: 0.3826181
Validation loss decreased (0.697464 --> 0.693355).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1297072
	speed: 0.3675s/iter; left time: 1587.9964s
Epoch: 17 cost time: 17.62579870223999
Epoch: 17, Steps: 130 | Train Loss: 0.1319604 Vali Loss: 0.6911026 Test Loss: 0.3804996
Validation loss decreased (0.693355 --> 0.691103).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1300368
	speed: 0.3677s/iter; left time: 1540.8917s
Epoch: 18 cost time: 17.834810256958008
Epoch: 18, Steps: 130 | Train Loss: 0.1305026 Vali Loss: 0.6885520 Test Loss: 0.3787054
Validation loss decreased (0.691103 --> 0.688552).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1258555
	speed: 0.3599s/iter; left time: 1461.5747s
Epoch: 19 cost time: 17.427638292312622
Epoch: 19, Steps: 130 | Train Loss: 0.1292999 Vali Loss: 0.6875058 Test Loss: 0.3773057
Validation loss decreased (0.688552 --> 0.687506).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1300985
	speed: 0.3636s/iter; left time: 1429.1860s
Epoch: 20 cost time: 17.405177116394043
Epoch: 20, Steps: 130 | Train Loss: 0.1281668 Vali Loss: 0.6848504 Test Loss: 0.3760838
Validation loss decreased (0.687506 --> 0.684850).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1319938
	speed: 0.3655s/iter; left time: 1389.4143s
Epoch: 21 cost time: 17.663044691085815
Epoch: 21, Steps: 130 | Train Loss: 0.1273331 Vali Loss: 0.6828355 Test Loss: 0.3749670
Validation loss decreased (0.684850 --> 0.682835).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1299471
	speed: 0.3722s/iter; left time: 1366.4046s
Epoch: 22 cost time: 18.421966314315796
Epoch: 22, Steps: 130 | Train Loss: 0.1265456 Vali Loss: 0.6810628 Test Loss: 0.3744896
Validation loss decreased (0.682835 --> 0.681063).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1324041
	speed: 0.2796s/iter; left time: 990.0142s
Epoch: 23 cost time: 10.472522020339966
Epoch: 23, Steps: 130 | Train Loss: 0.1258625 Vali Loss: 0.6811897 Test Loss: 0.3734088
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1254185
	speed: 0.2504s/iter; left time: 854.2396s
Epoch: 24 cost time: 16.044498205184937
Epoch: 24, Steps: 130 | Train Loss: 0.1251761 Vali Loss: 0.6807239 Test Loss: 0.3729157
Validation loss decreased (0.681063 --> 0.680724).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1284815
	speed: 0.3521s/iter; left time: 1155.0904s
Epoch: 25 cost time: 16.829052209854126
Epoch: 25, Steps: 130 | Train Loss: 0.1246894 Vali Loss: 0.6784613 Test Loss: 0.3722740
Validation loss decreased (0.680724 --> 0.678461).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1272456
	speed: 0.3391s/iter; left time: 1068.5582s
Epoch: 26 cost time: 16.68122100830078
Epoch: 26, Steps: 130 | Train Loss: 0.1241449 Vali Loss: 0.6786170 Test Loss: 0.3718261
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1282346
	speed: 0.3431s/iter; left time: 1036.6343s
Epoch: 27 cost time: 16.691043615341187
Epoch: 27, Steps: 130 | Train Loss: 0.1237657 Vali Loss: 0.6764532 Test Loss: 0.3715191
Validation loss decreased (0.678461 --> 0.676453).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1264343
	speed: 0.3415s/iter; left time: 987.3746s
Epoch: 28 cost time: 16.490952730178833
Epoch: 28, Steps: 130 | Train Loss: 0.1234311 Vali Loss: 0.6763508 Test Loss: 0.3710555
Validation loss decreased (0.676453 --> 0.676351).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1165280
	speed: 0.3461s/iter; left time: 955.4823s
Epoch: 29 cost time: 16.83277726173401
Epoch: 29, Steps: 130 | Train Loss: 0.1230460 Vali Loss: 0.6757246 Test Loss: 0.3707199
Validation loss decreased (0.676351 --> 0.675725).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1266645
	speed: 0.3033s/iter; left time: 797.8988s
Epoch: 30 cost time: 12.928793907165527
Epoch: 30, Steps: 130 | Train Loss: 0.1227068 Vali Loss: 0.6757927 Test Loss: 0.3703798
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1239688
	speed: 0.3198s/iter; left time: 799.8421s
Epoch: 31 cost time: 16.528233528137207
Epoch: 31, Steps: 130 | Train Loss: 0.1224778 Vali Loss: 0.6749192 Test Loss: 0.3702892
Validation loss decreased (0.675725 --> 0.674919).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1251219
	speed: 0.3383s/iter; left time: 802.2233s
Epoch: 32 cost time: 16.273457765579224
Epoch: 32, Steps: 130 | Train Loss: 0.1222044 Vali Loss: 0.6759828 Test Loss: 0.3700145
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1180469
	speed: 0.3173s/iter; left time: 711.0246s
Epoch: 33 cost time: 15.397477149963379
Epoch: 33, Steps: 130 | Train Loss: 0.1220059 Vali Loss: 0.6754124 Test Loss: 0.3699263
EarlyStopping counter: 2 out of 3
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1181139
	speed: 0.3552s/iter; left time: 749.8326s
Epoch: 34 cost time: 19.094616174697876
Epoch: 34, Steps: 130 | Train Loss: 0.1218300 Vali Loss: 0.6744339 Test Loss: 0.3698371
Validation loss decreased (0.674919 --> 0.674434).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1166002
	speed: 0.3771s/iter; left time: 747.0939s
Epoch: 35 cost time: 18.033561944961548
Epoch: 35, Steps: 130 | Train Loss: 0.1216383 Vali Loss: 0.6757775 Test Loss: 0.3697875
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1229440
	speed: 0.3473s/iter; left time: 642.8197s
Epoch: 36 cost time: 16.627376079559326
Epoch: 36, Steps: 130 | Train Loss: 0.1214695 Vali Loss: 0.6736908 Test Loss: 0.3696379
Validation loss decreased (0.674434 --> 0.673691).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1170005
	speed: 0.3270s/iter; left time: 562.8340s
Epoch: 37 cost time: 15.712624073028564
Epoch: 37, Steps: 130 | Train Loss: 0.1213316 Vali Loss: 0.6744022 Test Loss: 0.3695597
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1220007
	speed: 0.3280s/iter; left time: 521.9124s
Epoch: 38 cost time: 15.791561603546143
Epoch: 38, Steps: 130 | Train Loss: 0.1212148 Vali Loss: 0.6745458 Test Loss: 0.3695960
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1161689
	speed: 0.3384s/iter; left time: 494.3307s
Epoch: 39 cost time: 16.537222385406494
Epoch: 39, Steps: 130 | Train Loss: 0.1211056 Vali Loss: 0.6743125 Test Loss: 0.3694611
EarlyStopping counter: 3 out of 3
Early stopping
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=122, out_features=178, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  38915072.0
params:  21894.0
Trainable parameters:  21894
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3473764
	speed: 0.1289s/iter; left time: 824.9795s
Epoch: 1 cost time: 16.661271333694458
Epoch: 1, Steps: 130 | Train Loss: 0.3396043 Vali Loss: 0.6619789 Test Loss: 0.3669519
Validation loss decreased (inf --> 0.661979).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3365901
	speed: 0.2933s/iter; left time: 1839.2950s
Epoch: 2 cost time: 12.370734930038452
Epoch: 2, Steps: 130 | Train Loss: 0.3379045 Vali Loss: 0.6592453 Test Loss: 0.3673545
Validation loss decreased (0.661979 --> 0.659245).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3289390
	speed: 0.2713s/iter; left time: 1666.1566s
Epoch: 3 cost time: 14.29654312133789
Epoch: 3, Steps: 130 | Train Loss: 0.3372089 Vali Loss: 0.6566992 Test Loss: 0.3668709
Validation loss decreased (0.659245 --> 0.656699).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3522620
	speed: 0.3626s/iter; left time: 2179.6596s
Epoch: 4 cost time: 17.317075490951538
Epoch: 4, Steps: 130 | Train Loss: 0.3370691 Vali Loss: 0.6575989 Test Loss: 0.3670415
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3399580
	speed: 0.3757s/iter; left time: 2209.6434s
Epoch: 5 cost time: 17.069176197052002
Epoch: 5, Steps: 130 | Train Loss: 0.3366837 Vali Loss: 0.6540695 Test Loss: 0.3668836
Validation loss decreased (0.656699 --> 0.654069).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3090299
	speed: 0.3128s/iter; left time: 1798.9065s
Epoch: 6 cost time: 15.42875075340271
Epoch: 6, Steps: 130 | Train Loss: 0.3366528 Vali Loss: 0.6561229 Test Loss: 0.3670381
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3091754
	speed: 0.3788s/iter; left time: 2129.2050s
Epoch: 7 cost time: 17.453322172164917
Epoch: 7, Steps: 130 | Train Loss: 0.3366025 Vali Loss: 0.6555691 Test Loss: 0.3670430
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3373614
	speed: 0.3282s/iter; left time: 1802.0920s
Epoch: 8 cost time: 13.154003381729126
Epoch: 8, Steps: 130 | Train Loss: 0.3363318 Vali Loss: 0.6549386 Test Loss: 0.3669136
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_720_336_FITS_ETTm1_ftM_sl720_ll48_pl336_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.3666701316833496, mae:0.38524487614631653, rse:0.576216995716095, corr:[0.53611994 0.5490693  0.55440766 0.55457586 0.55474466 0.556551
 0.55880344 0.55982447 0.5595282  0.55907154 0.5593069  0.55999273
 0.5603812  0.5600323  0.55917484 0.5582265  0.5572895  0.5562213
 0.5548629  0.55337715 0.55210286 0.55110115 0.55017334 0.5491867
 0.5479522  0.54673094 0.5457345  0.5449276  0.54433733 0.54395974
 0.5439021  0.5443739  0.545283   0.54631466 0.54685706 0.54684675
 0.54633594 0.5457638  0.54541796 0.545222   0.5451126  0.54495746
 0.54487365 0.54502225 0.5452042  0.54521626 0.5450746  0.5448936
 0.54483837 0.54493785 0.5450829  0.5449732  0.544522   0.54385304
 0.5433973  0.54341817 0.5437732  0.54406446 0.5440874  0.54379827
 0.5434609  0.54333246 0.54336995 0.5433002  0.5431395  0.5430206
 0.54309475 0.5434163  0.5438656  0.5441934  0.54426634 0.54405546
 0.543637   0.54317546 0.5428497  0.5427094  0.5427145  0.5427849
 0.5427806  0.54261994 0.54230493 0.54192865 0.5416367  0.54144573
 0.54132086 0.5411142  0.5407996  0.5404406  0.5402629  0.54047704
 0.54102826 0.5416583  0.5420761  0.5421265  0.5418464  0.5414337
 0.5411219  0.5410329  0.54099077 0.54091424 0.54075813 0.5405364
 0.54029274 0.5399868  0.5396908  0.53947926 0.53931296 0.53925097
 0.539185   0.539054   0.5387892  0.5383765  0.5379212  0.5375622
 0.537332   0.53717566 0.53699183 0.536717   0.53645414 0.5363678
 0.5364577  0.5365638  0.53645265 0.536148   0.5358071  0.5355829
 0.5356025  0.53586304 0.5361405  0.536282   0.53617114 0.53588825
 0.5356257  0.5354351  0.5352415  0.535082   0.5350769  0.5351486
 0.5353067  0.5354602  0.53542894 0.53523535 0.53498566 0.53478795
 0.5346911  0.5346406  0.5347218  0.534979   0.53542316 0.5358629
 0.5360896  0.536015   0.5356237  0.53507805 0.53460526 0.5344285
 0.53450173 0.5346382  0.53475565 0.5347512  0.53476167 0.5348065
 0.53487456 0.5349325  0.5350225  0.5352261  0.5355865  0.5360538
 0.5364392  0.5365995  0.5366276  0.5366157  0.53657806 0.53656876
 0.53659064 0.5365958  0.536517   0.53637594 0.536214   0.5361245
 0.53612256 0.5361946  0.5362513  0.53631574 0.53642094 0.5365922
 0.5368515  0.53723544 0.5376748  0.5380151  0.53816724 0.5380948
 0.5378017  0.537409   0.53693837 0.53644705 0.5360001  0.5356165
 0.53519416 0.53464544 0.53392243 0.5330878  0.5322311  0.5314313
 0.5307256  0.5300775  0.5294372  0.5288491  0.5283494  0.5279442
 0.5275391  0.52707237 0.52645206 0.52569324 0.52484643 0.52417547
 0.5238225  0.523623   0.523421   0.5230892  0.5227487  0.52264535
 0.5229388  0.5234106  0.5238831  0.5242094  0.5243118  0.52427316
 0.52419555 0.5241415  0.52412176 0.52409524 0.5241105  0.52420706
 0.5243114  0.52436936 0.5242013  0.5240061  0.5238772  0.52396905
 0.52421635 0.5243736  0.52434903 0.5241656  0.5239575  0.5238184
 0.52384526 0.52405524 0.5242567  0.5243297  0.52415806 0.523918
 0.5237073  0.52372736 0.52383965 0.5238361  0.5236341  0.52335256
 0.523217   0.52340627 0.5238322  0.52423847 0.52439046 0.52434283
 0.52416474 0.52405065 0.524112   0.5243339  0.52456117 0.5246343
 0.52460486 0.5245536  0.5245556  0.5245861  0.524532   0.5243758
 0.52413285 0.5239876  0.52393514 0.52402043 0.5241095  0.5241529
 0.52424455 0.52440935 0.52454895 0.52456945 0.52434313 0.52380174
 0.52307886 0.52240413 0.5218217  0.52118737 0.5205096  0.51985043
 0.5193405  0.51896137 0.5187187  0.51839435 0.51786023 0.5171467
 0.5163715  0.5157473  0.5153688  0.5150901  0.5147245  0.51418835
 0.51377606 0.5135491  0.5134666  0.5133709  0.5132276  0.51300293
 0.51284325 0.5129554  0.51322883 0.513477   0.51351166 0.51333725
 0.5130758  0.5128036  0.51260644 0.5125311  0.5125995  0.51277506
 0.51293355 0.51309454 0.51316047 0.5131867  0.5131706  0.51306695
 0.512863   0.5124927  0.51240504 0.51311356 0.5132421  0.50817746]
