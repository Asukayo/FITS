Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=122, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTm1_720_192_FITS_ETTm1_ftM_sl720_ll48_pl192_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=122, out_features=154, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  33668096.0
params:  18942.0
Trainable parameters:  18942
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3928590
	speed: 0.1377s/iter; left time: 888.1216s
Epoch: 1 cost time: 17.969408750534058
Epoch: 1, Steps: 131 | Train Loss: 0.4602211 Vali Loss: 0.8498291 Test Loss: 0.5279470
Validation loss decreased (inf --> 0.849829).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2712495
	speed: 0.3640s/iter; left time: 2300.7197s
Epoch: 2 cost time: 16.74347949028015
Epoch: 2, Steps: 131 | Train Loss: 0.2988883 Vali Loss: 0.7444004 Test Loss: 0.4800816
Validation loss decreased (0.849829 --> 0.744400).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2304088
	speed: 0.3146s/iter; left time: 1946.9774s
Epoch: 3 cost time: 14.400045394897461
Epoch: 3, Steps: 131 | Train Loss: 0.2369960 Vali Loss: 0.7059853 Test Loss: 0.4662353
Validation loss decreased (0.744400 --> 0.705985).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1906675
	speed: 0.3031s/iter; left time: 1835.9778s
Epoch: 4 cost time: 15.733082056045532
Epoch: 4, Steps: 131 | Train Loss: 0.2022892 Vali Loss: 0.6822845 Test Loss: 0.4557286
Validation loss decreased (0.705985 --> 0.682285).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1651234
	speed: 0.3648s/iter; left time: 2162.3616s
Epoch: 5 cost time: 17.771639347076416
Epoch: 5, Steps: 131 | Train Loss: 0.1785977 Vali Loss: 0.6656829 Test Loss: 0.4472827
Validation loss decreased (0.682285 --> 0.665683).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1549326
	speed: 0.3907s/iter; left time: 2264.2229s
Epoch: 6 cost time: 19.326712369918823
Epoch: 6, Steps: 131 | Train Loss: 0.1609127 Vali Loss: 0.6521847 Test Loss: 0.4400335
Validation loss decreased (0.665683 --> 0.652185).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1436517
	speed: 0.4063s/iter; left time: 2301.8644s
Epoch: 7 cost time: 18.895999431610107
Epoch: 7, Steps: 131 | Train Loss: 0.1471161 Vali Loss: 0.6400879 Test Loss: 0.4314649
Validation loss decreased (0.652185 --> 0.640088).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1333344
	speed: 0.3723s/iter; left time: 2060.0974s
Epoch: 8 cost time: 16.1166672706604
Epoch: 8, Steps: 131 | Train Loss: 0.1361074 Vali Loss: 0.6299580 Test Loss: 0.4254312
Validation loss decreased (0.640088 --> 0.629958).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1302079
	speed: 0.2949s/iter; left time: 1593.5656s
Epoch: 9 cost time: 14.704595804214478
Epoch: 9, Steps: 131 | Train Loss: 0.1272009 Vali Loss: 0.6201212 Test Loss: 0.4199104
Validation loss decreased (0.629958 --> 0.620121).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1138015
	speed: 0.3113s/iter; left time: 1641.0300s
Epoch: 10 cost time: 14.358257055282593
Epoch: 10, Steps: 131 | Train Loss: 0.1199492 Vali Loss: 0.6129001 Test Loss: 0.4141318
Validation loss decreased (0.620121 --> 0.612900).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1086291
	speed: 0.3557s/iter; left time: 1828.7317s
Epoch: 11 cost time: 17.23413395881653
Epoch: 11, Steps: 131 | Train Loss: 0.1139575 Vali Loss: 0.6067186 Test Loss: 0.4096996
Validation loss decreased (0.612900 --> 0.606719).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1068701
	speed: 0.3580s/iter; left time: 1793.4165s
Epoch: 12 cost time: 17.00420093536377
Epoch: 12, Steps: 131 | Train Loss: 0.1089622 Vali Loss: 0.6000181 Test Loss: 0.4055520
Validation loss decreased (0.606719 --> 0.600018).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1047356
	speed: 0.3657s/iter; left time: 1784.3647s
Epoch: 13 cost time: 17.203554153442383
Epoch: 13, Steps: 131 | Train Loss: 0.1047880 Vali Loss: 0.5945213 Test Loss: 0.4021592
Validation loss decreased (0.600018 --> 0.594521).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.0970587
	speed: 0.3669s/iter; left time: 1742.0484s
Epoch: 14 cost time: 17.38950777053833
Epoch: 14, Steps: 131 | Train Loss: 0.1012910 Vali Loss: 0.5883387 Test Loss: 0.3983904
Validation loss decreased (0.594521 --> 0.588339).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.0952790
	speed: 0.3625s/iter; left time: 1673.6371s
Epoch: 15 cost time: 17.518290281295776
Epoch: 15, Steps: 131 | Train Loss: 0.0983290 Vali Loss: 0.5849151 Test Loss: 0.3948980
Validation loss decreased (0.588339 --> 0.584915).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1040632
	speed: 0.4020s/iter; left time: 1803.2419s
Epoch: 16 cost time: 20.234404802322388
Epoch: 16, Steps: 131 | Train Loss: 0.0957915 Vali Loss: 0.5804688 Test Loss: 0.3922200
Validation loss decreased (0.584915 --> 0.580469).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.0900266
	speed: 0.4229s/iter; left time: 1841.7785s
Epoch: 17 cost time: 20.144587516784668
Epoch: 17, Steps: 131 | Train Loss: 0.0936177 Vali Loss: 0.5772368 Test Loss: 0.3896397
Validation loss decreased (0.580469 --> 0.577237).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.0859323
	speed: 0.4050s/iter; left time: 1710.5752s
Epoch: 18 cost time: 17.784545421600342
Epoch: 18, Steps: 131 | Train Loss: 0.0916794 Vali Loss: 0.5738482 Test Loss: 0.3869722
Validation loss decreased (0.577237 --> 0.573848).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.0864445
	speed: 0.3672s/iter; left time: 1502.9331s
Epoch: 19 cost time: 17.200016260147095
Epoch: 19, Steps: 131 | Train Loss: 0.0900521 Vali Loss: 0.5706976 Test Loss: 0.3846205
Validation loss decreased (0.573848 --> 0.570698).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.0836893
	speed: 0.3520s/iter; left time: 1394.5134s
Epoch: 20 cost time: 16.948291540145874
Epoch: 20, Steps: 131 | Train Loss: 0.0886498 Vali Loss: 0.5680380 Test Loss: 0.3828180
Validation loss decreased (0.570698 --> 0.568038).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.0874225
	speed: 0.3545s/iter; left time: 1358.1015s
Epoch: 21 cost time: 16.092321634292603
Epoch: 21, Steps: 131 | Train Loss: 0.0874192 Vali Loss: 0.5655625 Test Loss: 0.3805486
Validation loss decreased (0.568038 --> 0.565563).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.0891432
	speed: 0.3028s/iter; left time: 1120.3257s
Epoch: 22 cost time: 13.754060745239258
Epoch: 22, Steps: 131 | Train Loss: 0.0863205 Vali Loss: 0.5643707 Test Loss: 0.3790744
Validation loss decreased (0.565563 --> 0.564371).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.0902284
	speed: 0.2916s/iter; left time: 1040.8422s
Epoch: 23 cost time: 15.172932147979736
Epoch: 23, Steps: 131 | Train Loss: 0.0853637 Vali Loss: 0.5614715 Test Loss: 0.3774866
Validation loss decreased (0.564371 --> 0.561472).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.0857482
	speed: 0.3900s/iter; left time: 1340.9844s
Epoch: 24 cost time: 20.617220163345337
Epoch: 24, Steps: 131 | Train Loss: 0.0845000 Vali Loss: 0.5591117 Test Loss: 0.3760199
Validation loss decreased (0.561472 --> 0.559112).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.0820152
	speed: 0.4233s/iter; left time: 1399.7691s
Epoch: 25 cost time: 20.092498302459717
Epoch: 25, Steps: 131 | Train Loss: 0.0837558 Vali Loss: 0.5579152 Test Loss: 0.3745755
Validation loss decreased (0.559112 --> 0.557915).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.0778639
	speed: 0.4456s/iter; left time: 1415.2452s
Epoch: 26 cost time: 21.423269748687744
Epoch: 26, Steps: 131 | Train Loss: 0.0830317 Vali Loss: 0.5552131 Test Loss: 0.3731960
Validation loss decreased (0.557915 --> 0.555213).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.0812086
	speed: 0.4560s/iter; left time: 1388.4607s
Epoch: 27 cost time: 21.91176962852478
Epoch: 27, Steps: 131 | Train Loss: 0.0824595 Vali Loss: 0.5535750 Test Loss: 0.3719850
Validation loss decreased (0.555213 --> 0.553575).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.0835131
	speed: 0.4354s/iter; left time: 1268.8999s
Epoch: 28 cost time: 19.970246076583862
Epoch: 28, Steps: 131 | Train Loss: 0.0819425 Vali Loss: 0.5529197 Test Loss: 0.3706933
Validation loss decreased (0.553575 --> 0.552920).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.0799586
	speed: 0.4045s/iter; left time: 1125.7829s
Epoch: 29 cost time: 17.90891695022583
Epoch: 29, Steps: 131 | Train Loss: 0.0814736 Vali Loss: 0.5525600 Test Loss: 0.3696229
Validation loss decreased (0.552920 --> 0.552560).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.0778386
	speed: 0.4007s/iter; left time: 1062.5500s
Epoch: 30 cost time: 20.047693490982056
Epoch: 30, Steps: 131 | Train Loss: 0.0810181 Vali Loss: 0.5511897 Test Loss: 0.3686062
Validation loss decreased (0.552560 --> 0.551190).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.0841326
	speed: 0.4114s/iter; left time: 1037.0560s
Epoch: 31 cost time: 19.974112510681152
Epoch: 31, Steps: 131 | Train Loss: 0.0806098 Vali Loss: 0.5496438 Test Loss: 0.3677811
Validation loss decreased (0.551190 --> 0.549644).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.0766470
	speed: 0.4132s/iter; left time: 987.5352s
Epoch: 32 cost time: 20.048003435134888
Epoch: 32, Steps: 131 | Train Loss: 0.0802898 Vali Loss: 0.5490333 Test Loss: 0.3669575
Validation loss decreased (0.549644 --> 0.549033).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.0772992
	speed: 0.4130s/iter; left time: 933.0587s
Epoch: 33 cost time: 19.813847064971924
Epoch: 33, Steps: 131 | Train Loss: 0.0799915 Vali Loss: 0.5479416 Test Loss: 0.3660570
Validation loss decreased (0.549033 --> 0.547942).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.0768236
	speed: 0.3547s/iter; left time: 754.7693s
Epoch: 34 cost time: 18.617297649383545
Epoch: 34, Steps: 131 | Train Loss: 0.0797149 Vali Loss: 0.5465820 Test Loss: 0.3652428
Validation loss decreased (0.547942 --> 0.546582).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.0816124
	speed: 0.4264s/iter; left time: 851.5115s
Epoch: 35 cost time: 21.102144956588745
Epoch: 35, Steps: 131 | Train Loss: 0.0794305 Vali Loss: 0.5468280 Test Loss: 0.3644161
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.0747524
	speed: 0.4349s/iter; left time: 811.4897s
Epoch: 36 cost time: 20.535186052322388
Epoch: 36, Steps: 131 | Train Loss: 0.0792033 Vali Loss: 0.5455300 Test Loss: 0.3636256
Validation loss decreased (0.546582 --> 0.545530).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.0789083
	speed: 0.4347s/iter; left time: 754.2828s
Epoch: 37 cost time: 20.528225421905518
Epoch: 37, Steps: 131 | Train Loss: 0.0790135 Vali Loss: 0.5449201 Test Loss: 0.3629827
Validation loss decreased (0.545530 --> 0.544920).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.0804182
	speed: 0.3712s/iter; left time: 595.4757s
Epoch: 38 cost time: 17.23395276069641
Epoch: 38, Steps: 131 | Train Loss: 0.0788058 Vali Loss: 0.5437685 Test Loss: 0.3622764
Validation loss decreased (0.544920 --> 0.543768).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.0770727
	speed: 0.3720s/iter; left time: 547.9451s
Epoch: 39 cost time: 18.48992657661438
Epoch: 39, Steps: 131 | Train Loss: 0.0786142 Vali Loss: 0.5431784 Test Loss: 0.3618843
Validation loss decreased (0.543768 --> 0.543178).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.0779830
	speed: 0.3707s/iter; left time: 497.5393s
Epoch: 40 cost time: 17.442617177963257
Epoch: 40, Steps: 131 | Train Loss: 0.0784383 Vali Loss: 0.5430213 Test Loss: 0.3612733
Validation loss decreased (0.543178 --> 0.543021).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.0806328
	speed: 0.3734s/iter; left time: 452.1274s
Epoch: 41 cost time: 18.418322324752808
Epoch: 41, Steps: 131 | Train Loss: 0.0782883 Vali Loss: 0.5418260 Test Loss: 0.3607231
Validation loss decreased (0.543021 --> 0.541826).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.0770786
	speed: 0.3982s/iter; left time: 430.0217s
Epoch: 42 cost time: 18.931888341903687
Epoch: 42, Steps: 131 | Train Loss: 0.0781526 Vali Loss: 0.5416893 Test Loss: 0.3601737
Validation loss decreased (0.541826 --> 0.541689).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.0807621
	speed: 0.4010s/iter; left time: 380.5133s
Epoch: 43 cost time: 19.600249767303467
Epoch: 43, Steps: 131 | Train Loss: 0.0780255 Vali Loss: 0.5419549 Test Loss: 0.3597110
EarlyStopping counter: 1 out of 3
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.0791056
	speed: 0.4001s/iter; left time: 327.2541s
Epoch: 44 cost time: 19.189626932144165
Epoch: 44, Steps: 131 | Train Loss: 0.0779426 Vali Loss: 0.5411465 Test Loss: 0.3591940
Validation loss decreased (0.541689 --> 0.541147).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.0766821
	speed: 0.3830s/iter; left time: 263.0888s
Epoch: 45 cost time: 18.85382628440857
Epoch: 45, Steps: 131 | Train Loss: 0.0778105 Vali Loss: 0.5408297 Test Loss: 0.3588529
Validation loss decreased (0.541147 --> 0.540830).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.0817775
	speed: 0.3755s/iter; left time: 208.7522s
Epoch: 46 cost time: 17.648340702056885
Epoch: 46, Steps: 131 | Train Loss: 0.0777085 Vali Loss: 0.5400547 Test Loss: 0.3583770
Validation loss decreased (0.540830 --> 0.540055).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.0762646
	speed: 0.3669s/iter; left time: 155.9530s
Epoch: 47 cost time: 18.307276725769043
Epoch: 47, Steps: 131 | Train Loss: 0.0776149 Vali Loss: 0.5401260 Test Loss: 0.3579685
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.0780093
	speed: 0.3750s/iter; left time: 110.2552s
Epoch: 48 cost time: 17.862070083618164
Epoch: 48, Steps: 131 | Train Loss: 0.0775569 Vali Loss: 0.5391055 Test Loss: 0.3577714
Validation loss decreased (0.540055 --> 0.539105).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.0764811
	speed: 0.3828s/iter; left time: 62.3950s
Epoch: 49 cost time: 19.077526569366455
Epoch: 49, Steps: 131 | Train Loss: 0.0774749 Vali Loss: 0.5396909 Test Loss: 0.3573141
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.0749830
	speed: 0.3933s/iter; left time: 12.5846s
Epoch: 50 cost time: 18.524960041046143
Epoch: 50, Steps: 131 | Train Loss: 0.0773886 Vali Loss: 0.5387334 Test Loss: 0.3568973
Validation loss decreased (0.539105 --> 0.538733).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=122, out_features=154, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  33668096.0
params:  18942.0
Trainable parameters:  18942
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2973486
	speed: 0.1409s/iter; left time: 908.7689s
Epoch: 1 cost time: 18.304850339889526
Epoch: 1, Steps: 131 | Train Loss: 0.3018375 Vali Loss: 0.5182353 Test Loss: 0.3428147
Validation loss decreased (inf --> 0.518235).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3039158
	speed: 0.3529s/iter; left time: 2230.2555s
Epoch: 2 cost time: 17.84227180480957
Epoch: 2, Steps: 131 | Train Loss: 0.2995819 Vali Loss: 0.5152726 Test Loss: 0.3399579
Validation loss decreased (0.518235 --> 0.515273).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3024909
	speed: 0.4057s/iter; left time: 2511.0288s
Epoch: 3 cost time: 19.496665000915527
Epoch: 3, Steps: 131 | Train Loss: 0.2986713 Vali Loss: 0.5155951 Test Loss: 0.3393757
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3193017
	speed: 0.4136s/iter; left time: 2505.3263s
Epoch: 4 cost time: 21.859180212020874
Epoch: 4, Steps: 131 | Train Loss: 0.2982675 Vali Loss: 0.5149529 Test Loss: 0.3390852
Validation loss decreased (0.515273 --> 0.514953).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3018880
	speed: 0.4619s/iter; left time: 2737.4141s
Epoch: 5 cost time: 21.951352834701538
Epoch: 5, Steps: 131 | Train Loss: 0.2979982 Vali Loss: 0.5137473 Test Loss: 0.3396498
Validation loss decreased (0.514953 --> 0.513747).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3028161
	speed: 0.4335s/iter; left time: 2512.7960s
Epoch: 6 cost time: 19.450888872146606
Epoch: 6, Steps: 131 | Train Loss: 0.2978174 Vali Loss: 0.5113287 Test Loss: 0.3392133
Validation loss decreased (0.513747 --> 0.511329).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3247353
	speed: 0.3849s/iter; left time: 2180.6735s
Epoch: 7 cost time: 19.025598287582397
Epoch: 7, Steps: 131 | Train Loss: 0.2976988 Vali Loss: 0.5130870 Test Loss: 0.3384123
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2845255
	speed: 0.3904s/iter; left time: 2160.3898s
Epoch: 8 cost time: 18.53756284713745
Epoch: 8, Steps: 131 | Train Loss: 0.2974960 Vali Loss: 0.5116166 Test Loss: 0.3388725
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2751692
	speed: 0.3733s/iter; left time: 2016.7289s
Epoch: 9 cost time: 17.575600624084473
Epoch: 9, Steps: 131 | Train Loss: 0.2975835 Vali Loss: 0.5134968 Test Loss: 0.3380975
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_720_192_FITS_ETTm1_ftM_sl720_ll48_pl192_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.33907604217529297, mae:0.3688545227050781, rse:0.5543066263198853, corr:[0.5413931  0.55340475 0.5582005  0.5588741  0.5600586  0.5626507
 0.5649042  0.56540823 0.5647526  0.5644144  0.5651365  0.56630045
 0.5668878  0.5664889  0.56550664 0.5645122  0.5636742  0.5627745
 0.5615307  0.5599959  0.5584228  0.5569263  0.5555219  0.5542932
 0.55306935 0.55201924 0.5511695  0.5503286  0.54955196 0.5489525
 0.54880184 0.5493944  0.550496   0.5515758  0.5519516  0.551716
 0.5510967  0.5506601  0.5506518  0.550794   0.55086935 0.5506743
 0.55036587 0.5502265  0.55016077 0.5500126  0.5498319  0.5497299
 0.5497923  0.54998857 0.5501984  0.5501476  0.5497856  0.5492072
 0.5487778  0.54872507 0.5489285  0.5490183  0.548904   0.5485267
 0.54812264 0.5479291  0.5479944  0.5481014  0.54825616 0.548454
 0.5486273  0.5487119  0.5487097  0.5486135  0.5485147  0.5484101
 0.548252   0.54801506 0.5478073  0.54765856 0.5475548  0.54746467
 0.5473318  0.5471381  0.546953   0.5468769  0.5469757  0.5471105
 0.5471688  0.5470038  0.5466491  0.5462226  0.54594016 0.5459429
 0.5461107  0.54624104 0.5462237  0.5461077  0.5460134  0.54598784
 0.5459972  0.5459324  0.5455544  0.5449799  0.54447526 0.54427296
 0.54440373 0.5445976  0.5446631  0.5445204  0.5441118  0.5436466
 0.5432328  0.5429876  0.5429044  0.5428724  0.542808   0.5426491
 0.54230654 0.5417756  0.5411679  0.5406374  0.5403792  0.5404648
 0.54066765 0.5406861  0.5403661  0.53996    0.5397724  0.53982216
 0.53992486 0.5398828  0.53959626 0.5393098  0.539246   0.539481
 0.53986305 0.5400318  0.5397503  0.53928584 0.539173   0.53950214
 0.5401435  0.5406743  0.5406989  0.54038715 0.54020226 0.5404647
 0.5410439  0.5414298  0.54136235 0.5408456  0.5402479  0.53988796
 0.5399288  0.5403421  0.54073733 0.54078734 0.5404747  0.54013133
 0.539967   0.53994364 0.5399802  0.5397449  0.5393295  0.53891355
 0.5387688  0.5389517  0.53932804 0.53959566 0.53960323 0.5394531
 0.53935    0.53939533 0.53961277 0.5397416  0.53940266 0.53876317
 0.5383384  0.53849643 0.53898716 0.5392454  0.53878045 0.5378468
 0.5370935  0.5370954  0.5376336  0.5382346  0.5384932  0.53848594
 0.53848577 0.53886926 0.53952104 0.5401436  0.5406442  0.5410148 ]
