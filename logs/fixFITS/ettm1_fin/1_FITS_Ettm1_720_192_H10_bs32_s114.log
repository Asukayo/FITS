Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTm1_720_192_FITS_ETTm1_ftM_sl720_ll48_pl192_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=90, out_features=114, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4596480.0
params:  10374.0
Trainable parameters:  10374
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3911456
	speed: 0.1231s/iter; left time: 3218.2424s
	iters: 200, epoch: 1 | loss: 0.3050463
	speed: 0.1235s/iter; left time: 3216.6486s
	iters: 300, epoch: 1 | loss: 0.3264586
	speed: 0.1146s/iter; left time: 2974.4784s
	iters: 400, epoch: 1 | loss: 0.2928343
	speed: 0.1238s/iter; left time: 3199.5894s
	iters: 500, epoch: 1 | loss: 0.3054506
	speed: 0.1270s/iter; left time: 3270.7635s
Epoch: 1 cost time: 64.36834979057312
Epoch: 1, Steps: 525 | Train Loss: 0.3437301 Vali Loss: 0.5438204 Test Loss: 0.3401343
Validation loss decreased (inf --> 0.543820).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3367464
	speed: 0.9526s/iter; left time: 24410.4798s
	iters: 200, epoch: 2 | loss: 0.2685224
	speed: 0.1519s/iter; left time: 3877.9065s
	iters: 300, epoch: 2 | loss: 0.2837370
	speed: 0.1538s/iter; left time: 3911.1439s
	iters: 400, epoch: 2 | loss: 0.3096864
	speed: 0.1450s/iter; left time: 3672.2926s
	iters: 500, epoch: 2 | loss: 0.2939735
	speed: 0.1271s/iter; left time: 3206.3920s
Epoch: 2 cost time: 76.73270201683044
Epoch: 2, Steps: 525 | Train Loss: 0.3030470 Vali Loss: 0.5260493 Test Loss: 0.3406381
Validation loss decreased (0.543820 --> 0.526049).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2538237
	speed: 0.8418s/iter; left time: 21130.7757s
	iters: 200, epoch: 3 | loss: 0.2845209
	speed: 0.1186s/iter; left time: 2966.0533s
	iters: 300, epoch: 3 | loss: 0.2765443
	speed: 0.1184s/iter; left time: 2947.4402s
	iters: 400, epoch: 3 | loss: 0.3405495
	speed: 0.1172s/iter; left time: 2906.8554s
	iters: 500, epoch: 3 | loss: 0.3370565
	speed: 0.1134s/iter; left time: 2801.1338s
Epoch: 3 cost time: 62.58558917045593
Epoch: 3, Steps: 525 | Train Loss: 0.3005252 Vali Loss: 0.5211452 Test Loss: 0.3392239
Validation loss decreased (0.526049 --> 0.521145).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3209821
	speed: 0.7657s/iter; left time: 18818.4129s
	iters: 200, epoch: 4 | loss: 0.3081016
	speed: 0.1215s/iter; left time: 2973.3140s
	iters: 300, epoch: 4 | loss: 0.3231990
	speed: 0.1247s/iter; left time: 3040.5795s
	iters: 400, epoch: 4 | loss: 0.3037803
	speed: 0.1398s/iter; left time: 3393.9955s
	iters: 500, epoch: 4 | loss: 0.2991855
	speed: 0.1371s/iter; left time: 3314.9140s
Epoch: 4 cost time: 68.41452312469482
Epoch: 4, Steps: 525 | Train Loss: 0.2996084 Vali Loss: 0.5182663 Test Loss: 0.3394480
Validation loss decreased (0.521145 --> 0.518266).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3351703
	speed: 0.9138s/iter; left time: 21978.5097s
	iters: 200, epoch: 5 | loss: 0.3324943
	speed: 0.1119s/iter; left time: 2678.9403s
	iters: 300, epoch: 5 | loss: 0.3348543
	speed: 0.1071s/iter; left time: 2554.6549s
	iters: 400, epoch: 5 | loss: 0.3268235
	speed: 0.1152s/iter; left time: 2736.2078s
	iters: 500, epoch: 5 | loss: 0.2850974
	speed: 0.1117s/iter; left time: 2642.4398s
Epoch: 5 cost time: 60.71335029602051
Epoch: 5, Steps: 525 | Train Loss: 0.2991860 Vali Loss: 0.5141839 Test Loss: 0.3397090
Validation loss decreased (0.518266 --> 0.514184).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2666498
	speed: 0.7555s/iter; left time: 17774.8839s
	iters: 200, epoch: 6 | loss: 0.3131057
	speed: 0.0933s/iter; left time: 2186.1754s
	iters: 300, epoch: 6 | loss: 0.3540786
	speed: 0.1068s/iter; left time: 2490.3863s
	iters: 400, epoch: 6 | loss: 0.2762177
	speed: 0.1036s/iter; left time: 2406.0483s
	iters: 500, epoch: 6 | loss: 0.3423865
	speed: 0.1162s/iter; left time: 2687.4496s
Epoch: 6 cost time: 54.66763710975647
Epoch: 6, Steps: 525 | Train Loss: 0.2989463 Vali Loss: 0.5153582 Test Loss: 0.3398089
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2921776
	speed: 0.7933s/iter; left time: 18245.9305s
	iters: 200, epoch: 7 | loss: 0.2539789
	speed: 0.1267s/iter; left time: 2900.8874s
	iters: 300, epoch: 7 | loss: 0.2883750
	speed: 0.1303s/iter; left time: 2971.2207s
	iters: 400, epoch: 7 | loss: 0.2683041
	speed: 0.1289s/iter; left time: 2926.4613s
	iters: 500, epoch: 7 | loss: 0.2432687
	speed: 0.1172s/iter; left time: 2649.1727s
Epoch: 7 cost time: 66.75610852241516
Epoch: 7, Steps: 525 | Train Loss: 0.2987706 Vali Loss: 0.5133717 Test Loss: 0.3393666
Validation loss decreased (0.514184 --> 0.513372).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2900501
	speed: 0.7704s/iter; left time: 17315.0749s
	iters: 200, epoch: 8 | loss: 0.2985250
	speed: 0.1083s/iter; left time: 2423.4968s
	iters: 300, epoch: 8 | loss: 0.2801991
	speed: 0.1058s/iter; left time: 2357.0576s
	iters: 400, epoch: 8 | loss: 0.2661242
	speed: 0.1213s/iter; left time: 2690.5966s
	iters: 500, epoch: 8 | loss: 0.2878084
	speed: 0.1231s/iter; left time: 2717.7107s
Epoch: 8 cost time: 60.69682025909424
Epoch: 8, Steps: 525 | Train Loss: 0.2986010 Vali Loss: 0.5147880 Test Loss: 0.3385942
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3055269
	speed: 0.8137s/iter; left time: 17861.0812s
	iters: 200, epoch: 9 | loss: 0.3333533
	speed: 0.1247s/iter; left time: 2725.1596s
	iters: 300, epoch: 9 | loss: 0.2379584
	speed: 0.1188s/iter; left time: 2584.2092s
	iters: 400, epoch: 9 | loss: 0.2688687
	speed: 0.1365s/iter; left time: 2955.7106s
	iters: 500, epoch: 9 | loss: 0.3065265
	speed: 0.1363s/iter; left time: 2936.5057s
Epoch: 9 cost time: 68.50463366508484
Epoch: 9, Steps: 525 | Train Loss: 0.2985118 Vali Loss: 0.5159425 Test Loss: 0.3383612
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2734949
	speed: 0.8611s/iter; left time: 18450.8764s
	iters: 200, epoch: 10 | loss: 0.3063202
	speed: 0.1132s/iter; left time: 2414.5858s
	iters: 300, epoch: 10 | loss: 0.2765431
	speed: 0.1114s/iter; left time: 2364.5125s
	iters: 400, epoch: 10 | loss: 0.3436371
	speed: 0.1295s/iter; left time: 2735.6718s
	iters: 500, epoch: 10 | loss: 0.3150146
	speed: 0.1244s/iter; left time: 2614.9117s
Epoch: 10 cost time: 62.616530895233154
Epoch: 10, Steps: 525 | Train Loss: 0.2983636 Vali Loss: 0.5147850 Test Loss: 0.3381097
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_720_192_FITS_ETTm1_ftM_sl720_ll48_pl192_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.33945637941360474, mae:0.3692582845687866, rse:0.5546174049377441, corr:[0.542495   0.55167705 0.55747914 0.5594373  0.55967396 0.5600701
 0.56110203 0.5625163  0.56385106 0.5647061  0.5650523  0.5649895
 0.5647797  0.56446713 0.56394017 0.5631184  0.56209034 0.56104374
 0.560072   0.559204   0.5583868  0.5574151  0.55615705 0.554761
 0.55323505 0.55189884 0.5509921  0.55052143 0.5505285  0.55082256
 0.55113405 0.55131406 0.55122626 0.5510435  0.55082804 0.5508082
 0.55083615 0.550844   0.5507259  0.5503654  0.5499592  0.54962075
 0.54945374 0.5495371  0.5496898  0.5497507  0.54974854 0.549693
 0.549566   0.54939383 0.54928803 0.5491752  0.5489927  0.5485995
 0.54809445 0.5476692  0.54752266 0.5476419  0.54797846 0.5482311
 0.54824835 0.547991   0.547561   0.5471102  0.5469809  0.5473002
 0.5479044  0.5485323  0.54899526 0.5491647  0.5490765  0.5487958
 0.54846525 0.54823613 0.548211   0.54829353 0.54836    0.5483459
 0.54822695 0.5480329  0.5478217  0.54762894 0.5474906  0.5473567
 0.54722065 0.54703945 0.5468365  0.5466055  0.5464184  0.5463952
 0.546521   0.54670703 0.54685587 0.5469061  0.5468326  0.54662853
 0.5463772  0.546189   0.5459651  0.5457038  0.5454069  0.5450979
 0.5448301  0.5445919  0.544463   0.54451174 0.5446234  0.54477537
 0.54487115 0.54489267 0.5448291  0.54466254 0.5443953  0.54405403
 0.543659   0.5432624  0.5429217  0.54265493 0.5425149  0.5425394
 0.5426346  0.54262775 0.54232556 0.54174554 0.5409826  0.5401638
 0.5394975  0.53921485 0.5393322  0.539751   0.5401767  0.5403894
 0.5403667  0.5401587  0.53982145 0.539553   0.5395309  0.53963006
 0.5398303  0.54008126 0.54025614 0.5403968  0.5405841  0.54084873
 0.54110247 0.54112375 0.5408341  0.54021657 0.53944415 0.5386936
 0.53819585 0.5381914  0.53860456 0.5392237  0.5397761  0.54015255
 0.54026026 0.54007035 0.5397742  0.53945696 0.5393395  0.5394275
 0.53967613 0.53993946 0.5401337  0.5402289  0.54027104 0.54032016
 0.5403627  0.54033047 0.54028696 0.54025173 0.540122   0.539913
 0.5397063  0.5395905  0.5395793  0.5396057  0.53949434 0.53919804
 0.538713   0.5381786  0.53771293 0.5375657  0.5377966  0.5382337
 0.5385804  0.53889275 0.5394183  0.5403415  0.54135877 0.5414983 ]
