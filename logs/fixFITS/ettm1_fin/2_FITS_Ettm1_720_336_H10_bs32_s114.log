Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_336', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTm1_720_336_FITS_ETTm1_ftM_sl720_ll48_pl336_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=90, out_features=132, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  5322240.0
params:  12012.0
Trainable parameters:  12012
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4358259
	speed: 0.1224s/iter; left time: 3189.0549s
	iters: 200, epoch: 1 | loss: 0.3554586
	speed: 0.1276s/iter; left time: 3311.8712s
	iters: 300, epoch: 1 | loss: 0.3182917
	speed: 0.1276s/iter; left time: 3297.9423s
	iters: 400, epoch: 1 | loss: 0.2413451
	speed: 0.1268s/iter; left time: 3265.4844s
	iters: 500, epoch: 1 | loss: 0.2082703
	speed: 0.1321s/iter; left time: 3387.7359s
Epoch: 1 cost time: 66.25540590286255
Epoch: 1, Steps: 523 | Train Loss: 0.3431083 Vali Loss: 0.8188354 Test Loss: 0.4756249
Validation loss decreased (inf --> 0.818835).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2167819
	speed: 0.7851s/iter; left time: 20042.9630s
	iters: 200, epoch: 2 | loss: 0.1829896
	speed: 0.1162s/iter; left time: 2954.7861s
	iters: 300, epoch: 2 | loss: 0.1797606
	speed: 0.1274s/iter; left time: 3227.8621s
	iters: 400, epoch: 2 | loss: 0.1739565
	speed: 0.1104s/iter; left time: 2784.1557s
	iters: 500, epoch: 2 | loss: 0.1696652
	speed: 0.1054s/iter; left time: 2648.5642s
Epoch: 2 cost time: 60.411785364151
Epoch: 2, Steps: 523 | Train Loss: 0.1814596 Vali Loss: 0.7242860 Test Loss: 0.4097535
Validation loss decreased (0.818835 --> 0.724286).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1411185
	speed: 0.7601s/iter; left time: 19007.5159s
	iters: 200, epoch: 3 | loss: 0.1345308
	speed: 0.1209s/iter; left time: 3010.4591s
	iters: 300, epoch: 3 | loss: 0.1461171
	speed: 0.1060s/iter; left time: 2628.8663s
	iters: 400, epoch: 3 | loss: 0.1338465
	speed: 0.1144s/iter; left time: 2827.2060s
	iters: 500, epoch: 3 | loss: 0.1266754
	speed: 0.1111s/iter; left time: 2734.1110s
Epoch: 3 cost time: 61.23124599456787
Epoch: 3, Steps: 523 | Train Loss: 0.1456036 Vali Loss: 0.6941160 Test Loss: 0.3848868
Validation loss decreased (0.724286 --> 0.694116).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1564873
	speed: 0.5303s/iter; left time: 12983.1643s
	iters: 200, epoch: 4 | loss: 0.1336147
	speed: 0.1134s/iter; left time: 2764.0452s
	iters: 300, epoch: 4 | loss: 0.1291761
	speed: 0.1154s/iter; left time: 2801.7774s
	iters: 400, epoch: 4 | loss: 0.1275621
	speed: 0.1029s/iter; left time: 2488.4851s
	iters: 500, epoch: 4 | loss: 0.1368416
	speed: 0.1038s/iter; left time: 2498.9862s
Epoch: 4 cost time: 53.88780331611633
Epoch: 4, Steps: 523 | Train Loss: 0.1324902 Vali Loss: 0.6800667 Test Loss: 0.3744833
Validation loss decreased (0.694116 --> 0.680067).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1246837
	speed: 0.7149s/iter; left time: 17129.2152s
	iters: 200, epoch: 5 | loss: 0.1208643
	speed: 0.1071s/iter; left time: 2554.4123s
	iters: 300, epoch: 5 | loss: 0.1334222
	speed: 0.1176s/iter; left time: 2794.5492s
	iters: 400, epoch: 5 | loss: 0.1264090
	speed: 0.1082s/iter; left time: 2560.7320s
	iters: 500, epoch: 5 | loss: 0.1293998
	speed: 0.1047s/iter; left time: 2465.6060s
Epoch: 5 cost time: 57.87862730026245
Epoch: 5, Steps: 523 | Train Loss: 0.1268949 Vali Loss: 0.6744130 Test Loss: 0.3707699
Validation loss decreased (0.680067 --> 0.674413).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1198613
	speed: 0.7021s/iter; left time: 16454.7796s
	iters: 200, epoch: 6 | loss: 0.1070897
	speed: 0.1216s/iter; left time: 2836.6323s
	iters: 300, epoch: 6 | loss: 0.1299449
	speed: 0.0928s/iter; left time: 2156.8906s
	iters: 400, epoch: 6 | loss: 0.1192598
	speed: 0.1155s/iter; left time: 2671.6903s
	iters: 500, epoch: 6 | loss: 0.1317454
	speed: 0.1086s/iter; left time: 2502.7732s
Epoch: 6 cost time: 58.73887586593628
Epoch: 6, Steps: 523 | Train Loss: 0.1244214 Vali Loss: 0.6727130 Test Loss: 0.3694959
Validation loss decreased (0.674413 --> 0.672713).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1209440
	speed: 0.9086s/iter; left time: 20817.9505s
	iters: 200, epoch: 7 | loss: 0.1282416
	speed: 0.1381s/iter; left time: 3150.3860s
	iters: 300, epoch: 7 | loss: 0.1298838
	speed: 0.1282s/iter; left time: 2911.0755s
	iters: 400, epoch: 7 | loss: 0.1053042
	speed: 0.1300s/iter; left time: 2938.9579s
	iters: 500, epoch: 7 | loss: 0.1160409
	speed: 0.1121s/iter; left time: 2524.0261s
Epoch: 7 cost time: 69.9404284954071
Epoch: 7, Steps: 523 | Train Loss: 0.1233471 Vali Loss: 0.6774334 Test Loss: 0.3698066
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1087305
	speed: 0.7545s/iter; left time: 16893.9250s
	iters: 200, epoch: 8 | loss: 0.1251331
	speed: 0.1087s/iter; left time: 2422.5645s
	iters: 300, epoch: 8 | loss: 0.1294245
	speed: 0.1000s/iter; left time: 2219.2518s
	iters: 400, epoch: 8 | loss: 0.1157269
	speed: 0.1040s/iter; left time: 2298.1201s
	iters: 500, epoch: 8 | loss: 0.1251443
	speed: 0.1162s/iter; left time: 2554.9261s
Epoch: 8 cost time: 58.56083965301514
Epoch: 8, Steps: 523 | Train Loss: 0.1229579 Vali Loss: 0.6756428 Test Loss: 0.3706669
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1209043
	speed: 0.7400s/iter; left time: 16182.1088s
	iters: 200, epoch: 9 | loss: 0.1248877
	speed: 0.1059s/iter; left time: 2304.6274s
	iters: 300, epoch: 9 | loss: 0.1256101
	speed: 0.0961s/iter; left time: 2081.5385s
	iters: 400, epoch: 9 | loss: 0.1179211
	speed: 0.0649s/iter; left time: 1400.6422s
	iters: 500, epoch: 9 | loss: 0.1257834
	speed: 0.0751s/iter; left time: 1612.1095s
Epoch: 9 cost time: 49.802985191345215
Epoch: 9, Steps: 523 | Train Loss: 0.1227920 Vali Loss: 0.6722864 Test Loss: 0.3712344
Validation loss decreased (0.672713 --> 0.672286).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1293516
	speed: 0.4585s/iter; left time: 9786.0248s
	iters: 200, epoch: 10 | loss: 0.1240704
	speed: 0.1140s/iter; left time: 2421.6526s
	iters: 300, epoch: 10 | loss: 0.1313095
	speed: 0.1094s/iter; left time: 2313.3663s
	iters: 400, epoch: 10 | loss: 0.1231938
	speed: 0.1186s/iter; left time: 2494.9077s
	iters: 500, epoch: 10 | loss: 0.1368267
	speed: 0.1098s/iter; left time: 2298.6907s
Epoch: 10 cost time: 60.90375280380249
Epoch: 10, Steps: 523 | Train Loss: 0.1227498 Vali Loss: 0.6741330 Test Loss: 0.3722579
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1380602
	speed: 0.7128s/iter; left time: 14841.6922s
	iters: 200, epoch: 11 | loss: 0.1213377
	speed: 0.1101s/iter; left time: 2281.1632s
	iters: 300, epoch: 11 | loss: 0.1197560
	speed: 0.1113s/iter; left time: 2295.2327s
	iters: 400, epoch: 11 | loss: 0.1174912
	speed: 0.1087s/iter; left time: 2230.0681s
	iters: 500, epoch: 11 | loss: 0.1232642
	speed: 0.1015s/iter; left time: 2072.5369s
Epoch: 11 cost time: 58.71674036979675
Epoch: 11, Steps: 523 | Train Loss: 0.1227537 Vali Loss: 0.6744716 Test Loss: 0.3716855
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1330523
	speed: 0.7135s/iter; left time: 14482.4428s
	iters: 200, epoch: 12 | loss: 0.1339781
	speed: 0.1136s/iter; left time: 2293.9301s
	iters: 300, epoch: 12 | loss: 0.1173799
	speed: 0.1130s/iter; left time: 2270.2915s
	iters: 400, epoch: 12 | loss: 0.1268569
	speed: 0.1143s/iter; left time: 2284.9095s
	iters: 500, epoch: 12 | loss: 0.1283221
	speed: 0.0958s/iter; left time: 1906.4145s
Epoch: 12 cost time: 59.27068829536438
Epoch: 12, Steps: 523 | Train Loss: 0.1227413 Vali Loss: 0.6742239 Test Loss: 0.3709776
EarlyStopping counter: 3 out of 3
Early stopping
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=90, out_features=132, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  5322240.0
params:  12012.0
Trainable parameters:  12012
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4279825
	speed: 0.1204s/iter; left time: 3137.6645s
	iters: 200, epoch: 1 | loss: 0.3022644
	speed: 0.1216s/iter; left time: 3154.7671s
	iters: 300, epoch: 1 | loss: 0.3265944
	speed: 0.1137s/iter; left time: 2939.9276s
	iters: 400, epoch: 1 | loss: 0.3234552
	speed: 0.0585s/iter; left time: 1507.2035s
	iters: 500, epoch: 1 | loss: 0.3515973
	speed: 0.0726s/iter; left time: 1862.9825s
Epoch: 1 cost time: 51.5869836807251
Epoch: 1, Steps: 523 | Train Loss: 0.3395015 Vali Loss: 0.6616642 Test Loss: 0.3683758
Validation loss decreased (inf --> 0.661664).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3566501
	speed: 0.6651s/iter; left time: 16977.5497s
	iters: 200, epoch: 2 | loss: 0.3731855
	speed: 0.0955s/iter; left time: 2427.5854s
	iters: 300, epoch: 2 | loss: 0.2824833
	speed: 0.1110s/iter; left time: 2810.9541s
	iters: 400, epoch: 2 | loss: 0.3213190
	speed: 0.1058s/iter; left time: 2668.8945s
	iters: 500, epoch: 2 | loss: 0.3219693
	speed: 0.1096s/iter; left time: 2753.4375s
Epoch: 2 cost time: 55.71788048744202
Epoch: 2, Steps: 523 | Train Loss: 0.3381386 Vali Loss: 0.6576447 Test Loss: 0.3676171
Validation loss decreased (0.661664 --> 0.657645).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4455946
	speed: 0.7028s/iter; left time: 17573.6762s
	iters: 200, epoch: 3 | loss: 0.3376643
	speed: 0.1012s/iter; left time: 2519.4306s
	iters: 300, epoch: 3 | loss: 0.3183590
	speed: 0.1130s/iter; left time: 2802.2905s
	iters: 400, epoch: 3 | loss: 0.3429417
	speed: 0.1084s/iter; left time: 2678.6553s
	iters: 500, epoch: 3 | loss: 0.3480403
	speed: 0.1061s/iter; left time: 2610.2383s
Epoch: 3 cost time: 58.06804347038269
Epoch: 3, Steps: 523 | Train Loss: 0.3377418 Vali Loss: 0.6563592 Test Loss: 0.3672538
Validation loss decreased (0.657645 --> 0.656359).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3645476
	speed: 0.6566s/iter; left time: 16074.5357s
	iters: 200, epoch: 4 | loss: 0.4016294
	speed: 0.0985s/iter; left time: 2402.3394s
	iters: 300, epoch: 4 | loss: 0.4131221
	speed: 0.0867s/iter; left time: 2105.5783s
	iters: 400, epoch: 4 | loss: 0.3200012
	speed: 0.0997s/iter; left time: 2410.5172s
	iters: 500, epoch: 4 | loss: 0.3022592
	speed: 0.1002s/iter; left time: 2411.8368s
Epoch: 4 cost time: 50.754029989242554
Epoch: 4, Steps: 523 | Train Loss: 0.3374231 Vali Loss: 0.6587882 Test Loss: 0.3670225
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3207341
	speed: 0.6053s/iter; left time: 14502.3146s
	iters: 200, epoch: 5 | loss: 0.3692125
	speed: 0.0699s/iter; left time: 1667.2581s
	iters: 300, epoch: 5 | loss: 0.3347164
	speed: 0.0703s/iter; left time: 1669.2245s
	iters: 400, epoch: 5 | loss: 0.3418130
	speed: 0.0838s/iter; left time: 1983.5393s
	iters: 500, epoch: 5 | loss: 0.3195610
	speed: 0.0840s/iter; left time: 1979.7116s
Epoch: 5 cost time: 42.54600501060486
Epoch: 5, Steps: 523 | Train Loss: 0.3373231 Vali Loss: 0.6554054 Test Loss: 0.3673761
Validation loss decreased (0.656359 --> 0.655405).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3577876
	speed: 0.7208s/iter; left time: 16891.9563s
	iters: 200, epoch: 6 | loss: 0.3330056
	speed: 0.1118s/iter; left time: 2608.4115s
	iters: 300, epoch: 6 | loss: 0.3877409
	speed: 0.1050s/iter; left time: 2440.5304s
	iters: 400, epoch: 6 | loss: 0.3544089
	speed: 0.1237s/iter; left time: 2861.7488s
	iters: 500, epoch: 6 | loss: 0.3329440
	speed: 0.1208s/iter; left time: 2782.6205s
Epoch: 6 cost time: 60.29615664482117
Epoch: 6, Steps: 523 | Train Loss: 0.3371782 Vali Loss: 0.6566780 Test Loss: 0.3671308
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4000076
	speed: 0.7819s/iter; left time: 17915.8590s
	iters: 200, epoch: 7 | loss: 0.3490939
	speed: 0.1099s/iter; left time: 2506.6653s
	iters: 300, epoch: 7 | loss: 0.3176519
	speed: 0.1032s/iter; left time: 2343.4486s
	iters: 400, epoch: 7 | loss: 0.3351622
	speed: 0.1026s/iter; left time: 2320.3157s
	iters: 500, epoch: 7 | loss: 0.3583854
	speed: 0.0932s/iter; left time: 2097.4352s
Epoch: 7 cost time: 56.10797905921936
Epoch: 7, Steps: 523 | Train Loss: 0.3371117 Vali Loss: 0.6541567 Test Loss: 0.3678619
Validation loss decreased (0.655405 --> 0.654157).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3705797
	speed: 0.6254s/iter; left time: 14003.0530s
	iters: 200, epoch: 8 | loss: 0.2804200
	speed: 0.0966s/iter; left time: 2153.4342s
	iters: 300, epoch: 8 | loss: 0.3333426
	speed: 0.1010s/iter; left time: 2241.7907s
	iters: 400, epoch: 8 | loss: 0.3215079
	speed: 0.0844s/iter; left time: 1864.1164s
	iters: 500, epoch: 8 | loss: 0.2833874
	speed: 0.0859s/iter; left time: 1887.9221s
Epoch: 8 cost time: 48.220152378082275
Epoch: 8, Steps: 523 | Train Loss: 0.3370999 Vali Loss: 0.6540465 Test Loss: 0.3674799
Validation loss decreased (0.654157 --> 0.654047).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3054726
	speed: 0.6502s/iter; left time: 14218.3911s
	iters: 200, epoch: 9 | loss: 0.3085064
	speed: 0.1112s/iter; left time: 2420.0099s
	iters: 300, epoch: 9 | loss: 0.3178614
	speed: 0.0790s/iter; left time: 1711.2779s
	iters: 400, epoch: 9 | loss: 0.3248761
	speed: 0.0913s/iter; left time: 1968.1228s
	iters: 500, epoch: 9 | loss: 0.4039586
	speed: 0.0683s/iter; left time: 1465.4293s
Epoch: 9 cost time: 48.000789165496826
Epoch: 9, Steps: 523 | Train Loss: 0.3370501 Vali Loss: 0.6550742 Test Loss: 0.3672205
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3535541
	speed: 0.6037s/iter; left time: 12885.2209s
	iters: 200, epoch: 10 | loss: 0.3155451
	speed: 0.1044s/iter; left time: 2218.8223s
	iters: 300, epoch: 10 | loss: 0.3699248
	speed: 0.0949s/iter; left time: 2005.6309s
	iters: 400, epoch: 10 | loss: 0.3590877
	speed: 0.0930s/iter; left time: 1957.3246s
	iters: 500, epoch: 10 | loss: 0.3413016
	speed: 0.1048s/iter; left time: 2194.3660s
Epoch: 10 cost time: 53.272727251052856
Epoch: 10, Steps: 523 | Train Loss: 0.3369433 Vali Loss: 0.6538216 Test Loss: 0.3674324
Validation loss decreased (0.654047 --> 0.653822).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3468238
	speed: 0.6312s/iter; left time: 13143.2088s
	iters: 200, epoch: 11 | loss: 0.3131454
	speed: 0.1002s/iter; left time: 2075.9938s
	iters: 300, epoch: 11 | loss: 0.3378524
	speed: 0.0945s/iter; left time: 1948.0498s
	iters: 400, epoch: 11 | loss: 0.3945211
	speed: 0.0939s/iter; left time: 1927.7530s
	iters: 500, epoch: 11 | loss: 0.3192714
	speed: 0.1006s/iter; left time: 2053.8405s
Epoch: 11 cost time: 51.8914589881897
Epoch: 11, Steps: 523 | Train Loss: 0.3368010 Vali Loss: 0.6547587 Test Loss: 0.3673364
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3091405
	speed: 0.6703s/iter; left time: 13605.9066s
	iters: 200, epoch: 12 | loss: 0.3706411
	speed: 0.1004s/iter; left time: 2028.1440s
	iters: 300, epoch: 12 | loss: 0.3804248
	speed: 0.1006s/iter; left time: 2022.8359s
	iters: 400, epoch: 12 | loss: 0.3152575
	speed: 0.1085s/iter; left time: 2169.8927s
	iters: 500, epoch: 12 | loss: 0.3428231
	speed: 0.1122s/iter; left time: 2232.9202s
Epoch: 12 cost time: 56.57940363883972
Epoch: 12, Steps: 523 | Train Loss: 0.3368353 Vali Loss: 0.6528990 Test Loss: 0.3677233
Validation loss decreased (0.653822 --> 0.652899).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3533460
	speed: 0.8027s/iter; left time: 15873.5947s
	iters: 200, epoch: 13 | loss: 0.3412454
	speed: 0.1214s/iter; left time: 2389.4287s
	iters: 300, epoch: 13 | loss: 0.3221018
	speed: 0.0794s/iter; left time: 1554.1654s
	iters: 400, epoch: 13 | loss: 0.3711438
	speed: 0.0752s/iter; left time: 1464.6616s
	iters: 500, epoch: 13 | loss: 0.3082229
	speed: 0.0910s/iter; left time: 1762.7274s
Epoch: 13 cost time: 52.64882183074951
Epoch: 13, Steps: 523 | Train Loss: 0.3367661 Vali Loss: 0.6551836 Test Loss: 0.3672944
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3597765
	speed: 0.6436s/iter; left time: 12390.4699s
	iters: 200, epoch: 14 | loss: 0.2887449
	speed: 0.0917s/iter; left time: 1755.4046s
	iters: 300, epoch: 14 | loss: 0.3133414
	speed: 0.0900s/iter; left time: 1714.8975s
	iters: 400, epoch: 14 | loss: 0.2945644
	speed: 0.0976s/iter; left time: 1849.4851s
	iters: 500, epoch: 14 | loss: 0.3510593
	speed: 0.1043s/iter; left time: 1965.4629s
Epoch: 14 cost time: 50.78533935546875
Epoch: 14, Steps: 523 | Train Loss: 0.3367890 Vali Loss: 0.6567906 Test Loss: 0.3669636
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2956158
	speed: 0.6687s/iter; left time: 12523.4642s
	iters: 200, epoch: 15 | loss: 0.3816482
	speed: 0.0934s/iter; left time: 1740.2915s
	iters: 300, epoch: 15 | loss: 0.2936621
	speed: 0.0917s/iter; left time: 1698.1972s
	iters: 400, epoch: 15 | loss: 0.3440987
	speed: 0.0950s/iter; left time: 1751.3776s
	iters: 500, epoch: 15 | loss: 0.2985604
	speed: 0.0916s/iter; left time: 1678.7970s
Epoch: 15 cost time: 51.0429744720459
Epoch: 15, Steps: 523 | Train Loss: 0.3367704 Vali Loss: 0.6564537 Test Loss: 0.3672341
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_720_336_FITS_ETTm1_ftM_sl720_ll48_pl336_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.36763012409210205, mae:0.3857811987400055, rse:0.5769708752632141, corr:[0.5393423  0.54771733 0.5521356  0.5532296  0.553194   0.5537171
 0.5551173  0.5569436  0.558515   0.5593109  0.5594167  0.55912346
 0.5588892  0.55881745 0.55870575 0.5582913  0.5574881  0.5563628
 0.55500084 0.55358064 0.5522611  0.5510092  0.54973286 0.54848236
 0.54707754 0.5456922  0.5445057  0.5436234  0.5432874  0.5435346
 0.5442238  0.5452001  0.5461379  0.5469446  0.5474342  0.54774237
 0.5477298  0.547475   0.5470526  0.5464605  0.5459365  0.54557157
 0.545433   0.5455485  0.54568505 0.545672   0.54556304 0.54539555
 0.54518044 0.5449524  0.5448581  0.5448668  0.5449255  0.5448274
 0.54458964 0.5442875  0.5440206  0.54381275 0.5437232  0.54361457
 0.5434375  0.54319304 0.5429054  0.5425677  0.54234385 0.54230255
 0.5423669  0.54243845 0.5424603  0.5423991  0.5423381  0.54233265
 0.54239476 0.5425131  0.54266256 0.542715   0.5425577  0.5422097
 0.5417633  0.5413676  0.5411415  0.5411035  0.54121125 0.5413153
 0.54134935 0.54124326 0.5410505  0.54082096 0.5406646  0.5407186
 0.54095423 0.5412547  0.54147947 0.54153377 0.541377   0.541008
 0.54052895 0.5401066  0.53967524 0.5392881  0.53898376 0.5387921
 0.53873205 0.5387222  0.5387867  0.538927   0.53897583 0.5389148
 0.53866196 0.53827584 0.53783077 0.53737813 0.5369768  0.5366759
 0.5364712  0.5363449  0.53626806 0.5361851  0.53608257 0.53599614
 0.5358805  0.5356843  0.53533876 0.53495187 0.53462124 0.53439
 0.53431195 0.5344504  0.5347245  0.5350668  0.53530735 0.53537923
 0.53536874 0.53534186 0.53529274 0.535273   0.53533113 0.5352966
 0.5351606  0.5349469  0.53462636 0.53432584 0.5341776  0.5342401
 0.53445685 0.5346298  0.5346854  0.534573   0.53436786 0.53410274
 0.5338591  0.5337885  0.53387743 0.53405994 0.5342111  0.5343291
 0.5343585  0.53425616 0.53412735 0.53396004 0.5338892  0.5339203
 0.5340548  0.5342239  0.534396   0.53455776 0.5347269  0.53493
 0.5350994  0.53515214 0.5351395  0.5350915  0.5349773  0.5348581
 0.5348138  0.53490543 0.5351343  0.5354572  0.535754   0.53595704
 0.53598756 0.53584015 0.53552014 0.5352047  0.53503114 0.53506005
 0.53530484 0.535757   0.53633344 0.53687924 0.53725564 0.537397
 0.5372361  0.53685266 0.536214   0.5353611  0.53444815 0.533667
 0.5330805  0.53270274 0.5324602  0.5322731  0.53201824 0.53159904
 0.53100103 0.5302531  0.5294155  0.5286076  0.52787435 0.5271898
 0.52648866 0.52577794 0.52506036 0.52437955 0.52371895 0.52319205
 0.5228758  0.5226898  0.52259415 0.5224689  0.5222872  0.5221146
 0.5220807  0.5221352  0.5223199  0.5226218  0.5229445  0.52324307
 0.52349424 0.52369195 0.52382576 0.5238354  0.52376217 0.52367604
 0.5236332  0.5237208  0.5238193  0.5240344  0.5242721  0.5245108
 0.5246658  0.52460474 0.52440774 0.5242133  0.5241462  0.52418256
 0.5242841  0.5244218  0.5245132  0.5245573  0.5244913  0.5243966
 0.5242255  0.5240763  0.5239183  0.5237459  0.5236025  0.52351815
 0.5235099  0.52359277 0.5237079  0.52381253 0.52388895 0.524028
 0.524173   0.5243339  0.52452    0.5247453  0.5249478  0.52502936
 0.52499884 0.52486    0.5246739  0.5245119  0.5244016  0.5243606
 0.5243285  0.52431893 0.52425903 0.52420896 0.5241554  0.52411187
 0.5241345  0.52421564 0.524276   0.5242792  0.5241589  0.5238321
 0.52331716 0.5227548  0.522195   0.5215677  0.52088976 0.5201859
 0.51952714 0.51891124 0.51844746 0.51809675 0.51781696 0.5175652
 0.5172537  0.5168579  0.5164332  0.5160187  0.5156603  0.5153711
 0.5152842  0.515304   0.5153476  0.5153379  0.5152822  0.51510984
 0.5148331  0.51452744 0.5141784  0.5138319  0.5135492  0.51343817
 0.51349396 0.5135984  0.51365644 0.5136061  0.5134236  0.51312953
 0.51280254 0.5126046  0.5125449  0.51258576 0.512555   0.51232564
 0.51195014 0.51156807 0.51145655 0.51177    0.51199085 0.51077706]
