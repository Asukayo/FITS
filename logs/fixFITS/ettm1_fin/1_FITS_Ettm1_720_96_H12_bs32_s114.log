Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTm1_720_96_FITS_ETTm1_ftM_sl720_ll48_pl96_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=106, out_features=120, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  5698560.0
params:  12840.0
Trainable parameters:  12840
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3174731
	speed: 0.1628s/iter; left time: 4273.5476s
	iters: 200, epoch: 1 | loss: 0.2850952
	speed: 0.1479s/iter; left time: 3866.5918s
	iters: 300, epoch: 1 | loss: 0.3682890
	speed: 0.1486s/iter; left time: 3870.9617s
	iters: 400, epoch: 1 | loss: 0.3108735
	speed: 0.1435s/iter; left time: 3723.6336s
	iters: 500, epoch: 1 | loss: 0.3143876
	speed: 0.1432s/iter; left time: 3701.0915s
Epoch: 1 cost time: 78.36280751228333
Epoch: 1, Steps: 527 | Train Loss: 0.2979772 Vali Loss: 0.4147950 Test Loss: 0.3121269
Validation loss decreased (inf --> 0.414795).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2407782
	speed: 1.0066s/iter; left time: 25892.8215s
	iters: 200, epoch: 2 | loss: 0.3089037
	speed: 0.1477s/iter; left time: 3785.4704s
	iters: 300, epoch: 2 | loss: 0.2970586
	speed: 0.1479s/iter; left time: 3775.7417s
	iters: 400, epoch: 2 | loss: 0.2561127
	speed: 0.1474s/iter; left time: 3747.7526s
	iters: 500, epoch: 2 | loss: 0.2799387
	speed: 0.1464s/iter; left time: 3706.5317s
Epoch: 2 cost time: 78.6134421825409
Epoch: 2, Steps: 527 | Train Loss: 0.2669016 Vali Loss: 0.4058580 Test Loss: 0.3107577
Validation loss decreased (0.414795 --> 0.405858).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2767352
	speed: 1.0466s/iter; left time: 26371.6051s
	iters: 200, epoch: 3 | loss: 0.2634404
	speed: 0.1623s/iter; left time: 4074.2518s
	iters: 300, epoch: 3 | loss: 0.3013269
	speed: 0.1637s/iter; left time: 4092.7729s
	iters: 400, epoch: 3 | loss: 0.2397877
	speed: 0.1569s/iter; left time: 3906.8933s
	iters: 500, epoch: 3 | loss: 0.2686453
	speed: 0.1494s/iter; left time: 3705.3409s
Epoch: 3 cost time: 84.34467887878418
Epoch: 3, Steps: 527 | Train Loss: 0.2646161 Vali Loss: 0.3997967 Test Loss: 0.3100744
Validation loss decreased (0.405858 --> 0.399797).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2651494
	speed: 1.0304s/iter; left time: 25420.4115s
	iters: 200, epoch: 4 | loss: 0.3032654
	speed: 0.1472s/iter; left time: 3615.9445s
	iters: 300, epoch: 4 | loss: 0.2515273
	speed: 0.1486s/iter; left time: 3637.1757s
	iters: 400, epoch: 4 | loss: 0.2307779
	speed: 0.1493s/iter; left time: 3639.2076s
	iters: 500, epoch: 4 | loss: 0.2628479
	speed: 0.1481s/iter; left time: 3595.3346s
Epoch: 4 cost time: 79.1499490737915
Epoch: 4, Steps: 527 | Train Loss: 0.2638072 Vali Loss: 0.3980356 Test Loss: 0.3105515
Validation loss decreased (0.399797 --> 0.398036).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2588233
	speed: 1.0489s/iter; left time: 25322.6063s
	iters: 200, epoch: 5 | loss: 0.2768708
	speed: 0.1584s/iter; left time: 3809.3169s
	iters: 300, epoch: 5 | loss: 0.2594573
	speed: 0.1548s/iter; left time: 3705.9299s
	iters: 400, epoch: 5 | loss: 0.2910612
	speed: 0.1576s/iter; left time: 3757.6833s
	iters: 500, epoch: 5 | loss: 0.2837519
	speed: 0.1548s/iter; left time: 3675.0199s
Epoch: 5 cost time: 83.25154066085815
Epoch: 5, Steps: 527 | Train Loss: 0.2633536 Vali Loss: 0.3985147 Test Loss: 0.3101060
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2627288
	speed: 1.0407s/iter; left time: 24578.2886s
	iters: 200, epoch: 6 | loss: 0.2854275
	speed: 0.1371s/iter; left time: 3224.3670s
	iters: 300, epoch: 6 | loss: 0.2376868
	speed: 0.1418s/iter; left time: 3320.8374s
	iters: 400, epoch: 6 | loss: 0.2471758
	speed: 0.1527s/iter; left time: 3559.9338s
	iters: 500, epoch: 6 | loss: 0.2800217
	speed: 0.1585s/iter; left time: 3678.6372s
Epoch: 6 cost time: 78.49220609664917
Epoch: 6, Steps: 527 | Train Loss: 0.2631396 Vali Loss: 0.4001233 Test Loss: 0.3101019
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2932984
	speed: 1.0775s/iter; left time: 24879.4610s
	iters: 200, epoch: 7 | loss: 0.2388270
	speed: 0.1553s/iter; left time: 3570.8774s
	iters: 300, epoch: 7 | loss: 0.3063272
	speed: 0.1527s/iter; left time: 3494.1961s
	iters: 400, epoch: 7 | loss: 0.2269756
	speed: 0.1684s/iter; left time: 3836.6358s
	iters: 500, epoch: 7 | loss: 0.2406090
	speed: 0.1679s/iter; left time: 3808.4366s
Epoch: 7 cost time: 85.40495252609253
Epoch: 7, Steps: 527 | Train Loss: 0.2628729 Vali Loss: 0.3945471 Test Loss: 0.3101160
Validation loss decreased (0.398036 --> 0.394547).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2691596
	speed: 1.1149s/iter; left time: 25155.3862s
	iters: 200, epoch: 8 | loss: 0.2813389
	speed: 0.1345s/iter; left time: 3020.3996s
	iters: 300, epoch: 8 | loss: 0.2997252
	speed: 0.1221s/iter; left time: 2729.5940s
	iters: 400, epoch: 8 | loss: 0.2396661
	speed: 0.1494s/iter; left time: 3326.5181s
	iters: 500, epoch: 8 | loss: 0.2548136
	speed: 0.1549s/iter; left time: 3432.0164s
Epoch: 8 cost time: 75.71963763237
Epoch: 8, Steps: 527 | Train Loss: 0.2627143 Vali Loss: 0.3952853 Test Loss: 0.3112478
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2655705
	speed: 0.9507s/iter; left time: 20947.6189s
	iters: 200, epoch: 9 | loss: 0.2298454
	speed: 0.1389s/iter; left time: 3046.6013s
	iters: 300, epoch: 9 | loss: 0.2519379
	speed: 0.1398s/iter; left time: 3053.1808s
	iters: 400, epoch: 9 | loss: 0.2418426
	speed: 0.1354s/iter; left time: 2942.3340s
	iters: 500, epoch: 9 | loss: 0.2579997
	speed: 0.1406s/iter; left time: 3042.8975s
Epoch: 9 cost time: 73.56225061416626
Epoch: 9, Steps: 527 | Train Loss: 0.2625507 Vali Loss: 0.3970542 Test Loss: 0.3098925
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2266248
	speed: 1.0446s/iter; left time: 22467.7996s
	iters: 200, epoch: 10 | loss: 0.2216846
	speed: 0.1482s/iter; left time: 3172.6755s
	iters: 300, epoch: 10 | loss: 0.2722232
	speed: 0.1375s/iter; left time: 2929.1366s
	iters: 400, epoch: 10 | loss: 0.2635777
	speed: 0.1402s/iter; left time: 2973.8686s
	iters: 500, epoch: 10 | loss: 0.2635628
	speed: 0.1384s/iter; left time: 2921.9739s
Epoch: 10 cost time: 76.11867451667786
Epoch: 10, Steps: 527 | Train Loss: 0.2624503 Vali Loss: 0.3987736 Test Loss: 0.3095108
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_720_96_FITS_ETTm1_ftM_sl720_ll48_pl96_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.3106432259082794, mae:0.3530808091163635, rse:0.5303503274917603, corr:[0.54237753 0.5532048  0.5585613  0.56018764 0.5612809  0.5630843
 0.564972   0.56608117 0.56641376 0.5666257  0.5672991  0.56820714
 0.56887716 0.5688881  0.56822425 0.567258   0.56637275 0.56556875
 0.56445867 0.56289554 0.56108695 0.55928826 0.55781406 0.55694646
 0.55628675 0.55551696 0.5544282  0.55311584 0.5521883  0.5520188
 0.5525952  0.5535807  0.55437183 0.5547477  0.55462277 0.5544413
 0.55420816 0.55390984 0.55343664 0.5526923  0.5520309  0.55167377
 0.55171233 0.5520661  0.5522936  0.5522003  0.5520516  0.55216026
 0.55259365 0.55311775 0.55349946 0.5534752  0.55306065 0.5523899
 0.55186856 0.5517283  0.5518672  0.5519402  0.5519133  0.5517405
 0.55166143 0.5518341  0.55218023 0.5523151  0.5521612  0.55176884
 0.5513164  0.55108505 0.5512448  0.55163413 0.5520507  0.55227846
 0.55226064 0.55210835 0.55205345 0.5520536  0.5519706  0.55170757
 0.5511883  0.5504293  0.5496112  0.54889816 0.54842305 0.5480563
 0.54770464 0.54722595 0.5467262  0.54637307 0.5463568  0.5467699
 0.5473327  0.5477315  0.54800236 0.54841334 0.54895014 0.54861796]
