Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTm1_720_96_FITS_ETTm1_ftM_sl720_ll48_pl96_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=90, out_features=102, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  16450560.0
params:  9282.0
Trainable parameters:  9282
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2974802
	speed: 0.1281s/iter; left time: 826.3745s
Epoch: 1 cost time: 16.903720140457153
Epoch: 1, Steps: 131 | Train Loss: 0.3532962 Vali Loss: 0.4664655 Test Loss: 0.3243956
Validation loss decreased (inf --> 0.466465).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2774645
	speed: 0.3725s/iter; left time: 2354.2370s
Epoch: 2 cost time: 19.17728567123413
Epoch: 2, Steps: 131 | Train Loss: 0.2786480 Vali Loss: 0.4335844 Test Loss: 0.3153299
Validation loss decreased (0.466465 --> 0.433584).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2807536
	speed: 0.4042s/iter; left time: 2501.3459s
Epoch: 3 cost time: 19.27364754676819
Epoch: 3, Steps: 131 | Train Loss: 0.2712456 Vali Loss: 0.4196663 Test Loss: 0.3124258
Validation loss decreased (0.433584 --> 0.419666).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2723600
	speed: 0.3992s/iter; left time: 2418.5645s
Epoch: 4 cost time: 19.053040981292725
Epoch: 4, Steps: 131 | Train Loss: 0.2684491 Vali Loss: 0.4131482 Test Loss: 0.3110316
Validation loss decreased (0.419666 --> 0.413148).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2606525
	speed: 0.3902s/iter; left time: 2312.7695s
Epoch: 5 cost time: 18.91173005104065
Epoch: 5, Steps: 131 | Train Loss: 0.2667285 Vali Loss: 0.4091432 Test Loss: 0.3103853
Validation loss decreased (0.413148 --> 0.409143).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2820528
	speed: 0.3754s/iter; left time: 2175.8574s
Epoch: 6 cost time: 18.484545707702637
Epoch: 6, Steps: 131 | Train Loss: 0.2658833 Vali Loss: 0.4060689 Test Loss: 0.3102813
Validation loss decreased (0.409143 --> 0.406069).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2441554
	speed: 0.3988s/iter; left time: 2259.3040s
Epoch: 7 cost time: 19.770485401153564
Epoch: 7, Steps: 131 | Train Loss: 0.2651459 Vali Loss: 0.4047723 Test Loss: 0.3098952
Validation loss decreased (0.406069 --> 0.404772).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2890742
	speed: 0.4111s/iter; left time: 2274.8770s
Epoch: 8 cost time: 18.84132957458496
Epoch: 8, Steps: 131 | Train Loss: 0.2646940 Vali Loss: 0.4027330 Test Loss: 0.3103219
Validation loss decreased (0.404772 --> 0.402733).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2725861
	speed: 0.3942s/iter; left time: 2129.6459s
Epoch: 9 cost time: 18.83858609199524
Epoch: 9, Steps: 131 | Train Loss: 0.2643104 Vali Loss: 0.4037017 Test Loss: 0.3103597
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2700776
	speed: 0.3967s/iter; left time: 2091.5050s
Epoch: 10 cost time: 18.77842092514038
Epoch: 10, Steps: 131 | Train Loss: 0.2638995 Vali Loss: 0.4006619 Test Loss: 0.3102809
Validation loss decreased (0.402733 --> 0.400662).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2669213
	speed: 0.3643s/iter; left time: 1873.0721s
Epoch: 11 cost time: 17.434875011444092
Epoch: 11, Steps: 131 | Train Loss: 0.2637385 Vali Loss: 0.3997272 Test Loss: 0.3100332
Validation loss decreased (0.400662 --> 0.399727).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2556682
	speed: 0.3557s/iter; left time: 1781.8243s
Epoch: 12 cost time: 17.95750904083252
Epoch: 12, Steps: 131 | Train Loss: 0.2634184 Vali Loss: 0.4002828 Test Loss: 0.3097682
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2735860
	speed: 0.3596s/iter; left time: 1754.4852s
Epoch: 13 cost time: 17.64431595802307
Epoch: 13, Steps: 131 | Train Loss: 0.2634354 Vali Loss: 0.3999063 Test Loss: 0.3096209
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2840379
	speed: 0.3557s/iter; left time: 1688.8979s
Epoch: 14 cost time: 17.669422149658203
Epoch: 14, Steps: 131 | Train Loss: 0.2633249 Vali Loss: 0.3983746 Test Loss: 0.3100190
Validation loss decreased (0.399727 --> 0.398375).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2625513
	speed: 0.3611s/iter; left time: 1667.3333s
Epoch: 15 cost time: 16.619617462158203
Epoch: 15, Steps: 131 | Train Loss: 0.2631779 Vali Loss: 0.3986096 Test Loss: 0.3100091
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2706865
	speed: 0.3484s/iter; left time: 1562.9222s
Epoch: 16 cost time: 17.143033981323242
Epoch: 16, Steps: 131 | Train Loss: 0.2632467 Vali Loss: 0.3977826 Test Loss: 0.3097720
Validation loss decreased (0.398375 --> 0.397783).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2532966
	speed: 0.3622s/iter; left time: 1577.1956s
Epoch: 17 cost time: 16.322376012802124
Epoch: 17, Steps: 131 | Train Loss: 0.2630312 Vali Loss: 0.3969148 Test Loss: 0.3099217
Validation loss decreased (0.397783 --> 0.396915).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2517994
	speed: 0.3383s/iter; left time: 1428.9699s
Epoch: 18 cost time: 16.25597596168518
Epoch: 18, Steps: 131 | Train Loss: 0.2628762 Vali Loss: 0.3975277 Test Loss: 0.3100076
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2508669
	speed: 0.3126s/iter; left time: 1279.6520s
Epoch: 19 cost time: 12.549152851104736
Epoch: 19, Steps: 131 | Train Loss: 0.2628697 Vali Loss: 0.3986577 Test Loss: 0.3101621
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2533321
	speed: 0.2482s/iter; left time: 983.3630s
Epoch: 20 cost time: 10.469315528869629
Epoch: 20, Steps: 131 | Train Loss: 0.2628281 Vali Loss: 0.3970287 Test Loss: 0.3101944
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_720_96_FITS_ETTm1_ftM_sl720_ll48_pl96_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.31004956364631653, mae:0.35252314805984497, rse:0.5298433303833008, corr:[0.5454626  0.5548282  0.5605881  0.5626682  0.563143   0.56378305
 0.5650109  0.5665367  0.56789374 0.5687346  0.5691442  0.56928617
 0.5694037  0.5694615  0.56924474 0.5685906  0.56756    0.56635773
 0.5651308  0.56399316 0.5629832  0.56193966 0.56070065 0.5593311
 0.55775696 0.55628747 0.55516654 0.5544263  0.5541778  0.55432636
 0.5546894  0.5551457  0.555515   0.55585283 0.5560668  0.5562848
 0.55630624 0.5561301  0.5557774  0.5552338  0.55475694 0.55444384
 0.554329   0.5544529  0.5545843  0.5545919  0.5545608  0.55456114
 0.554583   0.5545783  0.5545836  0.55452335 0.5543893  0.5540699
 0.5536835  0.5533841  0.5532712  0.5532461  0.55326897 0.55312586
 0.5528034  0.5524     0.5520879  0.55193037 0.5520841  0.5524946
 0.55294305 0.5532274  0.5532745  0.5530773  0.5527906  0.5525141
 0.55228424 0.55209744 0.55198574 0.5518365  0.55156654 0.55119187
 0.55078584 0.55045295 0.5502612  0.55014974 0.5500464  0.54976594
 0.5493067  0.5486929  0.5480631  0.5474422  0.54687744 0.5464678
 0.5461915  0.54616636 0.546642   0.54766065 0.5487179  0.54824215]
