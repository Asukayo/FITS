Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=512, c_out=7, checkpoints='./checkpoints/', cut_freq=122, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTm1_720_96_FITS_ETTm1_ftM_sl720_ll48_pl96_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=122, out_features=138, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  60340224.0
params:  16974.0
Trainable parameters:  16974
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 10.897064685821533
Epoch: 1, Steps: 65 | Train Loss: 0.4963501 Vali Loss: 0.8295014 Test Loss: 0.5498046
Validation loss decreased (inf --> 0.829501).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 11.973673105239868
Epoch: 2, Steps: 65 | Train Loss: 0.3635045 Vali Loss: 0.7184764 Test Loss: 0.4873324
Validation loss decreased (0.829501 --> 0.718476).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 11.898910522460938
Epoch: 3, Steps: 65 | Train Loss: 0.2979688 Vali Loss: 0.6838092 Test Loss: 0.4746628
Validation loss decreased (0.718476 --> 0.683809).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 12.127494096755981
Epoch: 4, Steps: 65 | Train Loss: 0.2590781 Vali Loss: 0.6641099 Test Loss: 0.4704394
Validation loss decreased (0.683809 --> 0.664110).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 13.186986684799194
Epoch: 5, Steps: 65 | Train Loss: 0.2325997 Vali Loss: 0.6539667 Test Loss: 0.4691290
Validation loss decreased (0.664110 --> 0.653967).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 12.16899061203003
Epoch: 6, Steps: 65 | Train Loss: 0.2129888 Vali Loss: 0.6438611 Test Loss: 0.4683533
Validation loss decreased (0.653967 --> 0.643861).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 14.322203159332275
Epoch: 7, Steps: 65 | Train Loss: 0.1975614 Vali Loss: 0.6357548 Test Loss: 0.4662865
Validation loss decreased (0.643861 --> 0.635755).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 13.034270524978638
Epoch: 8, Steps: 65 | Train Loss: 0.1850107 Vali Loss: 0.6261583 Test Loss: 0.4634651
Validation loss decreased (0.635755 --> 0.626158).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 11.74513030052185
Epoch: 9, Steps: 65 | Train Loss: 0.1743403 Vali Loss: 0.6204606 Test Loss: 0.4617265
Validation loss decreased (0.626158 --> 0.620461).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 12.318782329559326
Epoch: 10, Steps: 65 | Train Loss: 0.1651937 Vali Loss: 0.6141727 Test Loss: 0.4592364
Validation loss decreased (0.620461 --> 0.614173).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 11.427720785140991
Epoch: 11, Steps: 65 | Train Loss: 0.1571782 Vali Loss: 0.6079749 Test Loss: 0.4570548
Validation loss decreased (0.614173 --> 0.607975).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 12.113399028778076
Epoch: 12, Steps: 65 | Train Loss: 0.1499801 Vali Loss: 0.6013817 Test Loss: 0.4533035
Validation loss decreased (0.607975 --> 0.601382).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 11.557904243469238
Epoch: 13, Steps: 65 | Train Loss: 0.1437258 Vali Loss: 0.5966951 Test Loss: 0.4509048
Validation loss decreased (0.601382 --> 0.596695).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 11.734694957733154
Epoch: 14, Steps: 65 | Train Loss: 0.1380182 Vali Loss: 0.5919000 Test Loss: 0.4488083
Validation loss decreased (0.596695 --> 0.591900).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 11.993248224258423
Epoch: 15, Steps: 65 | Train Loss: 0.1329863 Vali Loss: 0.5867254 Test Loss: 0.4462796
Validation loss decreased (0.591900 --> 0.586725).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 12.305615425109863
Epoch: 16, Steps: 65 | Train Loss: 0.1283752 Vali Loss: 0.5815552 Test Loss: 0.4440545
Validation loss decreased (0.586725 --> 0.581555).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 11.80387544631958
Epoch: 17, Steps: 65 | Train Loss: 0.1242253 Vali Loss: 0.5776711 Test Loss: 0.4417965
Validation loss decreased (0.581555 --> 0.577671).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 11.754629611968994
Epoch: 18, Steps: 65 | Train Loss: 0.1204689 Vali Loss: 0.5758973 Test Loss: 0.4397015
Validation loss decreased (0.577671 --> 0.575897).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 12.41832685470581
Epoch: 19, Steps: 65 | Train Loss: 0.1170212 Vali Loss: 0.5708360 Test Loss: 0.4378908
Validation loss decreased (0.575897 --> 0.570836).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 13.142966508865356
Epoch: 20, Steps: 65 | Train Loss: 0.1138139 Vali Loss: 0.5686240 Test Loss: 0.4360844
Validation loss decreased (0.570836 --> 0.568624).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 13.047040700912476
Epoch: 21, Steps: 65 | Train Loss: 0.1109610 Vali Loss: 0.5653967 Test Loss: 0.4343533
Validation loss decreased (0.568624 --> 0.565397).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 12.892138242721558
Epoch: 22, Steps: 65 | Train Loss: 0.1083274 Vali Loss: 0.5619917 Test Loss: 0.4326796
Validation loss decreased (0.565397 --> 0.561992).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 12.484099388122559
Epoch: 23, Steps: 65 | Train Loss: 0.1059203 Vali Loss: 0.5597848 Test Loss: 0.4314114
Validation loss decreased (0.561992 --> 0.559785).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 12.019052743911743
Epoch: 24, Steps: 65 | Train Loss: 0.1036018 Vali Loss: 0.5556613 Test Loss: 0.4293535
Validation loss decreased (0.559785 --> 0.555661).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 11.685666561126709
Epoch: 25, Steps: 65 | Train Loss: 0.1015646 Vali Loss: 0.5543016 Test Loss: 0.4282853
Validation loss decreased (0.555661 --> 0.554302).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 12.513582468032837
Epoch: 26, Steps: 65 | Train Loss: 0.0996805 Vali Loss: 0.5511008 Test Loss: 0.4268795
Validation loss decreased (0.554302 --> 0.551101).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 11.925764083862305
Epoch: 27, Steps: 65 | Train Loss: 0.0978553 Vali Loss: 0.5499143 Test Loss: 0.4253579
Validation loss decreased (0.551101 --> 0.549914).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 12.221964120864868
Epoch: 28, Steps: 65 | Train Loss: 0.0962138 Vali Loss: 0.5476663 Test Loss: 0.4243312
Validation loss decreased (0.549914 --> 0.547666).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 11.508533477783203
Epoch: 29, Steps: 65 | Train Loss: 0.0946860 Vali Loss: 0.5462025 Test Loss: 0.4227867
Validation loss decreased (0.547666 --> 0.546202).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 11.764547109603882
Epoch: 30, Steps: 65 | Train Loss: 0.0932329 Vali Loss: 0.5445023 Test Loss: 0.4219389
Validation loss decreased (0.546202 --> 0.544502).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 11.859879732131958
Epoch: 31, Steps: 65 | Train Loss: 0.0919540 Vali Loss: 0.5421166 Test Loss: 0.4208309
Validation loss decreased (0.544502 --> 0.542117).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 12.16510009765625
Epoch: 32, Steps: 65 | Train Loss: 0.0907088 Vali Loss: 0.5393952 Test Loss: 0.4197678
Validation loss decreased (0.542117 --> 0.539395).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 12.088271141052246
Epoch: 33, Steps: 65 | Train Loss: 0.0895240 Vali Loss: 0.5387266 Test Loss: 0.4186675
Validation loss decreased (0.539395 --> 0.538727).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 13.02759337425232
Epoch: 34, Steps: 65 | Train Loss: 0.0884271 Vali Loss: 0.5370846 Test Loss: 0.4178139
Validation loss decreased (0.538727 --> 0.537085).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 12.647080183029175
Epoch: 35, Steps: 65 | Train Loss: 0.0874477 Vali Loss: 0.5358459 Test Loss: 0.4169821
Validation loss decreased (0.537085 --> 0.535846).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 13.226082563400269
Epoch: 36, Steps: 65 | Train Loss: 0.0865104 Vali Loss: 0.5339879 Test Loss: 0.4162363
Validation loss decreased (0.535846 --> 0.533988).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 12.3016037940979
Epoch: 37, Steps: 65 | Train Loss: 0.0856016 Vali Loss: 0.5337126 Test Loss: 0.4153647
Validation loss decreased (0.533988 --> 0.533713).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 11.72195291519165
Epoch: 38, Steps: 65 | Train Loss: 0.0847955 Vali Loss: 0.5323243 Test Loss: 0.4144802
Validation loss decreased (0.533713 --> 0.532324).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 11.892613887786865
Epoch: 39, Steps: 65 | Train Loss: 0.0839548 Vali Loss: 0.5303617 Test Loss: 0.4137623
Validation loss decreased (0.532324 --> 0.530362).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 11.992295980453491
Epoch: 40, Steps: 65 | Train Loss: 0.0832281 Vali Loss: 0.5302141 Test Loss: 0.4130637
Validation loss decreased (0.530362 --> 0.530214).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 11.997782468795776
Epoch: 41, Steps: 65 | Train Loss: 0.0825502 Vali Loss: 0.5288544 Test Loss: 0.4123163
Validation loss decreased (0.530214 --> 0.528854).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 12.025344133377075
Epoch: 42, Steps: 65 | Train Loss: 0.0818604 Vali Loss: 0.5278798 Test Loss: 0.4115991
Validation loss decreased (0.528854 --> 0.527880).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 11.176260709762573
Epoch: 43, Steps: 65 | Train Loss: 0.0812649 Vali Loss: 0.5266917 Test Loss: 0.4110000
Validation loss decreased (0.527880 --> 0.526692).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 11.737598180770874
Epoch: 44, Steps: 65 | Train Loss: 0.0806609 Vali Loss: 0.5250857 Test Loss: 0.4104431
Validation loss decreased (0.526692 --> 0.525086).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 11.582631587982178
Epoch: 45, Steps: 65 | Train Loss: 0.0801278 Vali Loss: 0.5246682 Test Loss: 0.4097965
Validation loss decreased (0.525086 --> 0.524668).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 12.652693033218384
Epoch: 46, Steps: 65 | Train Loss: 0.0796212 Vali Loss: 0.5229717 Test Loss: 0.4093147
Validation loss decreased (0.524668 --> 0.522972).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 12.112493515014648
Epoch: 47, Steps: 65 | Train Loss: 0.0791249 Vali Loss: 0.5225595 Test Loss: 0.4087341
Validation loss decreased (0.522972 --> 0.522560).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 11.27540397644043
Epoch: 48, Steps: 65 | Train Loss: 0.0786468 Vali Loss: 0.5217158 Test Loss: 0.4083212
Validation loss decreased (0.522560 --> 0.521716).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 12.950591087341309
Epoch: 49, Steps: 65 | Train Loss: 0.0781595 Vali Loss: 0.5216210 Test Loss: 0.4078418
Validation loss decreased (0.521716 --> 0.521621).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 12.62954568862915
Epoch: 50, Steps: 65 | Train Loss: 0.0777764 Vali Loss: 0.5203745 Test Loss: 0.4073180
Validation loss decreased (0.521621 --> 0.520375).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
train 33745
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=122, out_features=138, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  60340224.0
params:  16974.0
Trainable parameters:  16974
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 13.306742191314697
Epoch: 1, Steps: 65 | Train Loss: 0.2840289 Vali Loss: 0.4336686 Test Loss: 0.3385913
Validation loss decreased (inf --> 0.433669).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 11.780736684799194
Epoch: 2, Steps: 65 | Train Loss: 0.2693639 Vali Loss: 0.4134374 Test Loss: 0.3207612
Validation loss decreased (0.433669 --> 0.413437).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 11.78828477859497
Epoch: 3, Steps: 65 | Train Loss: 0.2659472 Vali Loss: 0.4066188 Test Loss: 0.3148796
Validation loss decreased (0.413437 --> 0.406619).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 12.509135007858276
Epoch: 4, Steps: 65 | Train Loss: 0.2646383 Vali Loss: 0.4046847 Test Loss: 0.3120799
Validation loss decreased (0.406619 --> 0.404685).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 12.053271770477295
Epoch: 5, Steps: 65 | Train Loss: 0.2640853 Vali Loss: 0.4024615 Test Loss: 0.3104545
Validation loss decreased (0.404685 --> 0.402462).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 12.096502542495728
Epoch: 6, Steps: 65 | Train Loss: 0.2634473 Vali Loss: 0.3997783 Test Loss: 0.3101972
Validation loss decreased (0.402462 --> 0.399778).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 11.884006977081299
Epoch: 7, Steps: 65 | Train Loss: 0.2631100 Vali Loss: 0.3984188 Test Loss: 0.3096815
Validation loss decreased (0.399778 --> 0.398419).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 11.804582118988037
Epoch: 8, Steps: 65 | Train Loss: 0.2625885 Vali Loss: 0.3988506 Test Loss: 0.3099137
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 12.069006443023682
Epoch: 9, Steps: 65 | Train Loss: 0.2623200 Vali Loss: 0.3985649 Test Loss: 0.3097482
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 12.218286037445068
Epoch: 10, Steps: 65 | Train Loss: 0.2621298 Vali Loss: 0.3957523 Test Loss: 0.3100892
Validation loss decreased (0.398419 --> 0.395752).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 12.55254316329956
Epoch: 11, Steps: 65 | Train Loss: 0.2624713 Vali Loss: 0.3957539 Test Loss: 0.3097803
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 11.81437611579895
Epoch: 12, Steps: 65 | Train Loss: 0.2622395 Vali Loss: 0.3966818 Test Loss: 0.3093425
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 11.773330926895142
Epoch: 13, Steps: 65 | Train Loss: 0.2620004 Vali Loss: 0.3956029 Test Loss: 0.3096237
Validation loss decreased (0.395752 --> 0.395603).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 13.166784286499023
Epoch: 14, Steps: 65 | Train Loss: 0.2619176 Vali Loss: 0.3960688 Test Loss: 0.3095900
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 12.581334352493286
Epoch: 15, Steps: 65 | Train Loss: 0.2618831 Vali Loss: 0.3955040 Test Loss: 0.3093532
Validation loss decreased (0.395603 --> 0.395504).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 12.246341466903687
Epoch: 16, Steps: 65 | Train Loss: 0.2617074 Vali Loss: 0.3950279 Test Loss: 0.3092392
Validation loss decreased (0.395504 --> 0.395028).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 11.400172472000122
Epoch: 17, Steps: 65 | Train Loss: 0.2615982 Vali Loss: 0.3938484 Test Loss: 0.3093344
Validation loss decreased (0.395028 --> 0.393848).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 11.540345191955566
Epoch: 18, Steps: 65 | Train Loss: 0.2618207 Vali Loss: 0.3961622 Test Loss: 0.3093137
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 10.386362791061401
Epoch: 19, Steps: 65 | Train Loss: 0.2616779 Vali Loss: 0.3952802 Test Loss: 0.3093643
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 10.900254726409912
Epoch: 20, Steps: 65 | Train Loss: 0.2616674 Vali Loss: 0.3940897 Test Loss: 0.3092932
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_720_96_FITS_ETTm1_ftM_sl720_ll48_pl96_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.30984461307525635, mae:0.352456271648407, rse:0.5296681523323059, corr:[0.54484636 0.55681366 0.56094575 0.56153965 0.56290585 0.565432
 0.56735903 0.5677126  0.5674279  0.56771386 0.5687525  0.56963974
 0.5697063  0.5690816  0.5683836  0.5679314  0.5674821  0.56664884
 0.56529653 0.56378937 0.5625118  0.5613714  0.56006145 0.5585575
 0.5568627  0.55549526 0.55463743 0.5539606  0.55336136 0.5528887
 0.5529179  0.5537542  0.55498445 0.55597764 0.5560745  0.5556432
 0.5550632  0.55481744 0.5548449  0.5546802  0.5542753  0.55375034
 0.55350214 0.55376554 0.55407184 0.5540334  0.55376273 0.553544
 0.5535108  0.5534854  0.55330646 0.5528289  0.55229443 0.55199075
 0.55219173 0.5526717  0.55295354 0.55269665 0.5522032  0.5517694
 0.55170953 0.5519002  0.5520428  0.55182344 0.55154634 0.55154663
 0.55180424 0.5520372  0.55204374 0.5517752  0.55149055 0.5513427
 0.5512878  0.5511668  0.55101436 0.5507421  0.55035555 0.5499865
 0.5496766  0.54938716 0.54904574 0.54854596 0.5480656  0.54767066
 0.54742527 0.5471228  0.5465745  0.5457536  0.54511195 0.5452205
 0.546003   0.5468174  0.5471137  0.5473417  0.5484103  0.550052  ]
