Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=122, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTm1_720_96_FITS_ETTm1_ftM_sl720_ll48_pl96_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=122, out_features=138, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  7542528.0
params:  16974.0
Trainable parameters:  16974
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3026245
	speed: 0.0794s/iter; left time: 2084.0379s
	iters: 200, epoch: 1 | loss: 0.3134900
	speed: 0.0766s/iter; left time: 2002.5099s
	iters: 300, epoch: 1 | loss: 0.2574879
	speed: 0.0821s/iter; left time: 2138.0779s
	iters: 400, epoch: 1 | loss: 0.2430473
	speed: 0.0783s/iter; left time: 2031.5333s
	iters: 500, epoch: 1 | loss: 0.2459534
	speed: 0.0782s/iter; left time: 2022.1470s
Epoch: 1 cost time: 41.5837824344635
Epoch: 1, Steps: 527 | Train Loss: 0.2951089 Vali Loss: 0.4168913 Test Loss: 0.3124444
Validation loss decreased (inf --> 0.416891).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2654885
	speed: 0.5699s/iter; left time: 14660.8710s
	iters: 200, epoch: 2 | loss: 0.2779428
	speed: 0.0756s/iter; left time: 1936.2774s
	iters: 300, epoch: 2 | loss: 0.2957178
	speed: 0.0777s/iter; left time: 1982.0740s
	iters: 400, epoch: 2 | loss: 0.2297885
	speed: 0.0737s/iter; left time: 1873.5657s
	iters: 500, epoch: 2 | loss: 0.2918612
	speed: 0.0785s/iter; left time: 1987.0839s
Epoch: 2 cost time: 41.091148853302
Epoch: 2, Steps: 527 | Train Loss: 0.2664847 Vali Loss: 0.4064823 Test Loss: 0.3090587
Validation loss decreased (0.416891 --> 0.406482).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2808223
	speed: 0.4914s/iter; left time: 12380.8828s
	iters: 200, epoch: 3 | loss: 0.2692348
	speed: 0.0721s/iter; left time: 1810.2437s
	iters: 300, epoch: 3 | loss: 0.3164782
	speed: 0.0720s/iter; left time: 1800.6966s
	iters: 400, epoch: 3 | loss: 0.2612005
	speed: 0.0762s/iter; left time: 1896.1661s
	iters: 500, epoch: 3 | loss: 0.3072077
	speed: 0.0761s/iter; left time: 1886.1686s
Epoch: 3 cost time: 39.33932876586914
Epoch: 3, Steps: 527 | Train Loss: 0.2643263 Vali Loss: 0.3994617 Test Loss: 0.3102841
Validation loss decreased (0.406482 --> 0.399462).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2223090
	speed: 0.5586s/iter; left time: 13779.7361s
	iters: 200, epoch: 4 | loss: 0.2425237
	speed: 0.0835s/iter; left time: 2052.4997s
	iters: 300, epoch: 4 | loss: 0.2852096
	speed: 0.0812s/iter; left time: 1986.5079s
	iters: 400, epoch: 4 | loss: 0.2338356
	speed: 0.0855s/iter; left time: 2084.5882s
	iters: 500, epoch: 4 | loss: 0.2647737
	speed: 0.0999s/iter; left time: 2423.9891s
Epoch: 4 cost time: 46.39781308174133
Epoch: 4, Steps: 527 | Train Loss: 0.2635107 Vali Loss: 0.3970805 Test Loss: 0.3100834
Validation loss decreased (0.399462 --> 0.397081).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2675241
	speed: 0.7520s/iter; left time: 18154.4875s
	iters: 200, epoch: 5 | loss: 0.3064875
	speed: 0.1084s/iter; left time: 2606.8546s
	iters: 300, epoch: 5 | loss: 0.2320788
	speed: 0.1097s/iter; left time: 2626.6338s
	iters: 400, epoch: 5 | loss: 0.2534927
	speed: 0.1116s/iter; left time: 2661.7838s
	iters: 500, epoch: 5 | loss: 0.2919948
	speed: 0.1081s/iter; left time: 2565.9317s
Epoch: 5 cost time: 57.86078333854675
Epoch: 5, Steps: 527 | Train Loss: 0.2630703 Vali Loss: 0.3965853 Test Loss: 0.3104703
Validation loss decreased (0.397081 --> 0.396585).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2653784
	speed: 0.7585s/iter; left time: 17911.5835s
	iters: 200, epoch: 6 | loss: 0.2683083
	speed: 0.1078s/iter; left time: 2534.4762s
	iters: 300, epoch: 6 | loss: 0.2568367
	speed: 0.1072s/iter; left time: 2509.6475s
	iters: 400, epoch: 6 | loss: 0.2403026
	speed: 0.1041s/iter; left time: 2426.2107s
	iters: 500, epoch: 6 | loss: 0.3143893
	speed: 0.1071s/iter; left time: 2486.7115s
Epoch: 6 cost time: 56.6856963634491
Epoch: 6, Steps: 527 | Train Loss: 0.2627137 Vali Loss: 0.3996174 Test Loss: 0.3090799
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2852509
	speed: 0.9212s/iter; left time: 21270.2227s
	iters: 200, epoch: 7 | loss: 0.3295378
	speed: 0.1332s/iter; left time: 3061.7936s
	iters: 300, epoch: 7 | loss: 0.2669862
	speed: 0.1369s/iter; left time: 3132.9107s
	iters: 400, epoch: 7 | loss: 0.2570679
	speed: 0.1340s/iter; left time: 3054.6949s
	iters: 500, epoch: 7 | loss: 0.3394774
	speed: 0.1381s/iter; left time: 3132.9451s
Epoch: 7 cost time: 72.50384497642517
Epoch: 7, Steps: 527 | Train Loss: 0.2625003 Vali Loss: 0.3940799 Test Loss: 0.3095640
Validation loss decreased (0.396585 --> 0.394080).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2699967
	speed: 0.9908s/iter; left time: 22354.2045s
	iters: 200, epoch: 8 | loss: 0.2613119
	speed: 0.1437s/iter; left time: 3227.0738s
	iters: 300, epoch: 8 | loss: 0.2581266
	speed: 0.1422s/iter; left time: 3180.7855s
	iters: 400, epoch: 8 | loss: 0.2714541
	speed: 0.1407s/iter; left time: 3132.9153s
	iters: 500, epoch: 8 | loss: 0.2391397
	speed: 0.1398s/iter; left time: 3097.1934s
Epoch: 8 cost time: 75.48215651512146
Epoch: 8, Steps: 527 | Train Loss: 0.2622981 Vali Loss: 0.3969150 Test Loss: 0.3093588
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2204177
	speed: 0.9517s/iter; left time: 20969.9004s
	iters: 200, epoch: 9 | loss: 0.2366712
	speed: 0.1333s/iter; left time: 2923.2443s
	iters: 300, epoch: 9 | loss: 0.2623024
	speed: 0.1378s/iter; left time: 3009.7098s
	iters: 400, epoch: 9 | loss: 0.2642750
	speed: 0.1344s/iter; left time: 2920.6435s
	iters: 500, epoch: 9 | loss: 0.2608917
	speed: 0.1333s/iter; left time: 2884.8419s
Epoch: 9 cost time: 69.24628067016602
Epoch: 9, Steps: 527 | Train Loss: 0.2621859 Vali Loss: 0.3972763 Test Loss: 0.3106049
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2549899
	speed: 0.9642s/iter; left time: 20737.8458s
	iters: 200, epoch: 10 | loss: 0.3043997
	speed: 0.1345s/iter; left time: 2878.7288s
	iters: 300, epoch: 10 | loss: 0.2635500
	speed: 0.1363s/iter; left time: 2904.0642s
	iters: 400, epoch: 10 | loss: 0.2757776
	speed: 0.1387s/iter; left time: 2940.6288s
	iters: 500, epoch: 10 | loss: 0.2472818
	speed: 0.1371s/iter; left time: 2893.5204s
Epoch: 10 cost time: 73.51739430427551
Epoch: 10, Steps: 527 | Train Loss: 0.2620454 Vali Loss: 0.3947902 Test Loss: 0.3085679
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_720_96_FITS_ETTm1_ftM_sl720_ll48_pl96_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.3100656569004059, mae:0.3522692322731018, rse:0.5298570394515991, corr:[0.5440521  0.5546917  0.5585834  0.559735   0.5614487  0.5638974
 0.5656441  0.5660493  0.56589204 0.566075   0.5668616  0.56774753
 0.56831145 0.5684362  0.56824756 0.56782585 0.56714815 0.56623226
 0.56513417 0.5640121  0.56283504 0.56139886 0.55970156 0.55802
 0.55635923 0.5550373  0.55407846 0.5532289  0.5526568  0.5524914
 0.55285746 0.55373454 0.55464906 0.555267   0.5553156  0.5553268
 0.5554876  0.55587816 0.5561617  0.5558553  0.55505526 0.55402803
 0.5532664  0.5531354  0.5533297  0.5535177  0.5537138  0.5540033
 0.55437845 0.5547466  0.5551402  0.5554362  0.55554605 0.55525917
 0.55466133 0.55393517 0.55332565 0.55301183 0.5532233  0.5536518
 0.5539582  0.5538775  0.55343443 0.5527375  0.55225426 0.5522389
 0.55253637 0.55281746 0.5528989  0.5527659  0.5526159  0.5525228
 0.55247796 0.5524363  0.5523935  0.55217415 0.5516565  0.55091083
 0.5501421  0.54961115 0.54948825 0.54969716 0.55010444 0.5503786
 0.5504232  0.55019146 0.5498509  0.5495648  0.5494651  0.5495843
 0.5496932  0.54959995 0.54951626 0.5501421  0.5516473  0.55260575]
