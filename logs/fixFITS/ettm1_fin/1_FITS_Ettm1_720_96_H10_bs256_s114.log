Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=512, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTm1_720_96_FITS_ETTm1_ftM_sl720_ll48_pl96_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=90, out_features=102, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  32901120.0
params:  9282.0
Trainable parameters:  9282
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 7.8703391551971436
Epoch: 1, Steps: 65 | Train Loss: 0.4080707 Vali Loss: 0.5370954 Test Loss: 0.3555982
Validation loss decreased (inf --> 0.537095).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 9.518420219421387
Epoch: 2, Steps: 65 | Train Loss: 0.2969939 Vali Loss: 0.4650024 Test Loss: 0.3252374
Validation loss decreased (0.537095 --> 0.465002).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 8.33313536643982
Epoch: 3, Steps: 65 | Train Loss: 0.2811090 Vali Loss: 0.4440005 Test Loss: 0.3184247
Validation loss decreased (0.465002 --> 0.444000).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.4021525382995605
Epoch: 4, Steps: 65 | Train Loss: 0.2752340 Vali Loss: 0.4317812 Test Loss: 0.3156209
Validation loss decreased (0.444000 --> 0.431781).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 5.738312721252441
Epoch: 5, Steps: 65 | Train Loss: 0.2719207 Vali Loss: 0.4252830 Test Loss: 0.3138551
Validation loss decreased (0.431781 --> 0.425283).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 7.468096971511841
Epoch: 6, Steps: 65 | Train Loss: 0.2701995 Vali Loss: 0.4202572 Test Loss: 0.3127539
Validation loss decreased (0.425283 --> 0.420257).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 5.261479616165161
Epoch: 7, Steps: 65 | Train Loss: 0.2684391 Vali Loss: 0.4155080 Test Loss: 0.3119213
Validation loss decreased (0.420257 --> 0.415508).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 8.285615921020508
Epoch: 8, Steps: 65 | Train Loss: 0.2675539 Vali Loss: 0.4128531 Test Loss: 0.3114325
Validation loss decreased (0.415508 --> 0.412853).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 7.6470787525177
Epoch: 9, Steps: 65 | Train Loss: 0.2668614 Vali Loss: 0.4118851 Test Loss: 0.3110098
Validation loss decreased (0.412853 --> 0.411885).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 8.849502563476562
Epoch: 10, Steps: 65 | Train Loss: 0.2663455 Vali Loss: 0.4092171 Test Loss: 0.3107881
Validation loss decreased (0.411885 --> 0.409217).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 9.547175884246826
Epoch: 11, Steps: 65 | Train Loss: 0.2660924 Vali Loss: 0.4081421 Test Loss: 0.3105695
Validation loss decreased (0.409217 --> 0.408142).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 8.926759958267212
Epoch: 12, Steps: 65 | Train Loss: 0.2655799 Vali Loss: 0.4072138 Test Loss: 0.3102355
Validation loss decreased (0.408142 --> 0.407214).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 9.122580766677856
Epoch: 13, Steps: 65 | Train Loss: 0.2650914 Vali Loss: 0.4058829 Test Loss: 0.3101638
Validation loss decreased (0.407214 --> 0.405883).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 9.083719491958618
Epoch: 14, Steps: 65 | Train Loss: 0.2647985 Vali Loss: 0.4057361 Test Loss: 0.3099523
Validation loss decreased (0.405883 --> 0.405736).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 9.391422033309937
Epoch: 15, Steps: 65 | Train Loss: 0.2647617 Vali Loss: 0.4044718 Test Loss: 0.3099722
Validation loss decreased (0.405736 --> 0.404472).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 9.043259143829346
Epoch: 16, Steps: 65 | Train Loss: 0.2644379 Vali Loss: 0.4036637 Test Loss: 0.3097785
Validation loss decreased (0.404472 --> 0.403664).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 8.429565191268921
Epoch: 17, Steps: 65 | Train Loss: 0.2643383 Vali Loss: 0.4027219 Test Loss: 0.3097212
Validation loss decreased (0.403664 --> 0.402722).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 8.748474359512329
Epoch: 18, Steps: 65 | Train Loss: 0.2642402 Vali Loss: 0.4026142 Test Loss: 0.3095260
Validation loss decreased (0.402722 --> 0.402614).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 9.044901132583618
Epoch: 19, Steps: 65 | Train Loss: 0.2639520 Vali Loss: 0.4013590 Test Loss: 0.3098999
Validation loss decreased (0.402614 --> 0.401359).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 9.115173816680908
Epoch: 20, Steps: 65 | Train Loss: 0.2638982 Vali Loss: 0.4009967 Test Loss: 0.3096886
Validation loss decreased (0.401359 --> 0.400997).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 9.194336652755737
Epoch: 21, Steps: 65 | Train Loss: 0.2637047 Vali Loss: 0.4012504 Test Loss: 0.3096793
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 9.630804300308228
Epoch: 22, Steps: 65 | Train Loss: 0.2636819 Vali Loss: 0.4006904 Test Loss: 0.3096305
Validation loss decreased (0.400997 --> 0.400690).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 10.361324071884155
Epoch: 23, Steps: 65 | Train Loss: 0.2636581 Vali Loss: 0.3998685 Test Loss: 0.3095168
Validation loss decreased (0.400690 --> 0.399868).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 10.094192028045654
Epoch: 24, Steps: 65 | Train Loss: 0.2635467 Vali Loss: 0.4003347 Test Loss: 0.3094979
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 9.907660245895386
Epoch: 25, Steps: 65 | Train Loss: 0.2635533 Vali Loss: 0.4004630 Test Loss: 0.3094968
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 9.254183292388916
Epoch: 26, Steps: 65 | Train Loss: 0.2633412 Vali Loss: 0.3997180 Test Loss: 0.3095634
Validation loss decreased (0.399868 --> 0.399718).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 9.725543737411499
Epoch: 27, Steps: 65 | Train Loss: 0.2633901 Vali Loss: 0.3994908 Test Loss: 0.3095902
Validation loss decreased (0.399718 --> 0.399491).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 6.973387002944946
Epoch: 28, Steps: 65 | Train Loss: 0.2632130 Vali Loss: 0.3997526 Test Loss: 0.3094698
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 7.431213140487671
Epoch: 29, Steps: 65 | Train Loss: 0.2630933 Vali Loss: 0.3996419 Test Loss: 0.3094194
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 8.2396821975708
Epoch: 30, Steps: 65 | Train Loss: 0.2631652 Vali Loss: 0.4000932 Test Loss: 0.3096054
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_720_96_FITS_ETTm1_ftM_sl720_ll48_pl96_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.3100191056728363, mae:0.3524692952632904, rse:0.5298172831535339, corr:[0.5451506  0.55495    0.56150293 0.5640593  0.564566   0.5650061
 0.5660123  0.5674365  0.56883866 0.5697715  0.5701632  0.5701381
 0.5699923  0.5697882  0.5693929  0.56867677 0.56765157 0.5664267
 0.5651001  0.56380457 0.5626369  0.56149507 0.5602515  0.5589537
 0.55749416 0.55612725 0.55509907 0.5544817  0.55440015 0.5547416
 0.55528206 0.5558248  0.5561422  0.5562951  0.5562762  0.5563072
 0.556261   0.5561443  0.5559257  0.5555032  0.5550629  0.55470043
 0.5545173  0.55460453 0.55475134 0.5547932  0.5547546  0.5546417
 0.5544389  0.5541705  0.5539863  0.55388933 0.55386865 0.5537618
 0.5535781  0.55337775 0.5532381  0.5531321  0.55312604 0.55307513
 0.55296427 0.5528114  0.5526691  0.5525121  0.5524991  0.55267435
 0.55293643 0.5531731  0.55332494 0.5533348  0.55325013 0.5530735
 0.55280477 0.5524674  0.5521657  0.55187243 0.5515513  0.5511915
 0.55078614 0.5503467  0.5499052  0.54942757 0.5489478  0.54839975
 0.5478502  0.5473152  0.5468636  0.5464201  0.5459487  0.54553676
 0.54520845 0.54509306 0.545373   0.5460061  0.54642797 0.5451423 ]
