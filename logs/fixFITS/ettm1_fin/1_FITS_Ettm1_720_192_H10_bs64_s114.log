Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTm1_720_192_FITS_ETTm1_ftM_sl720_ll48_pl192_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=90, out_features=114, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  9192960.0
params:  10374.0
Trainable parameters:  10374
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3677590
	speed: 0.1258s/iter; left time: 1635.9993s
	iters: 200, epoch: 1 | loss: 0.3492627
	speed: 0.1506s/iter; left time: 1942.5312s
Epoch: 1 cost time: 36.65984892845154
Epoch: 1, Steps: 262 | Train Loss: 0.3737133 Vali Loss: 0.5674721 Test Loss: 0.3430237
Validation loss decreased (inf --> 0.567472).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2867289
	speed: 0.5962s/iter; left time: 7594.5028s
	iters: 200, epoch: 2 | loss: 0.2853658
	speed: 0.1376s/iter; left time: 1739.5324s
Epoch: 2 cost time: 36.78070425987244
Epoch: 2, Steps: 262 | Train Loss: 0.3080750 Vali Loss: 0.5390162 Test Loss: 0.3398747
Validation loss decreased (0.567472 --> 0.539016).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2915197
	speed: 0.5694s/iter; left time: 7104.4237s
	iters: 200, epoch: 3 | loss: 0.2666466
	speed: 0.1185s/iter; left time: 1466.3675s
Epoch: 3 cost time: 31.51954960823059
Epoch: 3, Steps: 262 | Train Loss: 0.3028908 Vali Loss: 0.5275745 Test Loss: 0.3400534
Validation loss decreased (0.539016 --> 0.527574).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3012693
	speed: 0.5584s/iter; left time: 6820.4009s
	iters: 200, epoch: 4 | loss: 0.2985532
	speed: 0.1197s/iter; left time: 1449.8223s
Epoch: 4 cost time: 33.00431823730469
Epoch: 4, Steps: 262 | Train Loss: 0.3008720 Vali Loss: 0.5247349 Test Loss: 0.3391137
Validation loss decreased (0.527574 --> 0.524735).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3032782
	speed: 0.5672s/iter; left time: 6779.6130s
	iters: 200, epoch: 5 | loss: 0.3042003
	speed: 0.1176s/iter; left time: 1393.7239s
Epoch: 5 cost time: 31.972599506378174
Epoch: 5, Steps: 262 | Train Loss: 0.3000189 Vali Loss: 0.5198888 Test Loss: 0.3396913
Validation loss decreased (0.524735 --> 0.519889).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2884822
	speed: 0.5390s/iter; left time: 6301.1557s
	iters: 200, epoch: 6 | loss: 0.3192625
	speed: 0.1182s/iter; left time: 1370.6112s
Epoch: 6 cost time: 32.1265983581543
Epoch: 6, Steps: 262 | Train Loss: 0.2994043 Vali Loss: 0.5205958 Test Loss: 0.3387571
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3354543
	speed: 0.5429s/iter; left time: 6204.6383s
	iters: 200, epoch: 7 | loss: 0.3027538
	speed: 0.1176s/iter; left time: 1331.7571s
Epoch: 7 cost time: 31.92011070251465
Epoch: 7, Steps: 262 | Train Loss: 0.2991845 Vali Loss: 0.5173588 Test Loss: 0.3389543
Validation loss decreased (0.519889 --> 0.517359).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3109462
	speed: 0.5496s/iter; left time: 6136.8253s
	iters: 200, epoch: 8 | loss: 0.3177412
	speed: 0.1192s/iter; left time: 1319.6234s
Epoch: 8 cost time: 31.955301523208618
Epoch: 8, Steps: 262 | Train Loss: 0.2989019 Vali Loss: 0.5162030 Test Loss: 0.3388539
Validation loss decreased (0.517359 --> 0.516203).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2912607
	speed: 0.5464s/iter; left time: 5958.4905s
	iters: 200, epoch: 9 | loss: 0.2846903
	speed: 0.1279s/iter; left time: 1382.3399s
Epoch: 9 cost time: 34.06706166267395
Epoch: 9, Steps: 262 | Train Loss: 0.2987866 Vali Loss: 0.5171714 Test Loss: 0.3380081
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3112468
	speed: 0.5621s/iter; left time: 5982.4501s
	iters: 200, epoch: 10 | loss: 0.3516478
	speed: 0.1299s/iter; left time: 1369.0475s
Epoch: 10 cost time: 34.703726291656494
Epoch: 10, Steps: 262 | Train Loss: 0.2985196 Vali Loss: 0.5155972 Test Loss: 0.3384386
Validation loss decreased (0.516203 --> 0.515597).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2905644
	speed: 0.5823s/iter; left time: 6045.2272s
	iters: 200, epoch: 11 | loss: 0.2884139
	speed: 0.1256s/iter; left time: 1291.0342s
Epoch: 11 cost time: 34.301429271698
Epoch: 11, Steps: 262 | Train Loss: 0.2985664 Vali Loss: 0.5145736 Test Loss: 0.3390259
Validation loss decreased (0.515597 --> 0.514574).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3358269
	speed: 0.5843s/iter; left time: 5912.9412s
	iters: 200, epoch: 12 | loss: 0.3167707
	speed: 0.1295s/iter; left time: 1297.8987s
Epoch: 12 cost time: 34.85506582260132
Epoch: 12, Steps: 262 | Train Loss: 0.2984475 Vali Loss: 0.5147374 Test Loss: 0.3387813
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2927125
	speed: 0.5380s/iter; left time: 5302.8813s
	iters: 200, epoch: 13 | loss: 0.3274118
	speed: 0.1234s/iter; left time: 1203.8660s
Epoch: 13 cost time: 32.32227969169617
Epoch: 13, Steps: 262 | Train Loss: 0.2983240 Vali Loss: 0.5133060 Test Loss: 0.3386230
Validation loss decreased (0.514574 --> 0.513306).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2959920
	speed: 0.5164s/iter; left time: 4954.5301s
	iters: 200, epoch: 14 | loss: 0.3406179
	speed: 0.1150s/iter; left time: 1091.7691s
Epoch: 14 cost time: 30.316617250442505
Epoch: 14, Steps: 262 | Train Loss: 0.2980863 Vali Loss: 0.5140398 Test Loss: 0.3386612
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2987245
	speed: 0.4462s/iter; left time: 4164.8098s
	iters: 200, epoch: 15 | loss: 0.2719449
	speed: 0.0991s/iter; left time: 914.9275s
Epoch: 15 cost time: 26.880451202392578
Epoch: 15, Steps: 262 | Train Loss: 0.2980955 Vali Loss: 0.5138381 Test Loss: 0.3385687
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3008193
	speed: 0.4268s/iter; left time: 3871.8877s
	iters: 200, epoch: 16 | loss: 0.3135004
	speed: 0.0924s/iter; left time: 829.0465s
Epoch: 16 cost time: 26.74602770805359
Epoch: 16, Steps: 262 | Train Loss: 0.2982211 Vali Loss: 0.5129902 Test Loss: 0.3389096
Validation loss decreased (0.513306 --> 0.512990).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2844261
	speed: 0.5387s/iter; left time: 4745.1613s
	iters: 200, epoch: 17 | loss: 0.3132341
	speed: 0.1181s/iter; left time: 1028.1887s
Epoch: 17 cost time: 31.708786010742188
Epoch: 17, Steps: 262 | Train Loss: 0.2980324 Vali Loss: 0.5133643 Test Loss: 0.3386455
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2942087
	speed: 0.5423s/iter; left time: 4634.7554s
	iters: 200, epoch: 18 | loss: 0.2974772
	speed: 0.1183s/iter; left time: 999.5068s
Epoch: 18 cost time: 33.09466004371643
Epoch: 18, Steps: 262 | Train Loss: 0.2980141 Vali Loss: 0.5141103 Test Loss: 0.3385330
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2904570
	speed: 0.5950s/iter; left time: 4929.8578s
	iters: 200, epoch: 19 | loss: 0.3204760
	speed: 0.1246s/iter; left time: 1019.7744s
Epoch: 19 cost time: 34.66997933387756
Epoch: 19, Steps: 262 | Train Loss: 0.2980388 Vali Loss: 0.5127025 Test Loss: 0.3384118
Validation loss decreased (0.512990 --> 0.512703).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3361872
	speed: 0.5791s/iter; left time: 4646.2776s
	iters: 200, epoch: 20 | loss: 0.3384024
	speed: 0.1085s/iter; left time: 859.6145s
Epoch: 20 cost time: 30.284172296524048
Epoch: 20, Steps: 262 | Train Loss: 0.2979095 Vali Loss: 0.5125075 Test Loss: 0.3382416
Validation loss decreased (0.512703 --> 0.512507).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2927130
	speed: 0.5414s/iter; left time: 4201.4792s
	iters: 200, epoch: 21 | loss: 0.3268061
	speed: 0.1221s/iter; left time: 935.4859s
Epoch: 21 cost time: 33.757118225097656
Epoch: 21, Steps: 262 | Train Loss: 0.2980184 Vali Loss: 0.5117245 Test Loss: 0.3389566
Validation loss decreased (0.512507 --> 0.511725).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2967182
	speed: 0.5471s/iter; left time: 4102.3617s
	iters: 200, epoch: 22 | loss: 0.3045368
	speed: 0.1110s/iter; left time: 821.1165s
Epoch: 22 cost time: 31.120012283325195
Epoch: 22, Steps: 262 | Train Loss: 0.2979643 Vali Loss: 0.5138387 Test Loss: 0.3384099
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2998735
	speed: 0.5335s/iter; left time: 3860.9911s
	iters: 200, epoch: 23 | loss: 0.2745534
	speed: 0.1112s/iter; left time: 793.5274s
Epoch: 23 cost time: 30.489007234573364
Epoch: 23, Steps: 262 | Train Loss: 0.2979145 Vali Loss: 0.5133035 Test Loss: 0.3388517
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3204500
	speed: 0.5190s/iter; left time: 3620.2173s
	iters: 200, epoch: 24 | loss: 0.3043479
	speed: 0.1212s/iter; left time: 833.5421s
Epoch: 24 cost time: 31.56417226791382
Epoch: 24, Steps: 262 | Train Loss: 0.2978777 Vali Loss: 0.5121900 Test Loss: 0.3389198
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_720_192_FITS_ETTm1_ftM_sl720_ll48_pl192_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.33895188570022583, mae:0.36875495314598083, rse:0.5542051196098328, corr:[0.54302835 0.55108774 0.5559452  0.5577536  0.55834216 0.55915624
 0.560414   0.5617876  0.56292397 0.56363624 0.56409365 0.56442803
 0.5648043  0.565076   0.56496495 0.5642971  0.5631626  0.5617972
 0.5603663  0.558987   0.55771303 0.55643743 0.5550657  0.5536859
 0.5521964  0.5508581  0.5498941  0.5493238  0.549247   0.54957247
 0.5501221  0.550768   0.55129474 0.55174184 0.5520235  0.5522644
 0.55225164 0.5519724  0.5514563  0.5507125  0.5500595  0.5496838
 0.5496973  0.55008566 0.55049634 0.5506468  0.5505326  0.55019945
 0.549724   0.54925615 0.54901165 0.54898125 0.54906404 0.54900634
 0.5487603  0.5483789  0.5479959  0.54766893 0.5475231  0.54743844
 0.54737085 0.5473112  0.5472765  0.54723644 0.5473391  0.54760617
 0.547922   0.5481491  0.54822946 0.54814047 0.54800117 0.54788357
 0.5478397  0.5478846  0.5480071  0.54805994 0.54792637 0.5475939
 0.54713994 0.5467023  0.54640716 0.5462948  0.546361   0.54648495
 0.54660004 0.54661125 0.54653007 0.546357   0.5461838  0.5461535
 0.546288   0.5465227  0.5467763  0.5469675  0.5470309  0.54691195
 0.5466639  0.54639554 0.5460258  0.54561096 0.54521465 0.54490143
 0.5447172  0.5445968  0.5445627  0.5446259  0.5446271  0.54456085
 0.5443911  0.54419076 0.54402477 0.54390204 0.54382175 0.5437608
 0.5436608  0.5434784  0.5432103  0.5428555  0.5424916  0.5422278
 0.5420706  0.54195565 0.54176867 0.5415392  0.5413074  0.5410859
 0.54093176 0.54093003 0.5410336  0.5411852  0.54121476 0.54105437
 0.5407961  0.54054666 0.54033417 0.540252   0.5403588  0.54046017
 0.54052067 0.5405276  0.5404215  0.5403208  0.5403623  0.5405965
 0.54092884 0.5411328  0.5411338  0.5409155  0.5406009  0.5402676
 0.5400137  0.5399771  0.54008687 0.54020935 0.54020226 0.5400954
 0.53989404 0.5396313  0.53946733 0.5393877  0.53948945 0.5396991
 0.5399504  0.54014105 0.54026157 0.54035753 0.5405181  0.54078
 0.54106873 0.5412511  0.54134333 0.5413279  0.54109776 0.5407022
 0.54027295 0.53996456 0.5398525  0.53992814 0.54002875 0.5400552
 0.5399084  0.53962463 0.53925395 0.5390194  0.53903466 0.53924656
 0.5394411  0.53961354 0.5398638  0.5402761  0.5406845  0.54070306]
