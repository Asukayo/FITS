Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=122, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTm1_720_192_FITS_ETTm1_ftM_sl720_ll48_pl192_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=122, out_features=154, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  16834048.0
params:  18942.0
Trainable parameters:  18942
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3216135
	speed: 0.1460s/iter; left time: 1898.2067s
	iters: 200, epoch: 1 | loss: 0.3002763
	speed: 0.1429s/iter; left time: 1842.9182s
Epoch: 1 cost time: 37.8581166267395
Epoch: 1, Steps: 262 | Train Loss: 0.3694414 Vali Loss: 0.5680669 Test Loss: 0.3437983
Validation loss decreased (inf --> 0.568067).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3229644
	speed: 0.6405s/iter; left time: 8158.7115s
	iters: 200, epoch: 2 | loss: 0.3087019
	speed: 0.1432s/iter; left time: 1809.9476s
Epoch: 2 cost time: 38.21199584007263
Epoch: 2, Steps: 262 | Train Loss: 0.3072519 Vali Loss: 0.5390552 Test Loss: 0.3393959
Validation loss decreased (0.568067 --> 0.539055).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3043050
	speed: 0.6443s/iter; left time: 8038.7325s
	iters: 200, epoch: 3 | loss: 0.2729635
	speed: 0.1405s/iter; left time: 1738.4805s
Epoch: 3 cost time: 37.45700478553772
Epoch: 3, Steps: 262 | Train Loss: 0.3019060 Vali Loss: 0.5282698 Test Loss: 0.3385557
Validation loss decreased (0.539055 --> 0.528270).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2853844
	speed: 0.5705s/iter; left time: 6969.0601s
	iters: 200, epoch: 4 | loss: 0.2818928
	speed: 0.0913s/iter; left time: 1106.1789s
Epoch: 4 cost time: 26.07353115081787
Epoch: 4, Steps: 262 | Train Loss: 0.3002215 Vali Loss: 0.5227881 Test Loss: 0.3383980
Validation loss decreased (0.528270 --> 0.522788).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3075767
	speed: 0.4860s/iter; left time: 5809.4500s
	iters: 200, epoch: 5 | loss: 0.2862847
	speed: 0.1195s/iter; left time: 1416.7292s
Epoch: 5 cost time: 31.181785821914673
Epoch: 5, Steps: 262 | Train Loss: 0.2993808 Vali Loss: 0.5184422 Test Loss: 0.3385916
Validation loss decreased (0.522788 --> 0.518442).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2711684
	speed: 0.3991s/iter; left time: 4666.3519s
	iters: 200, epoch: 6 | loss: 0.2995693
	speed: 0.1088s/iter; left time: 1261.3905s
Epoch: 6 cost time: 28.80093765258789
Epoch: 6, Steps: 262 | Train Loss: 0.2987646 Vali Loss: 0.5184011 Test Loss: 0.3378591
Validation loss decreased (0.518442 --> 0.518401).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2889488
	speed: 0.6014s/iter; left time: 6873.5818s
	iters: 200, epoch: 7 | loss: 0.3081318
	speed: 0.1378s/iter; left time: 1561.0289s
Epoch: 7 cost time: 36.214518785476685
Epoch: 7, Steps: 262 | Train Loss: 0.2983244 Vali Loss: 0.5174169 Test Loss: 0.3384893
Validation loss decreased (0.518401 --> 0.517417).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2838404
	speed: 0.6226s/iter; left time: 6952.4657s
	iters: 200, epoch: 8 | loss: 0.3034362
	speed: 0.1346s/iter; left time: 1489.1823s
Epoch: 8 cost time: 36.33512091636658
Epoch: 8, Steps: 262 | Train Loss: 0.2981186 Vali Loss: 0.5157819 Test Loss: 0.3377385
Validation loss decreased (0.517417 --> 0.515782).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3032141
	speed: 0.6281s/iter; left time: 6849.3794s
	iters: 200, epoch: 9 | loss: 0.2914335
	speed: 0.1403s/iter; left time: 1515.7444s
Epoch: 9 cost time: 36.26753902435303
Epoch: 9, Steps: 262 | Train Loss: 0.2980414 Vali Loss: 0.5163181 Test Loss: 0.3381770
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3001883
	speed: 0.6339s/iter; left time: 6746.0715s
	iters: 200, epoch: 10 | loss: 0.3051531
	speed: 0.1327s/iter; left time: 1399.3355s
Epoch: 10 cost time: 36.09723782539368
Epoch: 10, Steps: 262 | Train Loss: 0.2978934 Vali Loss: 0.5140615 Test Loss: 0.3383919
Validation loss decreased (0.515782 --> 0.514062).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2878476
	speed: 0.6182s/iter; left time: 6417.0439s
	iters: 200, epoch: 11 | loss: 0.2948509
	speed: 0.1285s/iter; left time: 1321.5825s
Epoch: 11 cost time: 35.74374961853027
Epoch: 11, Steps: 262 | Train Loss: 0.2977658 Vali Loss: 0.5139576 Test Loss: 0.3377762
Validation loss decreased (0.514062 --> 0.513958).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2710553
	speed: 0.4674s/iter; left time: 4730.0612s
	iters: 200, epoch: 12 | loss: 0.3022340
	speed: 0.0799s/iter; left time: 800.7596s
Epoch: 12 cost time: 22.481825828552246
Epoch: 12, Steps: 262 | Train Loss: 0.2975142 Vali Loss: 0.5134184 Test Loss: 0.3381072
Validation loss decreased (0.513958 --> 0.513418).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3401480
	speed: 0.5453s/iter; left time: 5375.4654s
	iters: 200, epoch: 13 | loss: 0.3257859
	speed: 0.1515s/iter; left time: 1478.6103s
Epoch: 13 cost time: 38.971463680267334
Epoch: 13, Steps: 262 | Train Loss: 0.2976705 Vali Loss: 0.5126936 Test Loss: 0.3383069
Validation loss decreased (0.513418 --> 0.512694).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3184796
	speed: 0.4576s/iter; left time: 4390.4934s
	iters: 200, epoch: 14 | loss: 0.3177856
	speed: 0.0955s/iter; left time: 906.4885s
Epoch: 14 cost time: 26.094513177871704
Epoch: 14, Steps: 262 | Train Loss: 0.2973003 Vali Loss: 0.5136834 Test Loss: 0.3381177
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2995857
	speed: 0.5173s/iter; left time: 4827.9297s
	iters: 200, epoch: 15 | loss: 0.2979425
	speed: 0.1055s/iter; left time: 974.4616s
Epoch: 15 cost time: 28.8613600730896
Epoch: 15, Steps: 262 | Train Loss: 0.2975047 Vali Loss: 0.5127999 Test Loss: 0.3382584
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3174095
	speed: 0.4998s/iter; left time: 4534.1062s
	iters: 200, epoch: 16 | loss: 0.2559295
	speed: 0.1213s/iter; left time: 1087.9125s
Epoch: 16 cost time: 32.75423216819763
Epoch: 16, Steps: 262 | Train Loss: 0.2972594 Vali Loss: 0.5137923 Test Loss: 0.3381654
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_720_192_FITS_ETTm1_ftM_sl720_ll48_pl192_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.338291198015213, mae:0.3682950437068939, rse:0.5536647439002991, corr:[0.5410241  0.5509686  0.5540343  0.55462617 0.5562007  0.5589205
 0.56108856 0.5618184  0.56180584 0.56203115 0.5629068  0.5639953
 0.56478304 0.56497616 0.5646169  0.56387997 0.5629387  0.56198674
 0.5610769  0.560121   0.5589513  0.5574219  0.55567354 0.554198
 0.55305976 0.5522925  0.55161613 0.5507557  0.55002594 0.5497834
 0.550218   0.551194   0.5521099  0.55258065 0.5524132  0.5521927
 0.55208355 0.55209893 0.5520016  0.55156076 0.5510513  0.55068225
 0.55057377 0.55062276 0.55041206 0.5498552  0.54934675 0.54919827
 0.5493078  0.54930204 0.5490094  0.5484505  0.5479786  0.5478522
 0.5481555  0.54861623 0.5489179  0.5489029  0.54884344 0.54883003
 0.54892004 0.54897135 0.5488251  0.5483701  0.54793835 0.547789
 0.5479086  0.5481226  0.54829246 0.5483487  0.5483924  0.5484325
 0.5484205  0.54832906 0.5482415  0.54812086 0.54795116 0.54779965
 0.54769003 0.5476277  0.5476249  0.54764414 0.547653   0.54753846
 0.547305   0.54692906 0.5465218  0.5461941  0.54609793 0.5463523
 0.5468572  0.54743195 0.54793066 0.5482503  0.5483071  0.54802895
 0.5474838  0.54684347 0.5461271  0.54550713 0.54508615 0.5448609
 0.5447608  0.54462147 0.5445014  0.5445008  0.5445406  0.544659
 0.54475456 0.544786   0.5447001  0.54443693 0.5440517  0.5436504
 0.5433002  0.5430646  0.5429382  0.54277074 0.54247355 0.54206765
 0.5415816  0.5411539  0.54094607 0.54109746 0.54143643 0.54156744
 0.5412972  0.54078674 0.54029626 0.54007417 0.5400271  0.53999734
 0.5399738  0.53999215 0.54003376 0.5401058  0.54016215 0.5399454
 0.53958505 0.5393579  0.5393749  0.5396642  0.5400446  0.54030865
 0.5404156  0.54042935 0.54052395 0.54065144 0.5407105  0.5405246
 0.5401607  0.539961   0.5400229  0.5402096  0.5403255  0.540405
 0.54053646 0.54077387 0.5411599  0.5413641  0.5413093  0.5409876
 0.5406293  0.5404437  0.54048026 0.5405456  0.54046416 0.54028726
 0.54021454 0.5403815  0.5408072  0.5412416  0.5412752  0.5409303
 0.54055005 0.54047936 0.54070467 0.54092693 0.54074234 0.54022586
 0.53972113 0.5396125  0.5398398  0.54017466 0.5402819  0.540143
 0.5399779  0.54018754 0.5407688  0.54142183 0.5414619  0.5393225 ]
