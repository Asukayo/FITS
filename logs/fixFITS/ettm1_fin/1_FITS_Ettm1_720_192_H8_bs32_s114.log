Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=74, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTm1_720_192_FITS_ETTm1_ftM_sl720_ll48_pl192_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=74, out_features=93, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3083136.0
params:  6975.0
Trainable parameters:  6975
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3605965
	speed: 0.2171s/iter; left time: 5676.6208s
	iters: 200, epoch: 1 | loss: 0.3281659
	speed: 0.2115s/iter; left time: 5508.8037s
	iters: 300, epoch: 1 | loss: 0.2580830
	speed: 0.2133s/iter; left time: 5534.1668s
	iters: 400, epoch: 1 | loss: 0.2937741
	speed: 0.2185s/iter; left time: 5649.3410s
	iters: 500, epoch: 1 | loss: 0.3439610
	speed: 0.2160s/iter; left time: 5563.2316s
Epoch: 1 cost time: 113.4484281539917
Epoch: 1, Steps: 525 | Train Loss: 0.3382839 Vali Loss: 0.5408453 Test Loss: 0.3418657
Validation loss decreased (inf --> 0.540845).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3007905
	speed: 1.5419s/iter; left time: 39513.6641s
	iters: 200, epoch: 2 | loss: 0.2878285
	speed: 0.2216s/iter; left time: 5656.0682s
	iters: 300, epoch: 2 | loss: 0.3102971
	speed: 0.2255s/iter; left time: 5734.0410s
	iters: 400, epoch: 2 | loss: 0.2674604
	speed: 0.2446s/iter; left time: 6195.6106s
	iters: 500, epoch: 2 | loss: 0.2526699
	speed: 0.2290s/iter; left time: 5776.7714s
Epoch: 2 cost time: 122.08836436271667
Epoch: 2, Steps: 525 | Train Loss: 0.3033383 Vali Loss: 0.5258837 Test Loss: 0.3404935
Validation loss decreased (0.540845 --> 0.525884).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2875859
	speed: 1.4954s/iter; left time: 37535.1372s
	iters: 200, epoch: 3 | loss: 0.3100850
	speed: 0.2168s/iter; left time: 5419.8327s
	iters: 300, epoch: 3 | loss: 0.3959687
	speed: 0.2207s/iter; left time: 5495.7660s
	iters: 400, epoch: 3 | loss: 0.2726808
	speed: 0.2125s/iter; left time: 5271.2851s
	iters: 500, epoch: 3 | loss: 0.2411985
	speed: 0.2043s/iter; left time: 5046.9271s
Epoch: 3 cost time: 112.68135809898376
Epoch: 3, Steps: 525 | Train Loss: 0.3010167 Vali Loss: 0.5199360 Test Loss: 0.3404305
Validation loss decreased (0.525884 --> 0.519936).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3559246
	speed: 1.4427s/iter; left time: 35455.3458s
	iters: 200, epoch: 4 | loss: 0.3108240
	speed: 0.2003s/iter; left time: 4902.6004s
	iters: 300, epoch: 4 | loss: 0.2831624
	speed: 0.1557s/iter; left time: 3794.6216s
	iters: 400, epoch: 4 | loss: 0.3358020
	speed: 0.1960s/iter; left time: 4758.8326s
	iters: 500, epoch: 4 | loss: 0.2722198
	speed: 0.1991s/iter; left time: 4814.6250s
Epoch: 4 cost time: 103.07382869720459
Epoch: 4, Steps: 525 | Train Loss: 0.3001552 Vali Loss: 0.5210398 Test Loss: 0.3394983
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2691266
	speed: 1.5205s/iter; left time: 36568.4223s
	iters: 200, epoch: 5 | loss: 0.2965635
	speed: 0.2099s/iter; left time: 5027.9278s
	iters: 300, epoch: 5 | loss: 0.2997765
	speed: 0.1981s/iter; left time: 4724.9241s
	iters: 400, epoch: 5 | loss: 0.2622803
	speed: 0.2071s/iter; left time: 4918.8146s
	iters: 500, epoch: 5 | loss: 0.3080508
	speed: 0.1901s/iter; left time: 4496.5095s
Epoch: 5 cost time: 108.3962619304657
Epoch: 5, Steps: 525 | Train Loss: 0.2997512 Vali Loss: 0.5159177 Test Loss: 0.3396999
Validation loss decreased (0.519936 --> 0.515918).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2956602
	speed: 1.4298s/iter; left time: 33638.0373s
	iters: 200, epoch: 6 | loss: 0.2852196
	speed: 0.1900s/iter; left time: 4450.7716s
	iters: 300, epoch: 6 | loss: 0.2861453
	speed: 0.2030s/iter; left time: 4736.0171s
	iters: 400, epoch: 6 | loss: 0.2647630
	speed: 0.2003s/iter; left time: 4652.8547s
	iters: 500, epoch: 6 | loss: 0.2457563
	speed: 0.1912s/iter; left time: 4422.1059s
Epoch: 6 cost time: 104.72398447990417
Epoch: 6, Steps: 525 | Train Loss: 0.2993795 Vali Loss: 0.5145248 Test Loss: 0.3408189
Validation loss decreased (0.515918 --> 0.514525).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2968217
	speed: 1.3226s/iter; left time: 30420.1308s
	iters: 200, epoch: 7 | loss: 0.3029739
	speed: 0.2001s/iter; left time: 4583.5579s
	iters: 300, epoch: 7 | loss: 0.2869249
	speed: 0.2037s/iter; left time: 4644.6397s
	iters: 400, epoch: 7 | loss: 0.2783501
	speed: 0.2109s/iter; left time: 4787.0799s
	iters: 500, epoch: 7 | loss: 0.3469377
	speed: 0.2109s/iter; left time: 4766.2552s
Epoch: 7 cost time: 108.98534321784973
Epoch: 7, Steps: 525 | Train Loss: 0.2992046 Vali Loss: 0.5144385 Test Loss: 0.3391874
Validation loss decreased (0.514525 --> 0.514438).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2853300
	speed: 1.5540s/iter; left time: 34927.3572s
	iters: 200, epoch: 8 | loss: 0.3094983
	speed: 0.2007s/iter; left time: 4491.7378s
	iters: 300, epoch: 8 | loss: 0.2522982
	speed: 0.1927s/iter; left time: 4291.6502s
	iters: 400, epoch: 8 | loss: 0.2839802
	speed: 0.2020s/iter; left time: 4479.0388s
	iters: 500, epoch: 8 | loss: 0.2618926
	speed: 0.1930s/iter; left time: 4260.6200s
Epoch: 8 cost time: 106.16901397705078
Epoch: 8, Steps: 525 | Train Loss: 0.2991263 Vali Loss: 0.5133082 Test Loss: 0.3395544
Validation loss decreased (0.514438 --> 0.513308).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2806065
	speed: 1.3194s/iter; left time: 28963.0082s
	iters: 200, epoch: 9 | loss: 0.3266330
	speed: 0.1747s/iter; left time: 3818.0992s
	iters: 300, epoch: 9 | loss: 0.3052582
	speed: 0.1879s/iter; left time: 4087.1452s
	iters: 400, epoch: 9 | loss: 0.3565442
	speed: 0.1750s/iter; left time: 3788.0216s
	iters: 500, epoch: 9 | loss: 0.2454830
	speed: 0.1444s/iter; left time: 3112.3880s
Epoch: 9 cost time: 89.7624876499176
Epoch: 9, Steps: 525 | Train Loss: 0.2989267 Vali Loss: 0.5152909 Test Loss: 0.3394667
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3224325
	speed: 0.8997s/iter; left time: 19277.2880s
	iters: 200, epoch: 10 | loss: 0.3508502
	speed: 0.1453s/iter; left time: 3099.2848s
	iters: 300, epoch: 10 | loss: 0.2576547
	speed: 0.1879s/iter; left time: 3988.6257s
	iters: 400, epoch: 10 | loss: 0.3094405
	speed: 0.1720s/iter; left time: 3633.3989s
	iters: 500, epoch: 10 | loss: 0.3016316
	speed: 0.1663s/iter; left time: 3497.6330s
Epoch: 10 cost time: 84.91694593429565
Epoch: 10, Steps: 525 | Train Loss: 0.2989346 Vali Loss: 0.5130808 Test Loss: 0.3399084
Validation loss decreased (0.513308 --> 0.513081).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2770407
	speed: 1.2805s/iter; left time: 26763.3951s
	iters: 200, epoch: 11 | loss: 0.3002693
	speed: 0.2081s/iter; left time: 4329.6004s
	iters: 300, epoch: 11 | loss: 0.3117354
	speed: 0.1649s/iter; left time: 3412.8183s
	iters: 400, epoch: 11 | loss: 0.3048652
	speed: 0.1992s/iter; left time: 4103.5682s
	iters: 500, epoch: 11 | loss: 0.3046126
	speed: 0.2086s/iter; left time: 4277.1966s
Epoch: 11 cost time: 104.50255179405212
Epoch: 11, Steps: 525 | Train Loss: 0.2988283 Vali Loss: 0.5146367 Test Loss: 0.3397558
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3007097
	speed: 1.3367s/iter; left time: 27236.2561s
	iters: 200, epoch: 12 | loss: 0.2823900
	speed: 0.1888s/iter; left time: 3827.2992s
	iters: 300, epoch: 12 | loss: 0.3355071
	speed: 0.1957s/iter; left time: 3948.7325s
	iters: 400, epoch: 12 | loss: 0.2785146
	speed: 0.1921s/iter; left time: 3856.9208s
	iters: 500, epoch: 12 | loss: 0.2865323
	speed: 0.1940s/iter; left time: 3875.5484s
Epoch: 12 cost time: 101.58276748657227
Epoch: 12, Steps: 525 | Train Loss: 0.2988340 Vali Loss: 0.5145850 Test Loss: 0.3397709
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3267904
	speed: 1.3768s/iter; left time: 27331.4681s
	iters: 200, epoch: 13 | loss: 0.2670699
	speed: 0.1937s/iter; left time: 3826.1613s
	iters: 300, epoch: 13 | loss: 0.2535058
	speed: 0.1761s/iter; left time: 3461.1973s
	iters: 400, epoch: 13 | loss: 0.3084006
	speed: 0.1917s/iter; left time: 3747.8568s
	iters: 500, epoch: 13 | loss: 0.2848350
	speed: 0.1988s/iter; left time: 3866.1288s
Epoch: 13 cost time: 102.90226078033447
Epoch: 13, Steps: 525 | Train Loss: 0.2986087 Vali Loss: 0.5140411 Test Loss: 0.3392149
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_720_192_FITS_ETTm1_ftM_sl720_ll48_pl192_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.3399435579776764, mae:0.36976760625839233, rse:0.5550152659416199, corr:[0.5431916  0.5512249  0.5570911  0.5599505  0.56064427 0.56064606
 0.5608492  0.5616268  0.5629501  0.56444246 0.56569535 0.5663262
 0.56632924 0.56582576 0.56500536 0.5640257  0.5630026  0.5619639
 0.56082934 0.5595686  0.55822176 0.55676883 0.55521125 0.55372036
 0.5522658  0.5510302  0.5501156  0.54950845 0.5493075  0.5495049
 0.55000365 0.55075926 0.55156946 0.55233836 0.55283546 0.5530932
 0.5529812  0.55261225 0.5520858  0.5514243  0.5508225  0.5503354
 0.5500305  0.5499773  0.550028   0.5500309  0.54998004 0.54983944
 0.5495529  0.5491436  0.5487915  0.5485866  0.5485839  0.5486266
 0.548642   0.54857486 0.54843706 0.5482212  0.54805875 0.54793566
 0.54791254 0.547996   0.54811585 0.5481161  0.54801655 0.5478443
 0.547637   0.54748863 0.54751366 0.5477328  0.54814297 0.5486175
 0.5489818  0.5491192  0.5490336  0.54870856 0.54818803 0.5475785
 0.5469883  0.5465097  0.54617727 0.54595697 0.54582906 0.5457254
 0.54566693 0.5456404  0.5456972  0.54582965 0.5460543  0.5464048
 0.54681057 0.5471434  0.5473054  0.5472479  0.5469617  0.5464645
 0.545867   0.5453269  0.5447927  0.54429954 0.54385865 0.543477
 0.54317087 0.5428965  0.5427157  0.5426941  0.5427543  0.54289925
 0.54304147 0.54315263 0.54318905 0.5430916  0.5428433  0.5424727
 0.54202044 0.54154634 0.5411177  0.5407656  0.5405324  0.54045194
 0.5404617  0.54045075 0.5403024  0.54004735 0.53973526 0.53939426
 0.5390934  0.5389288  0.53890324 0.5390102  0.5391214  0.5391558
 0.53913426 0.5390784  0.53895473 0.5388311  0.53880674 0.5388015
 0.53885704 0.5389975  0.53911436 0.53921205 0.53931737 0.5394653
 0.53965783 0.5398295  0.54000574 0.5401715  0.54033923 0.54042715
 0.5403727  0.54023385 0.54002684 0.53979015 0.53956896 0.5394915
 0.53956205 0.5397143  0.53993446 0.5400975  0.54025614 0.54040587
 0.54059076 0.54080194 0.5410502  0.5413125  0.54155815 0.5417503
 0.54178435 0.5415924  0.5412929  0.5410165  0.54077816 0.54064125
 0.54063165 0.54071057 0.54078174 0.54074895 0.54050416 0.5400909
 0.5395771  0.53910303 0.53875834 0.5387218  0.53901505 0.53950584
 0.53992945 0.54018474 0.54025775 0.5401694  0.5398907  0.539483  ]
