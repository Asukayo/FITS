Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_336', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTm1_720_336_FITS_ETTm1_ftM_sl720_ll48_pl336_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=106, out_features=155, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  29442560.0
params:  16585.0
Trainable parameters:  16585
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4178040
	speed: 0.1615s/iter; left time: 1033.9658s
Epoch: 1 cost time: 20.817305326461792
Epoch: 1, Steps: 130 | Train Loss: 0.4876939 Vali Loss: 1.0659131 Test Loss: 0.6223855
Validation loss decreased (inf --> 1.065913).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3069762
	speed: 0.4244s/iter; left time: 2661.1094s
Epoch: 2 cost time: 22.24380660057068
Epoch: 2, Steps: 130 | Train Loss: 0.3260842 Vali Loss: 0.9177917 Test Loss: 0.5306767
Validation loss decreased (1.065913 --> 0.917792).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2443605
	speed: 0.4421s/iter; left time: 2714.8983s
Epoch: 3 cost time: 20.277464866638184
Epoch: 3, Steps: 130 | Train Loss: 0.2599682 Vali Loss: 0.8393945 Test Loss: 0.4822650
Validation loss decreased (0.917792 --> 0.839395).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2119129
	speed: 0.4115s/iter; left time: 2473.4241s
Epoch: 4 cost time: 18.00969886779785
Epoch: 4, Steps: 130 | Train Loss: 0.2218588 Vali Loss: 0.7986906 Test Loss: 0.4556743
Validation loss decreased (0.839395 --> 0.798691).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1923653
	speed: 0.3937s/iter; left time: 2315.0937s
Epoch: 5 cost time: 19.2786705493927
Epoch: 5, Steps: 130 | Train Loss: 0.1970855 Vali Loss: 0.7683812 Test Loss: 0.4349753
Validation loss decreased (0.798691 --> 0.768381).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1703198
	speed: 0.4012s/iter; left time: 2307.3888s
Epoch: 6 cost time: 19.68020486831665
Epoch: 6, Steps: 130 | Train Loss: 0.1801273 Vali Loss: 0.7471205 Test Loss: 0.4202019
Validation loss decreased (0.768381 --> 0.747120).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1698811
	speed: 0.3892s/iter; left time: 2187.8618s
Epoch: 7 cost time: 19.061145782470703
Epoch: 7, Steps: 130 | Train Loss: 0.1678509 Vali Loss: 0.7331603 Test Loss: 0.4096453
Validation loss decreased (0.747120 --> 0.733160).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1519497
	speed: 0.3969s/iter; left time: 2179.2620s
Epoch: 8 cost time: 18.338273525238037
Epoch: 8, Steps: 130 | Train Loss: 0.1587966 Vali Loss: 0.7208731 Test Loss: 0.4011946
Validation loss decreased (0.733160 --> 0.720873).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1561381
	speed: 0.3584s/iter; left time: 1921.4448s
Epoch: 9 cost time: 16.464520692825317
Epoch: 9, Steps: 130 | Train Loss: 0.1518999 Vali Loss: 0.7134029 Test Loss: 0.3956435
Validation loss decreased (0.720873 --> 0.713403).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1481638
	speed: 0.4184s/iter; left time: 2188.5111s
Epoch: 10 cost time: 20.62289834022522
Epoch: 10, Steps: 130 | Train Loss: 0.1465035 Vali Loss: 0.7061136 Test Loss: 0.3899605
Validation loss decreased (0.713403 --> 0.706114).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1391820
	speed: 0.4194s/iter; left time: 2139.4121s
Epoch: 11 cost time: 20.23350739479065
Epoch: 11, Steps: 130 | Train Loss: 0.1421958 Vali Loss: 0.7007163 Test Loss: 0.3856611
Validation loss decreased (0.706114 --> 0.700716).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1396493
	speed: 0.3787s/iter; left time: 1882.6308s
Epoch: 12 cost time: 18.048532247543335
Epoch: 12, Steps: 130 | Train Loss: 0.1387756 Vali Loss: 0.6959850 Test Loss: 0.3828261
Validation loss decreased (0.700716 --> 0.695985).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1402040
	speed: 0.3848s/iter; left time: 1863.0037s
Epoch: 13 cost time: 18.685096979141235
Epoch: 13, Steps: 130 | Train Loss: 0.1360576 Vali Loss: 0.6930732 Test Loss: 0.3797770
Validation loss decreased (0.695985 --> 0.693073).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1334030
	speed: 0.3730s/iter; left time: 1757.0893s
Epoch: 14 cost time: 18.194320678710938
Epoch: 14, Steps: 130 | Train Loss: 0.1337527 Vali Loss: 0.6894388 Test Loss: 0.3774375
Validation loss decreased (0.693073 --> 0.689439).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1345864
	speed: 0.3695s/iter; left time: 1692.6083s
Epoch: 15 cost time: 18.272623538970947
Epoch: 15, Steps: 130 | Train Loss: 0.1318924 Vali Loss: 0.6871384 Test Loss: 0.3758047
Validation loss decreased (0.689439 --> 0.687138).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1329389
	speed: 0.3966s/iter; left time: 1765.4410s
Epoch: 16 cost time: 18.9496910572052
Epoch: 16, Steps: 130 | Train Loss: 0.1303743 Vali Loss: 0.6836656 Test Loss: 0.3738995
Validation loss decreased (0.687138 --> 0.683666).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1273783
	speed: 0.3864s/iter; left time: 1669.5051s
Epoch: 17 cost time: 18.714155435562134
Epoch: 17, Steps: 130 | Train Loss: 0.1290979 Vali Loss: 0.6806374 Test Loss: 0.3725894
Validation loss decreased (0.683666 --> 0.680637).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1173131
	speed: 0.3853s/iter; left time: 1614.7275s
Epoch: 18 cost time: 20.673828601837158
Epoch: 18, Steps: 130 | Train Loss: 0.1280317 Vali Loss: 0.6796556 Test Loss: 0.3715455
Validation loss decreased (0.680637 --> 0.679656).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1306168
	speed: 0.4060s/iter; left time: 1648.7701s
Epoch: 19 cost time: 19.076628923416138
Epoch: 19, Steps: 130 | Train Loss: 0.1270897 Vali Loss: 0.6791980 Test Loss: 0.3711692
Validation loss decreased (0.679656 --> 0.679198).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1235855
	speed: 0.3849s/iter; left time: 1512.9107s
Epoch: 20 cost time: 17.194847583770752
Epoch: 20, Steps: 130 | Train Loss: 0.1263646 Vali Loss: 0.6776932 Test Loss: 0.3704321
Validation loss decreased (0.679198 --> 0.677693).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1207768
	speed: 0.4071s/iter; left time: 1547.3691s
Epoch: 21 cost time: 20.013518810272217
Epoch: 21, Steps: 130 | Train Loss: 0.1256854 Vali Loss: 0.6787363 Test Loss: 0.3699604
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1219834
	speed: 0.4387s/iter; left time: 1610.5305s
Epoch: 22 cost time: 22.027528524398804
Epoch: 22, Steps: 130 | Train Loss: 0.1251774 Vali Loss: 0.6781105 Test Loss: 0.3692943
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1199407
	speed: 0.4378s/iter; left time: 1550.1645s
Epoch: 23 cost time: 21.160658359527588
Epoch: 23, Steps: 130 | Train Loss: 0.1246154 Vali Loss: 0.6762193 Test Loss: 0.3690110
Validation loss decreased (0.677693 --> 0.676219).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1219892
	speed: 0.4036s/iter; left time: 1376.5125s
Epoch: 24 cost time: 16.822608709335327
Epoch: 24, Steps: 130 | Train Loss: 0.1242493 Vali Loss: 0.6765937 Test Loss: 0.3688264
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1249748
	speed: 0.3753s/iter; left time: 1231.4692s
Epoch: 25 cost time: 17.340684175491333
Epoch: 25, Steps: 130 | Train Loss: 0.1238433 Vali Loss: 0.6743806 Test Loss: 0.3685851
Validation loss decreased (0.676219 --> 0.674381).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1253659
	speed: 0.3798s/iter; left time: 1196.7282s
Epoch: 26 cost time: 18.544443607330322
Epoch: 26, Steps: 130 | Train Loss: 0.1235741 Vali Loss: 0.6742379 Test Loss: 0.3682027
Validation loss decreased (0.674381 --> 0.674238).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1277113
	speed: 0.3854s/iter; left time: 1164.4249s
Epoch: 27 cost time: 18.473649978637695
Epoch: 27, Steps: 130 | Train Loss: 0.1233118 Vali Loss: 0.6737770 Test Loss: 0.3682325
Validation loss decreased (0.674238 --> 0.673777).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1250043
	speed: 0.4053s/iter; left time: 1171.8199s
Epoch: 28 cost time: 19.871730089187622
Epoch: 28, Steps: 130 | Train Loss: 0.1230643 Vali Loss: 0.6752856 Test Loss: 0.3681979
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1259659
	speed: 0.4049s/iter; left time: 1117.9089s
Epoch: 29 cost time: 19.313098907470703
Epoch: 29, Steps: 130 | Train Loss: 0.1228391 Vali Loss: 0.6732805 Test Loss: 0.3680069
Validation loss decreased (0.673777 --> 0.673280).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1096983
	speed: 0.3900s/iter; left time: 1026.1009s
Epoch: 30 cost time: 18.978692770004272
Epoch: 30, Steps: 130 | Train Loss: 0.1226268 Vali Loss: 0.6723301 Test Loss: 0.3680941
Validation loss decreased (0.673280 --> 0.672330).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1177992
	speed: 0.3855s/iter; left time: 964.0952s
Epoch: 31 cost time: 18.79938507080078
Epoch: 31, Steps: 130 | Train Loss: 0.1224168 Vali Loss: 0.6727304 Test Loss: 0.3680813
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1240301
	speed: 0.3885s/iter; left time: 921.1793s
Epoch: 32 cost time: 18.16174030303955
Epoch: 32, Steps: 130 | Train Loss: 0.1223253 Vali Loss: 0.6739492 Test Loss: 0.3679622
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1210276
	speed: 0.3822s/iter; left time: 856.4224s
Epoch: 33 cost time: 19.106070280075073
Epoch: 33, Steps: 130 | Train Loss: 0.1221171 Vali Loss: 0.6717597 Test Loss: 0.3680927
Validation loss decreased (0.672330 --> 0.671760).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1228514
	speed: 0.4043s/iter; left time: 853.5012s
Epoch: 34 cost time: 19.669105529785156
Epoch: 34, Steps: 130 | Train Loss: 0.1219762 Vali Loss: 0.6729813 Test Loss: 0.3680833
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1138092
	speed: 0.4071s/iter; left time: 806.5080s
Epoch: 35 cost time: 19.44739317893982
Epoch: 35, Steps: 130 | Train Loss: 0.1219119 Vali Loss: 0.6727942 Test Loss: 0.3680671
EarlyStopping counter: 2 out of 3
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1239220
	speed: 0.3903s/iter; left time: 722.3608s
Epoch: 36 cost time: 18.538387298583984
Epoch: 36, Steps: 130 | Train Loss: 0.1218034 Vali Loss: 0.6725785 Test Loss: 0.3681310
EarlyStopping counter: 3 out of 3
Early stopping
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=106, out_features=155, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  29442560.0
params:  16585.0
Trainable parameters:  16585
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3307150
	speed: 0.1499s/iter; left time: 959.7898s
Epoch: 1 cost time: 19.06277298927307
Epoch: 1, Steps: 130 | Train Loss: 0.3397683 Vali Loss: 0.6611596 Test Loss: 0.3675154
Validation loss decreased (inf --> 0.661160).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3346033
	speed: 0.3730s/iter; left time: 2338.9546s
Epoch: 2 cost time: 18.556578159332275
Epoch: 2, Steps: 130 | Train Loss: 0.3379160 Vali Loss: 0.6592674 Test Loss: 0.3674323
Validation loss decreased (0.661160 --> 0.659267).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3424472
	speed: 0.4010s/iter; left time: 2462.4744s
Epoch: 3 cost time: 20.88573122024536
Epoch: 3, Steps: 130 | Train Loss: 0.3375900 Vali Loss: 0.6584370 Test Loss: 0.3670307
Validation loss decreased (0.659267 --> 0.658437).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3260711
	speed: 0.4407s/iter; left time: 2648.7594s
Epoch: 4 cost time: 20.725858688354492
Epoch: 4, Steps: 130 | Train Loss: 0.3371619 Vali Loss: 0.6574842 Test Loss: 0.3667227
Validation loss decreased (0.658437 --> 0.657484).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3417796
	speed: 0.4383s/iter; left time: 2577.8787s
Epoch: 5 cost time: 20.66716504096985
Epoch: 5, Steps: 130 | Train Loss: 0.3370795 Vali Loss: 0.6573104 Test Loss: 0.3670670
Validation loss decreased (0.657484 --> 0.657310).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3328790
	speed: 0.3732s/iter; left time: 2146.4845s
Epoch: 6 cost time: 17.231448888778687
Epoch: 6, Steps: 130 | Train Loss: 0.3367087 Vali Loss: 0.6569538 Test Loss: 0.3671998
Validation loss decreased (0.657310 --> 0.656954).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3276047
	speed: 0.3768s/iter; left time: 2117.9898s
Epoch: 7 cost time: 18.791526794433594
Epoch: 7, Steps: 130 | Train Loss: 0.3366555 Vali Loss: 0.6560544 Test Loss: 0.3665487
Validation loss decreased (0.656954 --> 0.656054).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3327940
	speed: 0.4098s/iter; left time: 2250.0847s
Epoch: 8 cost time: 19.934136867523193
Epoch: 8, Steps: 130 | Train Loss: 0.3367690 Vali Loss: 0.6550028 Test Loss: 0.3668271
Validation loss decreased (0.656054 --> 0.655003).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3161614
	speed: 0.3907s/iter; left time: 2094.6525s
Epoch: 9 cost time: 20.327073335647583
Epoch: 9, Steps: 130 | Train Loss: 0.3365367 Vali Loss: 0.6555090 Test Loss: 0.3669583
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3493049
	speed: 0.3939s/iter; left time: 2060.5164s
Epoch: 10 cost time: 17.901799201965332
Epoch: 10, Steps: 130 | Train Loss: 0.3365120 Vali Loss: 0.6562322 Test Loss: 0.3670024
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3496214
	speed: 0.3712s/iter; left time: 1893.5178s
Epoch: 11 cost time: 19.499276876449585
Epoch: 11, Steps: 130 | Train Loss: 0.3362152 Vali Loss: 0.6528314 Test Loss: 0.3671100
Validation loss decreased (0.655003 --> 0.652831).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3287482
	speed: 0.3815s/iter; left time: 1896.3756s
Epoch: 12 cost time: 20.172572135925293
Epoch: 12, Steps: 130 | Train Loss: 0.3364035 Vali Loss: 0.6527283 Test Loss: 0.3665586
Validation loss decreased (0.652831 --> 0.652728).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3384078
	speed: 0.3910s/iter; left time: 1892.8318s
Epoch: 13 cost time: 18.450701236724854
Epoch: 13, Steps: 130 | Train Loss: 0.3362301 Vali Loss: 0.6548686 Test Loss: 0.3668588
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3618607
	speed: 0.3922s/iter; left time: 1847.6190s
Epoch: 14 cost time: 19.335707902908325
Epoch: 14, Steps: 130 | Train Loss: 0.3364018 Vali Loss: 0.6543391 Test Loss: 0.3666599
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3286835
	speed: 0.3953s/iter; left time: 1810.7600s
Epoch: 15 cost time: 18.848167657852173
Epoch: 15, Steps: 130 | Train Loss: 0.3363614 Vali Loss: 0.6544723 Test Loss: 0.3667421
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_720_336_FITS_ETTm1_ftM_sl720_ll48_pl336_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.36634501814842224, mae:0.38497433066368103, rse:0.5759615302085876, corr:[0.5372053  0.5473284  0.5525128  0.5537198  0.55415684 0.5554623
 0.55730766 0.5587102  0.5592015  0.55913883 0.5592704  0.55977094
 0.5603557  0.5604477  0.55974954 0.55850893 0.5572473  0.55626637
 0.55540603 0.55440927 0.553122   0.5514954  0.5497312  0.5482751
 0.5471322  0.54628485 0.5455239  0.5446792  0.54399073 0.5437409
 0.54411435 0.5450441  0.5460082  0.5466494  0.546711   0.5465428
 0.5462804  0.5461158  0.5460361  0.5458176  0.54548746 0.54503024
 0.5445803  0.5443112  0.54416627 0.5441006  0.5441854  0.5443891
 0.5446022  0.5446909  0.54462916 0.54431355 0.54379344 0.54314333
 0.5426533  0.54252434 0.5427114  0.54290605 0.54290396 0.54255474
 0.5420538  0.5417517  0.54185826 0.5422266  0.542699   0.5430352
 0.5430792  0.5429024  0.54275167 0.5427811  0.543003   0.54321426
 0.5431946  0.54288095 0.5424063  0.54189676 0.5414486  0.5411255
 0.5409035  0.5407477  0.54062814 0.5405294  0.54047376 0.5404278
 0.54041827 0.54039377 0.5403597  0.5402949  0.5402675  0.540398
 0.54067975 0.5410161  0.54127765 0.5413751  0.5412797  0.54102606
 0.54074323 0.54057896 0.5404324  0.5402964  0.5401539  0.54000115
 0.53985626 0.5396626  0.539481   0.53935707 0.5391785  0.5389815
 0.53872585 0.5384723  0.5382479  0.5380207  0.5377638  0.53748196
 0.5371647  0.5368566  0.5366193  0.5364577  0.53639627 0.53645384
 0.5365339  0.5365246  0.53632516 0.5360412  0.5357513  0.5354731
 0.535241   0.53512543 0.53508425 0.53510314 0.5350589  0.53490376
 0.5347179  0.5345508  0.5344071  0.5343877  0.53458065 0.53480005
 0.5350008  0.5351388  0.53512365 0.5350557  0.5350686  0.5352433
 0.53553903 0.53576785 0.53586495 0.5358051  0.5357041  0.535593
 0.5354966  0.53544825 0.53536934 0.5351996  0.5349423  0.5347544
 0.53470665 0.53476715 0.53492844 0.5350357  0.535129   0.53519917
 0.5352935  0.5354113  0.5355595  0.53570527 0.53581643 0.53590184
 0.5359373  0.5359202  0.53595865 0.536055   0.53608143 0.5359889
 0.53579617 0.5355994  0.5354974  0.535564   0.5357448  0.5359768
 0.5361496  0.5362245  0.5361776  0.53613883 0.53619844 0.53636533
 0.53660065 0.536883   0.5371651  0.53737956 0.5375108  0.5375911
 0.53760874 0.53761905 0.5374811  0.53708917 0.5364394  0.53563786
 0.53477365 0.5339755  0.53329784 0.53275687 0.5322599  0.53171873
 0.5311082  0.5304504  0.5297965  0.52924    0.5287709  0.5283106
 0.5277492  0.5271029  0.5264161  0.5257845  0.52521664 0.5248251
 0.52462775 0.5244861  0.5243386  0.5241098  0.52384865 0.5236858
 0.5237219  0.52381325 0.5239255  0.5240131  0.52402204 0.52399045
 0.52398944 0.5240615  0.52418363 0.52426267 0.5242962  0.52433205
 0.5244061  0.52459836 0.52478945 0.5250913  0.52539665 0.5256741
 0.5258164  0.52568936 0.5253789  0.52505213 0.52486545 0.5247955
 0.5247852  0.5247868  0.52471447 0.52461714 0.52447015 0.5243888
 0.5243134  0.52430856 0.5242718  0.5241393  0.5239276  0.52369606
 0.52351654 0.5234646  0.5235373  0.52371264 0.52394897 0.5242676
 0.5245231  0.52464396 0.524625   0.5245179  0.5243476  0.5240945
 0.52384806 0.5236376  0.5235099  0.52351564 0.5236117  0.52375424
 0.5238425  0.52391136 0.5238884  0.52385783 0.5238034  0.5237646
 0.52382374 0.5239625  0.5240753  0.52408725 0.523903   0.5234605
 0.5228579  0.5223056  0.52188444 0.52150345 0.5211304  0.5207198
 0.5202762  0.5197559  0.5192777  0.5188092  0.5183169  0.51777554
 0.51714677 0.5165185  0.51604426 0.51576257 0.5156077  0.51540846
 0.515166   0.51475996 0.5142587  0.5138134  0.5136277  0.51366824
 0.51382935 0.5140043  0.5140115  0.51387745 0.5137197  0.5137025
 0.5138349  0.5139481  0.5139416  0.51380944 0.5136282  0.5134993
 0.513472   0.51361203 0.5137672  0.51383597 0.51371163 0.5133932
 0.5131097  0.51311165 0.5136063  0.51441866 0.5143149  0.5099523 ]
