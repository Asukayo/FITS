Args in experiment:
Namespace(H_order=12, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=512, c_out=7, checkpoints='./checkpoints/', cut_freq=106, d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm1_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTm1_720_96_FITS_ETTm1_ftM_sl720_ll48_pl96_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=106, out_features=120, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  45588480.0
params:  12840.0
Trainable parameters:  12840
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 8.57170557975769
Epoch: 1, Steps: 65 | Train Loss: 0.5131113 Vali Loss: 0.8814510 Test Loss: 0.5861952
Validation loss decreased (inf --> 0.881451).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 9.139209032058716
Epoch: 2, Steps: 65 | Train Loss: 0.3782415 Vali Loss: 0.7490225 Test Loss: 0.5144655
Validation loss decreased (0.881451 --> 0.749023).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 9.43640685081482
Epoch: 3, Steps: 65 | Train Loss: 0.3098065 Vali Loss: 0.6999077 Test Loss: 0.4941086
Validation loss decreased (0.749023 --> 0.699908).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 9.031139135360718
Epoch: 4, Steps: 65 | Train Loss: 0.2679931 Vali Loss: 0.6753962 Test Loss: 0.4879067
Validation loss decreased (0.699908 --> 0.675396).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 9.775784969329834
Epoch: 5, Steps: 65 | Train Loss: 0.2391242 Vali Loss: 0.6621577 Test Loss: 0.4856028
Validation loss decreased (0.675396 --> 0.662158).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 10.652663946151733
Epoch: 6, Steps: 65 | Train Loss: 0.2176243 Vali Loss: 0.6496775 Test Loss: 0.4821392
Validation loss decreased (0.662158 --> 0.649678).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 10.01868748664856
Epoch: 7, Steps: 65 | Train Loss: 0.2008893 Vali Loss: 0.6395514 Test Loss: 0.4791779
Validation loss decreased (0.649678 --> 0.639551).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 11.09547233581543
Epoch: 8, Steps: 65 | Train Loss: 0.1872353 Vali Loss: 0.6308984 Test Loss: 0.4765985
Validation loss decreased (0.639551 --> 0.630898).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 10.707689762115479
Epoch: 9, Steps: 65 | Train Loss: 0.1759337 Vali Loss: 0.6233591 Test Loss: 0.4728273
Validation loss decreased (0.630898 --> 0.623359).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 10.675918579101562
Epoch: 10, Steps: 65 | Train Loss: 0.1662031 Vali Loss: 0.6176893 Test Loss: 0.4698063
Validation loss decreased (0.623359 --> 0.617689).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 10.469652652740479
Epoch: 11, Steps: 65 | Train Loss: 0.1577611 Vali Loss: 0.6092530 Test Loss: 0.4672180
Validation loss decreased (0.617689 --> 0.609253).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 9.806821346282959
Epoch: 12, Steps: 65 | Train Loss: 0.1504736 Vali Loss: 0.6032658 Test Loss: 0.4624934
Validation loss decreased (0.609253 --> 0.603266).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 9.923718929290771
Epoch: 13, Steps: 65 | Train Loss: 0.1439605 Vali Loss: 0.5967100 Test Loss: 0.4593790
Validation loss decreased (0.603266 --> 0.596710).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 9.85499358177185
Epoch: 14, Steps: 65 | Train Loss: 0.1381636 Vali Loss: 0.5909292 Test Loss: 0.4560209
Validation loss decreased (0.596710 --> 0.590929).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 9.560805320739746
Epoch: 15, Steps: 65 | Train Loss: 0.1329767 Vali Loss: 0.5860085 Test Loss: 0.4535448
Validation loss decreased (0.590929 --> 0.586008).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 9.743492364883423
Epoch: 16, Steps: 65 | Train Loss: 0.1283493 Vali Loss: 0.5799337 Test Loss: 0.4505938
Validation loss decreased (0.586008 --> 0.579934).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 9.92933177947998
Epoch: 17, Steps: 65 | Train Loss: 0.1241903 Vali Loss: 0.5761794 Test Loss: 0.4475003
Validation loss decreased (0.579934 --> 0.576179).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 9.850173473358154
Epoch: 18, Steps: 65 | Train Loss: 0.1203679 Vali Loss: 0.5710309 Test Loss: 0.4449742
Validation loss decreased (0.576179 --> 0.571031).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 8.807495594024658
Epoch: 19, Steps: 65 | Train Loss: 0.1168785 Vali Loss: 0.5673879 Test Loss: 0.4424224
Validation loss decreased (0.571031 --> 0.567388).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 11.15757441520691
Epoch: 20, Steps: 65 | Train Loss: 0.1137280 Vali Loss: 0.5640619 Test Loss: 0.4406798
Validation loss decreased (0.567388 --> 0.564062).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 10.726869344711304
Epoch: 21, Steps: 65 | Train Loss: 0.1108549 Vali Loss: 0.5596164 Test Loss: 0.4382561
Validation loss decreased (0.564062 --> 0.559616).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 10.911649465560913
Epoch: 22, Steps: 65 | Train Loss: 0.1081722 Vali Loss: 0.5572916 Test Loss: 0.4360457
Validation loss decreased (0.559616 --> 0.557292).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 11.648626327514648
Epoch: 23, Steps: 65 | Train Loss: 0.1057376 Vali Loss: 0.5534227 Test Loss: 0.4339553
Validation loss decreased (0.557292 --> 0.553423).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 11.402082443237305
Epoch: 24, Steps: 65 | Train Loss: 0.1034689 Vali Loss: 0.5502570 Test Loss: 0.4323561
Validation loss decreased (0.553423 --> 0.550257).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 11.317850589752197
Epoch: 25, Steps: 65 | Train Loss: 0.1014229 Vali Loss: 0.5474998 Test Loss: 0.4308454
Validation loss decreased (0.550257 --> 0.547500).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 10.114687442779541
Epoch: 26, Steps: 65 | Train Loss: 0.0994835 Vali Loss: 0.5459048 Test Loss: 0.4289401
Validation loss decreased (0.547500 --> 0.545905).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 9.66270637512207
Epoch: 27, Steps: 65 | Train Loss: 0.0977481 Vali Loss: 0.5425489 Test Loss: 0.4273931
Validation loss decreased (0.545905 --> 0.542549).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 10.034754991531372
Epoch: 28, Steps: 65 | Train Loss: 0.0960822 Vali Loss: 0.5408773 Test Loss: 0.4260254
Validation loss decreased (0.542549 --> 0.540877).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 10.10283899307251
Epoch: 29, Steps: 65 | Train Loss: 0.0945797 Vali Loss: 0.5381216 Test Loss: 0.4246359
Validation loss decreased (0.540877 --> 0.538122).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 9.148650646209717
Epoch: 30, Steps: 65 | Train Loss: 0.0931141 Vali Loss: 0.5363289 Test Loss: 0.4231312
Validation loss decreased (0.538122 --> 0.536329).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 9.84614896774292
Epoch: 31, Steps: 65 | Train Loss: 0.0918033 Vali Loss: 0.5337985 Test Loss: 0.4219390
Validation loss decreased (0.536329 --> 0.533798).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 9.819509267807007
Epoch: 32, Steps: 65 | Train Loss: 0.0906060 Vali Loss: 0.5315996 Test Loss: 0.4209074
Validation loss decreased (0.533798 --> 0.531600).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 9.694332599639893
Epoch: 33, Steps: 65 | Train Loss: 0.0894083 Vali Loss: 0.5304641 Test Loss: 0.4196663
Validation loss decreased (0.531600 --> 0.530464).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 9.441534042358398
Epoch: 34, Steps: 65 | Train Loss: 0.0883637 Vali Loss: 0.5286101 Test Loss: 0.4187426
Validation loss decreased (0.530464 --> 0.528610).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 9.425658702850342
Epoch: 35, Steps: 65 | Train Loss: 0.0873678 Vali Loss: 0.5279632 Test Loss: 0.4176314
Validation loss decreased (0.528610 --> 0.527963).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 8.601337432861328
Epoch: 36, Steps: 65 | Train Loss: 0.0864365 Vali Loss: 0.5260254 Test Loss: 0.4166771
Validation loss decreased (0.527963 --> 0.526025).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 6.419033765792847
Epoch: 37, Steps: 65 | Train Loss: 0.0855379 Vali Loss: 0.5245146 Test Loss: 0.4155109
Validation loss decreased (0.526025 --> 0.524515).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 10.189113855361938
Epoch: 38, Steps: 65 | Train Loss: 0.0847337 Vali Loss: 0.5231648 Test Loss: 0.4149254
Validation loss decreased (0.524515 --> 0.523165).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 9.50391435623169
Epoch: 39, Steps: 65 | Train Loss: 0.0838947 Vali Loss: 0.5220919 Test Loss: 0.4140629
Validation loss decreased (0.523165 --> 0.522092).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 10.42640495300293
Epoch: 40, Steps: 65 | Train Loss: 0.0831827 Vali Loss: 0.5200000 Test Loss: 0.4132429
Validation loss decreased (0.522092 --> 0.520000).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 8.611072778701782
Epoch: 41, Steps: 65 | Train Loss: 0.0825336 Vali Loss: 0.5201641 Test Loss: 0.4125646
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 8.123144149780273
Epoch: 42, Steps: 65 | Train Loss: 0.0818323 Vali Loss: 0.5192124 Test Loss: 0.4119050
Validation loss decreased (0.520000 --> 0.519212).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 10.462193965911865
Epoch: 43, Steps: 65 | Train Loss: 0.0812510 Vali Loss: 0.5178258 Test Loss: 0.4111365
Validation loss decreased (0.519212 --> 0.517826).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 10.114871263504028
Epoch: 44, Steps: 65 | Train Loss: 0.0806344 Vali Loss: 0.5173724 Test Loss: 0.4105052
Validation loss decreased (0.517826 --> 0.517372).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 11.77146291732788
Epoch: 45, Steps: 65 | Train Loss: 0.0801353 Vali Loss: 0.5159236 Test Loss: 0.4098685
Validation loss decreased (0.517372 --> 0.515924).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 11.54782485961914
Epoch: 46, Steps: 65 | Train Loss: 0.0795730 Vali Loss: 0.5151206 Test Loss: 0.4093526
Validation loss decreased (0.515924 --> 0.515121).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 11.522639513015747
Epoch: 47, Steps: 65 | Train Loss: 0.0790893 Vali Loss: 0.5145020 Test Loss: 0.4086581
Validation loss decreased (0.515121 --> 0.514502).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 11.125905275344849
Epoch: 48, Steps: 65 | Train Loss: 0.0786493 Vali Loss: 0.5137295 Test Loss: 0.4081237
Validation loss decreased (0.514502 --> 0.513729).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 11.253132104873657
Epoch: 49, Steps: 65 | Train Loss: 0.0782456 Vali Loss: 0.5120015 Test Loss: 0.4076360
Validation loss decreased (0.513729 --> 0.512001).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 11.548092603683472
Epoch: 50, Steps: 65 | Train Loss: 0.0778002 Vali Loss: 0.5122764 Test Loss: 0.4071300
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.0497355408796396e-05
train 33745
val 11425
test 11425
Model(
  (freq_upsampler): Linear(in_features=106, out_features=120, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  45588480.0
params:  12840.0
Trainable parameters:  12840
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 11.441241025924683
Epoch: 1, Steps: 65 | Train Loss: 0.2823922 Vali Loss: 0.4264775 Test Loss: 0.3365091
Validation loss decreased (inf --> 0.426477).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 10.729857206344604
Epoch: 2, Steps: 65 | Train Loss: 0.2682054 Vali Loss: 0.4076569 Test Loss: 0.3193674
Validation loss decreased (0.426477 --> 0.407657).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 10.422254800796509
Epoch: 3, Steps: 65 | Train Loss: 0.2656925 Vali Loss: 0.4058820 Test Loss: 0.3141075
Validation loss decreased (0.407657 --> 0.405882).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 10.468308448791504
Epoch: 4, Steps: 65 | Train Loss: 0.2646375 Vali Loss: 0.4022728 Test Loss: 0.3121891
Validation loss decreased (0.405882 --> 0.402273).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 10.342136144638062
Epoch: 5, Steps: 65 | Train Loss: 0.2640954 Vali Loss: 0.3993409 Test Loss: 0.3116941
Validation loss decreased (0.402273 --> 0.399341).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 10.318920373916626
Epoch: 6, Steps: 65 | Train Loss: 0.2634682 Vali Loss: 0.3997991 Test Loss: 0.3110343
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 10.856245040893555
Epoch: 7, Steps: 65 | Train Loss: 0.2634941 Vali Loss: 0.3982412 Test Loss: 0.3103034
Validation loss decreased (0.399341 --> 0.398241).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 10.64821720123291
Epoch: 8, Steps: 65 | Train Loss: 0.2630431 Vali Loss: 0.3974885 Test Loss: 0.3104981
Validation loss decreased (0.398241 --> 0.397488).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 10.244840860366821
Epoch: 9, Steps: 65 | Train Loss: 0.2630237 Vali Loss: 0.3959303 Test Loss: 0.3102427
Validation loss decreased (0.397488 --> 0.395930).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 10.63904333114624
Epoch: 10, Steps: 65 | Train Loss: 0.2626973 Vali Loss: 0.3979673 Test Loss: 0.3098888
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 10.341469049453735
Epoch: 11, Steps: 65 | Train Loss: 0.2627761 Vali Loss: 0.3952501 Test Loss: 0.3101339
Validation loss decreased (0.395930 --> 0.395250).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 10.32884430885315
Epoch: 12, Steps: 65 | Train Loss: 0.2625097 Vali Loss: 0.3957046 Test Loss: 0.3102854
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 9.960503339767456
Epoch: 13, Steps: 65 | Train Loss: 0.2625396 Vali Loss: 0.3958588 Test Loss: 0.3100437
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 9.451231479644775
Epoch: 14, Steps: 65 | Train Loss: 0.2623155 Vali Loss: 0.3961911 Test Loss: 0.3099389
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_720_96_FITS_ETTm1_ftM_sl720_ll48_pl96_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.31056445837020874, mae:0.35306015610694885, rse:0.5302830934524536, corr:[0.54493654 0.5569775  0.56307393 0.5641646  0.5642534  0.56548005
 0.5675702  0.56931466 0.5699475  0.5697487  0.56961536 0.56989825
 0.5704114  0.57056963 0.56996113 0.5687182  0.5673456  0.56621766
 0.56526643 0.5642922  0.5631069  0.56156826 0.55981636 0.55827075
 0.556913   0.55577123 0.55470115 0.55358964 0.55275905 0.5524721
 0.5528039  0.55361205 0.5544185  0.55498904 0.5551748  0.5553428
 0.55540526 0.55532473 0.5550116  0.5543533  0.5537011  0.55334616
 0.55345875 0.5539158  0.55419016 0.5540133  0.5535804  0.5532293
 0.55319864 0.55342937 0.553729   0.5537639  0.5534708  0.552914
 0.5524986  0.55250174 0.5527996  0.5529415  0.5527696  0.5521884
 0.55154186 0.55124015 0.5514354  0.5517652  0.55202764 0.5520839
 0.5519609  0.55188495 0.5520783  0.5524063  0.55261934 0.55243367
 0.5518154  0.55102545 0.5505404  0.5504687  0.5506212  0.5506891
 0.5503807  0.5496375  0.5487692  0.54816294 0.5480908  0.5482912
 0.5483662  0.5478907  0.5469541  0.5459773  0.54550916 0.5458732
 0.54658127 0.54689443 0.5467348  0.54682595 0.54782265 0.5489153 ]
