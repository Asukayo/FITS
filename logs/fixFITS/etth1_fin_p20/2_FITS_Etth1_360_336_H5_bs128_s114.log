Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_360_336', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_360_336_FITS_ETTh1_ftM_sl360_ll48_pl336_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7945
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=90, out_features=174, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  28062720.0
params:  15834.0
Trainable parameters:  15834
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 0.764350414276123
Epoch: 1, Steps: 31 | Train Loss: 0.7873015 Vali Loss: 2.0068645 Test Loss: 0.9736297
Validation loss decreased (inf --> 2.006865).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.8687725067138672
Epoch: 2, Steps: 31 | Train Loss: 0.6790777 Vali Loss: 1.8480448 Test Loss: 0.8845717
Validation loss decreased (2.006865 --> 1.848045).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 0.8118240833282471
Epoch: 3, Steps: 31 | Train Loss: 0.6055427 Vali Loss: 1.7462093 Test Loss: 0.8246997
Validation loss decreased (1.848045 --> 1.746209).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 0.8027069568634033
Epoch: 4, Steps: 31 | Train Loss: 0.5558547 Vali Loss: 1.6776508 Test Loss: 0.7840999
Validation loss decreased (1.746209 --> 1.677651).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 0.8958327770233154
Epoch: 5, Steps: 31 | Train Loss: 0.5209407 Vali Loss: 1.6327978 Test Loss: 0.7561210
Validation loss decreased (1.677651 --> 1.632798).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 0.8184072971343994
Epoch: 6, Steps: 31 | Train Loss: 0.4955804 Vali Loss: 1.5957112 Test Loss: 0.7364786
Validation loss decreased (1.632798 --> 1.595711).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 0.8599073886871338
Epoch: 7, Steps: 31 | Train Loss: 0.4764342 Vali Loss: 1.5656028 Test Loss: 0.7221549
Validation loss decreased (1.595711 --> 1.565603).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 0.784003496170044
Epoch: 8, Steps: 31 | Train Loss: 0.4615527 Vali Loss: 1.5520337 Test Loss: 0.7114627
Validation loss decreased (1.565603 --> 1.552034).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 0.8457484245300293
Epoch: 9, Steps: 31 | Train Loss: 0.4494756 Vali Loss: 1.5312313 Test Loss: 0.7026154
Validation loss decreased (1.552034 --> 1.531231).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 0.8496026992797852
Epoch: 10, Steps: 31 | Train Loss: 0.4395325 Vali Loss: 1.5274919 Test Loss: 0.6954331
Validation loss decreased (1.531231 --> 1.527492).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 0.812896728515625
Epoch: 11, Steps: 31 | Train Loss: 0.4310019 Vali Loss: 1.5147055 Test Loss: 0.6886946
Validation loss decreased (1.527492 --> 1.514706).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 0.8472874164581299
Epoch: 12, Steps: 31 | Train Loss: 0.4236831 Vali Loss: 1.5046387 Test Loss: 0.6832535
Validation loss decreased (1.514706 --> 1.504639).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 0.82997727394104
Epoch: 13, Steps: 31 | Train Loss: 0.4172144 Vali Loss: 1.4933754 Test Loss: 0.6783797
Validation loss decreased (1.504639 --> 1.493375).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 0.7794837951660156
Epoch: 14, Steps: 31 | Train Loss: 0.4115049 Vali Loss: 1.4940846 Test Loss: 0.6740824
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 0.7802059650421143
Epoch: 15, Steps: 31 | Train Loss: 0.4062922 Vali Loss: 1.4820189 Test Loss: 0.6695994
Validation loss decreased (1.493375 --> 1.482019).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 0.788886547088623
Epoch: 16, Steps: 31 | Train Loss: 0.4015559 Vali Loss: 1.4773538 Test Loss: 0.6656724
Validation loss decreased (1.482019 --> 1.477354).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 0.7984497547149658
Epoch: 17, Steps: 31 | Train Loss: 0.3973438 Vali Loss: 1.4702854 Test Loss: 0.6619524
Validation loss decreased (1.477354 --> 1.470285).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 0.7545230388641357
Epoch: 18, Steps: 31 | Train Loss: 0.3934149 Vali Loss: 1.4626590 Test Loss: 0.6586567
Validation loss decreased (1.470285 --> 1.462659).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 0.7913134098052979
Epoch: 19, Steps: 31 | Train Loss: 0.3897253 Vali Loss: 1.4601438 Test Loss: 0.6554319
Validation loss decreased (1.462659 --> 1.460144).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 0.7388911247253418
Epoch: 20, Steps: 31 | Train Loss: 0.3864741 Vali Loss: 1.4566869 Test Loss: 0.6522160
Validation loss decreased (1.460144 --> 1.456687).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 0.7039427757263184
Epoch: 21, Steps: 31 | Train Loss: 0.3832688 Vali Loss: 1.4562466 Test Loss: 0.6495904
Validation loss decreased (1.456687 --> 1.456247).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 0.790452241897583
Epoch: 22, Steps: 31 | Train Loss: 0.3802852 Vali Loss: 1.4491191 Test Loss: 0.6467128
Validation loss decreased (1.456247 --> 1.449119).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 0.8517417907714844
Epoch: 23, Steps: 31 | Train Loss: 0.3777041 Vali Loss: 1.4371763 Test Loss: 0.6442907
Validation loss decreased (1.449119 --> 1.437176).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 0.7157275676727295
Epoch: 24, Steps: 31 | Train Loss: 0.3751453 Vali Loss: 1.4351737 Test Loss: 0.6415465
Validation loss decreased (1.437176 --> 1.435174).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 0.831519603729248
Epoch: 25, Steps: 31 | Train Loss: 0.3728326 Vali Loss: 1.4320549 Test Loss: 0.6396540
Validation loss decreased (1.435174 --> 1.432055).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 0.7774474620819092
Epoch: 26, Steps: 31 | Train Loss: 0.3706669 Vali Loss: 1.4334353 Test Loss: 0.6372378
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 0.7337081432342529
Epoch: 27, Steps: 31 | Train Loss: 0.3686499 Vali Loss: 1.4301413 Test Loss: 0.6352307
Validation loss decreased (1.432055 --> 1.430141).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 0.7766692638397217
Epoch: 28, Steps: 31 | Train Loss: 0.3667217 Vali Loss: 1.4350755 Test Loss: 0.6335750
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 0.7368113994598389
Epoch: 29, Steps: 31 | Train Loss: 0.3649572 Vali Loss: 1.4233720 Test Loss: 0.6314094
Validation loss decreased (1.430141 --> 1.423372).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 0.7784662246704102
Epoch: 30, Steps: 31 | Train Loss: 0.3631841 Vali Loss: 1.4245323 Test Loss: 0.6298661
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 0.755875825881958
Epoch: 31, Steps: 31 | Train Loss: 0.3616097 Vali Loss: 1.4260697 Test Loss: 0.6283321
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 0.767331600189209
Epoch: 32, Steps: 31 | Train Loss: 0.3602139 Vali Loss: 1.4088764 Test Loss: 0.6265716
Validation loss decreased (1.423372 --> 1.408876).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 0.7787692546844482
Epoch: 33, Steps: 31 | Train Loss: 0.3588661 Vali Loss: 1.4104939 Test Loss: 0.6251692
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 0.8148019313812256
Epoch: 34, Steps: 31 | Train Loss: 0.3575080 Vali Loss: 1.4203953 Test Loss: 0.6237968
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 0.7995338439941406
Epoch: 35, Steps: 31 | Train Loss: 0.3562118 Vali Loss: 1.4086924 Test Loss: 0.6223658
Validation loss decreased (1.408876 --> 1.408692).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 0.758622407913208
Epoch: 36, Steps: 31 | Train Loss: 0.3551433 Vali Loss: 1.4127144 Test Loss: 0.6210841
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 0.7666897773742676
Epoch: 37, Steps: 31 | Train Loss: 0.3540472 Vali Loss: 1.4060317 Test Loss: 0.6200319
Validation loss decreased (1.408692 --> 1.406032).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 0.7138779163360596
Epoch: 38, Steps: 31 | Train Loss: 0.3529333 Vali Loss: 1.4116964 Test Loss: 0.6189179
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 0.8082835674285889
Epoch: 39, Steps: 31 | Train Loss: 0.3519755 Vali Loss: 1.4105729 Test Loss: 0.6177701
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 0.755378246307373
Epoch: 40, Steps: 31 | Train Loss: 0.3510871 Vali Loss: 1.4042002 Test Loss: 0.6167604
Validation loss decreased (1.406032 --> 1.404200).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 0.7122893333435059
Epoch: 41, Steps: 31 | Train Loss: 0.3501872 Vali Loss: 1.4021335 Test Loss: 0.6158732
Validation loss decreased (1.404200 --> 1.402133).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 0.782160758972168
Epoch: 42, Steps: 31 | Train Loss: 0.3493844 Vali Loss: 1.4035643 Test Loss: 0.6148593
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 0.737356424331665
Epoch: 43, Steps: 31 | Train Loss: 0.3485498 Vali Loss: 1.4051943 Test Loss: 0.6139261
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 0.7317540645599365
Epoch: 44, Steps: 31 | Train Loss: 0.3478578 Vali Loss: 1.4027060 Test Loss: 0.6132178
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 0.7675726413726807
Epoch: 45, Steps: 31 | Train Loss: 0.3471429 Vali Loss: 1.3953004 Test Loss: 0.6123499
Validation loss decreased (1.402133 --> 1.395300).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 0.7736566066741943
Epoch: 46, Steps: 31 | Train Loss: 0.3464842 Vali Loss: 1.4011942 Test Loss: 0.6116210
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 0.765692949295044
Epoch: 47, Steps: 31 | Train Loss: 0.3459162 Vali Loss: 1.3989958 Test Loss: 0.6109478
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 0.7367348670959473
Epoch: 48, Steps: 31 | Train Loss: 0.3452059 Vali Loss: 1.3960139 Test Loss: 0.6102104
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 0.7878766059875488
Epoch: 49, Steps: 31 | Train Loss: 0.3445826 Vali Loss: 1.3987399 Test Loss: 0.6096262
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 0.7796530723571777
Epoch: 50, Steps: 31 | Train Loss: 0.3441685 Vali Loss: 1.3862433 Test Loss: 0.6090299
Validation loss decreased (1.395300 --> 1.386243).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 0.8147330284118652
Epoch: 51, Steps: 31 | Train Loss: 0.3437519 Vali Loss: 1.3916817 Test Loss: 0.6084756
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 0.7452185153961182
Epoch: 52, Steps: 31 | Train Loss: 0.3431035 Vali Loss: 1.3905871 Test Loss: 0.6078418
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 0.7233586311340332
Epoch: 53, Steps: 31 | Train Loss: 0.3426484 Vali Loss: 1.3931494 Test Loss: 0.6073468
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 0.6821236610412598
Epoch: 54, Steps: 31 | Train Loss: 0.3422722 Vali Loss: 1.3909059 Test Loss: 0.6068469
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 0.6847684383392334
Epoch: 55, Steps: 31 | Train Loss: 0.3418447 Vali Loss: 1.3844171 Test Loss: 0.6063843
Validation loss decreased (1.386243 --> 1.384417).  Saving model ...
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 0.7373836040496826
Epoch: 56, Steps: 31 | Train Loss: 0.3414605 Vali Loss: 1.3853042 Test Loss: 0.6059923
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 0.7871177196502686
Epoch: 57, Steps: 31 | Train Loss: 0.3410497 Vali Loss: 1.3862754 Test Loss: 0.6055356
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 0.8046915531158447
Epoch: 58, Steps: 31 | Train Loss: 0.3407535 Vali Loss: 1.3871152 Test Loss: 0.6050392
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 0.7284433841705322
Epoch: 59, Steps: 31 | Train Loss: 0.3404540 Vali Loss: 1.3836873 Test Loss: 0.6047313
Validation loss decreased (1.384417 --> 1.383687).  Saving model ...
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 0.7545151710510254
Epoch: 60, Steps: 31 | Train Loss: 0.3401526 Vali Loss: 1.3842111 Test Loss: 0.6043833
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 0.8176851272583008
Epoch: 61, Steps: 31 | Train Loss: 0.3397779 Vali Loss: 1.3777153 Test Loss: 0.6040416
Validation loss decreased (1.383687 --> 1.377715).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 0.7840979099273682
Epoch: 62, Steps: 31 | Train Loss: 0.3395068 Vali Loss: 1.3881074 Test Loss: 0.6037027
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 0.8343067169189453
Epoch: 63, Steps: 31 | Train Loss: 0.3392928 Vali Loss: 1.3849931 Test Loss: 0.6033853
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 0.7767157554626465
Epoch: 64, Steps: 31 | Train Loss: 0.3389084 Vali Loss: 1.3900462 Test Loss: 0.6030888
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 0.7596240043640137
Epoch: 65, Steps: 31 | Train Loss: 0.3388021 Vali Loss: 1.3807986 Test Loss: 0.6027724
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 0.7512712478637695
Epoch: 66, Steps: 31 | Train Loss: 0.3384464 Vali Loss: 1.3825130 Test Loss: 0.6025419
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 0.7553219795227051
Epoch: 67, Steps: 31 | Train Loss: 0.3383696 Vali Loss: 1.3832126 Test Loss: 0.6022474
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 0.7422182559967041
Epoch: 68, Steps: 31 | Train Loss: 0.3381418 Vali Loss: 1.3844615 Test Loss: 0.6020451
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 0.7377233505249023
Epoch: 69, Steps: 31 | Train Loss: 0.3378889 Vali Loss: 1.3843701 Test Loss: 0.6018092
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 0.7550406455993652
Epoch: 70, Steps: 31 | Train Loss: 0.3377445 Vali Loss: 1.3807607 Test Loss: 0.6015774
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 0.7181017398834229
Epoch: 71, Steps: 31 | Train Loss: 0.3375486 Vali Loss: 1.3787968 Test Loss: 0.6013621
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 0.7265441417694092
Epoch: 72, Steps: 31 | Train Loss: 0.3373506 Vali Loss: 1.3812976 Test Loss: 0.6011721
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 0.7291498184204102
Epoch: 73, Steps: 31 | Train Loss: 0.3371128 Vali Loss: 1.3737831 Test Loss: 0.6010016
Validation loss decreased (1.377715 --> 1.373783).  Saving model ...
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 0.7692978382110596
Epoch: 74, Steps: 31 | Train Loss: 0.3370652 Vali Loss: 1.3856946 Test Loss: 0.6008078
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 0.7591331005096436
Epoch: 75, Steps: 31 | Train Loss: 0.3368928 Vali Loss: 1.3835549 Test Loss: 0.6006395
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 0.6882472038269043
Epoch: 76, Steps: 31 | Train Loss: 0.3367749 Vali Loss: 1.3857545 Test Loss: 0.6004530
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 0.7853727340698242
Epoch: 77, Steps: 31 | Train Loss: 0.3366261 Vali Loss: 1.3777549 Test Loss: 0.6003367
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 0.7270298004150391
Epoch: 78, Steps: 31 | Train Loss: 0.3365400 Vali Loss: 1.3829570 Test Loss: 0.6001783
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 0.773200511932373
Epoch: 79, Steps: 31 | Train Loss: 0.3364065 Vali Loss: 1.3860769 Test Loss: 0.6000389
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 0.7539200782775879
Epoch: 80, Steps: 31 | Train Loss: 0.3362530 Vali Loss: 1.3800290 Test Loss: 0.5999182
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 0.7201604843139648
Epoch: 81, Steps: 31 | Train Loss: 0.3361343 Vali Loss: 1.3826928 Test Loss: 0.5997893
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 0.7735486030578613
Epoch: 82, Steps: 31 | Train Loss: 0.3361125 Vali Loss: 1.3826412 Test Loss: 0.5996631
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 0.7046103477478027
Epoch: 83, Steps: 31 | Train Loss: 0.3358834 Vali Loss: 1.3780771 Test Loss: 0.5995468
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 0.6955165863037109
Epoch: 84, Steps: 31 | Train Loss: 0.3357595 Vali Loss: 1.3799757 Test Loss: 0.5994305
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 0.7545628547668457
Epoch: 85, Steps: 31 | Train Loss: 0.3357844 Vali Loss: 1.3798805 Test Loss: 0.5993370
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 0.742267370223999
Epoch: 86, Steps: 31 | Train Loss: 0.3356525 Vali Loss: 1.3770667 Test Loss: 0.5992389
EarlyStopping counter: 13 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 0.7433397769927979
Epoch: 87, Steps: 31 | Train Loss: 0.3355411 Vali Loss: 1.3773710 Test Loss: 0.5991434
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 0.770195484161377
Epoch: 88, Steps: 31 | Train Loss: 0.3355733 Vali Loss: 1.3807998 Test Loss: 0.5990537
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 0.6984279155731201
Epoch: 89, Steps: 31 | Train Loss: 0.3354223 Vali Loss: 1.3732454 Test Loss: 0.5989783
Validation loss decreased (1.373783 --> 1.373245).  Saving model ...
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 0.8217959403991699
Epoch: 90, Steps: 31 | Train Loss: 0.3353784 Vali Loss: 1.3780427 Test Loss: 0.5988990
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 0.730811595916748
Epoch: 91, Steps: 31 | Train Loss: 0.3353797 Vali Loss: 1.3763670 Test Loss: 0.5988241
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 0.7019314765930176
Epoch: 92, Steps: 31 | Train Loss: 0.3352514 Vali Loss: 1.3770436 Test Loss: 0.5987467
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 0.7084648609161377
Epoch: 93, Steps: 31 | Train Loss: 0.3351352 Vali Loss: 1.3780593 Test Loss: 0.5986803
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 0.7400977611541748
Epoch: 94, Steps: 31 | Train Loss: 0.3351077 Vali Loss: 1.3803439 Test Loss: 0.5986129
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 0.7654521465301514
Epoch: 95, Steps: 31 | Train Loss: 0.3350701 Vali Loss: 1.3729895 Test Loss: 0.5985612
Validation loss decreased (1.373245 --> 1.372990).  Saving model ...
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 0.7913732528686523
Epoch: 96, Steps: 31 | Train Loss: 0.3350206 Vali Loss: 1.3782005 Test Loss: 0.5985009
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 0.7183761596679688
Epoch: 97, Steps: 31 | Train Loss: 0.3349502 Vali Loss: 1.3770221 Test Loss: 0.5984371
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 0.8015661239624023
Epoch: 98, Steps: 31 | Train Loss: 0.3349499 Vali Loss: 1.3772906 Test Loss: 0.5983947
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 0.6894850730895996
Epoch: 99, Steps: 31 | Train Loss: 0.3348638 Vali Loss: 1.3719974 Test Loss: 0.5983388
Validation loss decreased (1.372990 --> 1.371997).  Saving model ...
Updating learning rate to 3.2800715902127414e-06
Epoch: 100 cost time: 0.7004239559173584
Epoch: 100, Steps: 31 | Train Loss: 0.3347854 Vali Loss: 1.3766389 Test Loss: 0.5982909
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.1160680107021042e-06
train 7945
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=90, out_features=174, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  28062720.0
params:  15834.0
Trainable parameters:  15834
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 0.7391290664672852
Epoch: 1, Steps: 31 | Train Loss: 0.5410928 Vali Loss: 1.3370327 Test Loss: 0.5624225
Validation loss decreased (inf --> 1.337033).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.773867130279541
Epoch: 2, Steps: 31 | Train Loss: 0.5227322 Vali Loss: 1.3007249 Test Loss: 0.5364826
Validation loss decreased (1.337033 --> 1.300725).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 0.7922937870025635
Epoch: 3, Steps: 31 | Train Loss: 0.5095836 Vali Loss: 1.2700791 Test Loss: 0.5166471
Validation loss decreased (1.300725 --> 1.270079).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 0.8239531517028809
Epoch: 4, Steps: 31 | Train Loss: 0.4995751 Vali Loss: 1.2534446 Test Loss: 0.5014629
Validation loss decreased (1.270079 --> 1.253445).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 0.7890715599060059
Epoch: 5, Steps: 31 | Train Loss: 0.4915610 Vali Loss: 1.2420025 Test Loss: 0.4894485
Validation loss decreased (1.253445 --> 1.242002).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 0.7886977195739746
Epoch: 6, Steps: 31 | Train Loss: 0.4854220 Vali Loss: 1.2263653 Test Loss: 0.4793281
Validation loss decreased (1.242002 --> 1.226365).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 0.7797455787658691
Epoch: 7, Steps: 31 | Train Loss: 0.4803437 Vali Loss: 1.2096345 Test Loss: 0.4713100
Validation loss decreased (1.226365 --> 1.209635).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 0.8540942668914795
Epoch: 8, Steps: 31 | Train Loss: 0.4760644 Vali Loss: 1.2057204 Test Loss: 0.4648519
Validation loss decreased (1.209635 --> 1.205720).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 0.8574349880218506
Epoch: 9, Steps: 31 | Train Loss: 0.4726277 Vali Loss: 1.1977153 Test Loss: 0.4594800
Validation loss decreased (1.205720 --> 1.197715).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 0.8805375099182129
Epoch: 10, Steps: 31 | Train Loss: 0.4697483 Vali Loss: 1.1952577 Test Loss: 0.4550027
Validation loss decreased (1.197715 --> 1.195258).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 0.770073413848877
Epoch: 11, Steps: 31 | Train Loss: 0.4674372 Vali Loss: 1.1860079 Test Loss: 0.4514387
Validation loss decreased (1.195258 --> 1.186008).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 0.8336217403411865
Epoch: 12, Steps: 31 | Train Loss: 0.4655459 Vali Loss: 1.1822450 Test Loss: 0.4483828
Validation loss decreased (1.186008 --> 1.182245).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 0.7837252616882324
Epoch: 13, Steps: 31 | Train Loss: 0.4639862 Vali Loss: 1.1807628 Test Loss: 0.4458128
Validation loss decreased (1.182245 --> 1.180763).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 0.7502763271331787
Epoch: 14, Steps: 31 | Train Loss: 0.4625955 Vali Loss: 1.1786338 Test Loss: 0.4438075
Validation loss decreased (1.180763 --> 1.178634).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 0.7418136596679688
Epoch: 15, Steps: 31 | Train Loss: 0.4614365 Vali Loss: 1.1774044 Test Loss: 0.4420136
Validation loss decreased (1.178634 --> 1.177404).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 0.8479580879211426
Epoch: 16, Steps: 31 | Train Loss: 0.4604710 Vali Loss: 1.1746840 Test Loss: 0.4405842
Validation loss decreased (1.177404 --> 1.174684).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 0.8141112327575684
Epoch: 17, Steps: 31 | Train Loss: 0.4595792 Vali Loss: 1.1713678 Test Loss: 0.4392965
Validation loss decreased (1.174684 --> 1.171368).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 0.8000607490539551
Epoch: 18, Steps: 31 | Train Loss: 0.4590456 Vali Loss: 1.1619759 Test Loss: 0.4383290
Validation loss decreased (1.171368 --> 1.161976).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 0.8348112106323242
Epoch: 19, Steps: 31 | Train Loss: 0.4584088 Vali Loss: 1.1708270 Test Loss: 0.4375712
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 0.7217361927032471
Epoch: 20, Steps: 31 | Train Loss: 0.4577602 Vali Loss: 1.1706073 Test Loss: 0.4366474
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 0.8048653602600098
Epoch: 21, Steps: 31 | Train Loss: 0.4574896 Vali Loss: 1.1633492 Test Loss: 0.4360867
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 0.7456505298614502
Epoch: 22, Steps: 31 | Train Loss: 0.4571108 Vali Loss: 1.1722623 Test Loss: 0.4355388
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 0.7586336135864258
Epoch: 23, Steps: 31 | Train Loss: 0.4566809 Vali Loss: 1.1659477 Test Loss: 0.4351307
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 0.747941255569458
Epoch: 24, Steps: 31 | Train Loss: 0.4563406 Vali Loss: 1.1664431 Test Loss: 0.4347094
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 0.768998384475708
Epoch: 25, Steps: 31 | Train Loss: 0.4562693 Vali Loss: 1.1670123 Test Loss: 0.4343302
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 0.7324590682983398
Epoch: 26, Steps: 31 | Train Loss: 0.4560336 Vali Loss: 1.1607192 Test Loss: 0.4340721
Validation loss decreased (1.161976 --> 1.160719).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 0.7498688697814941
Epoch: 27, Steps: 31 | Train Loss: 0.4558544 Vali Loss: 1.1603268 Test Loss: 0.4338371
Validation loss decreased (1.160719 --> 1.160327).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 0.8062922954559326
Epoch: 28, Steps: 31 | Train Loss: 0.4558301 Vali Loss: 1.1579407 Test Loss: 0.4335899
Validation loss decreased (1.160327 --> 1.157941).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 0.7308506965637207
Epoch: 29, Steps: 31 | Train Loss: 0.4555689 Vali Loss: 1.1601844 Test Loss: 0.4333729
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 0.709463357925415
Epoch: 30, Steps: 31 | Train Loss: 0.4553599 Vali Loss: 1.1655256 Test Loss: 0.4332301
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 0.7312803268432617
Epoch: 31, Steps: 31 | Train Loss: 0.4551433 Vali Loss: 1.1596627 Test Loss: 0.4330499
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 0.7017931938171387
Epoch: 32, Steps: 31 | Train Loss: 0.4553771 Vali Loss: 1.1644537 Test Loss: 0.4329501
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 0.7440629005432129
Epoch: 33, Steps: 31 | Train Loss: 0.4550101 Vali Loss: 1.1607713 Test Loss: 0.4328540
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 0.7198288440704346
Epoch: 34, Steps: 31 | Train Loss: 0.4550431 Vali Loss: 1.1598783 Test Loss: 0.4327482
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 0.7450428009033203
Epoch: 35, Steps: 31 | Train Loss: 0.4548987 Vali Loss: 1.1628954 Test Loss: 0.4326848
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 0.7414214611053467
Epoch: 36, Steps: 31 | Train Loss: 0.4548587 Vali Loss: 1.1592432 Test Loss: 0.4326096
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 0.734278678894043
Epoch: 37, Steps: 31 | Train Loss: 0.4548640 Vali Loss: 1.1589859 Test Loss: 0.4325556
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 0.7115776538848877
Epoch: 38, Steps: 31 | Train Loss: 0.4548157 Vali Loss: 1.1603110 Test Loss: 0.4324763
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 0.7088778018951416
Epoch: 39, Steps: 31 | Train Loss: 0.4548334 Vali Loss: 1.1533916 Test Loss: 0.4324026
Validation loss decreased (1.157941 --> 1.153392).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 0.791109561920166
Epoch: 40, Steps: 31 | Train Loss: 0.4546517 Vali Loss: 1.1609823 Test Loss: 0.4323858
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 0.7485792636871338
Epoch: 41, Steps: 31 | Train Loss: 0.4546240 Vali Loss: 1.1618615 Test Loss: 0.4323365
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 0.7993905544281006
Epoch: 42, Steps: 31 | Train Loss: 0.4546188 Vali Loss: 1.1550369 Test Loss: 0.4322774
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 0.7140617370605469
Epoch: 43, Steps: 31 | Train Loss: 0.4545977 Vali Loss: 1.1570815 Test Loss: 0.4322456
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 0.7261464595794678
Epoch: 44, Steps: 31 | Train Loss: 0.4545486 Vali Loss: 1.1586163 Test Loss: 0.4322036
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 0.7965903282165527
Epoch: 45, Steps: 31 | Train Loss: 0.4543593 Vali Loss: 1.1573563 Test Loss: 0.4322033
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 0.7191190719604492
Epoch: 46, Steps: 31 | Train Loss: 0.4544918 Vali Loss: 1.1581253 Test Loss: 0.4321536
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 0.8107798099517822
Epoch: 47, Steps: 31 | Train Loss: 0.4545066 Vali Loss: 1.1556108 Test Loss: 0.4321266
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 0.7648196220397949
Epoch: 48, Steps: 31 | Train Loss: 0.4545033 Vali Loss: 1.1623523 Test Loss: 0.4321327
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 0.7919201850891113
Epoch: 49, Steps: 31 | Train Loss: 0.4544024 Vali Loss: 1.1595327 Test Loss: 0.4321035
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 0.7623286247253418
Epoch: 50, Steps: 31 | Train Loss: 0.4543158 Vali Loss: 1.1609573 Test Loss: 0.4320925
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 0.757622480392456
Epoch: 51, Steps: 31 | Train Loss: 0.4543594 Vali Loss: 1.1615939 Test Loss: 0.4320831
EarlyStopping counter: 12 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 0.7138853073120117
Epoch: 52, Steps: 31 | Train Loss: 0.4542614 Vali Loss: 1.1621857 Test Loss: 0.4320498
EarlyStopping counter: 13 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 0.6755580902099609
Epoch: 53, Steps: 31 | Train Loss: 0.4542514 Vali Loss: 1.1576993 Test Loss: 0.4320546
EarlyStopping counter: 14 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 0.708629846572876
Epoch: 54, Steps: 31 | Train Loss: 0.4543001 Vali Loss: 1.1563153 Test Loss: 0.4320411
EarlyStopping counter: 15 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 0.7654962539672852
Epoch: 55, Steps: 31 | Train Loss: 0.4543418 Vali Loss: 1.1551309 Test Loss: 0.4320179
EarlyStopping counter: 16 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 0.7538282871246338
Epoch: 56, Steps: 31 | Train Loss: 0.4543734 Vali Loss: 1.1611605 Test Loss: 0.4320140
EarlyStopping counter: 17 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 0.7844536304473877
Epoch: 57, Steps: 31 | Train Loss: 0.4541732 Vali Loss: 1.1638209 Test Loss: 0.4320011
EarlyStopping counter: 18 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 0.7629644870758057
Epoch: 58, Steps: 31 | Train Loss: 0.4542573 Vali Loss: 1.1594224 Test Loss: 0.4319967
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 0.7378108501434326
Epoch: 59, Steps: 31 | Train Loss: 0.4541857 Vali Loss: 1.1576712 Test Loss: 0.4319895
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_360_336_FITS_ETTh1_ftM_sl360_ll48_pl336_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.4306151568889618, mae:0.43071240186691284, rse:0.6247362494468689, corr:[0.2504625  0.2569726  0.2551851  0.25773266 0.25728863 0.2539266
 0.25199515 0.253136   0.25403488 0.25337905 0.25220543 0.25167257
 0.2519028  0.25181234 0.25100872 0.2502844  0.25013936 0.25039023
 0.25049794 0.25010604 0.24982741 0.25017294 0.25098693 0.25139377
 0.25100157 0.25069037 0.25084406 0.25077558 0.25008208 0.24938719
 0.24928257 0.24932098 0.24887379 0.2481424  0.24787726 0.2481437
 0.24840017 0.24822223 0.24795528 0.2479939  0.24843265 0.24884294
 0.24896449 0.24870813 0.24844445 0.24852398 0.24898927 0.24923708
 0.24879852 0.24813172 0.24749613 0.2469041  0.24605335 0.2450649
 0.2446069  0.24438792 0.24392888 0.24339673 0.24304323 0.2431436
 0.24309126 0.24281017 0.24249317 0.24252531 0.24292636 0.2434437
 0.24375303 0.24357143 0.24354398 0.24392062 0.24419867 0.24382772
 0.24303454 0.24236372 0.2418852  0.24146011 0.24109419 0.24086775
 0.24067478 0.24023813 0.23970392 0.23926865 0.23896627 0.23879008
 0.23865141 0.23849061 0.23837805 0.23831515 0.23835458 0.2384352
 0.23829652 0.23794979 0.23771022 0.23776647 0.23806049 0.2386427
 0.23938459 0.23985457 0.24011914 0.24008755 0.23997526 0.23997137
 0.24000843 0.23995891 0.23963968 0.23930694 0.23912466 0.23903365
 0.23887372 0.23870534 0.23874749 0.2391309  0.23955265 0.23976766
 0.23967865 0.23935424 0.23906404 0.23887709 0.23868297 0.23854426
 0.2385271  0.23831661 0.23771879 0.23686112 0.23624828 0.23592651
 0.23582406 0.2357242  0.23536159 0.23494245 0.23475507 0.23470663
 0.23459212 0.23450038 0.23452732 0.23464511 0.23496561 0.2352894
 0.23544534 0.23539728 0.2353863  0.23541898 0.23522827 0.23496099
 0.23489118 0.23471431 0.23423052 0.23346134 0.2328337  0.23245451
 0.23234084 0.23232375 0.23225561 0.23231977 0.2324179  0.23248972
 0.23244767 0.23239152 0.23228544 0.23224758 0.23228763 0.23243164
 0.23238954 0.23214549 0.23198123 0.23184276 0.23149164 0.23124729
 0.23152143 0.23209698 0.23245761 0.23247784 0.23247564 0.23258744
 0.2326909  0.23265867 0.2325828  0.2326636  0.23275174 0.23269762
 0.23256238 0.23243335 0.23240206 0.23249753 0.23268323 0.23299067
 0.23320147 0.23322527 0.23324725 0.23312347 0.23273076 0.23230128
 0.2320069  0.23173986 0.23109587 0.23028149 0.22961776 0.22920166
 0.2289615  0.22890863 0.22875613 0.2286098  0.22851658 0.22855474
 0.2286262  0.22867772 0.22872157 0.22890016 0.22919202 0.22931436
 0.22921334 0.22897796 0.22877504 0.22843799 0.22791912 0.22774495
 0.22803384 0.22806157 0.22781508 0.22737062 0.22711277 0.22704363
 0.22691177 0.2267985  0.22683595 0.22677654 0.22645062 0.22617525
 0.2259907  0.22583596 0.22587895 0.22604997 0.22624424 0.22631124
 0.22619796 0.22596614 0.22584513 0.22579072 0.22576308 0.225711
 0.22590798 0.22595856 0.22572908 0.22548062 0.2254979  0.22563082
 0.22567001 0.22574033 0.22592737 0.22591975 0.22567129 0.22544174
 0.2253077  0.2252197  0.22532728 0.22556026 0.22588098 0.2260811
 0.22611547 0.22603288 0.22619978 0.226375   0.22629228 0.22614878
 0.22610986 0.22593309 0.22529143 0.22462294 0.224228   0.22399396
 0.22372355 0.22344014 0.22331885 0.22325265 0.22308151 0.22283435
 0.22277795 0.22276586 0.22269653 0.22277658 0.2229376  0.22288065
 0.22280702 0.22283489 0.22314398 0.22328916 0.223212   0.22338526
 0.2241074  0.2246506  0.22461995 0.22430721 0.22431915 0.22451816
 0.22453278 0.22445409 0.22452706 0.22468466 0.22457579 0.22438876
 0.22426152 0.2240432  0.2241258  0.22443932 0.22479105 0.22468294
 0.22450244 0.22471377 0.22522153 0.22504902 0.22434844 0.22418833
 0.22479674 0.2251172  0.22444431 0.22396183 0.22401483 0.22365835
 0.22280563 0.22245343 0.22268724 0.22291711 0.22247602 0.22211063
 0.22213495 0.22184542 0.2217639  0.22260831 0.22278817 0.22178483
 0.22175479 0.22286603 0.2214722  0.21806781 0.22130436 0.22360468]
