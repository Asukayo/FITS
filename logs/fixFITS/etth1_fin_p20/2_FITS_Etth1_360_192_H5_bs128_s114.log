Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=90, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_360_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=360, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=100, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_360_192_FITS_ETTh1_ftM_sl360_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8089
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=90, out_features=138, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  22256640.0
params:  12558.0
Trainable parameters:  12558
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 0.7212462425231934
Epoch: 1, Steps: 31 | Train Loss: 0.6929170 Vali Loss: 1.7866195 Test Loss: 0.9360427
Validation loss decreased (inf --> 1.786620).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.7567565441131592
Epoch: 2, Steps: 31 | Train Loss: 0.6020528 Vali Loss: 1.6491001 Test Loss: 0.8551813
Validation loss decreased (1.786620 --> 1.649100).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 0.8007509708404541
Epoch: 3, Steps: 31 | Train Loss: 0.5386195 Vali Loss: 1.5504725 Test Loss: 0.8008870
Validation loss decreased (1.649100 --> 1.550472).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 0.8123898506164551
Epoch: 4, Steps: 31 | Train Loss: 0.4953792 Vali Loss: 1.4920201 Test Loss: 0.7634642
Validation loss decreased (1.550472 --> 1.492020).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 0.8154969215393066
Epoch: 5, Steps: 31 | Train Loss: 0.4645340 Vali Loss: 1.4415185 Test Loss: 0.7387394
Validation loss decreased (1.492020 --> 1.441519).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 0.7299435138702393
Epoch: 6, Steps: 31 | Train Loss: 0.4410204 Vali Loss: 1.4049956 Test Loss: 0.7205393
Validation loss decreased (1.441519 --> 1.404996).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 0.7054970264434814
Epoch: 7, Steps: 31 | Train Loss: 0.4226288 Vali Loss: 1.3795450 Test Loss: 0.7067583
Validation loss decreased (1.404996 --> 1.379545).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 0.7632308006286621
Epoch: 8, Steps: 31 | Train Loss: 0.4079855 Vali Loss: 1.3557627 Test Loss: 0.6963697
Validation loss decreased (1.379545 --> 1.355763).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 0.7108523845672607
Epoch: 9, Steps: 31 | Train Loss: 0.3954212 Vali Loss: 1.3407242 Test Loss: 0.6874896
Validation loss decreased (1.355763 --> 1.340724).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 0.6911940574645996
Epoch: 10, Steps: 31 | Train Loss: 0.3852283 Vali Loss: 1.3277545 Test Loss: 0.6807013
Validation loss decreased (1.340724 --> 1.327754).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 0.7061271667480469
Epoch: 11, Steps: 31 | Train Loss: 0.3760444 Vali Loss: 1.3151448 Test Loss: 0.6740301
Validation loss decreased (1.327754 --> 1.315145).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 0.7893800735473633
Epoch: 12, Steps: 31 | Train Loss: 0.3682963 Vali Loss: 1.3053429 Test Loss: 0.6686081
Validation loss decreased (1.315145 --> 1.305343).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 0.8869166374206543
Epoch: 13, Steps: 31 | Train Loss: 0.3610446 Vali Loss: 1.2952212 Test Loss: 0.6631759
Validation loss decreased (1.305343 --> 1.295221).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 0.7334256172180176
Epoch: 14, Steps: 31 | Train Loss: 0.3548888 Vali Loss: 1.2850574 Test Loss: 0.6589598
Validation loss decreased (1.295221 --> 1.285057).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 0.7427079677581787
Epoch: 15, Steps: 31 | Train Loss: 0.3494140 Vali Loss: 1.2768486 Test Loss: 0.6542171
Validation loss decreased (1.285057 --> 1.276849).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 0.789470911026001
Epoch: 16, Steps: 31 | Train Loss: 0.3438509 Vali Loss: 1.2660153 Test Loss: 0.6503233
Validation loss decreased (1.276849 --> 1.266015).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 0.707268476486206
Epoch: 17, Steps: 31 | Train Loss: 0.3391429 Vali Loss: 1.2604725 Test Loss: 0.6460822
Validation loss decreased (1.266015 --> 1.260473).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 0.8147375583648682
Epoch: 18, Steps: 31 | Train Loss: 0.3345902 Vali Loss: 1.2557381 Test Loss: 0.6430094
Validation loss decreased (1.260473 --> 1.255738).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 0.7113595008850098
Epoch: 19, Steps: 31 | Train Loss: 0.3305505 Vali Loss: 1.2490306 Test Loss: 0.6395845
Validation loss decreased (1.255738 --> 1.249031).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 0.7405557632446289
Epoch: 20, Steps: 31 | Train Loss: 0.3263144 Vali Loss: 1.2455389 Test Loss: 0.6362410
Validation loss decreased (1.249031 --> 1.245539).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 0.6932265758514404
Epoch: 21, Steps: 31 | Train Loss: 0.3233156 Vali Loss: 1.2439547 Test Loss: 0.6331851
Validation loss decreased (1.245539 --> 1.243955).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 0.6977963447570801
Epoch: 22, Steps: 31 | Train Loss: 0.3199142 Vali Loss: 1.2340930 Test Loss: 0.6305063
Validation loss decreased (1.243955 --> 1.234093).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 0.6995384693145752
Epoch: 23, Steps: 31 | Train Loss: 0.3169615 Vali Loss: 1.2285700 Test Loss: 0.6277656
Validation loss decreased (1.234093 --> 1.228570).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 0.7331442832946777
Epoch: 24, Steps: 31 | Train Loss: 0.3144450 Vali Loss: 1.2255787 Test Loss: 0.6253056
Validation loss decreased (1.228570 --> 1.225579).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 0.7374377250671387
Epoch: 25, Steps: 31 | Train Loss: 0.3115789 Vali Loss: 1.2190200 Test Loss: 0.6230614
Validation loss decreased (1.225579 --> 1.219020).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 0.7176382541656494
Epoch: 26, Steps: 31 | Train Loss: 0.3090608 Vali Loss: 1.2179867 Test Loss: 0.6207256
Validation loss decreased (1.219020 --> 1.217987).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 0.7112762928009033
Epoch: 27, Steps: 31 | Train Loss: 0.3066839 Vali Loss: 1.2180779 Test Loss: 0.6186873
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 0.7070832252502441
Epoch: 28, Steps: 31 | Train Loss: 0.3045252 Vali Loss: 1.2119067 Test Loss: 0.6166030
Validation loss decreased (1.217987 --> 1.211907).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 0.77130126953125
Epoch: 29, Steps: 31 | Train Loss: 0.3027662 Vali Loss: 1.2094107 Test Loss: 0.6143935
Validation loss decreased (1.211907 --> 1.209411).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 0.6759016513824463
Epoch: 30, Steps: 31 | Train Loss: 0.3002645 Vali Loss: 1.2036531 Test Loss: 0.6129596
Validation loss decreased (1.209411 --> 1.203653).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 0.780113935470581
Epoch: 31, Steps: 31 | Train Loss: 0.2986616 Vali Loss: 1.2004007 Test Loss: 0.6115728
Validation loss decreased (1.203653 --> 1.200401).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 0.7415268421173096
Epoch: 32, Steps: 31 | Train Loss: 0.2970911 Vali Loss: 1.1999235 Test Loss: 0.6096012
Validation loss decreased (1.200401 --> 1.199924).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 0.7625565528869629
Epoch: 33, Steps: 31 | Train Loss: 0.2951266 Vali Loss: 1.1940829 Test Loss: 0.6082081
Validation loss decreased (1.199924 --> 1.194083).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 0.7771780490875244
Epoch: 34, Steps: 31 | Train Loss: 0.2940269 Vali Loss: 1.1948841 Test Loss: 0.6067274
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 0.7914416790008545
Epoch: 35, Steps: 31 | Train Loss: 0.2925447 Vali Loss: 1.1941553 Test Loss: 0.6054869
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 0.7450175285339355
Epoch: 36, Steps: 31 | Train Loss: 0.2913373 Vali Loss: 1.1945040 Test Loss: 0.6041249
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 0.7622802257537842
Epoch: 37, Steps: 31 | Train Loss: 0.2897114 Vali Loss: 1.1948358 Test Loss: 0.6030884
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 0.7540590763092041
Epoch: 38, Steps: 31 | Train Loss: 0.2889641 Vali Loss: 1.1921315 Test Loss: 0.6016728
Validation loss decreased (1.194083 --> 1.192132).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 0.7278871536254883
Epoch: 39, Steps: 31 | Train Loss: 0.2874225 Vali Loss: 1.1879914 Test Loss: 0.6006019
Validation loss decreased (1.192132 --> 1.187991).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 0.7973096370697021
Epoch: 40, Steps: 31 | Train Loss: 0.2863773 Vali Loss: 1.1808412 Test Loss: 0.5998361
Validation loss decreased (1.187991 --> 1.180841).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 0.7700598239898682
Epoch: 41, Steps: 31 | Train Loss: 0.2854789 Vali Loss: 1.1814222 Test Loss: 0.5987555
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 0.766124963760376
Epoch: 42, Steps: 31 | Train Loss: 0.2843019 Vali Loss: 1.1800444 Test Loss: 0.5975462
Validation loss decreased (1.180841 --> 1.180044).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 0.7484714984893799
Epoch: 43, Steps: 31 | Train Loss: 0.2837350 Vali Loss: 1.1801893 Test Loss: 0.5967996
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 0.7442030906677246
Epoch: 44, Steps: 31 | Train Loss: 0.2827370 Vali Loss: 1.1760132 Test Loss: 0.5958583
Validation loss decreased (1.180044 --> 1.176013).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 0.7938644886016846
Epoch: 45, Steps: 31 | Train Loss: 0.2818312 Vali Loss: 1.1781949 Test Loss: 0.5950822
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 0.8499155044555664
Epoch: 46, Steps: 31 | Train Loss: 0.2810599 Vali Loss: 1.1783919 Test Loss: 0.5943463
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 0.7253410816192627
Epoch: 47, Steps: 31 | Train Loss: 0.2804762 Vali Loss: 1.1717836 Test Loss: 0.5935665
Validation loss decreased (1.176013 --> 1.171784).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 0.746624231338501
Epoch: 48, Steps: 31 | Train Loss: 0.2796873 Vali Loss: 1.1723998 Test Loss: 0.5928568
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 0.7521905899047852
Epoch: 49, Steps: 31 | Train Loss: 0.2790379 Vali Loss: 1.1727684 Test Loss: 0.5922720
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 0.7455458641052246
Epoch: 50, Steps: 31 | Train Loss: 0.2784153 Vali Loss: 1.1708024 Test Loss: 0.5916016
Validation loss decreased (1.171784 --> 1.170802).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 0.7773246765136719
Epoch: 51, Steps: 31 | Train Loss: 0.2776306 Vali Loss: 1.1727235 Test Loss: 0.5910211
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 0.7377514839172363
Epoch: 52, Steps: 31 | Train Loss: 0.2774925 Vali Loss: 1.1701347 Test Loss: 0.5904197
Validation loss decreased (1.170802 --> 1.170135).  Saving model ...
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 0.7830405235290527
Epoch: 53, Steps: 31 | Train Loss: 0.2766053 Vali Loss: 1.1667361 Test Loss: 0.5898230
Validation loss decreased (1.170135 --> 1.166736).  Saving model ...
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 0.8138277530670166
Epoch: 54, Steps: 31 | Train Loss: 0.2763660 Vali Loss: 1.1721760 Test Loss: 0.5893570
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 0.8037283420562744
Epoch: 55, Steps: 31 | Train Loss: 0.2758783 Vali Loss: 1.1676800 Test Loss: 0.5889099
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 0.8322312831878662
Epoch: 56, Steps: 31 | Train Loss: 0.2754252 Vali Loss: 1.1622772 Test Loss: 0.5884374
Validation loss decreased (1.166736 --> 1.162277).  Saving model ...
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 0.8647913932800293
Epoch: 57, Steps: 31 | Train Loss: 0.2749206 Vali Loss: 1.1650575 Test Loss: 0.5879212
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 0.8225605487823486
Epoch: 58, Steps: 31 | Train Loss: 0.2745814 Vali Loss: 1.1621603 Test Loss: 0.5875337
Validation loss decreased (1.162277 --> 1.162160).  Saving model ...
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 0.7926607131958008
Epoch: 59, Steps: 31 | Train Loss: 0.2743384 Vali Loss: 1.1682221 Test Loss: 0.5871661
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 0.8142924308776855
Epoch: 60, Steps: 31 | Train Loss: 0.2736022 Vali Loss: 1.1646985 Test Loss: 0.5868008
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 0.7495334148406982
Epoch: 61, Steps: 31 | Train Loss: 0.2734559 Vali Loss: 1.1597676 Test Loss: 0.5864461
Validation loss decreased (1.162160 --> 1.159768).  Saving model ...
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 0.9039406776428223
Epoch: 62, Steps: 31 | Train Loss: 0.2728973 Vali Loss: 1.1630303 Test Loss: 0.5860846
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 0.8072669506072998
Epoch: 63, Steps: 31 | Train Loss: 0.2729210 Vali Loss: 1.1598953 Test Loss: 0.5857780
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 0.6986734867095947
Epoch: 64, Steps: 31 | Train Loss: 0.2726184 Vali Loss: 1.1596346 Test Loss: 0.5855011
Validation loss decreased (1.159768 --> 1.159635).  Saving model ...
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 0.7647261619567871
Epoch: 65, Steps: 31 | Train Loss: 0.2723925 Vali Loss: 1.1616458 Test Loss: 0.5851879
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 0.7359809875488281
Epoch: 66, Steps: 31 | Train Loss: 0.2720715 Vali Loss: 1.1622708 Test Loss: 0.5849386
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 0.7644412517547607
Epoch: 67, Steps: 31 | Train Loss: 0.2716144 Vali Loss: 1.1595627 Test Loss: 0.5846819
Validation loss decreased (1.159635 --> 1.159563).  Saving model ...
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 0.7608215808868408
Epoch: 68, Steps: 31 | Train Loss: 0.2715766 Vali Loss: 1.1603854 Test Loss: 0.5844120
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 0.7604198455810547
Epoch: 69, Steps: 31 | Train Loss: 0.2711947 Vali Loss: 1.1632775 Test Loss: 0.5842310
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 0.7955026626586914
Epoch: 70, Steps: 31 | Train Loss: 0.2709792 Vali Loss: 1.1611389 Test Loss: 0.5840191
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 0.7629618644714355
Epoch: 71, Steps: 31 | Train Loss: 0.2706713 Vali Loss: 1.1612303 Test Loss: 0.5837457
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 0.7568440437316895
Epoch: 72, Steps: 31 | Train Loss: 0.2709371 Vali Loss: 1.1589987 Test Loss: 0.5835457
Validation loss decreased (1.159563 --> 1.158999).  Saving model ...
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 0.823131799697876
Epoch: 73, Steps: 31 | Train Loss: 0.2704491 Vali Loss: 1.1610572 Test Loss: 0.5833563
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 0.7012453079223633
Epoch: 74, Steps: 31 | Train Loss: 0.2701112 Vali Loss: 1.1592582 Test Loss: 0.5831670
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 0.8425023555755615
Epoch: 75, Steps: 31 | Train Loss: 0.2701174 Vali Loss: 1.1618803 Test Loss: 0.5829584
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 0.8114087581634521
Epoch: 76, Steps: 31 | Train Loss: 0.2700364 Vali Loss: 1.1573446 Test Loss: 0.5828137
Validation loss decreased (1.158999 --> 1.157345).  Saving model ...
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 0.777977466583252
Epoch: 77, Steps: 31 | Train Loss: 0.2697776 Vali Loss: 1.1569599 Test Loss: 0.5826331
Validation loss decreased (1.157345 --> 1.156960).  Saving model ...
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 0.7446727752685547
Epoch: 78, Steps: 31 | Train Loss: 0.2698463 Vali Loss: 1.1618679 Test Loss: 0.5824932
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 0.7171051502227783
Epoch: 79, Steps: 31 | Train Loss: 0.2696170 Vali Loss: 1.1513700 Test Loss: 0.5823320
Validation loss decreased (1.156960 --> 1.151370).  Saving model ...
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 0.7579982280731201
Epoch: 80, Steps: 31 | Train Loss: 0.2692968 Vali Loss: 1.1602027 Test Loss: 0.5822300
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 0.8234951496124268
Epoch: 81, Steps: 31 | Train Loss: 0.2690801 Vali Loss: 1.1613197 Test Loss: 0.5820963
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 0.7946457862854004
Epoch: 82, Steps: 31 | Train Loss: 0.2692191 Vali Loss: 1.1574299 Test Loss: 0.5819851
EarlyStopping counter: 3 out of 20
Updating learning rate to 7.84480283288145e-06
Epoch: 83 cost time: 0.7696340084075928
Epoch: 83, Steps: 31 | Train Loss: 0.2690933 Vali Loss: 1.1607177 Test Loss: 0.5818602
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.452562691237377e-06
Epoch: 84 cost time: 0.7676980495452881
Epoch: 84, Steps: 31 | Train Loss: 0.2689742 Vali Loss: 1.1590368 Test Loss: 0.5817494
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.079934556675507e-06
Epoch: 85 cost time: 0.812232494354248
Epoch: 85, Steps: 31 | Train Loss: 0.2687338 Vali Loss: 1.1608906 Test Loss: 0.5816212
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.725937828841732e-06
Epoch: 86 cost time: 0.7004311084747314
Epoch: 86, Steps: 31 | Train Loss: 0.2685763 Vali Loss: 1.1561873 Test Loss: 0.5815445
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.389640937399644e-06
Epoch: 87 cost time: 0.7340459823608398
Epoch: 87, Steps: 31 | Train Loss: 0.2684460 Vali Loss: 1.1520677 Test Loss: 0.5814676
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.070158890529662e-06
Epoch: 88 cost time: 0.7992072105407715
Epoch: 88, Steps: 31 | Train Loss: 0.2686447 Vali Loss: 1.1566733 Test Loss: 0.5813795
EarlyStopping counter: 9 out of 20
Updating learning rate to 5.766650946003179e-06
Epoch: 89 cost time: 0.7550420761108398
Epoch: 89, Steps: 31 | Train Loss: 0.2685018 Vali Loss: 1.1540129 Test Loss: 0.5812841
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.47831839870302e-06
Epoch: 90 cost time: 0.7476675510406494
Epoch: 90, Steps: 31 | Train Loss: 0.2685404 Vali Loss: 1.1571199 Test Loss: 0.5812173
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.204402478767869e-06
Epoch: 91 cost time: 0.7136504650115967
Epoch: 91, Steps: 31 | Train Loss: 0.2683378 Vali Loss: 1.1536735 Test Loss: 0.5811180
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.944182354829475e-06
Epoch: 92 cost time: 0.7569236755371094
Epoch: 92, Steps: 31 | Train Loss: 0.2680031 Vali Loss: 1.1601059 Test Loss: 0.5810651
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.696973237088e-06
Epoch: 93 cost time: 0.7731692790985107
Epoch: 93, Steps: 31 | Train Loss: 0.2680980 Vali Loss: 1.1541504 Test Loss: 0.5809864
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.462124575233601e-06
Epoch: 94 cost time: 0.8105392456054688
Epoch: 94, Steps: 31 | Train Loss: 0.2682486 Vali Loss: 1.1536307 Test Loss: 0.5809178
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.239018346471921e-06
Epoch: 95 cost time: 0.7410686016082764
Epoch: 95, Steps: 31 | Train Loss: 0.2677523 Vali Loss: 1.1561201 Test Loss: 0.5808496
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.027067429148324e-06
Epoch: 96 cost time: 0.7031416893005371
Epoch: 96, Steps: 31 | Train Loss: 0.2677867 Vali Loss: 1.1556771 Test Loss: 0.5807940
EarlyStopping counter: 17 out of 20
Updating learning rate to 3.825714057690908e-06
Epoch: 97 cost time: 0.744504451751709
Epoch: 97, Steps: 31 | Train Loss: 0.2678929 Vali Loss: 1.1543682 Test Loss: 0.5807436
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.6344283548063623e-06
Epoch: 98 cost time: 0.7539670467376709
Epoch: 98, Steps: 31 | Train Loss: 0.2678900 Vali Loss: 1.1541517 Test Loss: 0.5806980
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.452706937066044e-06
Epoch: 99 cost time: 0.7825701236724854
Epoch: 99, Steps: 31 | Train Loss: 0.2676800 Vali Loss: 1.1531887 Test Loss: 0.5806417
EarlyStopping counter: 20 out of 20
Early stopping
train 8089
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=90, out_features=138, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  22256640.0
params:  12558.0
Trainable parameters:  12558
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 0.7960045337677002
Epoch: 1, Steps: 31 | Train Loss: 0.4856849 Vali Loss: 1.0902547 Test Loss: 0.5314280
Validation loss decreased (inf --> 1.090255).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 0.8452770709991455
Epoch: 2, Steps: 31 | Train Loss: 0.4598020 Vali Loss: 1.0403172 Test Loss: 0.4957761
Validation loss decreased (1.090255 --> 1.040317).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 0.8429510593414307
Epoch: 3, Steps: 31 | Train Loss: 0.4410319 Vali Loss: 1.0108653 Test Loss: 0.4709775
Validation loss decreased (1.040317 --> 1.010865).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 0.8160631656646729
Epoch: 4, Steps: 31 | Train Loss: 0.4288192 Vali Loss: 0.9816102 Test Loss: 0.4533216
Validation loss decreased (1.010865 --> 0.981610).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 0.8187875747680664
Epoch: 5, Steps: 31 | Train Loss: 0.4201565 Vali Loss: 0.9649334 Test Loss: 0.4409570
Validation loss decreased (0.981610 --> 0.964933).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 0.7648642063140869
Epoch: 6, Steps: 31 | Train Loss: 0.4127670 Vali Loss: 0.9555668 Test Loss: 0.4319035
Validation loss decreased (0.964933 --> 0.955567).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 0.8434443473815918
Epoch: 7, Steps: 31 | Train Loss: 0.4083018 Vali Loss: 0.9458309 Test Loss: 0.4254473
Validation loss decreased (0.955567 --> 0.945831).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 0.8260805606842041
Epoch: 8, Steps: 31 | Train Loss: 0.4051161 Vali Loss: 0.9344701 Test Loss: 0.4210797
Validation loss decreased (0.945831 --> 0.934470).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 0.7692899703979492
Epoch: 9, Steps: 31 | Train Loss: 0.4030904 Vali Loss: 0.9343497 Test Loss: 0.4178398
Validation loss decreased (0.934470 --> 0.934350).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 0.8335480690002441
Epoch: 10, Steps: 31 | Train Loss: 0.4011971 Vali Loss: 0.9351134 Test Loss: 0.4157331
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 0.8061387538909912
Epoch: 11, Steps: 31 | Train Loss: 0.4000149 Vali Loss: 0.9298183 Test Loss: 0.4142585
Validation loss decreased (0.934350 --> 0.929818).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 0.8854093551635742
Epoch: 12, Steps: 31 | Train Loss: 0.3993999 Vali Loss: 0.9259430 Test Loss: 0.4131726
Validation loss decreased (0.929818 --> 0.925943).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 0.7523205280303955
Epoch: 13, Steps: 31 | Train Loss: 0.3983218 Vali Loss: 0.9233003 Test Loss: 0.4123425
Validation loss decreased (0.925943 --> 0.923300).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 0.8291993141174316
Epoch: 14, Steps: 31 | Train Loss: 0.3980868 Vali Loss: 0.9276651 Test Loss: 0.4118020
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 0.8224833011627197
Epoch: 15, Steps: 31 | Train Loss: 0.3978626 Vali Loss: 0.9223560 Test Loss: 0.4114833
Validation loss decreased (0.923300 --> 0.922356).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 0.7348856925964355
Epoch: 16, Steps: 31 | Train Loss: 0.3964107 Vali Loss: 0.9223459 Test Loss: 0.4112455
Validation loss decreased (0.922356 --> 0.922346).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 0.7912182807922363
Epoch: 17, Steps: 31 | Train Loss: 0.3969277 Vali Loss: 0.9285029 Test Loss: 0.4110720
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 0.6846115589141846
Epoch: 18, Steps: 31 | Train Loss: 0.3966122 Vali Loss: 0.9206783 Test Loss: 0.4109632
Validation loss decreased (0.922346 --> 0.920678).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 0.775911808013916
Epoch: 19, Steps: 31 | Train Loss: 0.3961688 Vali Loss: 0.9191197 Test Loss: 0.4108217
Validation loss decreased (0.920678 --> 0.919120).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 0.7790555953979492
Epoch: 20, Steps: 31 | Train Loss: 0.3965628 Vali Loss: 0.9220350 Test Loss: 0.4107492
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 0.788668155670166
Epoch: 21, Steps: 31 | Train Loss: 0.3962909 Vali Loss: 0.9190752 Test Loss: 0.4107866
Validation loss decreased (0.919120 --> 0.919075).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 0.6901826858520508
Epoch: 22, Steps: 31 | Train Loss: 0.3957688 Vali Loss: 0.9214795 Test Loss: 0.4107578
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 0.7481937408447266
Epoch: 23, Steps: 31 | Train Loss: 0.3963453 Vali Loss: 0.9230698 Test Loss: 0.4106858
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 0.7895781993865967
Epoch: 24, Steps: 31 | Train Loss: 0.3960411 Vali Loss: 0.9186299 Test Loss: 0.4106647
Validation loss decreased (0.919075 --> 0.918630).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 0.7439148426055908
Epoch: 25, Steps: 31 | Train Loss: 0.3960192 Vali Loss: 0.9238998 Test Loss: 0.4106646
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 0.758840799331665
Epoch: 26, Steps: 31 | Train Loss: 0.3963675 Vali Loss: 0.9219584 Test Loss: 0.4106236
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 0.8170628547668457
Epoch: 27, Steps: 31 | Train Loss: 0.3961149 Vali Loss: 0.9207678 Test Loss: 0.4106539
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 0.6867976188659668
Epoch: 28, Steps: 31 | Train Loss: 0.3958561 Vali Loss: 0.9262397 Test Loss: 0.4106312
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 0.744361400604248
Epoch: 29, Steps: 31 | Train Loss: 0.3964628 Vali Loss: 0.9208959 Test Loss: 0.4106798
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 0.7268474102020264
Epoch: 30, Steps: 31 | Train Loss: 0.3954990 Vali Loss: 0.9238739 Test Loss: 0.4106290
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 0.732513427734375
Epoch: 31, Steps: 31 | Train Loss: 0.3964402 Vali Loss: 0.9192036 Test Loss: 0.4106043
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 0.8115196228027344
Epoch: 32, Steps: 31 | Train Loss: 0.3950063 Vali Loss: 0.9205083 Test Loss: 0.4106263
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 0.771644115447998
Epoch: 33, Steps: 31 | Train Loss: 0.3959998 Vali Loss: 0.9207659 Test Loss: 0.4106210
EarlyStopping counter: 9 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 0.77107834815979
Epoch: 34, Steps: 31 | Train Loss: 0.3959319 Vali Loss: 0.9225748 Test Loss: 0.4105850
EarlyStopping counter: 10 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 0.7763597965240479
Epoch: 35, Steps: 31 | Train Loss: 0.3953862 Vali Loss: 0.9243206 Test Loss: 0.4105980
EarlyStopping counter: 11 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 0.8002443313598633
Epoch: 36, Steps: 31 | Train Loss: 0.3960788 Vali Loss: 0.9193247 Test Loss: 0.4106110
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 0.7536511421203613
Epoch: 37, Steps: 31 | Train Loss: 0.3952690 Vali Loss: 0.9200870 Test Loss: 0.4105730
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 0.7389893531799316
Epoch: 38, Steps: 31 | Train Loss: 0.3961867 Vali Loss: 0.9230868 Test Loss: 0.4106055
EarlyStopping counter: 14 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 0.7451272010803223
Epoch: 39, Steps: 31 | Train Loss: 0.3955173 Vali Loss: 0.9215496 Test Loss: 0.4105956
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 0.736011266708374
Epoch: 40, Steps: 31 | Train Loss: 0.3953839 Vali Loss: 0.9167424 Test Loss: 0.4105904
Validation loss decreased (0.918630 --> 0.916742).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 0.8286631107330322
Epoch: 41, Steps: 31 | Train Loss: 0.3955687 Vali Loss: 0.9202023 Test Loss: 0.4105862
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 0.7883684635162354
Epoch: 42, Steps: 31 | Train Loss: 0.3954414 Vali Loss: 0.9183607 Test Loss: 0.4105980
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 0.8103296756744385
Epoch: 43, Steps: 31 | Train Loss: 0.3951575 Vali Loss: 0.9194379 Test Loss: 0.4106062
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 0.7686212062835693
Epoch: 44, Steps: 31 | Train Loss: 0.3950814 Vali Loss: 0.9185295 Test Loss: 0.4105992
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 0.768052339553833
Epoch: 45, Steps: 31 | Train Loss: 0.3960135 Vali Loss: 0.9171893 Test Loss: 0.4105760
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 0.7807023525238037
Epoch: 46, Steps: 31 | Train Loss: 0.3956372 Vali Loss: 0.9206212 Test Loss: 0.4105837
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 0.7725472450256348
Epoch: 47, Steps: 31 | Train Loss: 0.3959547 Vali Loss: 0.9208647 Test Loss: 0.4105775
EarlyStopping counter: 7 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 0.7981669902801514
Epoch: 48, Steps: 31 | Train Loss: 0.3959808 Vali Loss: 0.9157144 Test Loss: 0.4105893
Validation loss decreased (0.916742 --> 0.915714).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 0.8505945205688477
Epoch: 49, Steps: 31 | Train Loss: 0.3954270 Vali Loss: 0.9199408 Test Loss: 0.4105916
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 0.8229334354400635
Epoch: 50, Steps: 31 | Train Loss: 0.3963416 Vali Loss: 0.9145892 Test Loss: 0.4105590
Validation loss decreased (0.915714 --> 0.914589).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
Epoch: 51 cost time: 0.7970983982086182
Epoch: 51, Steps: 31 | Train Loss: 0.3957281 Vali Loss: 0.9176073 Test Loss: 0.4105840
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.8472487638356575e-05
Epoch: 52 cost time: 0.8123948574066162
Epoch: 52, Steps: 31 | Train Loss: 0.3952867 Vali Loss: 0.9192818 Test Loss: 0.4105838
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.654886325643875e-05
Epoch: 53 cost time: 0.7958221435546875
Epoch: 53, Steps: 31 | Train Loss: 0.3956554 Vali Loss: 0.9204562 Test Loss: 0.4105657
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.47214200936168e-05
Epoch: 54 cost time: 0.7685859203338623
Epoch: 54, Steps: 31 | Train Loss: 0.3957438 Vali Loss: 0.9205817 Test Loss: 0.4105979
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.298534908893597e-05
Epoch: 55 cost time: 0.7801015377044678
Epoch: 55, Steps: 31 | Train Loss: 0.3950428 Vali Loss: 0.9222754 Test Loss: 0.4105876
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.1336081634489166e-05
Epoch: 56 cost time: 0.7944478988647461
Epoch: 56, Steps: 31 | Train Loss: 0.3954256 Vali Loss: 0.9211054 Test Loss: 0.4105737
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.9769277552764706e-05
Epoch: 57 cost time: 0.8605852127075195
Epoch: 57, Steps: 31 | Train Loss: 0.3955846 Vali Loss: 0.9203516 Test Loss: 0.4105697
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.8280813675126466e-05
Epoch: 58 cost time: 0.8100402355194092
Epoch: 58, Steps: 31 | Train Loss: 0.3956888 Vali Loss: 0.9147487 Test Loss: 0.4105764
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.6866772991370145e-05
Epoch: 59 cost time: 0.7736659049987793
Epoch: 59, Steps: 31 | Train Loss: 0.3957750 Vali Loss: 0.9185983 Test Loss: 0.4105776
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.5523434341801633e-05
Epoch: 60 cost time: 0.7132585048675537
Epoch: 60, Steps: 31 | Train Loss: 0.3956492 Vali Loss: 0.9195763 Test Loss: 0.4105770
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.4247262624711552e-05
Epoch: 61 cost time: 0.7846806049346924
Epoch: 61, Steps: 31 | Train Loss: 0.3956394 Vali Loss: 0.9163976 Test Loss: 0.4105824
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.3034899493475973e-05
Epoch: 62 cost time: 0.7591586112976074
Epoch: 62, Steps: 31 | Train Loss: 0.3956374 Vali Loss: 0.9122112 Test Loss: 0.4105768
Validation loss decreased (0.914589 --> 0.912211).  Saving model ...
Updating learning rate to 2.1883154518802173e-05
Epoch: 63 cost time: 0.7813417911529541
Epoch: 63, Steps: 31 | Train Loss: 0.3952829 Vali Loss: 0.9198321 Test Loss: 0.4105769
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0788996792862066e-05
Epoch: 64 cost time: 0.8098621368408203
Epoch: 64, Steps: 31 | Train Loss: 0.3953680 Vali Loss: 0.9159795 Test Loss: 0.4105661
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.974954695321896e-05
Epoch: 65 cost time: 0.8017263412475586
Epoch: 65, Steps: 31 | Train Loss: 0.3954886 Vali Loss: 0.9167238 Test Loss: 0.4105681
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.876206960555801e-05
Epoch: 66 cost time: 0.7959365844726562
Epoch: 66, Steps: 31 | Train Loss: 0.3957003 Vali Loss: 0.9178913 Test Loss: 0.4105686
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.782396612528011e-05
Epoch: 67 cost time: 0.7620007991790771
Epoch: 67, Steps: 31 | Train Loss: 0.3949097 Vali Loss: 0.9183629 Test Loss: 0.4105649
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.6932767819016104e-05
Epoch: 68 cost time: 0.7498791217803955
Epoch: 68, Steps: 31 | Train Loss: 0.3952766 Vali Loss: 0.9183160 Test Loss: 0.4105652
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.6086129428065296e-05
Epoch: 69 cost time: 0.8680100440979004
Epoch: 69, Steps: 31 | Train Loss: 0.3954383 Vali Loss: 0.9184543 Test Loss: 0.4105652
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.5281822956662033e-05
Epoch: 70 cost time: 0.8312101364135742
Epoch: 70, Steps: 31 | Train Loss: 0.3959886 Vali Loss: 0.9163394 Test Loss: 0.4105594
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.451773180882893e-05
Epoch: 71 cost time: 0.8388671875
Epoch: 71, Steps: 31 | Train Loss: 0.3950219 Vali Loss: 0.9205004 Test Loss: 0.4105614
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.3791845218387483e-05
Epoch: 72 cost time: 0.7918713092803955
Epoch: 72, Steps: 31 | Train Loss: 0.3959255 Vali Loss: 0.9177256 Test Loss: 0.4105589
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.3102252957468109e-05
Epoch: 73 cost time: 0.8444898128509521
Epoch: 73, Steps: 31 | Train Loss: 0.3949223 Vali Loss: 0.9148324 Test Loss: 0.4105623
EarlyStopping counter: 11 out of 20
Updating learning rate to 1.2447140309594702e-05
Epoch: 74 cost time: 0.8225488662719727
Epoch: 74, Steps: 31 | Train Loss: 0.3952779 Vali Loss: 0.9169507 Test Loss: 0.4105635
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.1824783294114967e-05
Epoch: 75 cost time: 0.8100297451019287
Epoch: 75, Steps: 31 | Train Loss: 0.3956354 Vali Loss: 0.9159028 Test Loss: 0.4105588
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.1233544129409218e-05
Epoch: 76 cost time: 0.8019759654998779
Epoch: 76, Steps: 31 | Train Loss: 0.3961551 Vali Loss: 0.9200665 Test Loss: 0.4105616
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.0671866922938755e-05
Epoch: 77 cost time: 0.788642168045044
Epoch: 77, Steps: 31 | Train Loss: 0.3951725 Vali Loss: 0.9190590 Test Loss: 0.4105562
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.0138273576791817e-05
Epoch: 78 cost time: 0.8010463714599609
Epoch: 78, Steps: 31 | Train Loss: 0.3954242 Vali Loss: 0.9200870 Test Loss: 0.4105562
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.631359897952226e-06
Epoch: 79 cost time: 0.8298799991607666
Epoch: 79, Steps: 31 | Train Loss: 0.3959479 Vali Loss: 0.9214447 Test Loss: 0.4105583
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.149791903054614e-06
Epoch: 80 cost time: 0.803647518157959
Epoch: 80, Steps: 31 | Train Loss: 0.3957689 Vali Loss: 0.9177436 Test Loss: 0.4105564
EarlyStopping counter: 18 out of 20
Updating learning rate to 8.692302307901884e-06
Epoch: 81 cost time: 0.8419137001037598
Epoch: 81, Steps: 31 | Train Loss: 0.3955657 Vali Loss: 0.9180220 Test Loss: 0.4105519
EarlyStopping counter: 19 out of 20
Updating learning rate to 8.25768719250679e-06
Epoch: 82 cost time: 0.8843533992767334
Epoch: 82, Steps: 31 | Train Loss: 0.3956345 Vali Loss: 0.9185596 Test Loss: 0.4105537
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTh1_360_192_FITS_ETTh1_ftM_sl360_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.4070318639278412, mae:0.4153605103492737, rse:0.6058589220046997, corr:[0.26247633 0.26929697 0.26879808 0.26984116 0.26865754 0.26579922
 0.2640537  0.2645526  0.26492187 0.26444244 0.2637665  0.2634724
 0.26354837 0.26334232 0.2627817  0.26244694 0.26243776 0.2625623
 0.26251253 0.262072   0.26176086 0.26189658 0.26232493 0.26257548
 0.26224965 0.26194745 0.2619195  0.26177424 0.26125687 0.2607655
 0.26060262 0.2604195  0.25997573 0.25951174 0.25943634 0.25964448
 0.2598299  0.25983196 0.25975576 0.25983384 0.2602245  0.26056758
 0.26068944 0.26048458 0.26021707 0.26008555 0.26026714 0.26037297
 0.25984928 0.25897518 0.2581112  0.25746807 0.25671938 0.25574762
 0.2551842  0.25488758 0.25452286 0.25420257 0.25394967 0.2540253
 0.25404915 0.25385216 0.25355458 0.25350505 0.2537721  0.25419888
 0.25449678 0.25435266 0.25425473 0.25450093 0.25475445 0.2544811
 0.25374806 0.25297332 0.25231418 0.25182572 0.25156567 0.2513947
 0.25113842 0.25060254 0.2500741  0.24975133 0.24955447 0.2493829
 0.24930269 0.24927127 0.24930555 0.24931775 0.24940297 0.24954131
 0.24943617 0.24907611 0.24884497 0.2488278  0.24895185 0.24937966
 0.2500217  0.2502451  0.25025892 0.25011253 0.24998192 0.24993055
 0.24984124 0.24972977 0.24948989 0.24927896 0.24914499 0.24898508
 0.24873067 0.2485281  0.24859187 0.24910598 0.24962936 0.24988046
 0.24981256 0.24958001 0.24938539 0.249184   0.24891773 0.24877638
 0.24882293 0.24855608 0.24776155 0.24682614 0.24627551 0.24591033
 0.24567676 0.24549861 0.2452554  0.24490148 0.24464747 0.24445285
 0.24418512 0.24404782 0.24410836 0.24415997 0.24449566 0.24479507
 0.24499314 0.24507372 0.24511918 0.24505916 0.24477397 0.24453798
 0.24460058 0.24432871 0.24363662 0.24278921 0.24222177 0.24166775
 0.24126339 0.24115597 0.2411485  0.24130183 0.24137314 0.24139543
 0.24120203 0.24108171 0.24107984 0.24119309 0.24127206 0.24130532
 0.24136384 0.2414442  0.24151295 0.24125066 0.24079984 0.240694
 0.24111623 0.24140716 0.24137378 0.24127792 0.24122854 0.24093728
 0.24056818 0.24044828 0.24044766 0.24061689 0.24089059 0.24100123
 0.2407526  0.2404092  0.24076954 0.24145296 0.24104188 0.24028133
 0.24092928 0.24192698 0.24041204 0.2381628  0.2402028  0.23741364]
