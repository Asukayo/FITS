Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=122, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_720', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=20, pred_len=720, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33121
val 10801
test 10801
Model(
  (freq_upsampler): Linear(in_features=122, out_features=244, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  13336064.0
params:  30012.0
Trainable parameters:  30012
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.7197096
	speed: 0.0642s/iter; left time: 1654.3017s
	iters: 200, epoch: 1 | loss: 0.4710934
	speed: 0.0499s/iter; left time: 1280.9506s
	iters: 300, epoch: 1 | loss: 0.4469335
	speed: 0.0458s/iter; left time: 1171.2328s
	iters: 400, epoch: 1 | loss: 0.3487870
	speed: 0.0585s/iter; left time: 1489.2258s
	iters: 500, epoch: 1 | loss: 0.6107816
	speed: 0.0409s/iter; left time: 1037.0943s
Epoch: 1 cost time: 26.966184377670288
Epoch: 1, Steps: 517 | Train Loss: 0.5486480 Vali Loss: 0.2701803 Test Loss: 0.3629707
Validation loss decreased (inf --> 0.270180).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3708029
	speed: 0.2639s/iter; left time: 6658.4111s
	iters: 200, epoch: 2 | loss: 0.3320675
	speed: 0.0387s/iter; left time: 972.9179s
	iters: 300, epoch: 2 | loss: 0.5134643
	speed: 0.0471s/iter; left time: 1178.5711s
	iters: 400, epoch: 2 | loss: 0.5520068
	speed: 0.0500s/iter; left time: 1245.8582s
	iters: 500, epoch: 2 | loss: 0.4061249
	speed: 0.0408s/iter; left time: 1012.9669s
Epoch: 2 cost time: 23.404919385910034
Epoch: 2, Steps: 517 | Train Loss: 0.5090037 Vali Loss: 0.2652887 Test Loss: 0.3565470
Validation loss decreased (0.270180 --> 0.265289).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5522892
	speed: 0.1674s/iter; left time: 4137.4300s
	iters: 200, epoch: 3 | loss: 0.5195129
	speed: 0.0172s/iter; left time: 422.8169s
	iters: 300, epoch: 3 | loss: 0.3718223
	speed: 0.0145s/iter; left time: 354.6089s
	iters: 400, epoch: 3 | loss: 0.4020281
	speed: 0.0174s/iter; left time: 424.4851s
	iters: 500, epoch: 3 | loss: 0.3816572
	speed: 0.0144s/iter; left time: 349.6690s
Epoch: 3 cost time: 8.588353633880615
Epoch: 3, Steps: 517 | Train Loss: 0.5027208 Vali Loss: 0.2639688 Test Loss: 0.3536555
Validation loss decreased (0.265289 --> 0.263969).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.6928350
	speed: 0.1088s/iter; left time: 2633.8791s
	iters: 200, epoch: 4 | loss: 0.4413150
	speed: 0.0607s/iter; left time: 1463.2744s
	iters: 300, epoch: 4 | loss: 0.4124093
	speed: 0.0827s/iter; left time: 1983.9930s
	iters: 400, epoch: 4 | loss: 0.5143206
	speed: 0.0551s/iter; left time: 1317.2410s
	iters: 500, epoch: 4 | loss: 0.3914354
	speed: 0.0559s/iter; left time: 1330.0888s
Epoch: 4 cost time: 31.317895650863647
Epoch: 4, Steps: 517 | Train Loss: 0.4999306 Vali Loss: 0.2628311 Test Loss: 0.3522895
Validation loss decreased (0.263969 --> 0.262831).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.7537253
	speed: 0.3559s/iter; left time: 8429.6792s
	iters: 200, epoch: 5 | loss: 0.7216605
	speed: 0.0596s/iter; left time: 1406.4392s
	iters: 300, epoch: 5 | loss: 0.5490957
	speed: 0.0527s/iter; left time: 1236.6137s
	iters: 400, epoch: 5 | loss: 0.5702733
	speed: 0.0647s/iter; left time: 1512.6464s
	iters: 500, epoch: 5 | loss: 0.5855682
	speed: 0.0565s/iter; left time: 1314.8740s
Epoch: 5 cost time: 30.30280613899231
Epoch: 5, Steps: 517 | Train Loss: 0.4983863 Vali Loss: 0.2620227 Test Loss: 0.3519369
Validation loss decreased (0.262831 --> 0.262023).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3783397
	speed: 0.3848s/iter; left time: 8914.7358s
	iters: 200, epoch: 6 | loss: 0.5346798
	speed: 0.0713s/iter; left time: 1644.8857s
	iters: 300, epoch: 6 | loss: 0.6404246
	speed: 0.0731s/iter; left time: 1679.5595s
	iters: 400, epoch: 6 | loss: 0.5159972
	speed: 0.0607s/iter; left time: 1387.8481s
	iters: 500, epoch: 6 | loss: 0.5465347
	speed: 0.0321s/iter; left time: 731.9224s
Epoch: 6 cost time: 33.025275230407715
Epoch: 6, Steps: 517 | Train Loss: 0.4968081 Vali Loss: 0.2612632 Test Loss: 0.3509581
Validation loss decreased (0.262023 --> 0.261263).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4665707
	speed: 0.3999s/iter; left time: 9056.6483s
	iters: 200, epoch: 7 | loss: 0.3687764
	speed: 0.0702s/iter; left time: 1581.9240s
	iters: 300, epoch: 7 | loss: 0.3714474
	speed: 0.0627s/iter; left time: 1408.2971s
	iters: 400, epoch: 7 | loss: 0.4350717
	speed: 0.0395s/iter; left time: 882.7874s
	iters: 500, epoch: 7 | loss: 0.4552605
	speed: 0.0740s/iter; left time: 1647.4290s
Epoch: 7 cost time: 31.905383825302124
Epoch: 7, Steps: 517 | Train Loss: 0.4966921 Vali Loss: 0.2618034 Test Loss: 0.3504373
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4847679
	speed: 0.2985s/iter; left time: 6606.8365s
	iters: 200, epoch: 8 | loss: 0.5103638
	speed: 0.0552s/iter; left time: 1217.2568s
	iters: 300, epoch: 8 | loss: 0.3246916
	speed: 0.0541s/iter; left time: 1187.5232s
	iters: 400, epoch: 8 | loss: 0.4128484
	speed: 0.0585s/iter; left time: 1276.7843s
	iters: 500, epoch: 8 | loss: 0.5111876
	speed: 0.0672s/iter; left time: 1460.2174s
Epoch: 8 cost time: 31.979276418685913
Epoch: 8, Steps: 517 | Train Loss: 0.4960475 Vali Loss: 0.2607688 Test Loss: 0.3506491
Validation loss decreased (0.261263 --> 0.260769).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2885132
	speed: 0.3134s/iter; left time: 6774.2208s
	iters: 200, epoch: 9 | loss: 0.3554109
	speed: 0.0435s/iter; left time: 934.9352s
	iters: 300, epoch: 9 | loss: 0.8352968
	speed: 0.0580s/iter; left time: 1241.2217s
	iters: 400, epoch: 9 | loss: 0.4039202
	speed: 0.0516s/iter; left time: 1099.3385s
	iters: 500, epoch: 9 | loss: 0.3549455
	speed: 0.0572s/iter; left time: 1213.1395s
Epoch: 9 cost time: 26.973076581954956
Epoch: 9, Steps: 517 | Train Loss: 0.4952917 Vali Loss: 0.2610238 Test Loss: 0.3502347
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4097140
	speed: 0.2499s/iter; left time: 5271.7660s
	iters: 200, epoch: 10 | loss: 0.5090281
	speed: 0.0522s/iter; left time: 1096.6302s
	iters: 300, epoch: 10 | loss: 0.4057861
	speed: 0.0182s/iter; left time: 379.6567s
	iters: 400, epoch: 10 | loss: 0.4751686
	speed: 0.0579s/iter; left time: 1204.2206s
	iters: 500, epoch: 10 | loss: 0.4631514
	speed: 0.0333s/iter; left time: 689.2994s
Epoch: 10 cost time: 22.693542003631592
Epoch: 10, Steps: 517 | Train Loss: 0.4953817 Vali Loss: 0.2607771 Test Loss: 0.3500126
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3969906
	speed: 0.3148s/iter; left time: 6479.3105s
	iters: 200, epoch: 11 | loss: 0.6404904
	speed: 0.0543s/iter; left time: 1111.9122s
	iters: 300, epoch: 11 | loss: 0.3792319
	speed: 0.0548s/iter; left time: 1116.3784s
	iters: 400, epoch: 11 | loss: 0.7438977
	speed: 0.0408s/iter; left time: 827.0355s
	iters: 500, epoch: 11 | loss: 0.4844472
	speed: 0.0445s/iter; left time: 898.4318s
Epoch: 11 cost time: 25.81475329399109
Epoch: 11, Steps: 517 | Train Loss: 0.4947555 Vali Loss: 0.2603962 Test Loss: 0.3499590
Validation loss decreased (0.260769 --> 0.260396).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.5246851
	speed: 0.1196s/iter; left time: 2399.9688s
	iters: 200, epoch: 12 | loss: 0.4575416
	speed: 0.0220s/iter; left time: 439.6393s
	iters: 300, epoch: 12 | loss: 0.5369515
	speed: 0.0173s/iter; left time: 343.1444s
	iters: 400, epoch: 12 | loss: 0.5328496
	speed: 0.0203s/iter; left time: 400.9439s
	iters: 500, epoch: 12 | loss: 0.6009557
	speed: 0.0393s/iter; left time: 771.8198s
Epoch: 12 cost time: 12.202969789505005
Epoch: 12, Steps: 517 | Train Loss: 0.4948182 Vali Loss: 0.2608759 Test Loss: 0.3497577
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3677973
	speed: 0.0921s/iter; left time: 1800.0605s
	iters: 200, epoch: 13 | loss: 0.5381834
	speed: 0.0200s/iter; left time: 389.7285s
	iters: 300, epoch: 13 | loss: 0.5375205
	speed: 0.0239s/iter; left time: 462.1106s
	iters: 400, epoch: 13 | loss: 0.3743559
	speed: 0.0519s/iter; left time: 999.1858s
	iters: 500, epoch: 13 | loss: 0.4433626
	speed: 0.0575s/iter; left time: 1100.6792s
Epoch: 13 cost time: 18.44378399848938
Epoch: 13, Steps: 517 | Train Loss: 0.4944277 Vali Loss: 0.2601879 Test Loss: 0.3500009
Validation loss decreased (0.260396 --> 0.260188).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.5684583
	speed: 0.3099s/iter; left time: 5896.9209s
	iters: 200, epoch: 14 | loss: 0.4239477
	speed: 0.0547s/iter; left time: 1035.7621s
	iters: 300, epoch: 14 | loss: 0.4380983
	speed: 0.0552s/iter; left time: 1039.7848s
	iters: 400, epoch: 14 | loss: 0.7061442
	speed: 0.0432s/iter; left time: 809.5792s
	iters: 500, epoch: 14 | loss: 0.3630552
	speed: 0.0537s/iter; left time: 1000.8378s
Epoch: 14 cost time: 27.763837575912476
Epoch: 14, Steps: 517 | Train Loss: 0.4942192 Vali Loss: 0.2605183 Test Loss: 0.3496459
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4464323
	speed: 0.2549s/iter; left time: 4718.8666s
	iters: 200, epoch: 15 | loss: 0.4621503
	speed: 0.0291s/iter; left time: 535.6213s
	iters: 300, epoch: 15 | loss: 0.5787721
	speed: 0.0233s/iter; left time: 426.9628s
	iters: 400, epoch: 15 | loss: 0.3224739
	speed: 0.0600s/iter; left time: 1093.6723s
	iters: 500, epoch: 15 | loss: 0.5547746
	speed: 0.0485s/iter; left time: 877.6856s
Epoch: 15 cost time: 22.773077964782715
Epoch: 15, Steps: 517 | Train Loss: 0.4942680 Vali Loss: 0.2600130 Test Loss: 0.3499075
Validation loss decreased (0.260188 --> 0.260013).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.5499299
	speed: 0.2616s/iter; left time: 4708.4811s
	iters: 200, epoch: 16 | loss: 0.6842170
	speed: 0.0440s/iter; left time: 786.8411s
	iters: 300, epoch: 16 | loss: 0.4121274
	speed: 0.0479s/iter; left time: 852.9158s
	iters: 400, epoch: 16 | loss: 0.5375891
	speed: 0.0434s/iter; left time: 768.4912s
	iters: 500, epoch: 16 | loss: 0.9236253
	speed: 0.0512s/iter; left time: 901.7517s
Epoch: 16 cost time: 24.363330364227295
Epoch: 16, Steps: 517 | Train Loss: 0.4940959 Vali Loss: 0.2600181 Test Loss: 0.3495925
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.6948555
	speed: 0.2610s/iter; left time: 4562.1007s
	iters: 200, epoch: 17 | loss: 0.6284915
	speed: 0.0450s/iter; left time: 782.8337s
	iters: 300, epoch: 17 | loss: 0.3403642
	speed: 0.0573s/iter; left time: 990.1177s
	iters: 400, epoch: 17 | loss: 0.4989587
	speed: 0.0421s/iter; left time: 723.1160s
	iters: 500, epoch: 17 | loss: 0.5762051
	speed: 0.0254s/iter; left time: 434.6555s
Epoch: 17 cost time: 23.14799213409424
Epoch: 17, Steps: 517 | Train Loss: 0.4940235 Vali Loss: 0.2600096 Test Loss: 0.3495759
Validation loss decreased (0.260013 --> 0.260010).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.6382076
	speed: 0.2971s/iter; left time: 5039.1273s
	iters: 200, epoch: 18 | loss: 0.3890481
	speed: 0.0530s/iter; left time: 894.3482s
	iters: 300, epoch: 18 | loss: 0.4388400
	speed: 0.0485s/iter; left time: 812.9930s
	iters: 400, epoch: 18 | loss: 0.4530002
	speed: 0.0545s/iter; left time: 907.6726s
	iters: 500, epoch: 18 | loss: 0.3076460
	speed: 0.0607s/iter; left time: 1005.5807s
Epoch: 18 cost time: 29.432167053222656
Epoch: 18, Steps: 517 | Train Loss: 0.4940975 Vali Loss: 0.2601848 Test Loss: 0.3496614
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4030567
	speed: 0.2973s/iter; left time: 4888.8050s
	iters: 200, epoch: 19 | loss: 0.4157561
	speed: 0.0634s/iter; left time: 1036.1570s
	iters: 300, epoch: 19 | loss: 0.4633636
	speed: 0.0458s/iter; left time: 743.3489s
	iters: 400, epoch: 19 | loss: 0.5662958
	speed: 0.0617s/iter; left time: 995.7240s
	iters: 500, epoch: 19 | loss: 0.4376409
	speed: 0.0500s/iter; left time: 801.8710s
Epoch: 19 cost time: 28.788978338241577
Epoch: 19, Steps: 517 | Train Loss: 0.4940588 Vali Loss: 0.2599503 Test Loss: 0.3496702
Validation loss decreased (0.260010 --> 0.259950).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4353240
	speed: 0.2220s/iter; left time: 3536.5201s
	iters: 200, epoch: 20 | loss: 0.2956614
	speed: 0.0525s/iter; left time: 830.5604s
	iters: 300, epoch: 20 | loss: 0.3873155
	speed: 0.0443s/iter; left time: 696.6486s
	iters: 400, epoch: 20 | loss: 0.4662756
	speed: 0.0467s/iter; left time: 729.3097s
	iters: 500, epoch: 20 | loss: 0.3293166
	speed: 0.0438s/iter; left time: 680.6411s
Epoch: 20 cost time: 24.477738857269287
Epoch: 20, Steps: 517 | Train Loss: 0.4936141 Vali Loss: 0.2598756 Test Loss: 0.3495265
Validation loss decreased (0.259950 --> 0.259876).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.6025768
	speed: 0.2673s/iter; left time: 4119.9553s
	iters: 200, epoch: 21 | loss: 0.2972690
	speed: 0.0283s/iter; left time: 433.7961s
	iters: 300, epoch: 21 | loss: 0.3815855
	speed: 0.0483s/iter; left time: 733.9311s
	iters: 400, epoch: 21 | loss: 0.3528313
	speed: 0.0451s/iter; left time: 681.2089s
	iters: 500, epoch: 21 | loss: 0.4056429
	speed: 0.0460s/iter; left time: 690.0929s
Epoch: 21 cost time: 23.136003255844116
Epoch: 21, Steps: 517 | Train Loss: 0.4939607 Vali Loss: 0.2600741 Test Loss: 0.3497546
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4279274
	speed: 0.2477s/iter; left time: 3689.8331s
	iters: 200, epoch: 22 | loss: 0.5659460
	speed: 0.0293s/iter; left time: 432.7730s
	iters: 300, epoch: 22 | loss: 0.3562518
	speed: 0.0145s/iter; left time: 213.0742s
	iters: 400, epoch: 22 | loss: 0.5165719
	speed: 0.0349s/iter; left time: 509.0812s
	iters: 500, epoch: 22 | loss: 0.3244622
	speed: 0.0518s/iter; left time: 750.4263s
Epoch: 22 cost time: 19.126864433288574
Epoch: 22, Steps: 517 | Train Loss: 0.4938241 Vali Loss: 0.2595433 Test Loss: 0.3496276
Validation loss decreased (0.259876 --> 0.259543).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3344132
	speed: 0.2365s/iter; left time: 3399.9380s
	iters: 200, epoch: 23 | loss: 0.2892982
	speed: 0.0442s/iter; left time: 630.9532s
	iters: 300, epoch: 23 | loss: 0.5008813
	speed: 0.0541s/iter; left time: 766.2913s
	iters: 400, epoch: 23 | loss: 0.6058786
	speed: 0.0288s/iter; left time: 405.5432s
	iters: 500, epoch: 23 | loss: 0.3594183
	speed: 0.0479s/iter; left time: 669.6448s
Epoch: 23 cost time: 23.7768132686615
Epoch: 23, Steps: 517 | Train Loss: 0.4936624 Vali Loss: 0.2600714 Test Loss: 0.3495283
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.5772009
	speed: 0.2208s/iter; left time: 3059.8140s
	iters: 200, epoch: 24 | loss: 0.4986439
	speed: 0.0436s/iter; left time: 599.8494s
	iters: 300, epoch: 24 | loss: 0.9670485
	speed: 0.0535s/iter; left time: 730.3526s
	iters: 400, epoch: 24 | loss: 0.4264973
	speed: 0.0458s/iter; left time: 621.4435s
	iters: 500, epoch: 24 | loss: 0.7858377
	speed: 0.0560s/iter; left time: 753.3171s
Epoch: 24 cost time: 25.60486674308777
Epoch: 24, Steps: 517 | Train Loss: 0.4937356 Vali Loss: 0.2600133 Test Loss: 0.3495110
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.6582542
	speed: 0.2404s/iter; left time: 3208.0198s
	iters: 200, epoch: 25 | loss: 0.5659631
	speed: 0.0394s/iter; left time: 521.5839s
	iters: 300, epoch: 25 | loss: 0.4129370
	speed: 0.0311s/iter; left time: 408.4447s
	iters: 400, epoch: 25 | loss: 0.4141868
	speed: 0.0350s/iter; left time: 456.9280s
	iters: 500, epoch: 25 | loss: 0.6600139
	speed: 0.0130s/iter; left time: 168.4104s
Epoch: 25 cost time: 17.53161644935608
Epoch: 25, Steps: 517 | Train Loss: 0.4937108 Vali Loss: 0.2600785 Test Loss: 0.3493150
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.5799513
	speed: 0.1023s/iter; left time: 1312.5329s
	iters: 200, epoch: 26 | loss: 0.5967228
	speed: 0.0141s/iter; left time: 179.8212s
	iters: 300, epoch: 26 | loss: 0.4793154
	speed: 0.0125s/iter; left time: 158.1275s
	iters: 400, epoch: 26 | loss: 0.3104537
	speed: 0.0134s/iter; left time: 167.4213s
	iters: 500, epoch: 26 | loss: 0.4715571
	speed: 0.0127s/iter; left time: 157.7070s
Epoch: 26 cost time: 7.78911828994751
Epoch: 26, Steps: 517 | Train Loss: 0.4936019 Vali Loss: 0.2602245 Test Loss: 0.3493979
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.5625643
	speed: 0.0784s/iter; left time: 965.2457s
	iters: 200, epoch: 27 | loss: 0.4788878
	speed: 0.0148s/iter; left time: 180.2089s
	iters: 300, epoch: 27 | loss: 0.4837516
	speed: 0.0137s/iter; left time: 165.6995s
	iters: 400, epoch: 27 | loss: 0.3184363
	speed: 0.0129s/iter; left time: 154.4925s
	iters: 500, epoch: 27 | loss: 0.6477823
	speed: 0.0126s/iter; left time: 150.5961s
Epoch: 27 cost time: 7.774857521057129
Epoch: 27, Steps: 517 | Train Loss: 0.4933930 Vali Loss: 0.2600906 Test Loss: 0.3494098
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3060110
	speed: 0.1165s/iter; left time: 1373.9502s
	iters: 200, epoch: 28 | loss: 0.6485267
	speed: 0.0147s/iter; left time: 171.6929s
	iters: 300, epoch: 28 | loss: 0.3243287
	speed: 0.0188s/iter; left time: 217.8992s
	iters: 400, epoch: 28 | loss: 0.9217708
	speed: 0.0175s/iter; left time: 201.6486s
	iters: 500, epoch: 28 | loss: 0.4604900
	speed: 0.0154s/iter; left time: 175.0265s
Epoch: 28 cost time: 8.995068311691284
Epoch: 28, Steps: 517 | Train Loss: 0.4935141 Vali Loss: 0.2598856 Test Loss: 0.3493908
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4731051
	speed: 0.1045s/iter; left time: 1177.8353s
	iters: 200, epoch: 29 | loss: 0.4313889
	speed: 0.0097s/iter; left time: 108.8888s
	iters: 300, epoch: 29 | loss: 0.6347060
	speed: 0.0083s/iter; left time: 92.4328s
	iters: 400, epoch: 29 | loss: 0.4667006
	speed: 0.0174s/iter; left time: 190.4286s
	iters: 500, epoch: 29 | loss: 0.4539603
	speed: 0.0221s/iter; left time: 239.8690s
Epoch: 29 cost time: 8.911042928695679
Epoch: 29, Steps: 517 | Train Loss: 0.4934541 Vali Loss: 0.2596695 Test Loss: 0.3494380
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.5351345
	speed: 0.1004s/iter; left time: 1080.2953s
	iters: 200, epoch: 30 | loss: 0.4483067
	speed: 0.0204s/iter; left time: 217.4075s
	iters: 300, epoch: 30 | loss: 0.5070875
	speed: 0.0270s/iter; left time: 284.7553s
	iters: 400, epoch: 30 | loss: 0.3411696
	speed: 0.0149s/iter; left time: 155.3959s
	iters: 500, epoch: 30 | loss: 0.5079653
	speed: 0.0185s/iter; left time: 191.9305s
Epoch: 30 cost time: 10.406728506088257
Epoch: 30, Steps: 517 | Train Loss: 0.4932493 Vali Loss: 0.2597043 Test Loss: 0.3494828
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2937585
	speed: 0.1295s/iter; left time: 1326.6057s
	iters: 200, epoch: 31 | loss: 0.6553645
	speed: 0.0240s/iter; left time: 243.1536s
	iters: 300, epoch: 31 | loss: 0.5211950
	speed: 0.0190s/iter; left time: 190.7925s
	iters: 400, epoch: 31 | loss: 0.4665093
	speed: 0.0206s/iter; left time: 204.3113s
	iters: 500, epoch: 31 | loss: 0.6171494
	speed: 0.0648s/iter; left time: 637.7585s
Epoch: 31 cost time: 17.83695101737976
Epoch: 31, Steps: 517 | Train Loss: 0.4932695 Vali Loss: 0.2597174 Test Loss: 0.3494328
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.6020455
	speed: 0.2595s/iter; left time: 2523.4840s
	iters: 200, epoch: 32 | loss: 0.4261709
	speed: 0.0647s/iter; left time: 622.5671s
	iters: 300, epoch: 32 | loss: 0.3864172
	speed: 0.0622s/iter; left time: 592.6579s
	iters: 400, epoch: 32 | loss: 0.4050919
	speed: 0.0467s/iter; left time: 440.0111s
	iters: 500, epoch: 32 | loss: 0.5192059
	speed: 0.0524s/iter; left time: 488.1843s
Epoch: 32 cost time: 28.848381519317627
Epoch: 32, Steps: 517 | Train Loss: 0.4933116 Vali Loss: 0.2597999 Test Loss: 0.3494073
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4578586
	speed: 0.2937s/iter; left time: 2704.1181s
	iters: 200, epoch: 33 | loss: 0.4465963
	speed: 0.0563s/iter; left time: 512.4232s
	iters: 300, epoch: 33 | loss: 0.7559181
	speed: 0.0670s/iter; left time: 603.5566s
	iters: 400, epoch: 33 | loss: 0.6129347
	speed: 0.0425s/iter; left time: 378.6189s
	iters: 500, epoch: 33 | loss: 0.4201415
	speed: 0.0623s/iter; left time: 548.4294s
Epoch: 33 cost time: 29.25622844696045
Epoch: 33, Steps: 517 | Train Loss: 0.4932209 Vali Loss: 0.2600507 Test Loss: 0.3493728
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.8391523
	speed: 0.3919s/iter; left time: 3405.9884s
	iters: 200, epoch: 34 | loss: 0.4536468
	speed: 0.0500s/iter; left time: 429.5573s
	iters: 300, epoch: 34 | loss: 0.9828022
	speed: 0.0655s/iter; left time: 556.3722s
	iters: 400, epoch: 34 | loss: 0.4253008
	speed: 0.0632s/iter; left time: 530.6556s
	iters: 500, epoch: 34 | loss: 0.3945090
	speed: 0.0680s/iter; left time: 563.4739s
Epoch: 34 cost time: 32.6063814163208
Epoch: 34, Steps: 517 | Train Loss: 0.4933397 Vali Loss: 0.2598002 Test Loss: 0.3494508
EarlyStopping counter: 12 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4420629
	speed: 0.3168s/iter; left time: 2589.1372s
	iters: 200, epoch: 35 | loss: 0.4169205
	speed: 0.0580s/iter; left time: 468.4649s
	iters: 300, epoch: 35 | loss: 0.5187556
	speed: 0.0089s/iter; left time: 70.8950s
	iters: 400, epoch: 35 | loss: 0.5251099
	speed: 0.0548s/iter; left time: 431.2260s
	iters: 500, epoch: 35 | loss: 0.4746660
	speed: 0.0583s/iter; left time: 453.2323s
Epoch: 35 cost time: 25.10042977333069
Epoch: 35, Steps: 517 | Train Loss: 0.4933478 Vali Loss: 0.2597442 Test Loss: 0.3494258
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.5283161
	speed: 0.2257s/iter; left time: 1728.2093s
	iters: 200, epoch: 36 | loss: 0.5050063
	speed: 0.0508s/iter; left time: 383.7748s
	iters: 300, epoch: 36 | loss: 0.4077174
	speed: 0.0556s/iter; left time: 414.8828s
	iters: 400, epoch: 36 | loss: 0.3119992
	speed: 0.0600s/iter; left time: 441.1464s
	iters: 500, epoch: 36 | loss: 0.6882871
	speed: 0.0537s/iter; left time: 389.5732s
Epoch: 36 cost time: 29.098006010055542
Epoch: 36, Steps: 517 | Train Loss: 0.4931397 Vali Loss: 0.2599700 Test Loss: 0.3494363
EarlyStopping counter: 14 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3061348
	speed: 0.2361s/iter; left time: 1685.3733s
	iters: 200, epoch: 37 | loss: 0.4462836
	speed: 0.0295s/iter; left time: 207.6433s
	iters: 300, epoch: 37 | loss: 0.5677998
	speed: 0.0320s/iter; left time: 221.8670s
	iters: 400, epoch: 37 | loss: 0.6040074
	speed: 0.0258s/iter; left time: 176.3072s
	iters: 500, epoch: 37 | loss: 0.4818608
	speed: 0.0139s/iter; left time: 93.5347s
Epoch: 37 cost time: 13.23583984375
Epoch: 37, Steps: 517 | Train Loss: 0.4933521 Vali Loss: 0.2599365 Test Loss: 0.3494140
EarlyStopping counter: 15 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.7668806
	speed: 0.1214s/iter; left time: 803.9779s
	iters: 200, epoch: 38 | loss: 0.6791407
	speed: 0.0275s/iter; left time: 179.1446s
	iters: 300, epoch: 38 | loss: 0.6446082
	speed: 0.0264s/iter; left time: 169.7917s
	iters: 400, epoch: 38 | loss: 0.3188477
	speed: 0.0206s/iter; left time: 130.4350s
	iters: 500, epoch: 38 | loss: 0.4327864
	speed: 0.0246s/iter; left time: 153.2296s
Epoch: 38 cost time: 13.321563005447388
Epoch: 38, Steps: 517 | Train Loss: 0.4930988 Vali Loss: 0.2599481 Test Loss: 0.3493470
EarlyStopping counter: 16 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.5890977
	speed: 0.1216s/iter; left time: 742.4051s
	iters: 200, epoch: 39 | loss: 0.6270924
	speed: 0.0230s/iter; left time: 137.9521s
	iters: 300, epoch: 39 | loss: 0.4573421
	speed: 0.0295s/iter; left time: 174.4747s
	iters: 400, epoch: 39 | loss: 0.4133631
	speed: 0.0386s/iter; left time: 223.9795s
	iters: 500, epoch: 39 | loss: 0.3921817
	speed: 0.0204s/iter; left time: 116.2740s
Epoch: 39 cost time: 14.549236059188843
Epoch: 39, Steps: 517 | Train Loss: 0.4930913 Vali Loss: 0.2599525 Test Loss: 0.3493326
EarlyStopping counter: 17 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.5839242
	speed: 0.1101s/iter; left time: 615.3137s
	iters: 200, epoch: 40 | loss: 0.4183263
	speed: 0.0203s/iter; left time: 111.4462s
	iters: 300, epoch: 40 | loss: 0.7330133
	speed: 0.0228s/iter; left time: 122.5871s
	iters: 400, epoch: 40 | loss: 0.3425902
	speed: 0.0261s/iter; left time: 138.1100s
	iters: 500, epoch: 40 | loss: 0.6174958
	speed: 0.0217s/iter; left time: 112.7935s
Epoch: 40 cost time: 12.453810214996338
Epoch: 40, Steps: 517 | Train Loss: 0.4932052 Vali Loss: 0.2599076 Test Loss: 0.3493427
EarlyStopping counter: 18 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.6426342
	speed: 0.1013s/iter; left time: 513.5402s
	iters: 200, epoch: 41 | loss: 0.3320211
	speed: 0.0344s/iter; left time: 170.9724s
	iters: 300, epoch: 41 | loss: 0.5816699
	speed: 0.0402s/iter; left time: 195.8249s
	iters: 400, epoch: 41 | loss: 0.6500517
	speed: 0.0494s/iter; left time: 235.8934s
	iters: 500, epoch: 41 | loss: 0.5939192
	speed: 0.0428s/iter; left time: 199.9762s
Epoch: 41 cost time: 20.184378623962402
Epoch: 41, Steps: 517 | Train Loss: 0.4929889 Vali Loss: 0.2600787 Test Loss: 0.3492965
EarlyStopping counter: 19 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.3747474
	speed: 0.2334s/iter; left time: 1063.1287s
	iters: 200, epoch: 42 | loss: 0.6400951
	speed: 0.0589s/iter; left time: 262.2310s
	iters: 300, epoch: 42 | loss: 0.3037362
	speed: 0.0455s/iter; left time: 197.9658s
	iters: 400, epoch: 42 | loss: 0.3454978
	speed: 0.0335s/iter; left time: 142.7179s
	iters: 500, epoch: 42 | loss: 0.5525488
	speed: 0.0382s/iter; left time: 158.7486s
Epoch: 42 cost time: 23.451759099960327
Epoch: 42, Steps: 517 | Train Loss: 0.4931199 Vali Loss: 0.2598768 Test Loss: 0.3493329
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : ETTm2_720_720_FITS_ETTm2_ftM_sl720_ll48_pl720_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.34898707270622253, mae:0.3778073489665985, rse:0.4748419523239136, corr:[0.54650134 0.5437502  0.5374437  0.53632146 0.5381341  0.5384974
 0.53702486 0.5359121  0.53626084 0.53723776 0.5372993  0.536319
 0.53544736 0.53543603 0.5360971  0.53638554 0.53577477 0.5347553
 0.53401405 0.5337717  0.5336277  0.5329658  0.5318828  0.53100425
 0.5306955  0.53084373 0.53086424 0.53025854 0.5291771  0.52822506
 0.52777463 0.52782184 0.5278806  0.5274924  0.5267415  0.5260266
 0.5255582  0.52527374 0.52483994 0.524137   0.52334285 0.52269864
 0.5223644  0.5221729  0.5217945  0.5210306  0.5200555  0.51917726
 0.5185129  0.51798207 0.5173985  0.5166586  0.5157646  0.5148931
 0.5142311  0.5138064  0.5134445  0.5129818  0.5124273  0.5119039
 0.51157355 0.51146096 0.5114319  0.51132995 0.5111398  0.5109754
 0.5107805  0.51054597 0.5102015  0.50975496 0.50930566 0.50897706
 0.5087833  0.50861293 0.50830024 0.5078471  0.5073415  0.5068359
 0.50633126 0.5057413  0.5049478  0.5040744  0.50331086 0.5027434
 0.5023109  0.5018869  0.501361   0.50082844 0.5003544  0.49996173
 0.49959096 0.49911174 0.49842876 0.49759573 0.49667034 0.49563137
 0.49439892 0.492996   0.49148265 0.4900471  0.4888178  0.4877404
 0.4866632  0.4854761  0.48424956 0.48319393 0.48241022 0.48176658
 0.48095635 0.47986406 0.478626   0.47750112 0.4767191  0.47613978
 0.47551155 0.47476074 0.4739895  0.4732824  0.47264773 0.47186914
 0.47085878 0.46964222 0.4685253  0.4677652  0.46736944 0.46701562
 0.46638125 0.4653548  0.46412668 0.4630206  0.46222368 0.46159
 0.46089894 0.4600832  0.4593577  0.45893404 0.4587262  0.45842156
 0.45764187 0.45629522 0.45472997 0.4535931  0.45318606 0.45308813
 0.45271432 0.45172015 0.45040956 0.44927517 0.44863403 0.44824222
 0.44767082 0.4467078  0.4454771  0.44445318 0.443991   0.44393274
 0.44377995 0.44316036 0.44208404 0.44102198 0.4403416  0.440174
 0.44030148 0.44051182 0.44066143 0.44066244 0.44039175 0.43980753
 0.43897548 0.4380942  0.4373412  0.4369024  0.4366381  0.43626133
 0.4356022  0.43480372 0.43415457 0.43381426 0.4336319  0.43333566
 0.4326742  0.43174568 0.4308877  0.43026957 0.42980433 0.4293024
 0.42874798 0.42823726 0.4278945  0.42756888 0.42694083 0.42574167
 0.4240989  0.4226098  0.42158863 0.42097676 0.42036822 0.4192673
 0.41755193 0.41550896 0.41372836 0.41256842 0.41184303 0.4110818
 0.40999353 0.40864936 0.40733877 0.40626627 0.40540186 0.4045096
 0.4033138  0.40196604 0.40082967 0.40008113 0.3995487  0.39878234
 0.3975711  0.39603454 0.3946234  0.39350367 0.3925466  0.3915502
 0.3904437  0.38938007 0.3885553  0.3877966  0.38691702 0.38586438
 0.38470054 0.38372883 0.38308132 0.38261127 0.3819937  0.38107857
 0.37997225 0.3790914  0.37871495 0.37875903 0.37890545 0.37879848
 0.37837595 0.37774158 0.3770905  0.37655872 0.37591988 0.3751592
 0.37444073 0.37406948 0.37413037 0.37443355 0.37480822 0.37507036
 0.37519932 0.37528127 0.3751554  0.37470073 0.3738859  0.37304455
 0.37259045 0.3727378  0.37317023 0.3732961  0.37264886 0.3714338
 0.37031135 0.3698827  0.37026763 0.37089503 0.3710331  0.37037802
 0.36933053 0.3684814  0.36808357 0.36799124 0.36778545 0.3672668
 0.3666584  0.36615947 0.36586097 0.36572945 0.36554095 0.36532825
 0.36519447 0.36523494 0.36529994 0.36503315 0.364188   0.36275944
 0.3612166  0.36009425 0.35936818 0.35872528 0.35797888 0.35717186
 0.35663584 0.35640338 0.35619503 0.35568842 0.3548462  0.3538394
 0.3530883  0.3526339  0.3523199  0.35168347 0.35069674 0.34966427
 0.34908336 0.34901974 0.34916705 0.34901896 0.34830454 0.347313
 0.34641704 0.34606487 0.3462071  0.3464916  0.34660482 0.34646934
 0.34614506 0.34586948 0.34579092 0.34588382 0.34603253 0.346153
 0.34612218 0.3459214  0.34558052 0.3451907  0.3450784  0.3453706
 0.34603432 0.34662476 0.34675974 0.34635273 0.34556428 0.34487683
 0.34453166 0.34439844 0.34431297 0.34417945 0.34400156 0.34387875
 0.34392342 0.34403452 0.34398025 0.34362948 0.34311134 0.34273857
 0.34267402 0.34289822 0.34319443 0.34336728 0.34340003 0.34331036
 0.3430865  0.34269843 0.34207904 0.3414784  0.3410455  0.34099358
 0.3412025  0.34136054 0.3412175  0.34082308 0.34043017 0.34033597
 0.3404349  0.3405378  0.34042433 0.34016573 0.34004804 0.34015772
 0.34035534 0.34036136 0.34000444 0.3394607  0.3391373  0.33933845
 0.33989185 0.34026453 0.34001914 0.3392063  0.3384795  0.33823434
 0.33848843 0.33874354 0.3384871  0.33757713 0.33638924 0.33556217
 0.33522376 0.3350423  0.33452907 0.33349568 0.33220294 0.33107033
 0.33034915 0.32997382 0.32958624 0.3290451  0.32849315 0.32796744
 0.32743365 0.3267346  0.32585293 0.32500857 0.32443795 0.3243706
 0.32466835 0.32507494 0.32525778 0.3250573  0.32463658 0.3241477
 0.3237449  0.32342127 0.3230962  0.32283825 0.32274738 0.3228843
 0.32318026 0.32345268 0.32357186 0.32361978 0.323723   0.32386324
 0.32388896 0.32360843 0.32314053 0.32279018 0.32284525 0.32326728
 0.32372168 0.323793   0.32349834 0.3232093  0.3232755  0.3236058
 0.32376873 0.32351208 0.32271343 0.3217028  0.3210934  0.32116687
 0.32151467 0.32165548 0.321241   0.32032406 0.3193636  0.31866774
 0.31827348 0.31795728 0.31760272 0.31722578 0.31704634 0.31715116
 0.31732926 0.317318   0.31702068 0.31661633 0.31641537 0.31632853
 0.31618237 0.3157989  0.31523705 0.31477493 0.31460238 0.3146232
 0.31451714 0.3139996  0.31311816 0.3122556  0.3118401  0.31182674
 0.31184542 0.31140727 0.31045255 0.30923578 0.3082069  0.3075227
 0.3070108  0.3064631  0.3056428  0.3046146  0.30356944 0.30255687
 0.3014416  0.30017316 0.29880384 0.2976747  0.29697138 0.29663232
 0.29639536 0.29603532 0.2953989  0.29450485 0.29362148 0.2929384
 0.2924887  0.29209545 0.29161385 0.29104647 0.29031795 0.2895012
 0.2885215  0.2874706  0.28655672 0.28592464 0.2856599  0.285564
 0.28538966 0.28502715 0.28454277 0.28410664 0.28384072 0.2836827
 0.28344366 0.28300545 0.2826535  0.28247973 0.28244063 0.28240123
 0.28216898 0.2817106  0.28114235 0.28075892 0.28076836 0.28105026
 0.28127885 0.2812195  0.28084978 0.2804022  0.28013414 0.28005728
 0.27997446 0.27970216 0.27928463 0.27881718 0.27847454 0.27837712
 0.2784895  0.27867746 0.27869868 0.2784286  0.27779618 0.27687195
 0.27594483 0.2753482  0.27518442 0.2752947  0.27531612 0.275089
 0.2746265  0.27424425 0.27422175 0.2745778  0.27491635 0.27499893
 0.2746753  0.27417058 0.2737211  0.2735269  0.27360594 0.27376756
 0.27378237 0.27348763 0.27295956 0.27236873 0.27192274 0.27175122
 0.27180535 0.27192333 0.27185273 0.27146208 0.2706987  0.26949826
 0.26796934 0.26647326 0.26511824 0.26390517 0.2628194  0.2619404
 0.2612896  0.26074356 0.26013994 0.25933737 0.25830987 0.2572846
 0.25647885 0.25596058 0.2557141  0.25550523 0.2551044  0.25446102
 0.2536172  0.25267527 0.2518581  0.2512     0.25080892 0.25069398
 0.250767   0.25097442 0.25108567 0.25095576 0.25066376 0.25030866
 0.2498994  0.24953185 0.24926598 0.24894542 0.24860473 0.24832381
 0.2482869  0.24836957 0.24854518 0.24872623 0.24875453 0.24862488
 0.24854864 0.24881673 0.24937142 0.25002995 0.25055256 0.2508981
 0.251104   0.251262   0.25139597 0.25148866 0.25145766 0.25137857
 0.25137404 0.25158963 0.25194165 0.25191814 0.2515751  0.25104326
 0.2506801  0.25074583 0.25107047 0.2514474  0.2513963  0.25094476
 0.25033417 0.24999069 0.24990526 0.24981587 0.24975704 0.24954684
 0.24940717 0.24935047 0.24931979 0.24914773 0.24889374 0.24848811
 0.24822347 0.248099   0.24796163 0.2478986  0.24798661 0.24820037
 0.24839504 0.248555   0.24844116 0.24812795 0.24803863 0.24840884
 0.24908245 0.24969691 0.2497704  0.24904466 0.24782926 0.24674588
 0.24613707 0.24583377 0.24529743 0.24411952 0.24254964 0.241095
 0.24019197 0.23983292 0.23989528 0.2397391  0.2392004  0.23840724
 0.2377379  0.23737569 0.23709564 0.23651874 0.23566426 0.23458299
 0.2336513  0.23298672 0.23233083 0.23167416 0.2308948  0.23020092
 0.22993132 0.22999734 0.23014134 0.22985911 0.22915378 0.22834727
 0.2279004  0.22744867 0.22670667 0.22564347 0.22457665 0.22400726
 0.22389306 0.22383596 0.22337487 0.22281545 0.22239801 0.22238494
 0.22208898 0.22092721 0.21970989 0.2200932  0.22154249 0.21822351]
