Args in experiment:
Namespace(H_order=14, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=96, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=122, d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTm2_720_336', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_720_336_FITS_ETTm2_ftM_sl720_ll48_pl336_H14_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=122, out_features=178, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  19457536.0
params:  21894.0
Trainable parameters:  21894
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5128622
	speed: 0.0144s/iter; left time: 186.3301s
	iters: 200, epoch: 1 | loss: 0.4390127
	speed: 0.0093s/iter; left time: 119.9528s
Epoch: 1 cost time: 3.0909667015075684
Epoch: 1, Steps: 261 | Train Loss: 0.4602177 Vali Loss: 0.2103010 Test Loss: 0.2890623
Validation loss decreased (inf --> 0.210301).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4245509
	speed: 0.0524s/iter; left time: 665.1143s
	iters: 200, epoch: 2 | loss: 0.4684555
	speed: 0.0090s/iter; left time: 113.6423s
Epoch: 2 cost time: 3.1759965419769287
Epoch: 2, Steps: 261 | Train Loss: 0.4026469 Vali Loss: 0.2019339 Test Loss: 0.2788179
Validation loss decreased (0.210301 --> 0.201934).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4102253
	speed: 0.0577s/iter; left time: 716.8425s
	iters: 200, epoch: 3 | loss: 0.2954649
	speed: 0.0110s/iter; left time: 135.9705s
Epoch: 3 cost time: 3.6492249965667725
Epoch: 3, Steps: 261 | Train Loss: 0.3918597 Vali Loss: 0.1986489 Test Loss: 0.2750032
Validation loss decreased (0.201934 --> 0.198649).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4936701
	speed: 0.0536s/iter; left time: 651.9481s
	iters: 200, epoch: 4 | loss: 0.3284155
	speed: 0.0102s/iter; left time: 122.9053s
Epoch: 4 cost time: 3.1258249282836914
Epoch: 4, Steps: 261 | Train Loss: 0.3866332 Vali Loss: 0.1964975 Test Loss: 0.2728049
Validation loss decreased (0.198649 --> 0.196497).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3812787
	speed: 0.0528s/iter; left time: 628.7210s
	iters: 200, epoch: 5 | loss: 0.3373215
	speed: 0.0102s/iter; left time: 120.0520s
Epoch: 5 cost time: 3.2862942218780518
Epoch: 5, Steps: 261 | Train Loss: 0.3829253 Vali Loss: 0.1956069 Test Loss: 0.2715401
Validation loss decreased (0.196497 --> 0.195607).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3733286
	speed: 0.0573s/iter; left time: 667.4211s
	iters: 200, epoch: 6 | loss: 0.3458129
	speed: 0.0103s/iter; left time: 118.7340s
Epoch: 6 cost time: 3.402827024459839
Epoch: 6, Steps: 261 | Train Loss: 0.3819515 Vali Loss: 0.1949159 Test Loss: 0.2706824
Validation loss decreased (0.195607 --> 0.194916).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4550209
	speed: 0.0557s/iter; left time: 633.8413s
	iters: 200, epoch: 7 | loss: 0.4714533
	speed: 0.0105s/iter; left time: 118.6803s
Epoch: 7 cost time: 3.1483566761016846
Epoch: 7, Steps: 261 | Train Loss: 0.3799390 Vali Loss: 0.1942233 Test Loss: 0.2696479
Validation loss decreased (0.194916 --> 0.194223).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3291706
	speed: 0.0515s/iter; left time: 572.6372s
	iters: 200, epoch: 8 | loss: 0.3757976
	speed: 0.0091s/iter; left time: 100.1835s
Epoch: 8 cost time: 2.7656986713409424
Epoch: 8, Steps: 261 | Train Loss: 0.3793322 Vali Loss: 0.1937510 Test Loss: 0.2692032
Validation loss decreased (0.194223 --> 0.193751).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3446513
	speed: 0.0489s/iter; left time: 531.4467s
	iters: 200, epoch: 9 | loss: 0.2931778
	speed: 0.0091s/iter; left time: 97.5075s
Epoch: 9 cost time: 2.867844343185425
Epoch: 9, Steps: 261 | Train Loss: 0.3781748 Vali Loss: 0.1937901 Test Loss: 0.2690680
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.5070029
	speed: 0.0519s/iter; left time: 550.4461s
	iters: 200, epoch: 10 | loss: 0.3982140
	speed: 0.0107s/iter; left time: 112.5623s
Epoch: 10 cost time: 3.2538273334503174
Epoch: 10, Steps: 261 | Train Loss: 0.3775923 Vali Loss: 0.1933014 Test Loss: 0.2688375
Validation loss decreased (0.193751 --> 0.193301).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3322040
	speed: 0.0517s/iter; left time: 534.9267s
	iters: 200, epoch: 11 | loss: 0.4102698
	speed: 0.0098s/iter; left time: 99.8686s
Epoch: 11 cost time: 3.1145122051239014
Epoch: 11, Steps: 261 | Train Loss: 0.3767842 Vali Loss: 0.1933514 Test Loss: 0.2686237
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.5813174
	speed: 0.0561s/iter; left time: 565.2179s
	iters: 200, epoch: 12 | loss: 0.3533948
	speed: 0.0095s/iter; left time: 94.8975s
Epoch: 12 cost time: 3.385936737060547
Epoch: 12, Steps: 261 | Train Loss: 0.3768743 Vali Loss: 0.1933146 Test Loss: 0.2685336
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3151031
	speed: 0.0513s/iter; left time: 503.5730s
	iters: 200, epoch: 13 | loss: 0.3575438
	speed: 0.0108s/iter; left time: 105.0394s
Epoch: 13 cost time: 3.297781229019165
Epoch: 13, Steps: 261 | Train Loss: 0.3764307 Vali Loss: 0.1931071 Test Loss: 0.2681892
Validation loss decreased (0.193301 --> 0.193107).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.5236226
	speed: 0.0632s/iter; left time: 603.7874s
	iters: 200, epoch: 14 | loss: 0.2780688
	speed: 0.0098s/iter; left time: 92.6069s
Epoch: 14 cost time: 3.2754628658294678
Epoch: 14, Steps: 261 | Train Loss: 0.3763715 Vali Loss: 0.1929023 Test Loss: 0.2681724
Validation loss decreased (0.193107 --> 0.192902).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3259245
	speed: 0.1343s/iter; left time: 1248.3312s
	iters: 200, epoch: 15 | loss: 0.4504992
	speed: 0.0115s/iter; left time: 106.0235s
Epoch: 15 cost time: 3.5022759437561035
Epoch: 15, Steps: 261 | Train Loss: 0.3758750 Vali Loss: 0.1928833 Test Loss: 0.2682613
Validation loss decreased (0.192902 --> 0.192883).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4323370
	speed: 0.1069s/iter; left time: 966.0943s
	iters: 200, epoch: 16 | loss: 0.3607631
	speed: 0.0102s/iter; left time: 91.4719s
Epoch: 16 cost time: 3.236018657684326
Epoch: 16, Steps: 261 | Train Loss: 0.3756711 Vali Loss: 0.1926350 Test Loss: 0.2679336
Validation loss decreased (0.192883 --> 0.192635).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4301091
	speed: 0.2058s/iter; left time: 1806.3032s
	iters: 200, epoch: 17 | loss: 0.3739873
	speed: 0.0098s/iter; left time: 85.0920s
Epoch: 17 cost time: 3.2029383182525635
Epoch: 17, Steps: 261 | Train Loss: 0.3748789 Vali Loss: 0.1928115 Test Loss: 0.2680135
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3833673
	speed: 0.1330s/iter; left time: 1132.2960s
	iters: 200, epoch: 18 | loss: 0.3829374
	speed: 0.0092s/iter; left time: 77.7801s
Epoch: 18 cost time: 11.266327619552612
Epoch: 18, Steps: 261 | Train Loss: 0.3754179 Vali Loss: 0.1926536 Test Loss: 0.2679210
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4742998
	speed: 0.0514s/iter; left time: 424.1589s
	iters: 200, epoch: 19 | loss: 0.3666595
	speed: 0.0098s/iter; left time: 80.2510s
Epoch: 19 cost time: 3.033022165298462
Epoch: 19, Steps: 261 | Train Loss: 0.3751817 Vali Loss: 0.1925668 Test Loss: 0.2678769
Validation loss decreased (0.192635 --> 0.192567).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2900872
	speed: 0.5903s/iter; left time: 4717.5583s
	iters: 200, epoch: 20 | loss: 0.3969035
	speed: 0.0187s/iter; left time: 147.6839s
Epoch: 20 cost time: 9.905659675598145
Epoch: 20, Steps: 261 | Train Loss: 0.3752531 Vali Loss: 0.1927816 Test Loss: 0.2679087
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4847815
	speed: 0.1248s/iter; left time: 964.6087s
	iters: 200, epoch: 21 | loss: 0.2766257
	speed: 0.0099s/iter; left time: 75.6208s
Epoch: 21 cost time: 2.8405137062072754
Epoch: 21, Steps: 261 | Train Loss: 0.3752708 Vali Loss: 0.1926031 Test Loss: 0.2678680
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2954676
	speed: 0.0459s/iter; left time: 343.0366s
	iters: 200, epoch: 22 | loss: 0.3578084
	speed: 0.0082s/iter; left time: 60.2908s
Epoch: 22 cost time: 2.7293567657470703
Epoch: 22, Steps: 261 | Train Loss: 0.3746317 Vali Loss: 0.1927599 Test Loss: 0.2679766
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2881082
	speed: 0.0453s/iter; left time: 326.3266s
	iters: 200, epoch: 23 | loss: 0.2994666
	speed: 0.0082s/iter; left time: 58.1971s
Epoch: 23 cost time: 2.7447357177734375
Epoch: 23, Steps: 261 | Train Loss: 0.3746310 Vali Loss: 0.1924036 Test Loss: 0.2676035
Validation loss decreased (0.192567 --> 0.192404).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3248081
	speed: 0.2037s/iter; left time: 1415.0601s
	iters: 200, epoch: 24 | loss: 0.4010035
	speed: 0.0087s/iter; left time: 59.8475s
Epoch: 24 cost time: 2.9435672760009766
Epoch: 24, Steps: 261 | Train Loss: 0.3749819 Vali Loss: 0.1926427 Test Loss: 0.2676817
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4213168
	speed: 0.0493s/iter; left time: 329.3467s
	iters: 200, epoch: 25 | loss: 0.3274378
	speed: 0.0087s/iter; left time: 57.4355s
Epoch: 25 cost time: 2.6979711055755615
Epoch: 25, Steps: 261 | Train Loss: 0.3747908 Vali Loss: 0.1925303 Test Loss: 0.2676753
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3240127
	speed: 0.0496s/iter; left time: 318.7271s
	iters: 200, epoch: 26 | loss: 0.2434493
	speed: 0.0091s/iter; left time: 57.4036s
Epoch: 26 cost time: 3.1090009212493896
Epoch: 26, Steps: 261 | Train Loss: 0.3740348 Vali Loss: 0.1925737 Test Loss: 0.2677135
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3424720
	speed: 0.0459s/iter; left time: 282.9980s
	iters: 200, epoch: 27 | loss: 0.4088286
	speed: 0.0080s/iter; left time: 48.2986s
Epoch: 27 cost time: 2.6500368118286133
Epoch: 27, Steps: 261 | Train Loss: 0.3744995 Vali Loss: 0.1925241 Test Loss: 0.2676634
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3449174
	speed: 0.0433s/iter; left time: 255.4639s
	iters: 200, epoch: 28 | loss: 0.4601102
	speed: 0.0081s/iter; left time: 47.1493s
Epoch: 28 cost time: 2.6253702640533447
Epoch: 28, Steps: 261 | Train Loss: 0.3742728 Vali Loss: 0.1925036 Test Loss: 0.2676547
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3467771
	speed: 0.0435s/iter; left time: 245.3701s
	iters: 200, epoch: 29 | loss: 0.3963549
	speed: 0.0084s/iter; left time: 46.3807s
Epoch: 29 cost time: 2.719043731689453
Epoch: 29, Steps: 261 | Train Loss: 0.3739531 Vali Loss: 0.1922959 Test Loss: 0.2675454
Validation loss decreased (0.192404 --> 0.192296).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.4215829
	speed: 0.3548s/iter; left time: 1909.7444s
	iters: 200, epoch: 30 | loss: 0.2825077
	speed: 0.0082s/iter; left time: 43.0772s
Epoch: 30 cost time: 2.76458740234375
Epoch: 30, Steps: 261 | Train Loss: 0.3742932 Vali Loss: 0.1926558 Test Loss: 0.2676482
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2450437
	speed: 0.0452s/iter; left time: 231.5408s
	iters: 200, epoch: 31 | loss: 0.3228921
	speed: 0.0080s/iter; left time: 40.1820s
Epoch: 31 cost time: 2.6420164108276367
Epoch: 31, Steps: 261 | Train Loss: 0.3742356 Vali Loss: 0.1925238 Test Loss: 0.2675733
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.5735908
	speed: 0.0458s/iter; left time: 222.3990s
	iters: 200, epoch: 32 | loss: 0.3249943
	speed: 0.0073s/iter; left time: 34.9233s
Epoch: 32 cost time: 2.521407127380371
Epoch: 32, Steps: 261 | Train Loss: 0.3741373 Vali Loss: 0.1924377 Test Loss: 0.2673995
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3510099
	speed: 0.0441s/iter; left time: 202.8819s
	iters: 200, epoch: 33 | loss: 0.2810546
	speed: 0.0085s/iter; left time: 38.4243s
Epoch: 33 cost time: 2.6420087814331055
Epoch: 33, Steps: 261 | Train Loss: 0.3737581 Vali Loss: 0.1923892 Test Loss: 0.2675000
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.4066544
	speed: 0.0444s/iter; left time: 192.3993s
	iters: 200, epoch: 34 | loss: 0.2199365
	speed: 0.0078s/iter; left time: 33.2555s
Epoch: 34 cost time: 2.6074421405792236
Epoch: 34, Steps: 261 | Train Loss: 0.3736462 Vali Loss: 0.1924621 Test Loss: 0.2675648
EarlyStopping counter: 5 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.3190724
	speed: 0.0456s/iter; left time: 186.0791s
	iters: 200, epoch: 35 | loss: 0.2751568
	speed: 0.0080s/iter; left time: 31.8600s
Epoch: 35 cost time: 2.6111996173858643
Epoch: 35, Steps: 261 | Train Loss: 0.3743150 Vali Loss: 0.1923756 Test Loss: 0.2674454
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.4971986
	speed: 0.0455s/iter; left time: 173.5454s
	iters: 200, epoch: 36 | loss: 0.3531803
	speed: 0.0077s/iter; left time: 28.5322s
Epoch: 36 cost time: 2.67240571975708
Epoch: 36, Steps: 261 | Train Loss: 0.3738579 Vali Loss: 0.1924765 Test Loss: 0.2674192
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3521232
	speed: 0.1077s/iter; left time: 382.8435s
	iters: 200, epoch: 37 | loss: 0.5391935
	speed: 0.0079s/iter; left time: 27.3373s
Epoch: 37 cost time: 2.613530158996582
Epoch: 37, Steps: 261 | Train Loss: 0.3738431 Vali Loss: 0.1924705 Test Loss: 0.2674085
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4667978
	speed: 0.0449s/iter; left time: 147.8574s
	iters: 200, epoch: 38 | loss: 0.2736641
	speed: 0.0076s/iter; left time: 24.1938s
Epoch: 38 cost time: 2.532379627227783
Epoch: 38, Steps: 261 | Train Loss: 0.3737344 Vali Loss: 0.1922745 Test Loss: 0.2674709
Validation loss decreased (0.192296 --> 0.192274).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4980132
	speed: 0.4641s/iter; left time: 1407.6641s
	iters: 200, epoch: 39 | loss: 0.3269297
	speed: 0.0209s/iter; left time: 61.3773s
Epoch: 39 cost time: 9.665754318237305
Epoch: 39, Steps: 261 | Train Loss: 0.3737627 Vali Loss: 0.1923062 Test Loss: 0.2674349
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4212120
	speed: 0.1093s/iter; left time: 303.0136s
	iters: 200, epoch: 40 | loss: 0.3015848
	speed: 0.0082s/iter; left time: 21.9908s
Epoch: 40 cost time: 2.690523386001587
Epoch: 40, Steps: 261 | Train Loss: 0.3741626 Vali Loss: 0.1924027 Test Loss: 0.2674181
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3559215
	speed: 0.0435s/iter; left time: 109.1297s
	iters: 200, epoch: 41 | loss: 0.3276137
	speed: 0.0072s/iter; left time: 17.2462s
Epoch: 41 cost time: 2.3828158378601074
Epoch: 41, Steps: 261 | Train Loss: 0.3736780 Vali Loss: 0.1922832 Test Loss: 0.2674438
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.5364872
	speed: 0.0430s/iter; left time: 96.6530s
	iters: 200, epoch: 42 | loss: 0.4289061
	speed: 0.0074s/iter; left time: 15.8548s
Epoch: 42 cost time: 2.491729497909546
Epoch: 42, Steps: 261 | Train Loss: 0.3737520 Vali Loss: 0.1924015 Test Loss: 0.2674290
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.4964337
	speed: 0.0449s/iter; left time: 89.2169s
	iters: 200, epoch: 43 | loss: 0.3151522
	speed: 0.0076s/iter; left time: 14.3771s
Epoch: 43 cost time: 2.5591681003570557
Epoch: 43, Steps: 261 | Train Loss: 0.3740123 Vali Loss: 0.1924497 Test Loss: 0.2674195
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.3451380
	speed: 0.0434s/iter; left time: 75.0398s
	iters: 200, epoch: 44 | loss: 0.2715254
	speed: 0.0076s/iter; left time: 12.3387s
Epoch: 44 cost time: 2.5626771450042725
Epoch: 44, Steps: 261 | Train Loss: 0.3733079 Vali Loss: 0.1923437 Test Loss: 0.2673919
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2921128
	speed: 0.0438s/iter; left time: 64.2741s
	iters: 200, epoch: 45 | loss: 0.4033171
	speed: 0.0071s/iter; left time: 9.6493s
Epoch: 45 cost time: 2.4876794815063477
Epoch: 45, Steps: 261 | Train Loss: 0.3734469 Vali Loss: 0.1923756 Test Loss: 0.2674097
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.3930499
	speed: 0.0426s/iter; left time: 51.4129s
	iters: 200, epoch: 46 | loss: 0.4431330
	speed: 0.0074s/iter; left time: 8.1686s
Epoch: 46 cost time: 2.41151762008667
Epoch: 46, Steps: 261 | Train Loss: 0.3739663 Vali Loss: 0.1923805 Test Loss: 0.2674074
EarlyStopping counter: 8 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.3852370
	speed: 0.0421s/iter; left time: 39.7633s
	iters: 200, epoch: 47 | loss: 0.4833737
	speed: 0.0080s/iter; left time: 6.7316s
Epoch: 47 cost time: 2.600090265274048
Epoch: 47, Steps: 261 | Train Loss: 0.3738692 Vali Loss: 0.1923565 Test Loss: 0.2673983
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.3203049
	speed: 0.0438s/iter; left time: 29.9648s
	iters: 200, epoch: 48 | loss: 0.3877850
	speed: 0.0077s/iter; left time: 4.4775s
Epoch: 48 cost time: 2.6074366569519043
Epoch: 48, Steps: 261 | Train Loss: 0.3739140 Vali Loss: 0.1923603 Test Loss: 0.2673865
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.4648236
	speed: 0.0432s/iter; left time: 18.2724s
	iters: 200, epoch: 49 | loss: 0.3411207
	speed: 0.0072s/iter; left time: 2.3396s
Epoch: 49 cost time: 2.5174028873443604
Epoch: 49, Steps: 261 | Train Loss: 0.3738366 Vali Loss: 0.1921152 Test Loss: 0.2673911
Validation loss decreased (0.192274 --> 0.192115).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.3207347
	speed: 0.4895s/iter; left time: 79.2936s
	iters: 200, epoch: 50 | loss: 0.3381368
	speed: 0.0087s/iter; left time: 0.5371s
Epoch: 50 cost time: 2.8621315956115723
Epoch: 50, Steps: 261 | Train Loss: 0.3733552 Vali Loss: 0.1923275 Test Loss: 0.2673641
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.0497355408796396e-05
>>>>>>>testing : ETTm2_720_336_FITS_ETTm2_ftM_sl720_ll48_pl336_H14_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.2684093713760376, mae:0.32602086663246155, rse:0.41846534609794617, corr:[0.5592283  0.5581962  0.5527413  0.5517032  0.553435   0.5540332
 0.55277187 0.55150163 0.5514811  0.5523237  0.5527289  0.5521738
 0.5513816  0.5511392  0.5515829  0.55195546 0.55158514 0.55059433
 0.54958683 0.5490384  0.54891115 0.5487145  0.5481394  0.54735607
 0.5467176  0.5464345  0.5463461  0.54608434 0.54547673 0.54471624
 0.54408854 0.54379076 0.54361385 0.54322857 0.5425729  0.5418462
 0.54121095 0.54073375 0.5402616  0.5396642  0.5389652  0.5382913
 0.5378005  0.5374683  0.5371192  0.53655    0.5357572  0.5348953
 0.5340971  0.5334467  0.5328955  0.53234744 0.53167135 0.5308938
 0.5301618  0.52961445 0.5291804  0.52875465 0.52831966 0.5279424
 0.5277094  0.52766705 0.52766794 0.52753025 0.5272344  0.5269152
 0.5266424  0.52647096 0.5263317  0.5261238  0.52581507 0.52547747
 0.52515405 0.524849   0.5244623  0.5240038  0.52350277 0.5230021
 0.52249163 0.5219643  0.52131146 0.5206144  0.51997286 0.51947117
 0.5190923  0.51870626 0.51817894 0.5175516  0.51694375 0.516469
 0.5161428  0.5158284  0.5153283  0.51460123 0.5136792  0.51258034
 0.51132905 0.5099762  0.5085031  0.5070205  0.5057059  0.50463736
 0.50374633 0.50281537 0.5017338  0.5005094  0.49933782 0.49837306
 0.49756965 0.4968217  0.49605998 0.49525672 0.49448192 0.49368563
 0.49278778 0.491836   0.4909305  0.49010763 0.4894363  0.4888134
 0.48819065 0.48742098 0.48655474 0.4856358  0.48473224 0.4838979
 0.48314306 0.48236185 0.48146233 0.48047465 0.47951746 0.47866088
 0.477917   0.47722208 0.47652492 0.47584185 0.47522128 0.4747339
 0.4742972  0.47381938 0.47320223 0.4724987  0.4718271  0.4711684
 0.47049785 0.4696988  0.46890163 0.46816662 0.46758175 0.46708164
 0.4665934  0.46603656 0.46529087 0.46441802 0.46360788 0.4630095
 0.46253958 0.46207264 0.4615219  0.4610136  0.4605788  0.46024436
 0.45990974 0.4595455  0.45915428 0.45879802 0.4584721  0.4581914
 0.45795408 0.4577419  0.4574168  0.45698944 0.45651436 0.45604193
 0.4555987  0.45516685 0.45471275 0.4542241  0.45365068 0.45308203
 0.4524516  0.45177802 0.45121783 0.4508092  0.45048523 0.450149
 0.44974345 0.44926792 0.44868264 0.44792762 0.4469677  0.44579098
 0.4444973  0.44329584 0.4421121  0.4408951  0.43971378 0.4385349
 0.4373882  0.436245   0.43512323 0.43398276 0.4328304  0.43170905
 0.43066677 0.4296807  0.42865726 0.4275552  0.42647347 0.42552105
 0.42460498 0.42376003 0.42304236 0.4224071  0.42175692 0.42089072
 0.4198154  0.41865417 0.4176752  0.41683254 0.415868   0.4146642
 0.41328746 0.41201967 0.4111416  0.4104956  0.40985927 0.40902674
 0.4078356  0.40656558 0.4055067  0.40489477 0.40460968 0.40438312
 0.40392494 0.40325946 0.4025165  0.40190592 0.40152317 0.4012049
 0.40078756 0.4001249  0.3994306  0.39909586 0.39904147 0.39912432
 0.3991095  0.39887634 0.3984141  0.39790168 0.39773396 0.39790732
 0.3981841  0.39839348 0.3982589  0.39786437 0.39733914 0.3969085
 0.39660725 0.39638573 0.396187   0.39600664 0.39580986 0.39563385
 0.3954265  0.39510924 0.39483526 0.39468268 0.39458376 0.3943703
 0.39395776 0.39342812 0.39280877 0.39234343 0.39210394 0.39204133
 0.3921403  0.39211068 0.3918531  0.39151776 0.39114133 0.39077765
 0.39036137 0.38994357 0.389647   0.38951322 0.38940516 0.3888742
 0.38777366 0.38644168 0.38510737 0.38402802 0.3833361  0.38283935
 0.3824555  0.38203624 0.38157645 0.38121313 0.38106892 0.38074854
 0.38020518 0.3794361  0.3788452  0.37848848 0.37834495 0.37815577
 0.37779796 0.37723655 0.3769037  0.3770077  0.3772244  0.37725624
 0.37669092 0.3760345  0.3759393  0.37656513 0.37739235 0.37767142
 0.37698284 0.37595275 0.37555537 0.37604657 0.3766521  0.37665492
 0.37598664 0.3755314  0.37608546 0.37708172 0.3774882  0.37654147
 0.3753405  0.3753828  0.37654918 0.37672618 0.37249205 0.36390704]
