Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=320, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_720_j336_H10', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=20, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_720_j336_H10_FITS_custom_ftM_sl720_ll48_pl336_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11225
val 1421
test 3173
Model(
  (freq_upsampler): Linear(in_features=320, out_features=469, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  8279613440.0
params:  150549.0
Trainable parameters:  150549
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5183504
	speed: 0.4674s/iter; left time: 4043.3837s
Epoch: 1 cost time: 80.695232629776
Epoch: 1, Steps: 175 | Train Loss: 0.6279354 Vali Loss: 0.4957942 Test Loss: 0.5761248
Validation loss decreased (inf --> 0.495794).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3018279
	speed: 1.4630s/iter; left time: 12400.7451s
Epoch: 2 cost time: 91.82907700538635
Epoch: 2, Steps: 175 | Train Loss: 0.3079612 Vali Loss: 0.3670822 Test Loss: 0.4361879
Validation loss decreased (0.495794 --> 0.367082).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2674870
	speed: 1.3680s/iter; left time: 11355.7911s
Epoch: 3 cost time: 82.14541864395142
Epoch: 3, Steps: 175 | Train Loss: 0.2572687 Vali Loss: 0.3466565 Test Loss: 0.4174319
Validation loss decreased (0.367082 --> 0.346656).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2505256
	speed: 1.4679s/iter; left time: 11928.2000s
Epoch: 4 cost time: 91.59499502182007
Epoch: 4, Steps: 175 | Train Loss: 0.2500375 Vali Loss: 0.3426661 Test Loss: 0.4151914
Validation loss decreased (0.346656 --> 0.342666).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2481294
	speed: 1.4130s/iter; left time: 11234.5562s
Epoch: 5 cost time: 83.74850916862488
Epoch: 5, Steps: 175 | Train Loss: 0.2488808 Vali Loss: 0.3417666 Test Loss: 0.4146785
Validation loss decreased (0.342666 --> 0.341767).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2579808
	speed: 1.3355s/iter; left time: 10384.7930s
Epoch: 6 cost time: 80.47713041305542
Epoch: 6, Steps: 175 | Train Loss: 0.2484901 Vali Loss: 0.3411890 Test Loss: 0.4144338
Validation loss decreased (0.341767 --> 0.341189).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2477874
	speed: 1.2861s/iter; left time: 9775.6506s
Epoch: 7 cost time: 80.38171291351318
Epoch: 7, Steps: 175 | Train Loss: 0.2483263 Vali Loss: 0.3407360 Test Loss: 0.4143751
Validation loss decreased (0.341189 --> 0.340736).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2423423
	speed: 1.4365s/iter; left time: 10667.4485s
Epoch: 8 cost time: 94.36808323860168
Epoch: 8, Steps: 175 | Train Loss: 0.2482487 Vali Loss: 0.3399244 Test Loss: 0.4136754
Validation loss decreased (0.340736 --> 0.339924).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2427510
	speed: 1.5764s/iter; left time: 11430.5195s
Epoch: 9 cost time: 93.62147831916809
Epoch: 9, Steps: 175 | Train Loss: 0.2480875 Vali Loss: 0.3400007 Test Loss: 0.4143630
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2419101
	speed: 1.5320s/iter; left time: 10840.6981s
Epoch: 10 cost time: 94.04329538345337
Epoch: 10, Steps: 175 | Train Loss: 0.2480648 Vali Loss: 0.3399558 Test Loss: 0.4136218
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2491984
	speed: 1.5107s/iter; left time: 10425.5332s
Epoch: 11 cost time: 93.77189755439758
Epoch: 11, Steps: 175 | Train Loss: 0.2480053 Vali Loss: 0.3400095 Test Loss: 0.4138741
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2634880
	speed: 1.5204s/iter; left time: 10226.5240s
Epoch: 12 cost time: 88.26999545097351
Epoch: 12, Steps: 175 | Train Loss: 0.2480233 Vali Loss: 0.3401050 Test Loss: 0.4138945
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2506993
	speed: 1.5054s/iter; left time: 9861.6842s
Epoch: 13 cost time: 95.83027052879333
Epoch: 13, Steps: 175 | Train Loss: 0.2479442 Vali Loss: 0.3398429 Test Loss: 0.4140028
Validation loss decreased (0.339924 --> 0.339843).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2458948
	speed: 1.5454s/iter; left time: 9853.4127s
Epoch: 14 cost time: 88.60465812683105
Epoch: 14, Steps: 175 | Train Loss: 0.2479189 Vali Loss: 0.3398371 Test Loss: 0.4135173
Validation loss decreased (0.339843 --> 0.339837).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2462643
	speed: 1.4540s/iter; left time: 9016.4882s
Epoch: 15 cost time: 92.79065132141113
Epoch: 15, Steps: 175 | Train Loss: 0.2478767 Vali Loss: 0.3401074 Test Loss: 0.4136072
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2500698
	speed: 1.4479s/iter; left time: 8725.2648s
Epoch: 16 cost time: 90.10466694831848
Epoch: 16, Steps: 175 | Train Loss: 0.2478187 Vali Loss: 0.3397353 Test Loss: 0.4139637
Validation loss decreased (0.339837 --> 0.339735).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2521452
	speed: 1.4433s/iter; left time: 8444.9134s
Epoch: 17 cost time: 92.65995788574219
Epoch: 17, Steps: 175 | Train Loss: 0.2478283 Vali Loss: 0.3395292 Test Loss: 0.4133056
Validation loss decreased (0.339735 --> 0.339529).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2486740
	speed: 1.5735s/iter; left time: 8930.9042s
Epoch: 18 cost time: 89.68802165985107
Epoch: 18, Steps: 175 | Train Loss: 0.2477774 Vali Loss: 0.3397770 Test Loss: 0.4135497
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2356018
	speed: 1.3207s/iter; left time: 7265.3257s
Epoch: 19 cost time: 80.45072388648987
Epoch: 19, Steps: 175 | Train Loss: 0.2477418 Vali Loss: 0.3393832 Test Loss: 0.4131559
Validation loss decreased (0.339529 --> 0.339383).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2492038
	speed: 1.3335s/iter; left time: 7102.4068s
Epoch: 20 cost time: 79.47115421295166
Epoch: 20, Steps: 175 | Train Loss: 0.2477288 Vali Loss: 0.3396201 Test Loss: 0.4131935
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2547207
	speed: 1.3038s/iter; left time: 6716.0025s
Epoch: 21 cost time: 84.44837880134583
Epoch: 21, Steps: 175 | Train Loss: 0.2477151 Vali Loss: 0.3394337 Test Loss: 0.4133584
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2518081
	speed: 1.3835s/iter; left time: 6884.0753s
Epoch: 22 cost time: 86.29828667640686
Epoch: 22, Steps: 175 | Train Loss: 0.2476638 Vali Loss: 0.3395844 Test Loss: 0.4135735
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2510543
	speed: 1.4314s/iter; left time: 6872.2131s
Epoch: 23 cost time: 87.39235854148865
Epoch: 23, Steps: 175 | Train Loss: 0.2476247 Vali Loss: 0.3397439 Test Loss: 0.4133985
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2510667
	speed: 1.3946s/iter; left time: 6451.3048s
Epoch: 24 cost time: 84.76903462409973
Epoch: 24, Steps: 175 | Train Loss: 0.2476383 Vali Loss: 0.3394983 Test Loss: 0.4132266
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2505659
	speed: 1.3999s/iter; left time: 6230.7770s
Epoch: 25 cost time: 89.59717464447021
Epoch: 25, Steps: 175 | Train Loss: 0.2476025 Vali Loss: 0.3393037 Test Loss: 0.4131648
Validation loss decreased (0.339383 --> 0.339304).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2466692
	speed: 1.5299s/iter; left time: 6541.9704s
Epoch: 26 cost time: 91.64367151260376
Epoch: 26, Steps: 175 | Train Loss: 0.2475636 Vali Loss: 0.3392597 Test Loss: 0.4130951
Validation loss decreased (0.339304 --> 0.339260).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2371866
	speed: 1.5265s/iter; left time: 6260.3787s
Epoch: 27 cost time: 92.92508554458618
Epoch: 27, Steps: 175 | Train Loss: 0.2475954 Vali Loss: 0.3392617 Test Loss: 0.4132463
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2437642
	speed: 1.3648s/iter; left time: 5358.2735s
Epoch: 28 cost time: 83.17107844352722
Epoch: 28, Steps: 175 | Train Loss: 0.2475121 Vali Loss: 0.3389798 Test Loss: 0.4134025
Validation loss decreased (0.339260 --> 0.338980).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2468204
	speed: 1.3646s/iter; left time: 5118.5029s
Epoch: 29 cost time: 85.24606418609619
Epoch: 29, Steps: 175 | Train Loss: 0.2475192 Vali Loss: 0.3393378 Test Loss: 0.4133289
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2682327
	speed: 1.4139s/iter; left time: 5056.1548s
Epoch: 30 cost time: 81.85607552528381
Epoch: 30, Steps: 175 | Train Loss: 0.2474599 Vali Loss: 0.3393093 Test Loss: 0.4130107
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2627707
	speed: 1.4718s/iter; left time: 5005.4759s
Epoch: 31 cost time: 95.75392866134644
Epoch: 31, Steps: 175 | Train Loss: 0.2474918 Vali Loss: 0.3389071 Test Loss: 0.4129248
Validation loss decreased (0.338980 --> 0.338907).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2430488
	speed: 1.4710s/iter; left time: 4745.4938s
Epoch: 32 cost time: 86.77056741714478
Epoch: 32, Steps: 175 | Train Loss: 0.2474099 Vali Loss: 0.3393068 Test Loss: 0.4129656
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2458472
	speed: 1.4375s/iter; left time: 4385.7050s
Epoch: 33 cost time: 87.949551820755
Epoch: 33, Steps: 175 | Train Loss: 0.2474504 Vali Loss: 0.3388953 Test Loss: 0.4129803
Validation loss decreased (0.338907 --> 0.338895).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2501101
	speed: 1.4286s/iter; left time: 4108.5680s
Epoch: 34 cost time: 85.29896378517151
Epoch: 34, Steps: 175 | Train Loss: 0.2473920 Vali Loss: 0.3390184 Test Loss: 0.4130808
EarlyStopping counter: 1 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2502046
	speed: 1.4623s/iter; left time: 3949.7094s
Epoch: 35 cost time: 89.65284657478333
Epoch: 35, Steps: 175 | Train Loss: 0.2474088 Vali Loss: 0.3395877 Test Loss: 0.4129259
EarlyStopping counter: 2 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2542402
	speed: 1.4779s/iter; left time: 3733.2136s
Epoch: 36 cost time: 85.14836978912354
Epoch: 36, Steps: 175 | Train Loss: 0.2473944 Vali Loss: 0.3393117 Test Loss: 0.4130543
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2487253
	speed: 1.4012s/iter; left time: 3294.3158s
Epoch: 37 cost time: 89.77104258537292
Epoch: 37, Steps: 175 | Train Loss: 0.2473564 Vali Loss: 0.3391305 Test Loss: 0.4130977
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2602147
	speed: 1.5097s/iter; left time: 3285.1430s
Epoch: 38 cost time: 90.7659113407135
Epoch: 38, Steps: 175 | Train Loss: 0.2473483 Vali Loss: 0.3391230 Test Loss: 0.4129888
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2443245
	speed: 1.4863s/iter; left time: 2974.0470s
Epoch: 39 cost time: 89.18648600578308
Epoch: 39, Steps: 175 | Train Loss: 0.2473664 Vali Loss: 0.3391257 Test Loss: 0.4128067
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2581142
	speed: 1.5532s/iter; left time: 2836.1386s
Epoch: 40 cost time: 92.58371043205261
Epoch: 40, Steps: 175 | Train Loss: 0.2472905 Vali Loss: 0.3391235 Test Loss: 0.4127565
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2528608
	speed: 1.4378s/iter; left time: 2373.7378s
Epoch: 41 cost time: 87.25170373916626
Epoch: 41, Steps: 175 | Train Loss: 0.2473333 Vali Loss: 0.3393125 Test Loss: 0.4129328
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2332091
	speed: 1.4662s/iter; left time: 2164.1394s
Epoch: 42 cost time: 90.61996674537659
Epoch: 42, Steps: 175 | Train Loss: 0.2473138 Vali Loss: 0.3390329 Test Loss: 0.4127009
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2373906
	speed: 1.4018s/iter; left time: 1823.7631s
Epoch: 43 cost time: 81.83712410926819
Epoch: 43, Steps: 175 | Train Loss: 0.2472585 Vali Loss: 0.3393615 Test Loss: 0.4130531
EarlyStopping counter: 10 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2566416
	speed: 1.3725s/iter; left time: 1545.4906s
Epoch: 44 cost time: 83.80661678314209
Epoch: 44, Steps: 175 | Train Loss: 0.2473107 Vali Loss: 0.3391765 Test Loss: 0.4130537
EarlyStopping counter: 11 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2543047
	speed: 1.4889s/iter; left time: 1415.9296s
Epoch: 45 cost time: 95.58125925064087
Epoch: 45, Steps: 175 | Train Loss: 0.2472662 Vali Loss: 0.3394602 Test Loss: 0.4130300
EarlyStopping counter: 12 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2523747
	speed: 1.5623s/iter; left time: 1212.3756s
Epoch: 46 cost time: 92.99310755729675
Epoch: 46, Steps: 175 | Train Loss: 0.2472624 Vali Loss: 0.3391035 Test Loss: 0.4127064
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2387141
	speed: 1.4164s/iter; left time: 851.2266s
Epoch: 47 cost time: 82.40945816040039
Epoch: 47, Steps: 175 | Train Loss: 0.2472404 Vali Loss: 0.3392172 Test Loss: 0.4127813
EarlyStopping counter: 14 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2442196
	speed: 1.3797s/iter; left time: 587.7443s
Epoch: 48 cost time: 85.35014963150024
Epoch: 48, Steps: 175 | Train Loss: 0.2472744 Vali Loss: 0.3392110 Test Loss: 0.4128000
EarlyStopping counter: 15 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2623316
	speed: 1.5520s/iter; left time: 389.5431s
Epoch: 49 cost time: 97.94387865066528
Epoch: 49, Steps: 175 | Train Loss: 0.2472332 Vali Loss: 0.3392172 Test Loss: 0.4128658
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2473587
	speed: 1.5222s/iter; left time: 115.6844s
Epoch: 50 cost time: 87.47418355941772
Epoch: 50, Steps: 175 | Train Loss: 0.2472275 Vali Loss: 0.3394307 Test Loss: 0.4128787
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.0497355408796396e-05
>>>>>>>testing : Traffic_720_j336_H10_FITS_custom_ftM_sl720_ll48_pl336_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3173
mse:0.4105404019355774, mae:0.27871280908584595, rse:0.5265955924987793, corr:[0.2688712  0.28458226 0.28301618 0.28407764 0.28369552 0.28457287
 0.2846534  0.28484902 0.28527954 0.28464955 0.28459787 0.28389895
 0.2840649  0.2839162  0.28349993 0.2835365  0.28323346 0.28330046
 0.28329948 0.2838059  0.28404263 0.28362936 0.28349957 0.28357628
 0.28519472 0.2853441  0.28523484 0.28526837 0.28483546 0.2842922
 0.28384426 0.2840573  0.28402752 0.28359982 0.28388536 0.2839177
 0.2838985  0.2839812  0.28394058 0.28404704 0.28417093 0.2844472
 0.28417557 0.28417248 0.2843474  0.2839089  0.2838495  0.28365797
 0.28413245 0.28470227 0.28456882 0.2843158  0.284022   0.28397173
 0.28404522 0.28391245 0.2840138  0.283804   0.28394026 0.28438008
 0.28421196 0.2843731  0.2844787  0.2841768  0.28416926 0.2842255
 0.28412524 0.28394493 0.28411108 0.28403172 0.28376532 0.2840089
 0.28415623 0.28393862 0.28385282 0.28401917 0.2836884  0.2832668
 0.28325373 0.28313375 0.28356075 0.28371698 0.28344592 0.28371352
 0.28356776 0.28357914 0.28394258 0.28401327 0.2844625  0.284728
 0.28480777 0.2844679  0.28377572 0.2834798  0.28327155 0.28355023
 0.28342304 0.2831535  0.28348896 0.28348702 0.28365803 0.28380755
 0.2835045  0.28375024 0.28395915 0.2839275  0.28389272 0.28364998
 0.28351715 0.28341553 0.28353453 0.2837412  0.28387648 0.28393912
 0.2836316  0.28345957 0.28338987 0.2830259  0.28296027 0.28306338
 0.28292125 0.28301144 0.28347176 0.28401527 0.28422323 0.28400972
 0.28341597 0.28321368 0.2834593  0.28375262 0.2838208  0.28362697
 0.2839621  0.2842386  0.28420413 0.28437033 0.28420302 0.28427842
 0.28430644 0.28382513 0.28362846 0.28350836 0.28366345 0.28369418
 0.28355938 0.28391165 0.28434822 0.2845744  0.2845434  0.28442302
 0.284327   0.28428513 0.28464398 0.28465554 0.28433895 0.28426945
 0.2840886  0.28422022 0.28435755 0.28401074 0.28373358 0.28395677
 0.28446436 0.2844674  0.2842516  0.28418633 0.28414002 0.28417483
 0.28517133 0.2855959  0.28567916 0.28571087 0.28584298 0.28541398
 0.28514668 0.28529543 0.28533697 0.28558254 0.28549576 0.28531796
 0.28539556 0.28522632 0.28507736 0.2847279  0.28443414 0.28445417
 0.28436726 0.28446192 0.2844822  0.28420278 0.2840064  0.28410614
 0.28480223 0.28479716 0.28521293 0.2855985  0.28521943 0.28499088
 0.2851822  0.28493533 0.28467268 0.28485322 0.28490207 0.28493103
 0.28468975 0.2839999  0.2839583  0.28421855 0.2839648  0.28387788
 0.2840173  0.2839563  0.2834696  0.28329995 0.2835935  0.283661
 0.2841493  0.28440017 0.28459814 0.28461495 0.28390878 0.28404623
 0.28441378 0.2840958  0.28399706 0.28378847 0.2840356  0.28424314
 0.2838471  0.28393942 0.28375882 0.2834522  0.2836446  0.28384656
 0.28399342 0.28373364 0.28337592 0.28288844 0.28281826 0.28323334
 0.2832067  0.28344685 0.28384745 0.28388152 0.28389233 0.28408232
 0.28426516 0.28376433 0.28367803 0.28388593 0.28335497 0.2831315
 0.2831919  0.2833854  0.2834979  0.28306383 0.28315333 0.28358954
 0.28357968 0.28310397 0.282742   0.28300187 0.28301808 0.28297862
 0.2829376  0.2828443  0.2829714  0.28311127 0.2837465  0.28415653
 0.2838772  0.28379604 0.28343534 0.28311813 0.28316516 0.28308675
 0.28288257 0.2825825  0.28240773 0.28219348 0.28224045 0.28243795
 0.28238857 0.2823558  0.28215408 0.28205624 0.28218132 0.2824715
 0.28273496 0.28288493 0.28338295 0.28366768 0.2836385  0.28380233
 0.2834841  0.28347763 0.28329208 0.28325328 0.28350773 0.28268498
 0.28293335 0.2832768  0.2829116  0.28311777 0.28275046 0.28315857
 0.28340864 0.28293228 0.28307208 0.28262818 0.2826137  0.28280896
 0.28284135 0.2833128  0.28374904 0.2841621  0.28413692 0.28400135
 0.2839076  0.2836658  0.28393707 0.28356707 0.28332245 0.2835641
 0.2835732  0.2838117  0.28359678 0.2838404  0.28369752 0.28382418
 0.28364295 0.2831657  0.28267804 0.28173396 0.2832525  0.28403032]
