Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=320, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_720_j96_H10', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=20, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_720_j96_H10_FITS_custom_ftM_sl720_ll48_pl96_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11465
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=320, out_features=362, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  12781322240.0
params:  116202.0
Trainable parameters:  116202
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 57.83906698226929
Epoch: 1, Steps: 89 | Train Loss: 0.5814861 Vali Loss: 0.4210800 Test Loss: 0.4909311
Validation loss decreased (inf --> 0.421080).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 54.855263233184814
Epoch: 2, Steps: 89 | Train Loss: 0.2622747 Vali Loss: 0.3339008 Test Loss: 0.3994757
Validation loss decreased (0.421080 --> 0.333901).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 54.86220097541809
Epoch: 3, Steps: 89 | Train Loss: 0.2346836 Vali Loss: 0.3294279 Test Loss: 0.3931476
Validation loss decreased (0.333901 --> 0.329428).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 55.684142112731934
Epoch: 4, Steps: 89 | Train Loss: 0.2324134 Vali Loss: 0.3273665 Test Loss: 0.3921518
Validation loss decreased (0.329428 --> 0.327366).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 57.93328905105591
Epoch: 5, Steps: 89 | Train Loss: 0.2319767 Vali Loss: 0.3269015 Test Loss: 0.3912126
Validation loss decreased (0.327366 --> 0.326902).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 55.21273159980774
Epoch: 6, Steps: 89 | Train Loss: 0.2317064 Vali Loss: 0.3250308 Test Loss: 0.3909990
Validation loss decreased (0.326902 --> 0.325031).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 54.83382439613342
Epoch: 7, Steps: 89 | Train Loss: 0.2316379 Vali Loss: 0.3256717 Test Loss: 0.3903193
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 55.786685943603516
Epoch: 8, Steps: 89 | Train Loss: 0.2314621 Vali Loss: 0.3251551 Test Loss: 0.3900631
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 50.82532238960266
Epoch: 9, Steps: 89 | Train Loss: 0.2312230 Vali Loss: 0.3251684 Test Loss: 0.3899755
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 50.916545391082764
Epoch: 10, Steps: 89 | Train Loss: 0.2312491 Vali Loss: 0.3259024 Test Loss: 0.3897969
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 53.67681550979614
Epoch: 11, Steps: 89 | Train Loss: 0.2311441 Vali Loss: 0.3256373 Test Loss: 0.3898475
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 45.23788642883301
Epoch: 12, Steps: 89 | Train Loss: 0.2311034 Vali Loss: 0.3255497 Test Loss: 0.3897294
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 49.91018605232239
Epoch: 13, Steps: 89 | Train Loss: 0.2309809 Vali Loss: 0.3249656 Test Loss: 0.3900530
Validation loss decreased (0.325031 --> 0.324966).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 50.33700108528137
Epoch: 14, Steps: 89 | Train Loss: 0.2309715 Vali Loss: 0.3240262 Test Loss: 0.3897083
Validation loss decreased (0.324966 --> 0.324026).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 49.64820218086243
Epoch: 15, Steps: 89 | Train Loss: 0.2308349 Vali Loss: 0.3242977 Test Loss: 0.3894209
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 52.96611833572388
Epoch: 16, Steps: 89 | Train Loss: 0.2309037 Vali Loss: 0.3252004 Test Loss: 0.3894749
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 53.830737590789795
Epoch: 17, Steps: 89 | Train Loss: 0.2306785 Vali Loss: 0.3255705 Test Loss: 0.3896269
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 55.200271129608154
Epoch: 18, Steps: 89 | Train Loss: 0.2306372 Vali Loss: 0.3251597 Test Loss: 0.3893766
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 53.23885107040405
Epoch: 19, Steps: 89 | Train Loss: 0.2306753 Vali Loss: 0.3251028 Test Loss: 0.3891780
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 53.17675518989563
Epoch: 20, Steps: 89 | Train Loss: 0.2306950 Vali Loss: 0.3245645 Test Loss: 0.3889742
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 54.00900197029114
Epoch: 21, Steps: 89 | Train Loss: 0.2305492 Vali Loss: 0.3236336 Test Loss: 0.3892130
Validation loss decreased (0.324026 --> 0.323634).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 50.965864181518555
Epoch: 22, Steps: 89 | Train Loss: 0.2305685 Vali Loss: 0.3249078 Test Loss: 0.3889365
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 55.50279116630554
Epoch: 23, Steps: 89 | Train Loss: 0.2304206 Vali Loss: 0.3252477 Test Loss: 0.3890690
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 57.46478629112244
Epoch: 24, Steps: 89 | Train Loss: 0.2304666 Vali Loss: 0.3249559 Test Loss: 0.3890643
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 52.23881697654724
Epoch: 25, Steps: 89 | Train Loss: 0.2304298 Vali Loss: 0.3237076 Test Loss: 0.3888909
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 54.97332811355591
Epoch: 26, Steps: 89 | Train Loss: 0.2303950 Vali Loss: 0.3240103 Test Loss: 0.3891587
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 53.40625357627869
Epoch: 27, Steps: 89 | Train Loss: 0.2304983 Vali Loss: 0.3228284 Test Loss: 0.3890455
Validation loss decreased (0.323634 --> 0.322828).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 53.481369972229004
Epoch: 28, Steps: 89 | Train Loss: 0.2303460 Vali Loss: 0.3238509 Test Loss: 0.3889222
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 54.65792393684387
Epoch: 29, Steps: 89 | Train Loss: 0.2304174 Vali Loss: 0.3237567 Test Loss: 0.3885811
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 59.62469005584717
Epoch: 30, Steps: 89 | Train Loss: 0.2304271 Vali Loss: 0.3245772 Test Loss: 0.3889555
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 58.54802131652832
Epoch: 31, Steps: 89 | Train Loss: 0.2302324 Vali Loss: 0.3238238 Test Loss: 0.3885858
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 53.0134711265564
Epoch: 32, Steps: 89 | Train Loss: 0.2302813 Vali Loss: 0.3241567 Test Loss: 0.3888328
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 53.17610192298889
Epoch: 33, Steps: 89 | Train Loss: 0.2303722 Vali Loss: 0.3248312 Test Loss: 0.3887925
EarlyStopping counter: 6 out of 20
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 52.35472917556763
Epoch: 34, Steps: 89 | Train Loss: 0.2303434 Vali Loss: 0.3234052 Test Loss: 0.3890391
EarlyStopping counter: 7 out of 20
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 48.6496319770813
Epoch: 35, Steps: 89 | Train Loss: 0.2302465 Vali Loss: 0.3234676 Test Loss: 0.3888065
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 55.50636315345764
Epoch: 36, Steps: 89 | Train Loss: 0.2303155 Vali Loss: 0.3238454 Test Loss: 0.3888935
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 54.72131085395813
Epoch: 37, Steps: 89 | Train Loss: 0.2302864 Vali Loss: 0.3227915 Test Loss: 0.3886674
Validation loss decreased (0.322828 --> 0.322792).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 56.423768281936646
Epoch: 38, Steps: 89 | Train Loss: 0.2302049 Vali Loss: 0.3228338 Test Loss: 0.3888176
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 56.90934467315674
Epoch: 39, Steps: 89 | Train Loss: 0.2301872 Vali Loss: 0.3247676 Test Loss: 0.3887054
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 54.724159717559814
Epoch: 40, Steps: 89 | Train Loss: 0.2302673 Vali Loss: 0.3232453 Test Loss: 0.3887354
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 55.40964865684509
Epoch: 41, Steps: 89 | Train Loss: 0.2302015 Vali Loss: 0.3241616 Test Loss: 0.3887550
EarlyStopping counter: 4 out of 20
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 58.11478233337402
Epoch: 42, Steps: 89 | Train Loss: 0.2302470 Vali Loss: 0.3244089 Test Loss: 0.3887537
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 56.28330850601196
Epoch: 43, Steps: 89 | Train Loss: 0.2301763 Vali Loss: 0.3232689 Test Loss: 0.3887123
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 53.59347152709961
Epoch: 44, Steps: 89 | Train Loss: 0.2301865 Vali Loss: 0.3239244 Test Loss: 0.3886651
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 52.031827211380005
Epoch: 45, Steps: 89 | Train Loss: 0.2301150 Vali Loss: 0.3251088 Test Loss: 0.3885462
EarlyStopping counter: 8 out of 20
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 51.81453323364258
Epoch: 46, Steps: 89 | Train Loss: 0.2300536 Vali Loss: 0.3235322 Test Loss: 0.3886826
EarlyStopping counter: 9 out of 20
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 49.89685130119324
Epoch: 47, Steps: 89 | Train Loss: 0.2300022 Vali Loss: 0.3240763 Test Loss: 0.3886734
EarlyStopping counter: 10 out of 20
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 50.84359812736511
Epoch: 48, Steps: 89 | Train Loss: 0.2300786 Vali Loss: 0.3234333 Test Loss: 0.3885992
EarlyStopping counter: 11 out of 20
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 52.27406334877014
Epoch: 49, Steps: 89 | Train Loss: 0.2301337 Vali Loss: 0.3228076 Test Loss: 0.3886140
EarlyStopping counter: 12 out of 20
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 55.00668382644653
Epoch: 50, Steps: 89 | Train Loss: 0.2301430 Vali Loss: 0.3233443 Test Loss: 0.3886354
EarlyStopping counter: 13 out of 20
Updating learning rate to 4.0497355408796396e-05
>>>>>>>testing : Traffic_720_j96_H10_FITS_custom_ftM_sl720_ll48_pl96_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3413
mse:0.38576334714889526, mae:0.2685497999191284, rse:0.5142969489097595, corr:[0.2761696  0.29280764 0.2918663  0.29248095 0.29212037 0.29249838
 0.29284346 0.29269907 0.29266936 0.29231855 0.2928769  0.29264277
 0.29289126 0.29249346 0.29188704 0.292166   0.2918204  0.29182658
 0.29205814 0.29220235 0.29209486 0.2918115  0.2917291  0.29160416
 0.2933478  0.2938797  0.2935495  0.2932627  0.29290614 0.29281157
 0.29279023 0.2928077  0.2926507  0.29242167 0.29253286 0.29226395
 0.29222244 0.29223377 0.29220226 0.2922256  0.29208174 0.29257688
 0.2927037  0.29257366 0.29254824 0.2923113  0.2921683  0.2917603
 0.29229844 0.29258814 0.29207733 0.29215845 0.29235408 0.2923532
 0.2921611  0.29176855 0.29189825 0.29181787 0.2919313  0.2921013
 0.29205504 0.29235163 0.292518   0.29278186 0.29259437 0.29237953
 0.29239002 0.29230082 0.29248044 0.2922917  0.2922766  0.29212746
 0.29179022 0.29190874 0.29148617 0.2914435  0.29145995 0.29143873
 0.2916233  0.29116246 0.29107937 0.29083508 0.29132232 0.2917932
 0.29150102 0.2917594  0.29161432 0.29226214 0.29185662 0.29163992
 0.2916539  0.29073587 0.2908363  0.28957778 0.2913449  0.29139605]
