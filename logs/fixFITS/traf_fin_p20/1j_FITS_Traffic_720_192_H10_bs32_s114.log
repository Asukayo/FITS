Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=320, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=0, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_720_j192_H10', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=20, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Traffic_720_j192_H10_FITS_custom_ftM_sl720_ll48_pl192_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11369
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=320, out_features=405, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  7149772800.0
params:  130005.0
Trainable parameters:  130005
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4632013
	speed: 0.5875s/iter; left time: 5140.8556s
Epoch: 1 cost time: 104.18800640106201
Epoch: 1, Steps: 177 | Train Loss: 0.5765818 Vali Loss: 0.4141167 Test Loss: 0.4844957
Validation loss decreased (inf --> 0.414117).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2390003
	speed: 1.6932s/iter; left time: 14517.6942s
Epoch: 2 cost time: 107.14645862579346
Epoch: 2, Steps: 177 | Train Loss: 0.2627363 Vali Loss: 0.3365055 Test Loss: 0.4043534
Validation loss decreased (0.414117 --> 0.336506).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2519696
	speed: 1.5925s/iter; left time: 13372.4610s
Epoch: 3 cost time: 94.09733867645264
Epoch: 3, Steps: 177 | Train Loss: 0.2403588 Vali Loss: 0.3314621 Test Loss: 0.4012780
Validation loss decreased (0.336506 --> 0.331462).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2458528
	speed: 1.4874s/iter; left time: 12226.4539s
Epoch: 4 cost time: 87.86559271812439
Epoch: 4, Steps: 177 | Train Loss: 0.2387880 Vali Loss: 0.3296986 Test Loss: 0.4002364
Validation loss decreased (0.331462 --> 0.329699).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2307007
	speed: 1.5051s/iter; left time: 12105.2333s
Epoch: 5 cost time: 100.08736681938171
Epoch: 5, Steps: 177 | Train Loss: 0.2383362 Vali Loss: 0.3293718 Test Loss: 0.3996509
Validation loss decreased (0.329699 --> 0.329372).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2281806
	speed: 1.6583s/iter; left time: 13044.3339s
Epoch: 6 cost time: 96.33206939697266
Epoch: 6, Steps: 177 | Train Loss: 0.2381486 Vali Loss: 0.3283527 Test Loss: 0.3997698
Validation loss decreased (0.329372 --> 0.328353).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2332138
	speed: 1.4850s/iter; left time: 11417.9056s
Epoch: 7 cost time: 92.57608485221863
Epoch: 7, Steps: 177 | Train Loss: 0.2379903 Vali Loss: 0.3281344 Test Loss: 0.3992220
Validation loss decreased (0.328353 --> 0.328134).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2329792
	speed: 1.4644s/iter; left time: 11000.8113s
Epoch: 8 cost time: 91.9454185962677
Epoch: 8, Steps: 177 | Train Loss: 0.2379113 Vali Loss: 0.3282386 Test Loss: 0.3996683
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2388185
	speed: 1.3816s/iter; left time: 10133.9967s
Epoch: 9 cost time: 85.04090762138367
Epoch: 9, Steps: 177 | Train Loss: 0.2377494 Vali Loss: 0.3279355 Test Loss: 0.3992249
Validation loss decreased (0.328134 --> 0.327935).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2430404
	speed: 1.4900s/iter; left time: 10665.7702s
Epoch: 10 cost time: 93.84901905059814
Epoch: 10, Steps: 177 | Train Loss: 0.2376959 Vali Loss: 0.3278152 Test Loss: 0.3988684
Validation loss decreased (0.327935 --> 0.327815).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2453781
	speed: 1.3795s/iter; left time: 9630.1547s
Epoch: 11 cost time: 82.06293177604675
Epoch: 11, Steps: 177 | Train Loss: 0.2376820 Vali Loss: 0.3281740 Test Loss: 0.3993391
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2209958
	speed: 1.2940s/iter; left time: 8804.3648s
Epoch: 12 cost time: 81.96302962303162
Epoch: 12, Steps: 177 | Train Loss: 0.2375604 Vali Loss: 0.3277493 Test Loss: 0.3987450
Validation loss decreased (0.327815 --> 0.327749).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2429018
	speed: 1.3616s/iter; left time: 9023.2614s
Epoch: 13 cost time: 79.88981461524963
Epoch: 13, Steps: 177 | Train Loss: 0.2375110 Vali Loss: 0.3281755 Test Loss: 0.3991496
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2353089
	speed: 1.3425s/iter; left time: 8659.0160s
Epoch: 14 cost time: 82.97923111915588
Epoch: 14, Steps: 177 | Train Loss: 0.2374996 Vali Loss: 0.3284810 Test Loss: 0.3992397
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2266957
	speed: 1.3542s/iter; left time: 8495.0185s
Epoch: 15 cost time: 85.00218296051025
Epoch: 15, Steps: 177 | Train Loss: 0.2374835 Vali Loss: 0.3278340 Test Loss: 0.3985871
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2416578
	speed: 1.3361s/iter; left time: 8144.8631s
Epoch: 16 cost time: 81.92406058311462
Epoch: 16, Steps: 177 | Train Loss: 0.2373855 Vali Loss: 0.3281241 Test Loss: 0.3985521
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2305911
	speed: 1.4038s/iter; left time: 8309.2368s
Epoch: 17 cost time: 83.55147528648376
Epoch: 17, Steps: 177 | Train Loss: 0.2373593 Vali Loss: 0.3280856 Test Loss: 0.3989188
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2337917
	speed: 1.3632s/iter; left time: 7827.2255s
Epoch: 18 cost time: 84.96018171310425
Epoch: 18, Steps: 177 | Train Loss: 0.2373602 Vali Loss: 0.3272713 Test Loss: 0.3982428
Validation loss decreased (0.327749 --> 0.327271).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2370752
	speed: 1.3176s/iter; left time: 7332.6465s
Epoch: 19 cost time: 85.35752320289612
Epoch: 19, Steps: 177 | Train Loss: 0.2372770 Vali Loss: 0.3277011 Test Loss: 0.3983302
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2405757
	speed: 1.3813s/iter; left time: 7442.4869s
Epoch: 20 cost time: 86.0574688911438
Epoch: 20, Steps: 177 | Train Loss: 0.2372154 Vali Loss: 0.3275740 Test Loss: 0.3984728
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2348602
	speed: 1.3300s/iter; left time: 6930.5566s
Epoch: 21 cost time: 80.25812983512878
Epoch: 21, Steps: 177 | Train Loss: 0.2372315 Vali Loss: 0.3277280 Test Loss: 0.3984953
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2346834
	speed: 1.3409s/iter; left time: 6749.9351s
Epoch: 22 cost time: 88.69089579582214
Epoch: 22, Steps: 177 | Train Loss: 0.2371996 Vali Loss: 0.3276369 Test Loss: 0.3983785
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2294952
	speed: 1.2304s/iter; left time: 5975.8125s
Epoch: 23 cost time: 71.44512724876404
Epoch: 23, Steps: 177 | Train Loss: 0.2371778 Vali Loss: 0.3275433 Test Loss: 0.3985119
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2332417
	speed: 1.1789s/iter; left time: 5517.2137s
Epoch: 24 cost time: 75.19620299339294
Epoch: 24, Steps: 177 | Train Loss: 0.2371850 Vali Loss: 0.3275902 Test Loss: 0.3983420
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2275171
	speed: 1.4052s/iter; left time: 6327.5475s
Epoch: 25 cost time: 90.39449524879456
Epoch: 25, Steps: 177 | Train Loss: 0.2371170 Vali Loss: 0.3270508 Test Loss: 0.3980586
Validation loss decreased (0.327271 --> 0.327051).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.2277818
	speed: 1.2735s/iter; left time: 5509.0136s
Epoch: 26 cost time: 77.38523507118225
Epoch: 26, Steps: 177 | Train Loss: 0.2371155 Vali Loss: 0.3278565 Test Loss: 0.3981757
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.2336031
	speed: 1.2745s/iter; left time: 5287.8480s
Epoch: 27 cost time: 76.44148421287537
Epoch: 27, Steps: 177 | Train Loss: 0.2371138 Vali Loss: 0.3272183 Test Loss: 0.3983411
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.2258583
	speed: 1.2347s/iter; left time: 4904.2005s
Epoch: 28 cost time: 75.23844075202942
Epoch: 28, Steps: 177 | Train Loss: 0.2370942 Vali Loss: 0.3276189 Test Loss: 0.3984267
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.2256512
	speed: 1.2510s/iter; left time: 4747.4389s
Epoch: 29 cost time: 80.72076416015625
Epoch: 29, Steps: 177 | Train Loss: 0.2370145 Vali Loss: 0.3272296 Test Loss: 0.3984216
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.2522412
	speed: 1.3020s/iter; left time: 4710.4981s
Epoch: 30 cost time: 72.99444532394409
Epoch: 30, Steps: 177 | Train Loss: 0.2370053 Vali Loss: 0.3266625 Test Loss: 0.3983192
Validation loss decreased (0.327051 --> 0.326662).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.2374199
	speed: 1.2296s/iter; left time: 4231.1538s
Epoch: 31 cost time: 79.19058680534363
Epoch: 31, Steps: 177 | Train Loss: 0.2369679 Vali Loss: 0.3276635 Test Loss: 0.3984751
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.2412833
	speed: 1.2736s/iter; left time: 4157.1456s
Epoch: 32 cost time: 78.28746366500854
Epoch: 32, Steps: 177 | Train Loss: 0.2369366 Vali Loss: 0.3278542 Test Loss: 0.3983138
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.2381013
	speed: 1.2749s/iter; left time: 3935.6888s
Epoch: 33 cost time: 78.84406590461731
Epoch: 33, Steps: 177 | Train Loss: 0.2369646 Vali Loss: 0.3277695 Test Loss: 0.3984404
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.2284368
	speed: 1.2846s/iter; left time: 3738.1092s
Epoch: 34 cost time: 77.11387252807617
Epoch: 34, Steps: 177 | Train Loss: 0.2369475 Vali Loss: 0.3276123 Test Loss: 0.3982171
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.2425017
	speed: 1.3047s/iter; left time: 3565.6469s
Epoch: 35 cost time: 83.54367065429688
Epoch: 35, Steps: 177 | Train Loss: 0.2369529 Vali Loss: 0.3272572 Test Loss: 0.3979954
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.2268499
	speed: 1.3264s/iter; left time: 3390.2759s
Epoch: 36 cost time: 74.82382869720459
Epoch: 36, Steps: 177 | Train Loss: 0.2369093 Vali Loss: 0.3266968 Test Loss: 0.3980177
EarlyStopping counter: 6 out of 20
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.2397149
	speed: 1.1804s/iter; left time: 2808.0669s
Epoch: 37 cost time: 74.28362345695496
Epoch: 37, Steps: 177 | Train Loss: 0.2369105 Vali Loss: 0.3275328 Test Loss: 0.3979694
EarlyStopping counter: 7 out of 20
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.2385261
	speed: 1.2673s/iter; left time: 2790.6621s
Epoch: 38 cost time: 81.59808778762817
Epoch: 38, Steps: 177 | Train Loss: 0.2369055 Vali Loss: 0.3276168 Test Loss: 0.3978799
EarlyStopping counter: 8 out of 20
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.2612723
	speed: 1.2450s/iter; left time: 2521.1140s
Epoch: 39 cost time: 75.97226929664612
Epoch: 39, Steps: 177 | Train Loss: 0.2368215 Vali Loss: 0.3278143 Test Loss: 0.3981390
EarlyStopping counter: 9 out of 20
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.2375423
	speed: 1.3252s/iter; left time: 2448.9164s
Epoch: 40 cost time: 90.51009917259216
Epoch: 40, Steps: 177 | Train Loss: 0.2368645 Vali Loss: 0.3271240 Test Loss: 0.3981271
EarlyStopping counter: 10 out of 20
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.2422002
	speed: 1.3532s/iter; left time: 2261.2330s
Epoch: 41 cost time: 75.39056515693665
Epoch: 41, Steps: 177 | Train Loss: 0.2368730 Vali Loss: 0.3269776 Test Loss: 0.3981264
EarlyStopping counter: 11 out of 20
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.2249620
	speed: 1.2521s/iter; left time: 1870.7073s
Epoch: 42 cost time: 79.30232977867126
Epoch: 42, Steps: 177 | Train Loss: 0.2368388 Vali Loss: 0.3268609 Test Loss: 0.3977835
EarlyStopping counter: 12 out of 20
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.2364848
	speed: 1.3046s/iter; left time: 1718.1119s
Epoch: 43 cost time: 74.09344983100891
Epoch: 43, Steps: 177 | Train Loss: 0.2368184 Vali Loss: 0.3272483 Test Loss: 0.3978112
EarlyStopping counter: 13 out of 20
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.2536357
	speed: 1.1538s/iter; left time: 1315.3769s
Epoch: 44 cost time: 78.27262258529663
Epoch: 44, Steps: 177 | Train Loss: 0.2368337 Vali Loss: 0.3271721 Test Loss: 0.3979942
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.2412068
	speed: 1.3217s/iter; left time: 1272.8425s
Epoch: 45 cost time: 82.58619451522827
Epoch: 45, Steps: 177 | Train Loss: 0.2368214 Vali Loss: 0.3267654 Test Loss: 0.3979501
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.2307801
	speed: 1.3036s/iter; left time: 1024.5943s
Epoch: 46 cost time: 80.22912430763245
Epoch: 46, Steps: 177 | Train Loss: 0.2367452 Vali Loss: 0.3266311 Test Loss: 0.3979826
Validation loss decreased (0.326662 --> 0.326631).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.2317231
	speed: 1.3240s/iter; left time: 806.3378s
Epoch: 47 cost time: 80.47573256492615
Epoch: 47, Steps: 177 | Train Loss: 0.2367736 Vali Loss: 0.3267733 Test Loss: 0.3979632
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.2454562
	speed: 1.3070s/iter; left time: 564.6041s
Epoch: 48 cost time: 85.68494033813477
Epoch: 48, Steps: 177 | Train Loss: 0.2367235 Vali Loss: 0.3268212 Test Loss: 0.3978944
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.2282544
	speed: 1.3886s/iter; left time: 354.1037s
Epoch: 49 cost time: 81.35494923591614
Epoch: 49, Steps: 177 | Train Loss: 0.2366570 Vali Loss: 0.3270847 Test Loss: 0.3978470
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.2349664
	speed: 1.2806s/iter; left time: 99.8878s
Epoch: 50 cost time: 83.49387288093567
Epoch: 50, Steps: 177 | Train Loss: 0.2367637 Vali Loss: 0.3270220 Test Loss: 0.3978671
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.0497355408796396e-05
>>>>>>>testing : Traffic_720_j192_H10_FITS_custom_ftM_sl720_ll48_pl192_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3317
mse:0.3971109092235565, mae:0.272395521402359, rse:0.5200976729393005, corr:[0.27334166 0.2905575  0.28912267 0.28998563 0.289773   0.2904519
 0.29025826 0.2902285  0.29011038 0.28994513 0.29022324 0.28943577
 0.28942576 0.28891033 0.28904006 0.2894079  0.2890187  0.2891721
 0.28896475 0.28910333 0.2892074  0.28902474 0.28886282 0.28862828
 0.29031914 0.29057086 0.29025382 0.29007053 0.28983143 0.2900896
 0.29013214 0.28998327 0.28979355 0.28974196 0.2899677  0.2896627
 0.28989068 0.28987545 0.28969565 0.2900299  0.28968295 0.2898014
 0.28970253 0.28924417 0.28928128 0.28902662 0.2888313  0.28881413
 0.28926635 0.28931168 0.28912136 0.28919265 0.2892298  0.28924403
 0.28909996 0.288977   0.2892701  0.2894009  0.28951475 0.2891806
 0.28873363 0.28881404 0.28859574 0.28874254 0.2887311  0.28821048
 0.2881696  0.2881126  0.28822386 0.28828993 0.28822517 0.28832176
 0.28808653 0.28804907 0.28803465 0.2879599  0.28794858 0.28792363
 0.28804407 0.28815123 0.28855807 0.28859577 0.28838083 0.28834602
 0.28798765 0.2879544  0.28802565 0.28789613 0.28803244 0.28804967
 0.2882019  0.28809857 0.28772536 0.28766045 0.28755906 0.28769884
 0.28742176 0.28734872 0.2876167  0.2876957  0.28801754 0.28771564
 0.28750473 0.28792197 0.28793317 0.28778765 0.28757238 0.28763136
 0.2876897  0.28753883 0.28760415 0.28756338 0.28761896 0.28746045
 0.28723547 0.28748062 0.2873088  0.2869958  0.2870035  0.28705314
 0.28709385 0.2870003  0.2872494  0.2879053  0.28795174 0.28762898
 0.28776503 0.2880258  0.28788495 0.2880973  0.2881165  0.287817
 0.28782865 0.28755575 0.28756258 0.2875665  0.2873689  0.28743732
 0.2872531  0.28731564 0.2873829  0.2872868  0.28737932 0.28730515
 0.2878748  0.28806165 0.28787354 0.28832474 0.2884769  0.28851086
 0.2885642  0.28837213 0.28833815 0.28814778 0.2882435  0.2883319
 0.28838298 0.28855008 0.28831863 0.28818488 0.28798404 0.28816596
 0.28818145 0.2879589  0.28816107 0.28799796 0.2881534  0.28808668
 0.28932023 0.29015324 0.28969783 0.2893618  0.28923625 0.2893715
 0.28959945 0.28904155 0.28913677 0.2890035  0.28906596 0.28906813
 0.2886581  0.28904858 0.28860998 0.28918046 0.28910157 0.2887015
 0.2886319  0.28791943 0.288372   0.28682047 0.28789207 0.28864947]
