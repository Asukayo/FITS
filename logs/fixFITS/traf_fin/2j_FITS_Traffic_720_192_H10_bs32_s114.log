Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=320, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_720_j192_H10', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : Traffic_720_j192_H10_FITS_custom_ftM_sl720_ll48_pl192_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11369
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=320, out_features=405, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  7149772800.0
params:  130005.0
Trainable parameters:  130005
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.8616899
	speed: 0.5241s/iter; left time: 4586.1476s
Epoch: 1 cost time: 89.02419924736023
Epoch: 1, Steps: 177 | Train Loss: 0.9311963 Vali Loss: 0.9944126 Test Loss: 1.1438853
Validation loss decreased (inf --> 0.994413).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6448860
	speed: 1.4627s/iter; left time: 12541.1257s
Epoch: 2 cost time: 92.94514441490173
Epoch: 2, Steps: 177 | Train Loss: 0.6595380 Vali Loss: 0.8800784 Test Loss: 1.0106620
Validation loss decreased (0.994413 --> 0.880078).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5300119
	speed: 1.4436s/iter; left time: 12121.9091s
Epoch: 3 cost time: 90.88188743591309
Epoch: 3, Steps: 177 | Train Loss: 0.5320284 Vali Loss: 0.7854280 Test Loss: 0.9035009
Validation loss decreased (0.880078 --> 0.785428).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4361094
	speed: 1.4394s/iter; left time: 11831.5048s
Epoch: 4 cost time: 90.94426608085632
Epoch: 4, Steps: 177 | Train Loss: 0.4384434 Vali Loss: 0.7102852 Test Loss: 0.8185205
Validation loss decreased (0.785428 --> 0.710285).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3582040
	speed: 1.4292s/iter; left time: 11495.1981s
Epoch: 5 cost time: 87.28081178665161
Epoch: 5, Steps: 177 | Train Loss: 0.3658367 Vali Loss: 0.6479418 Test Loss: 0.7469045
Validation loss decreased (0.710285 --> 0.647942).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3025645
	speed: 1.4485s/iter; left time: 11393.9911s
Epoch: 6 cost time: 89.80603909492493
Epoch: 6, Steps: 177 | Train Loss: 0.3082811 Vali Loss: 0.5903018 Test Loss: 0.6818946
Validation loss decreased (0.647942 --> 0.590302).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2569544
	speed: 1.3299s/iter; left time: 10225.6541s
Epoch: 7 cost time: 84.76222109794617
Epoch: 7, Steps: 177 | Train Loss: 0.2620241 Vali Loss: 0.5480223 Test Loss: 0.6338988
Validation loss decreased (0.590302 --> 0.548022).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2213292
	speed: 1.4177s/iter; left time: 10649.9680s
Epoch: 8 cost time: 89.66311526298523
Epoch: 8, Steps: 177 | Train Loss: 0.2245205 Vali Loss: 0.5111486 Test Loss: 0.5925773
Validation loss decreased (0.548022 --> 0.511149).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1916279
	speed: 1.3988s/iter; left time: 10260.0021s
Epoch: 9 cost time: 80.54686212539673
Epoch: 9, Steps: 177 | Train Loss: 0.1939321 Vali Loss: 0.4787556 Test Loss: 0.5559018
Validation loss decreased (0.511149 --> 0.478756).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1682575
	speed: 1.3937s/iter; left time: 9975.8329s
Epoch: 10 cost time: 87.35702729225159
Epoch: 10, Steps: 177 | Train Loss: 0.1689283 Vali Loss: 0.4573381 Test Loss: 0.5319749
Validation loss decreased (0.478756 --> 0.457338).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1497606
	speed: 1.5376s/iter; left time: 10733.7465s
Epoch: 11 cost time: 98.68416571617126
Epoch: 11, Steps: 177 | Train Loss: 0.1483944 Vali Loss: 0.4337410 Test Loss: 0.5061850
Validation loss decreased (0.457338 --> 0.433741).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1270236
	speed: 1.3583s/iter; left time: 9241.6801s
Epoch: 12 cost time: 77.59253573417664
Epoch: 12, Steps: 177 | Train Loss: 0.1315045 Vali Loss: 0.4151738 Test Loss: 0.4856665
Validation loss decreased (0.433741 --> 0.415174).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1174568
	speed: 1.2470s/iter; left time: 8263.6293s
Epoch: 13 cost time: 74.62679982185364
Epoch: 13, Steps: 177 | Train Loss: 0.1176092 Vali Loss: 0.4017774 Test Loss: 0.4709648
Validation loss decreased (0.415174 --> 0.401777).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1051731
	speed: 1.1925s/iter; left time: 7691.8197s
Epoch: 14 cost time: 74.06943106651306
Epoch: 14, Steps: 177 | Train Loss: 0.1061763 Vali Loss: 0.3899542 Test Loss: 0.4578042
Validation loss decreased (0.401777 --> 0.389954).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.0941667
	speed: 1.3515s/iter; left time: 8478.0246s
Epoch: 15 cost time: 87.6075713634491
Epoch: 15, Steps: 177 | Train Loss: 0.0967601 Vali Loss: 0.3780806 Test Loss: 0.4454142
Validation loss decreased (0.389954 --> 0.378081).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.0891331
	speed: 1.4520s/iter; left time: 8851.6499s
Epoch: 16 cost time: 96.3385660648346
Epoch: 16, Steps: 177 | Train Loss: 0.0889841 Vali Loss: 0.3700063 Test Loss: 0.4364875
Validation loss decreased (0.378081 --> 0.370006).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.0804950
	speed: 1.4960s/iter; left time: 8854.9202s
Epoch: 17 cost time: 91.8849630355835
Epoch: 17, Steps: 177 | Train Loss: 0.0826036 Vali Loss: 0.3624907 Test Loss: 0.4288966
Validation loss decreased (0.370006 --> 0.362491).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.0770385
	speed: 1.5546s/iter; left time: 8926.6887s
Epoch: 18 cost time: 94.00830292701721
Epoch: 18, Steps: 177 | Train Loss: 0.0773658 Vali Loss: 0.3569847 Test Loss: 0.4236710
Validation loss decreased (0.362491 --> 0.356985).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.0723223
	speed: 1.5176s/iter; left time: 8445.5894s
Epoch: 19 cost time: 95.7500159740448
Epoch: 19, Steps: 177 | Train Loss: 0.0730540 Vali Loss: 0.3526829 Test Loss: 0.4190064
Validation loss decreased (0.356985 --> 0.352683).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.0698026
	speed: 1.5052s/iter; left time: 8109.9276s
Epoch: 20 cost time: 97.73796057701111
Epoch: 20, Steps: 177 | Train Loss: 0.0695234 Vali Loss: 0.3484034 Test Loss: 0.4151058
Validation loss decreased (0.352683 --> 0.348403).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.0657344
	speed: 1.5417s/iter; left time: 8033.5975s
Epoch: 21 cost time: 89.90770721435547
Epoch: 21, Steps: 177 | Train Loss: 0.0666523 Vali Loss: 0.3452097 Test Loss: 0.4117799
Validation loss decreased (0.348403 --> 0.345210).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.0640093
	speed: 1.4157s/iter; left time: 7126.4833s
Epoch: 22 cost time: 93.39675402641296
Epoch: 22, Steps: 177 | Train Loss: 0.0643134 Vali Loss: 0.3426331 Test Loss: 0.4094246
Validation loss decreased (0.345210 --> 0.342633).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.0608563
	speed: 1.4276s/iter; left time: 6933.6132s
Epoch: 23 cost time: 85.97573471069336
Epoch: 23, Steps: 177 | Train Loss: 0.0624128 Vali Loss: 0.3402565 Test Loss: 0.4074470
Validation loss decreased (0.342633 --> 0.340256).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.0603147
	speed: 1.4291s/iter; left time: 6688.1053s
Epoch: 24 cost time: 95.15727615356445
Epoch: 24, Steps: 177 | Train Loss: 0.0608819 Vali Loss: 0.3386685 Test Loss: 0.4059682
Validation loss decreased (0.340256 --> 0.338668).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.0579013
	speed: 1.7155s/iter; left time: 7724.8749s
Epoch: 25 cost time: 95.50782442092896
Epoch: 25, Steps: 177 | Train Loss: 0.0596314 Vali Loss: 0.3366437 Test Loss: 0.4044092
Validation loss decreased (0.338668 --> 0.336644).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.0569298
	speed: 1.1946s/iter; left time: 5167.8219s
Epoch: 26 cost time: 62.16344475746155
Epoch: 26, Steps: 177 | Train Loss: 0.0586441 Vali Loss: 0.3363108 Test Loss: 0.4036272
Validation loss decreased (0.336644 --> 0.336311).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.0570726
	speed: 0.9993s/iter; left time: 4146.1323s
Epoch: 27 cost time: 62.31452965736389
Epoch: 27, Steps: 177 | Train Loss: 0.0578547 Vali Loss: 0.3347646 Test Loss: 0.4031022
Validation loss decreased (0.336311 --> 0.334765).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.0547960
	speed: 1.0416s/iter; left time: 4137.1819s
Epoch: 28 cost time: 62.17937159538269
Epoch: 28, Steps: 177 | Train Loss: 0.0572278 Vali Loss: 0.3343914 Test Loss: 0.4025685
Validation loss decreased (0.334765 --> 0.334391).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.0544372
	speed: 1.0320s/iter; left time: 3916.2869s
Epoch: 29 cost time: 62.670626401901245
Epoch: 29, Steps: 177 | Train Loss: 0.0567179 Vali Loss: 0.3334835 Test Loss: 0.4022836
Validation loss decreased (0.334391 --> 0.333484).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.0590672
	speed: 0.9370s/iter; left time: 3390.0464s
Epoch: 30 cost time: 64.9800922870636
Epoch: 30, Steps: 177 | Train Loss: 0.0563298 Vali Loss: 0.3324501 Test Loss: 0.4019755
Validation loss decreased (0.333484 --> 0.332450).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.0561894
	speed: 1.2884s/iter; left time: 4433.2900s
Epoch: 31 cost time: 80.26425194740295
Epoch: 31, Steps: 177 | Train Loss: 0.0560216 Vali Loss: 0.3329649 Test Loss: 0.4017929
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.0569203
	speed: 1.2929s/iter; left time: 4220.0964s
Epoch: 32 cost time: 81.89074325561523
Epoch: 32, Steps: 177 | Train Loss: 0.0557814 Vali Loss: 0.3328394 Test Loss: 0.4015239
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.0557958
	speed: 1.3978s/iter; left time: 4315.0535s
Epoch: 33 cost time: 94.6134705543518
Epoch: 33, Steps: 177 | Train Loss: 0.0556100 Vali Loss: 0.3325647 Test Loss: 0.4016193
EarlyStopping counter: 3 out of 3
Early stopping
train 11369
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=320, out_features=405, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  7149772800.0
params:  130005.0
Trainable parameters:  130005
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2409852
	speed: 0.3800s/iter; left time: 3325.0454s
Epoch: 1 cost time: 70.0375235080719
Epoch: 1, Steps: 177 | Train Loss: 0.2390520 Vali Loss: 0.3299280 Test Loss: 0.4002095
Validation loss decreased (inf --> 0.329928).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2505537
	speed: 1.2637s/iter; left time: 10834.7972s
Epoch: 2 cost time: 82.041184425354
Epoch: 2, Steps: 177 | Train Loss: 0.2384194 Vali Loss: 0.3288281 Test Loss: 0.4005775
Validation loss decreased (0.329928 --> 0.328828).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2298022
	speed: 1.3417s/iter; left time: 11266.4423s
Epoch: 3 cost time: 86.53014636039734
Epoch: 3, Steps: 177 | Train Loss: 0.2382002 Vali Loss: 0.3284306 Test Loss: 0.3997902
Validation loss decreased (0.328828 --> 0.328431).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2432669
	speed: 1.4646s/iter; left time: 12038.6519s
Epoch: 4 cost time: 98.22072553634644
Epoch: 4, Steps: 177 | Train Loss: 0.2381311 Vali Loss: 0.3286533 Test Loss: 0.4000873
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2449704
	speed: 1.5300s/iter; left time: 12305.6077s
Epoch: 5 cost time: 85.89594149589539
Epoch: 5, Steps: 177 | Train Loss: 0.2380071 Vali Loss: 0.3286419 Test Loss: 0.4000468
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2385669
	speed: 1.3488s/iter; left time: 10609.5643s
Epoch: 6 cost time: 81.53657078742981
Epoch: 6, Steps: 177 | Train Loss: 0.2378737 Vali Loss: 0.3281768 Test Loss: 0.3994633
Validation loss decreased (0.328431 --> 0.328177).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2348976
	speed: 1.3352s/iter; left time: 10266.1885s
Epoch: 7 cost time: 86.52842569351196
Epoch: 7, Steps: 177 | Train Loss: 0.2378889 Vali Loss: 0.3283985 Test Loss: 0.4002587
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2410896
	speed: 1.4235s/iter; left time: 10693.0340s
Epoch: 8 cost time: 85.69905257225037
Epoch: 8, Steps: 177 | Train Loss: 0.2377657 Vali Loss: 0.3283365 Test Loss: 0.3995457
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2374294
	speed: 1.3569s/iter; left time: 9952.5617s
Epoch: 9 cost time: 86.36820316314697
Epoch: 9, Steps: 177 | Train Loss: 0.2377221 Vali Loss: 0.3281864 Test Loss: 0.3996382
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Traffic_720_j192_H10_FITS_custom_ftM_sl720_ll48_pl192_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3317
mse:0.39859363436698914, mae:0.2751369774341583, rse:0.52106773853302, corr:[0.2746204  0.29001018 0.291303   0.29122368 0.2906936  0.29062945
 0.29023492 0.29002732 0.28989077 0.28950736 0.28927645 0.28880268
 0.28865498 0.28858435 0.28872308 0.28934163 0.2890505  0.2889139
 0.28900793 0.28910652 0.28990012 0.29010507 0.29014218 0.289959
 0.29049987 0.29100335 0.29086116 0.29014722 0.29037607 0.29088718
 0.29107726 0.29069707 0.29038426 0.2903945  0.2898487  0.28911635
 0.2883703  0.28806305 0.28885624 0.2894296  0.28914246 0.28836352
 0.2876658  0.28803605 0.28856215 0.28891227 0.28867573 0.28811243
 0.288764   0.28871655 0.28863236 0.2895849  0.29012683 0.28975254
 0.28946334 0.28954524 0.2896426  0.28952953 0.28901932 0.28814256
 0.2876943  0.28787488 0.28832987 0.28835174 0.2884104  0.28891677
 0.28836071 0.28811473 0.28871238 0.288299   0.28777713 0.2875435
 0.28780156 0.2884531  0.2887318  0.28916994 0.28959697 0.28949553
 0.28850493 0.2876835  0.28780955 0.28739947 0.28687066 0.28723824
 0.28792688 0.28856596 0.28855297 0.28820583 0.2878482  0.28725842
 0.28731444 0.28748578 0.28780207 0.28818884 0.28795275 0.28813738
 0.2876357  0.28706658 0.28724614 0.2874394  0.28816214 0.28816378
 0.2871218  0.28708848 0.28735438 0.28668436 0.286599   0.28738764
 0.28762347 0.28786057 0.28852817 0.2883599  0.28766584 0.28746474
 0.2873048  0.2869595  0.2868609  0.286594   0.28652188 0.28753266
 0.28825963 0.28806773 0.28790256 0.28822353 0.28853342 0.2882553
 0.2874286  0.28676614 0.2867221  0.28728452 0.28810713 0.2880058
 0.2870141  0.286902   0.28781623 0.28812358 0.28756443 0.28721762
 0.28683317 0.2866105  0.28677577 0.2869654  0.28803903 0.28877544
 0.2886636  0.2886359  0.28879693 0.28934273 0.28883407 0.28725836
 0.28702876 0.2874366  0.2873786  0.2874395  0.28777075 0.28787476
 0.28717953 0.28733513 0.28861853 0.28867146 0.28767148 0.28705293
 0.28788278 0.28903094 0.28862187 0.28807697 0.28805318 0.28844434
 0.29023314 0.29057583 0.29028785 0.29005498 0.28968456 0.28900036
 0.28874695 0.28871024 0.28821254 0.288543   0.288762   0.28829184
 0.28856325 0.2888269  0.2897162  0.29030988 0.2891199  0.28879493
 0.28877944 0.2895165  0.2894349  0.28864533 0.28952703 0.28831172]
