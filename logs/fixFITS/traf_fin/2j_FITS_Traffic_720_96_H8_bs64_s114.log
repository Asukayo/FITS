Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=258, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_720_j96_H8', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : Traffic_720_j96_H8_FITS_custom_ftM_sl720_ll48_pl96_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11465
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=258, out_features=292, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  8312272896.0
params:  75628.0
Trainable parameters:  75628
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 63.64621162414551
Epoch: 1, Steps: 89 | Train Loss: 1.0248478 Vali Loss: 1.1293517 Test Loss: 1.2934233
Validation loss decreased (inf --> 1.129352).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 64.46907114982605
Epoch: 2, Steps: 89 | Train Loss: 0.7830093 Vali Loss: 1.0101798 Test Loss: 1.1566881
Validation loss decreased (1.129352 --> 1.010180).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 62.06993579864502
Epoch: 3, Steps: 89 | Train Loss: 0.6850030 Vali Loss: 0.9433191 Test Loss: 1.0830683
Validation loss decreased (1.010180 --> 0.943319).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 64.88826298713684
Epoch: 4, Steps: 89 | Train Loss: 0.6136300 Vali Loss: 0.8927425 Test Loss: 1.0257127
Validation loss decreased (0.943319 --> 0.892742).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 67.5242555141449
Epoch: 5, Steps: 89 | Train Loss: 0.5545672 Vali Loss: 0.8458812 Test Loss: 0.9733765
Validation loss decreased (0.892742 --> 0.845881).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 63.39454007148743
Epoch: 6, Steps: 89 | Train Loss: 0.5044429 Vali Loss: 0.8054217 Test Loss: 0.9275773
Validation loss decreased (0.845881 --> 0.805422).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 66.02887272834778
Epoch: 7, Steps: 89 | Train Loss: 0.4612910 Vali Loss: 0.7665148 Test Loss: 0.8818408
Validation loss decreased (0.805422 --> 0.766515).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 70.8501398563385
Epoch: 8, Steps: 89 | Train Loss: 0.4237344 Vali Loss: 0.7331955 Test Loss: 0.8435709
Validation loss decreased (0.766515 --> 0.733195).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 66.02391767501831
Epoch: 9, Steps: 89 | Train Loss: 0.3909236 Vali Loss: 0.7014698 Test Loss: 0.8098242
Validation loss decreased (0.733195 --> 0.701470).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 63.71046590805054
Epoch: 10, Steps: 89 | Train Loss: 0.3619664 Vali Loss: 0.6776145 Test Loss: 0.7805762
Validation loss decreased (0.701470 --> 0.677614).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 65.94345235824585
Epoch: 11, Steps: 89 | Train Loss: 0.3363813 Vali Loss: 0.6503369 Test Loss: 0.7508686
Validation loss decreased (0.677614 --> 0.650337).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 64.10678958892822
Epoch: 12, Steps: 89 | Train Loss: 0.3136007 Vali Loss: 0.6289421 Test Loss: 0.7244347
Validation loss decreased (0.650337 --> 0.628942).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 69.68749022483826
Epoch: 13, Steps: 89 | Train Loss: 0.2933729 Vali Loss: 0.6062143 Test Loss: 0.6982431
Validation loss decreased (0.628942 --> 0.606214).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 66.44485783576965
Epoch: 14, Steps: 89 | Train Loss: 0.2751598 Vali Loss: 0.5901240 Test Loss: 0.6801873
Validation loss decreased (0.606214 --> 0.590124).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 67.06889510154724
Epoch: 15, Steps: 89 | Train Loss: 0.2588673 Vali Loss: 0.5729584 Test Loss: 0.6617226
Validation loss decreased (0.590124 --> 0.572958).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 69.24466323852539
Epoch: 16, Steps: 89 | Train Loss: 0.2441450 Vali Loss: 0.5582522 Test Loss: 0.6430427
Validation loss decreased (0.572958 --> 0.558252).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 69.92208433151245
Epoch: 17, Steps: 89 | Train Loss: 0.2309019 Vali Loss: 0.5442420 Test Loss: 0.6287313
Validation loss decreased (0.558252 --> 0.544242).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 66.69499564170837
Epoch: 18, Steps: 89 | Train Loss: 0.2188571 Vali Loss: 0.5302173 Test Loss: 0.6120216
Validation loss decreased (0.544242 --> 0.530217).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 66.94660377502441
Epoch: 19, Steps: 89 | Train Loss: 0.2079631 Vali Loss: 0.5198388 Test Loss: 0.5997298
Validation loss decreased (0.530217 --> 0.519839).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 65.7906801700592
Epoch: 20, Steps: 89 | Train Loss: 0.1980196 Vali Loss: 0.5103841 Test Loss: 0.5887049
Validation loss decreased (0.519839 --> 0.510384).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 67.37803077697754
Epoch: 21, Steps: 89 | Train Loss: 0.1889407 Vali Loss: 0.4990906 Test Loss: 0.5764122
Validation loss decreased (0.510384 --> 0.499091).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 64.00735688209534
Epoch: 22, Steps: 89 | Train Loss: 0.1806793 Vali Loss: 0.4912618 Test Loss: 0.5662376
Validation loss decreased (0.499091 --> 0.491262).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 64.4275074005127
Epoch: 23, Steps: 89 | Train Loss: 0.1730710 Vali Loss: 0.4803807 Test Loss: 0.5556194
Validation loss decreased (0.491262 --> 0.480381).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 64.55854868888855
Epoch: 24, Steps: 89 | Train Loss: 0.1661496 Vali Loss: 0.4739412 Test Loss: 0.5481083
Validation loss decreased (0.480381 --> 0.473941).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 68.8425042629242
Epoch: 25, Steps: 89 | Train Loss: 0.1597269 Vali Loss: 0.4672419 Test Loss: 0.5397933
Validation loss decreased (0.473941 --> 0.467242).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 64.07585573196411
Epoch: 26, Steps: 89 | Train Loss: 0.1538440 Vali Loss: 0.4613267 Test Loss: 0.5331780
Validation loss decreased (0.467242 --> 0.461327).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 56.67885112762451
Epoch: 27, Steps: 89 | Train Loss: 0.1484102 Vali Loss: 0.4542999 Test Loss: 0.5259522
Validation loss decreased (0.461327 --> 0.454300).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 54.88827133178711
Epoch: 28, Steps: 89 | Train Loss: 0.1434106 Vali Loss: 0.4489990 Test Loss: 0.5199648
Validation loss decreased (0.454300 --> 0.448999).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 60.977694034576416
Epoch: 29, Steps: 89 | Train Loss: 0.1387563 Vali Loss: 0.4448411 Test Loss: 0.5138113
Validation loss decreased (0.448999 --> 0.444841).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 66.4358811378479
Epoch: 30, Steps: 89 | Train Loss: 0.1344946 Vali Loss: 0.4398225 Test Loss: 0.5087852
Validation loss decreased (0.444841 --> 0.439822).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 61.81382369995117
Epoch: 31, Steps: 89 | Train Loss: 0.1305033 Vali Loss: 0.4344706 Test Loss: 0.5034701
Validation loss decreased (0.439822 --> 0.434471).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 60.77188444137573
Epoch: 32, Steps: 89 | Train Loss: 0.1267891 Vali Loss: 0.4317077 Test Loss: 0.4994383
Validation loss decreased (0.434471 --> 0.431708).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 59.49400329589844
Epoch: 33, Steps: 89 | Train Loss: 0.1233784 Vali Loss: 0.4278289 Test Loss: 0.4955154
Validation loss decreased (0.431708 --> 0.427829).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 55.896913290023804
Epoch: 34, Steps: 89 | Train Loss: 0.1201642 Vali Loss: 0.4232595 Test Loss: 0.4908740
Validation loss decreased (0.427829 --> 0.423259).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 57.28548741340637
Epoch: 35, Steps: 89 | Train Loss: 0.1171729 Vali Loss: 0.4196424 Test Loss: 0.4861127
Validation loss decreased (0.423259 --> 0.419642).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 62.299304246902466
Epoch: 36, Steps: 89 | Train Loss: 0.1143779 Vali Loss: 0.4175009 Test Loss: 0.4832910
Validation loss decreased (0.419642 --> 0.417501).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 65.09191036224365
Epoch: 37, Steps: 89 | Train Loss: 0.1118138 Vali Loss: 0.4137616 Test Loss: 0.4794844
Validation loss decreased (0.417501 --> 0.413762).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 62.00034284591675
Epoch: 38, Steps: 89 | Train Loss: 0.1093638 Vali Loss: 0.4115452 Test Loss: 0.4766811
Validation loss decreased (0.413762 --> 0.411545).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 61.461894512176514
Epoch: 39, Steps: 89 | Train Loss: 0.1070938 Vali Loss: 0.4073295 Test Loss: 0.4734573
Validation loss decreased (0.411545 --> 0.407329).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 60.87682342529297
Epoch: 40, Steps: 89 | Train Loss: 0.1049657 Vali Loss: 0.4071105 Test Loss: 0.4714296
Validation loss decreased (0.407329 --> 0.407110).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 57.78070306777954
Epoch: 41, Steps: 89 | Train Loss: 0.1029703 Vali Loss: 0.4034969 Test Loss: 0.4685777
Validation loss decreased (0.407110 --> 0.403497).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 53.32945370674133
Epoch: 42, Steps: 89 | Train Loss: 0.1010967 Vali Loss: 0.4004438 Test Loss: 0.4659852
Validation loss decreased (0.403497 --> 0.400444).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 59.37090826034546
Epoch: 43, Steps: 89 | Train Loss: 0.0993461 Vali Loss: 0.3995355 Test Loss: 0.4641154
Validation loss decreased (0.400444 --> 0.399536).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 59.772624254226685
Epoch: 44, Steps: 89 | Train Loss: 0.0976955 Vali Loss: 0.3963796 Test Loss: 0.4615725
Validation loss decreased (0.399536 --> 0.396380).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 59.87551164627075
Epoch: 45, Steps: 89 | Train Loss: 0.0961387 Vali Loss: 0.3950942 Test Loss: 0.4593361
Validation loss decreased (0.396380 --> 0.395094).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 61.79528307914734
Epoch: 46, Steps: 89 | Train Loss: 0.0946605 Vali Loss: 0.3937251 Test Loss: 0.4574261
Validation loss decreased (0.395094 --> 0.393725).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 59.760255098342896
Epoch: 47, Steps: 89 | Train Loss: 0.0932871 Vali Loss: 0.3928240 Test Loss: 0.4557752
Validation loss decreased (0.393725 --> 0.392824).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 60.11745619773865
Epoch: 48, Steps: 89 | Train Loss: 0.0919989 Vali Loss: 0.3912520 Test Loss: 0.4538262
Validation loss decreased (0.392824 --> 0.391252).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 60.10862994194031
Epoch: 49, Steps: 89 | Train Loss: 0.0907621 Vali Loss: 0.3896595 Test Loss: 0.4524000
Validation loss decreased (0.391252 --> 0.389659).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 59.70089054107666
Epoch: 50, Steps: 89 | Train Loss: 0.0896235 Vali Loss: 0.3877794 Test Loss: 0.4511688
Validation loss decreased (0.389659 --> 0.387779).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
train 11465
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=258, out_features=292, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  8312272896.0
params:  75628.0
Trainable parameters:  75628
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 60.05113625526428
Epoch: 1, Steps: 89 | Train Loss: 0.2410781 Vali Loss: 0.3280798 Test Loss: 0.3930197
Validation loss decreased (inf --> 0.328080).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 61.79111433029175
Epoch: 2, Steps: 89 | Train Loss: 0.2329920 Vali Loss: 0.3276583 Test Loss: 0.3924840
Validation loss decreased (0.328080 --> 0.327658).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 57.18574285507202
Epoch: 3, Steps: 89 | Train Loss: 0.2327599 Vali Loss: 0.3270796 Test Loss: 0.3926907
Validation loss decreased (0.327658 --> 0.327080).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 57.17178797721863
Epoch: 4, Steps: 89 | Train Loss: 0.2324692 Vali Loss: 0.3269651 Test Loss: 0.3913381
Validation loss decreased (0.327080 --> 0.326965).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 53.672311544418335
Epoch: 5, Steps: 89 | Train Loss: 0.2323570 Vali Loss: 0.3266812 Test Loss: 0.3915470
Validation loss decreased (0.326965 --> 0.326681).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 59.75720500946045
Epoch: 6, Steps: 89 | Train Loss: 0.2322853 Vali Loss: 0.3268699 Test Loss: 0.3912646
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 60.45453667640686
Epoch: 7, Steps: 89 | Train Loss: 0.2322081 Vali Loss: 0.3265666 Test Loss: 0.3916072
Validation loss decreased (0.326681 --> 0.326567).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 60.959123849868774
Epoch: 8, Steps: 89 | Train Loss: 0.2319122 Vali Loss: 0.3256225 Test Loss: 0.3906744
Validation loss decreased (0.326567 --> 0.325622).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 61.03194975852966
Epoch: 9, Steps: 89 | Train Loss: 0.2320650 Vali Loss: 0.3262070 Test Loss: 0.3908192
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 61.32600975036621
Epoch: 10, Steps: 89 | Train Loss: 0.2318281 Vali Loss: 0.3256631 Test Loss: 0.3906746
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 61.24807047843933
Epoch: 11, Steps: 89 | Train Loss: 0.2318828 Vali Loss: 0.3262562 Test Loss: 0.3905880
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Traffic_720_j96_H8_FITS_custom_ftM_sl720_ll48_pl96_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3413
mse:0.3877926170825958, mae:0.2719964385032654, rse:0.515647828578949, corr:[0.2800632  0.29273447 0.2940384  0.29332298 0.29300472 0.29283693
 0.2924983  0.29292658 0.29328957 0.2933999  0.29363638 0.29312363
 0.29234892 0.29218167 0.29208782 0.29180032 0.29173034 0.29223174
 0.29298836 0.29298112 0.29221097 0.29222515 0.29291952 0.2929552
 0.2937318  0.29390734 0.2935152  0.29288182 0.29314926 0.2937306
 0.29351464 0.2933473  0.2936005  0.29346985 0.29313585 0.2928519
 0.29233587 0.29211882 0.2924175  0.29256412 0.29273558 0.2931269
 0.29303303 0.2925473  0.29244083 0.29246956 0.2922481  0.29248455
 0.29338306 0.29380244 0.2939858  0.29371157 0.29318094 0.29317284
 0.29339582 0.29329082 0.29327956 0.2933752  0.29310676 0.29300833
 0.29308602 0.2925564  0.29211247 0.29257554 0.29317346 0.29308993
 0.29267734 0.292503   0.29276112 0.2931643  0.29306138 0.29276425
 0.29288325 0.2932121  0.2932974  0.29319617 0.2929483  0.292649
 0.29247296 0.29223478 0.29185942 0.29177615 0.29217908 0.29257923
 0.29255134 0.29200125 0.29128274 0.29145446 0.29237244 0.29251063
 0.29200375 0.29144576 0.29067597 0.29031083 0.2899028  0.2917511 ]
