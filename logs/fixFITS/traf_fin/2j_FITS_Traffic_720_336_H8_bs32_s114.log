Args in experiment:
Namespace(H_order=8, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=258, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_720_j336_H8', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : Traffic_720_j336_H8_FITS_custom_ftM_sl720_ll48_pl336_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11225
val 1421
test 3173
Model(
  (freq_upsampler): Linear(in_features=258, out_features=378, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  5380204032.0
params:  97902.0
Trainable parameters:  97902
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.8589967
	speed: 0.5126s/iter; left time: 4434.1514s
Epoch: 1 cost time: 85.32090449333191
Epoch: 1, Steps: 175 | Train Loss: 0.9567864 Vali Loss: 1.0243769 Test Loss: 1.1883656
Validation loss decreased (inf --> 1.024377).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6559164
	speed: 1.4723s/iter; left time: 12478.8455s
Epoch: 2 cost time: 94.1337776184082
Epoch: 2, Steps: 175 | Train Loss: 0.6755034 Vali Loss: 0.8967134 Test Loss: 1.0399888
Validation loss decreased (1.024377 --> 0.896713).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5466781
	speed: 1.5600s/iter; left time: 12949.7994s
Epoch: 3 cost time: 99.5390408039093
Epoch: 3, Steps: 175 | Train Loss: 0.5519442 Vali Loss: 0.7957622 Test Loss: 0.9239311
Validation loss decreased (0.896713 --> 0.795762).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4493939
	speed: 1.4980s/iter; left time: 12172.6612s
Epoch: 4 cost time: 85.22425961494446
Epoch: 4, Steps: 175 | Train Loss: 0.4612304 Vali Loss: 0.7179490 Test Loss: 0.8335819
Validation loss decreased (0.795762 --> 0.717949).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3986064
	speed: 1.3500s/iter; left time: 10733.7262s
Epoch: 5 cost time: 88.60455536842346
Epoch: 5, Steps: 175 | Train Loss: 0.3910418 Vali Loss: 0.6539864 Test Loss: 0.7599124
Validation loss decreased (0.717949 --> 0.653986).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3292703
	speed: 1.5801s/iter; left time: 12286.7405s
Epoch: 6 cost time: 96.65520215034485
Epoch: 6, Steps: 175 | Train Loss: 0.3355105 Vali Loss: 0.5988817 Test Loss: 0.6969318
Validation loss decreased (0.653986 --> 0.598882).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2896205
	speed: 1.6576s/iter; left time: 12599.2675s
Epoch: 7 cost time: 105.83010268211365
Epoch: 7, Steps: 175 | Train Loss: 0.2910026 Vali Loss: 0.5549750 Test Loss: 0.6466054
Validation loss decreased (0.598882 --> 0.554975).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2529119
	speed: 1.4966s/iter; left time: 11113.4344s
Epoch: 8 cost time: 89.12879872322083
Epoch: 8, Steps: 175 | Train Loss: 0.2549826 Vali Loss: 0.5187303 Test Loss: 0.6060371
Validation loss decreased (0.554975 --> 0.518730).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2276105
	speed: 1.5881s/iter; left time: 11514.9788s
Epoch: 9 cost time: 100.76789999008179
Epoch: 9, Steps: 175 | Train Loss: 0.2255876 Vali Loss: 0.4877523 Test Loss: 0.5706221
Validation loss decreased (0.518730 --> 0.487752).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1974889
	speed: 1.6300s/iter; left time: 11534.0063s
Epoch: 10 cost time: 103.88001823425293
Epoch: 10, Steps: 175 | Train Loss: 0.2015174 Vali Loss: 0.4642072 Test Loss: 0.5438719
Validation loss decreased (0.487752 --> 0.464207).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1851205
	speed: 1.7149s/iter; left time: 11834.6232s
Epoch: 11 cost time: 102.8140857219696
Epoch: 11, Steps: 175 | Train Loss: 0.1817254 Vali Loss: 0.4423898 Test Loss: 0.5188204
Validation loss decreased (0.464207 --> 0.442390).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1655423
	speed: 1.6123s/iter; left time: 10844.3691s
Epoch: 12 cost time: 104.14336252212524
Epoch: 12, Steps: 175 | Train Loss: 0.1654269 Vali Loss: 0.4261269 Test Loss: 0.5012065
Validation loss decreased (0.442390 --> 0.426127).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1517076
	speed: 1.6372s/iter; left time: 10725.0653s
Epoch: 13 cost time: 100.92193222045898
Epoch: 13, Steps: 175 | Train Loss: 0.1519735 Vali Loss: 0.4109580 Test Loss: 0.4846320
Validation loss decreased (0.426127 --> 0.410958).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1396433
	speed: 1.6782s/iter; left time: 10700.0669s
Epoch: 14 cost time: 103.28724098205566
Epoch: 14, Steps: 175 | Train Loss: 0.1408437 Vali Loss: 0.3994698 Test Loss: 0.4719591
Validation loss decreased (0.410958 --> 0.399470).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1295517
	speed: 1.6030s/iter; left time: 9940.3447s
Epoch: 15 cost time: 95.54529213905334
Epoch: 15, Steps: 175 | Train Loss: 0.1316486 Vali Loss: 0.3901194 Test Loss: 0.4616483
Validation loss decreased (0.399470 --> 0.390119).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1210118
	speed: 1.5908s/iter; left time: 9586.0316s
Epoch: 16 cost time: 96.76505398750305
Epoch: 16, Steps: 175 | Train Loss: 0.1240741 Vali Loss: 0.3817624 Test Loss: 0.4523722
Validation loss decreased (0.390119 --> 0.381762).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1186840
	speed: 1.4743s/iter; left time: 8626.2791s
Epoch: 17 cost time: 82.19258332252502
Epoch: 17, Steps: 175 | Train Loss: 0.1178005 Vali Loss: 0.3747352 Test Loss: 0.4449179
Validation loss decreased (0.381762 --> 0.374735).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1137339
	speed: 1.4175s/iter; left time: 8045.5212s
Epoch: 18 cost time: 91.88529229164124
Epoch: 18, Steps: 175 | Train Loss: 0.1126698 Vali Loss: 0.3698556 Test Loss: 0.4397735
Validation loss decreased (0.374735 --> 0.369856).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1100577
	speed: 1.5082s/iter; left time: 8296.6335s
Epoch: 19 cost time: 90.74796533584595
Epoch: 19, Steps: 175 | Train Loss: 0.1084198 Vali Loss: 0.3641507 Test Loss: 0.4342707
Validation loss decreased (0.369856 --> 0.364151).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1009786
	speed: 1.5206s/iter; left time: 8098.9739s
Epoch: 20 cost time: 95.8680374622345
Epoch: 20, Steps: 175 | Train Loss: 0.1049182 Vali Loss: 0.3608691 Test Loss: 0.4307409
Validation loss decreased (0.364151 --> 0.360869).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1001255
	speed: 1.5439s/iter; left time: 7952.3877s
Epoch: 21 cost time: 93.27701497077942
Epoch: 21, Steps: 175 | Train Loss: 0.1020919 Vali Loss: 0.3580663 Test Loss: 0.4282659
Validation loss decreased (0.360869 --> 0.358066).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.0996451
	speed: 1.4789s/iter; left time: 7358.8956s
Epoch: 22 cost time: 93.08896827697754
Epoch: 22, Steps: 175 | Train Loss: 0.0997376 Vali Loss: 0.3550471 Test Loss: 0.4252886
Validation loss decreased (0.358066 --> 0.355047).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.0946594
	speed: 1.6380s/iter; left time: 7864.2700s
Epoch: 23 cost time: 105.83689999580383
Epoch: 23, Steps: 175 | Train Loss: 0.0978302 Vali Loss: 0.3528405 Test Loss: 0.4230630
Validation loss decreased (0.355047 --> 0.352840).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.0980057
	speed: 1.5566s/iter; left time: 7201.0358s
Epoch: 24 cost time: 93.85880017280579
Epoch: 24, Steps: 175 | Train Loss: 0.0962900 Vali Loss: 0.3510426 Test Loss: 0.4215388
Validation loss decreased (0.352840 --> 0.351043).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.0926031
	speed: 1.5160s/iter; left time: 6747.9028s
Epoch: 25 cost time: 86.44428062438965
Epoch: 25, Steps: 175 | Train Loss: 0.0950468 Vali Loss: 0.3494727 Test Loss: 0.4201993
Validation loss decreased (0.351043 --> 0.349473).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.0944014
	speed: 1.5216s/iter; left time: 6506.1483s
Epoch: 26 cost time: 101.10135078430176
Epoch: 26, Steps: 175 | Train Loss: 0.0940133 Vali Loss: 0.3481945 Test Loss: 0.4190665
Validation loss decreased (0.349473 --> 0.348195).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.0951893
	speed: 1.5863s/iter; left time: 6505.3938s
Epoch: 27 cost time: 97.83331227302551
Epoch: 27, Steps: 175 | Train Loss: 0.0932045 Vali Loss: 0.3466365 Test Loss: 0.4182711
Validation loss decreased (0.348195 --> 0.346636).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.0927210
	speed: 1.6200s/iter; left time: 6360.1787s
Epoch: 28 cost time: 95.45281219482422
Epoch: 28, Steps: 175 | Train Loss: 0.0925552 Vali Loss: 0.3465538 Test Loss: 0.4180847
Validation loss decreased (0.346636 --> 0.346554).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.0907073
	speed: 1.5666s/iter; left time: 5876.2634s
Epoch: 29 cost time: 97.31779909133911
Epoch: 29, Steps: 175 | Train Loss: 0.0920470 Vali Loss: 0.3458171 Test Loss: 0.4174262
Validation loss decreased (0.346554 --> 0.345817).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.0900390
	speed: 1.4835s/iter; left time: 5304.9064s
Epoch: 30 cost time: 86.67043781280518
Epoch: 30, Steps: 175 | Train Loss: 0.0916330 Vali Loss: 0.3453815 Test Loss: 0.4176017
Validation loss decreased (0.345817 --> 0.345382).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.0946759
	speed: 1.4087s/iter; left time: 4790.9504s
Epoch: 31 cost time: 90.70245742797852
Epoch: 31, Steps: 175 | Train Loss: 0.0912926 Vali Loss: 0.3450823 Test Loss: 0.4170133
Validation loss decreased (0.345382 --> 0.345082).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.0906538
	speed: 1.6168s/iter; left time: 5215.8215s
Epoch: 32 cost time: 105.79866647720337
Epoch: 32, Steps: 175 | Train Loss: 0.0910227 Vali Loss: 0.3442465 Test Loss: 0.4166550
Validation loss decreased (0.345082 --> 0.344247).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.0916294
	speed: 1.5514s/iter; left time: 4733.3299s
Epoch: 33 cost time: 90.90560173988342
Epoch: 33, Steps: 175 | Train Loss: 0.0908357 Vali Loss: 0.3439570 Test Loss: 0.4164626
Validation loss decreased (0.344247 --> 0.343957).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.0899880
	speed: 1.5271s/iter; left time: 4392.0425s
Epoch: 34 cost time: 95.37135624885559
Epoch: 34, Steps: 175 | Train Loss: 0.0906812 Vali Loss: 0.3437783 Test Loss: 0.4165584
Validation loss decreased (0.343957 --> 0.343778).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.0921123
	speed: 1.5631s/iter; left time: 4221.8237s
Epoch: 35 cost time: 98.78667736053467
Epoch: 35, Steps: 175 | Train Loss: 0.0905482 Vali Loss: 0.3437038 Test Loss: 0.4164426
Validation loss decreased (0.343778 --> 0.343704).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.0870821
	speed: 1.7416s/iter; left time: 4399.2367s
Epoch: 36 cost time: 100.8474645614624
Epoch: 36, Steps: 175 | Train Loss: 0.0904562 Vali Loss: 0.3431582 Test Loss: 0.4163956
Validation loss decreased (0.343704 --> 0.343158).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.0883324
	speed: 1.5256s/iter; left time: 3586.7331s
Epoch: 37 cost time: 95.15036678314209
Epoch: 37, Steps: 175 | Train Loss: 0.0903822 Vali Loss: 0.3427409 Test Loss: 0.4161309
Validation loss decreased (0.343158 --> 0.342741).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.0886227
	speed: 1.5405s/iter; left time: 3352.0555s
Epoch: 38 cost time: 93.29766631126404
Epoch: 38, Steps: 175 | Train Loss: 0.0903132 Vali Loss: 0.3432076 Test Loss: 0.4160777
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.0920381
	speed: 1.5655s/iter; left time: 3132.6363s
Epoch: 39 cost time: 97.65072059631348
Epoch: 39, Steps: 175 | Train Loss: 0.0902797 Vali Loss: 0.3431966 Test Loss: 0.4163117
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.0928003
	speed: 1.5757s/iter; left time: 2877.1973s
Epoch: 40 cost time: 95.86683464050293
Epoch: 40, Steps: 175 | Train Loss: 0.0902566 Vali Loss: 0.3426626 Test Loss: 0.4162333
Validation loss decreased (0.342741 --> 0.342663).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.0897629
	speed: 1.5201s/iter; left time: 2509.7191s
Epoch: 41 cost time: 94.00167560577393
Epoch: 41, Steps: 175 | Train Loss: 0.0902088 Vali Loss: 0.3429585 Test Loss: 0.4163350
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.0894241
	speed: 1.6071s/iter; left time: 2372.0649s
Epoch: 42 cost time: 105.8487548828125
Epoch: 42, Steps: 175 | Train Loss: 0.0901672 Vali Loss: 0.3428910 Test Loss: 0.4160346
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.0907023
	speed: 1.5140s/iter; left time: 1969.6967s
Epoch: 43 cost time: 84.42779874801636
Epoch: 43, Steps: 175 | Train Loss: 0.0901603 Vali Loss: 0.3427233 Test Loss: 0.4163445
EarlyStopping counter: 3 out of 3
Early stopping
train 11225
val 1421
test 3173
Model(
  (freq_upsampler): Linear(in_features=258, out_features=378, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  5380204032.0
params:  97902.0
Trainable parameters:  97902
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2457134
	speed: 0.5236s/iter; left time: 4529.4567s
Epoch: 1 cost time: 92.42914366722107
Epoch: 1, Steps: 175 | Train Loss: 0.2497821 Vali Loss: 0.3412661 Test Loss: 0.4160532
Validation loss decreased (inf --> 0.341266).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2528850
	speed: 1.4476s/iter; left time: 12269.9057s
Epoch: 2 cost time: 86.36236906051636
Epoch: 2, Steps: 175 | Train Loss: 0.2493718 Vali Loss: 0.3416243 Test Loss: 0.4155899
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2497974
	speed: 1.4943s/iter; left time: 12403.9006s
Epoch: 3 cost time: 93.73211860656738
Epoch: 3, Steps: 175 | Train Loss: 0.2492692 Vali Loss: 0.3417207 Test Loss: 0.4158330
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2643013
	speed: 1.4338s/iter; left time: 11651.3920s
Epoch: 4 cost time: 86.86670112609863
Epoch: 4, Steps: 175 | Train Loss: 0.2491283 Vali Loss: 0.3414500 Test Loss: 0.4153798
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Traffic_720_j336_H8_FITS_custom_ftM_sl720_ll48_pl336_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3173
mse:0.413546621799469, mae:0.28309616446495056, rse:0.5285201072692871, corr:[0.2749028  0.28493726 0.2855488  0.28533322 0.28503177 0.28524187
 0.28461698 0.28356948 0.28345656 0.2839463  0.28417566 0.28405896
 0.28370947 0.28331122 0.28328702 0.28376824 0.28407514 0.28397754
 0.28389066 0.2837699  0.2835376  0.28329584 0.2830515  0.2836648
 0.285322   0.28510836 0.2847142  0.28499374 0.2848234  0.28433612
 0.28424475 0.2840923  0.28413305 0.28511333 0.28585288 0.2853121
 0.28426516 0.28355142 0.2833554  0.28376925 0.2844617  0.28471345
 0.2849103  0.28557506 0.28590736 0.28530008 0.28447098 0.28412673
 0.2844041  0.28459346 0.2841683  0.2831982  0.28317624 0.28406197
 0.28452232 0.28452617 0.28462645 0.28494126 0.2852103  0.28476033
 0.283812   0.28344983 0.28386053 0.28429836 0.2844831  0.28438252
 0.284208   0.28436136 0.28539506 0.28619814 0.285288   0.2836601
 0.2828817  0.28298607 0.28334418 0.2836053  0.28370053 0.2837424
 0.2839982  0.28422055 0.28402573 0.28371638 0.28365797 0.2837059
 0.2836343  0.28319132 0.28265372 0.28285408 0.28358078 0.2836616
 0.28338936 0.2835612  0.283638   0.28324485 0.28343952 0.28443667
 0.28463203 0.28433675 0.28458792 0.28497055 0.2847732  0.28415823
 0.2838403  0.28405896 0.28463915 0.28528202 0.285351   0.28463712
 0.28405562 0.2839329  0.2833876  0.282609   0.28273812 0.28348437
 0.28397292 0.2843182  0.28446528 0.2838256  0.28323063 0.28340423
 0.28341147 0.28312704 0.28300926 0.28299725 0.28293604 0.28298187
 0.28296852 0.28282887 0.28306293 0.2836789  0.28427348 0.2846576
 0.2846995  0.28449214 0.2843441  0.2841175  0.2837512  0.28359252
 0.28369588 0.2838061  0.28408125 0.28460023 0.28490242 0.28505573
 0.2856041  0.28585044 0.2854335  0.28513327 0.28528094 0.2850559
 0.2846089  0.28473145 0.28482363 0.28424507 0.2838065  0.28395578
 0.28415146 0.2843107  0.2845576  0.28459403 0.28425825 0.2838784
 0.28391188 0.2842793  0.28450397 0.28466755 0.28477952 0.28477037
 0.28564155 0.2859034  0.2861154  0.28644854 0.28686696 0.28685632
 0.2861973  0.28576738 0.28604344 0.28631175 0.28613326 0.2857973
 0.2853108  0.28489536 0.28510302 0.28557906 0.285797   0.28577375
 0.2853618  0.28496057 0.28520322 0.28560302 0.28532732 0.28507116
 0.2855595  0.28534132 0.28549302 0.28601378 0.28609324 0.28598064
 0.28608108 0.28599226 0.2856867  0.28559795 0.285285   0.2846743
 0.28467312 0.2853695  0.2859826  0.28628108 0.28634232 0.2860332
 0.28565064 0.2854273  0.2849699  0.28446314 0.28413936 0.28344554
 0.2823654  0.28219095 0.2833635  0.2842127  0.2842491  0.28434613
 0.28450936 0.284235   0.28383416 0.28381705 0.28409386 0.28410557
 0.28377417 0.283868   0.2847029  0.2852725  0.28534114 0.285357
 0.28494805 0.2844027  0.2848759  0.28533527 0.2844445  0.2832879
 0.28314167 0.28353196 0.28379673 0.2839488  0.28398404 0.28377786
 0.28347376 0.28329104 0.28327367 0.28326073 0.28306854 0.28285292
 0.28300503 0.2833642  0.2834343  0.28335992 0.28370142 0.2843255
 0.28465146 0.28464997 0.2846176  0.2843546  0.28350806 0.28258917
 0.28222343 0.2821881  0.28207463 0.2822506  0.28269154 0.2827299
 0.28233868 0.28221428 0.28268358 0.28325263 0.28343323 0.2834078
 0.2835623  0.28355065 0.28283104 0.28190008 0.28193608 0.28299177
 0.28396082 0.2844915  0.28462347 0.28405932 0.28333938 0.2831447
 0.2832396  0.28354463 0.2836962  0.28355753 0.28305742 0.28234515
 0.28176996 0.2816807  0.28203505 0.2823514  0.28218    0.2817379
 0.2817665  0.2821396  0.28212452 0.28188848 0.2819775  0.2823466
 0.2829121  0.28375843 0.28447816 0.2844309  0.28371966 0.28343388
 0.2839194  0.28355572 0.28270313 0.28285763 0.2833304  0.28282872
 0.28238562 0.28290835 0.28345236 0.2833507  0.28332466 0.2837213
 0.28371134 0.28319454 0.28331074 0.28386283 0.28366354 0.283251
 0.28346825 0.28369004 0.28371873 0.2834994  0.2830142  0.28244117]
