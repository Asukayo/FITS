Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=165, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_720_j336_H5', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : Traffic_720_j336_H5_FITS_custom_ftM_sl720_ll48_pl336_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11225
val 1421
test 3173
Model(
  (freq_upsampler): Linear(in_features=165, out_features=241, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2193755520.0
params:  40006.0
Trainable parameters:  40006
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.8951279
	speed: 0.5997s/iter; left time: 5187.5964s
Epoch: 1 cost time: 102.44278407096863
Epoch: 1, Steps: 175 | Train Loss: 0.9720416 Vali Loss: 1.0308362 Test Loss: 1.1912470
Validation loss decreased (inf --> 1.030836).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6636178
	speed: 1.5889s/iter; left time: 13467.5124s
Epoch: 2 cost time: 96.21058750152588
Epoch: 2, Steps: 175 | Train Loss: 0.6832394 Vali Loss: 0.8896391 Test Loss: 1.0276532
Validation loss decreased (1.030836 --> 0.889639).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5561011
	speed: 1.5234s/iter; left time: 12645.5681s
Epoch: 3 cost time: 95.65419626235962
Epoch: 3, Steps: 175 | Train Loss: 0.5612313 Vali Loss: 0.7954159 Test Loss: 0.9193094
Validation loss decreased (0.889639 --> 0.795416).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4707397
	speed: 1.6027s/iter; left time: 13023.6072s
Epoch: 4 cost time: 100.75189018249512
Epoch: 4, Steps: 175 | Train Loss: 0.4729029 Vali Loss: 0.7152270 Test Loss: 0.8277064
Validation loss decreased (0.795416 --> 0.715227).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3965938
	speed: 1.5191s/iter; left time: 12078.1780s
Epoch: 5 cost time: 91.60779118537903
Epoch: 5, Steps: 175 | Train Loss: 0.4047329 Vali Loss: 0.6524239 Test Loss: 0.7566847
Validation loss decreased (0.715227 --> 0.652424).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3457734
	speed: 1.4944s/iter; left time: 11620.6623s
Epoch: 6 cost time: 90.18250870704651
Epoch: 6, Steps: 175 | Train Loss: 0.3507441 Vali Loss: 0.6002910 Test Loss: 0.6971141
Validation loss decreased (0.652424 --> 0.600291).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3027277
	speed: 1.5090s/iter; left time: 11470.2297s
Epoch: 7 cost time: 94.27751803398132
Epoch: 7, Steps: 175 | Train Loss: 0.3074571 Vali Loss: 0.5584596 Test Loss: 0.6493620
Validation loss decreased (0.600291 --> 0.558460).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2720442
	speed: 1.5245s/iter; left time: 11321.1735s
Epoch: 8 cost time: 93.10674357414246
Epoch: 8, Steps: 175 | Train Loss: 0.2723352 Vali Loss: 0.5229283 Test Loss: 0.6094306
Validation loss decreased (0.558460 --> 0.522928).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2418951
	speed: 1.6147s/iter; left time: 11707.9095s
Epoch: 9 cost time: 93.29437565803528
Epoch: 9, Steps: 175 | Train Loss: 0.2437136 Vali Loss: 0.4935367 Test Loss: 0.5755641
Validation loss decreased (0.522928 --> 0.493537).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2250165
	speed: 1.4619s/iter; left time: 10344.7256s
Epoch: 10 cost time: 84.4613790512085
Epoch: 10, Steps: 175 | Train Loss: 0.2202404 Vali Loss: 0.4686766 Test Loss: 0.5480353
Validation loss decreased (0.493537 --> 0.468677).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1970236
	speed: 1.4398s/iter; left time: 9935.8086s
Epoch: 11 cost time: 95.65496230125427
Epoch: 11, Steps: 175 | Train Loss: 0.2009536 Vali Loss: 0.4489940 Test Loss: 0.5257698
Validation loss decreased (0.468677 --> 0.448994).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1851351
	speed: 1.4924s/iter; left time: 10037.7781s
Epoch: 12 cost time: 86.01148533821106
Epoch: 12, Steps: 175 | Train Loss: 0.1850379 Vali Loss: 0.4322309 Test Loss: 0.5074304
Validation loss decreased (0.448994 --> 0.432231).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1699778
	speed: 1.5125s/iter; left time: 9908.0802s
Epoch: 13 cost time: 95.32537913322449
Epoch: 13, Steps: 175 | Train Loss: 0.1719227 Vali Loss: 0.4171827 Test Loss: 0.4908145
Validation loss decreased (0.432231 --> 0.417183).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1651861
	speed: 1.5172s/iter; left time: 9673.3763s
Epoch: 14 cost time: 88.88727402687073
Epoch: 14, Steps: 175 | Train Loss: 0.1610708 Vali Loss: 0.4054772 Test Loss: 0.4784287
Validation loss decreased (0.417183 --> 0.405477).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1503117
	speed: 1.4582s/iter; left time: 9042.0351s
Epoch: 15 cost time: 90.18196129798889
Epoch: 15, Steps: 175 | Train Loss: 0.1521006 Vali Loss: 0.3965745 Test Loss: 0.4685923
Validation loss decreased (0.405477 --> 0.396574).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1436008
	speed: 1.4879s/iter; left time: 8965.9541s
Epoch: 16 cost time: 90.17780208587646
Epoch: 16, Steps: 175 | Train Loss: 0.1447147 Vali Loss: 0.3887321 Test Loss: 0.4602587
Validation loss decreased (0.396574 --> 0.388732).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1356917
	speed: 1.5858s/iter; left time: 9278.6214s
Epoch: 17 cost time: 108.12511873245239
Epoch: 17, Steps: 175 | Train Loss: 0.1385884 Vali Loss: 0.3815617 Test Loss: 0.4529573
Validation loss decreased (0.388732 --> 0.381562).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1376153
	speed: 1.6153s/iter; left time: 9168.2671s
Epoch: 18 cost time: 93.813894033432
Epoch: 18, Steps: 175 | Train Loss: 0.1335817 Vali Loss: 0.3764301 Test Loss: 0.4473223
Validation loss decreased (0.381562 --> 0.376430).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1313476
	speed: 1.5269s/iter; left time: 8399.2529s
Epoch: 19 cost time: 95.71138858795166
Epoch: 19, Steps: 175 | Train Loss: 0.1294324 Vali Loss: 0.3716478 Test Loss: 0.4428921
Validation loss decreased (0.376430 --> 0.371648).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1240987
	speed: 1.4737s/iter; left time: 7849.1358s
Epoch: 20 cost time: 92.77143669128418
Epoch: 20, Steps: 175 | Train Loss: 0.1260119 Vali Loss: 0.3679708 Test Loss: 0.4394106
Validation loss decreased (0.371648 --> 0.367971).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1239158
	speed: 1.5029s/iter; left time: 7741.4979s
Epoch: 21 cost time: 90.56890726089478
Epoch: 21, Steps: 175 | Train Loss: 0.1232429 Vali Loss: 0.3649742 Test Loss: 0.4362875
Validation loss decreased (0.367971 --> 0.364974).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1186437
	speed: 1.4883s/iter; left time: 7405.8695s
Epoch: 22 cost time: 88.06059432029724
Epoch: 22, Steps: 175 | Train Loss: 0.1209581 Vali Loss: 0.3617224 Test Loss: 0.4335384
Validation loss decreased (0.364974 --> 0.361722).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1177948
	speed: 1.4316s/iter; left time: 6872.9989s
Epoch: 23 cost time: 89.45484471321106
Epoch: 23, Steps: 175 | Train Loss: 0.1191067 Vali Loss: 0.3601180 Test Loss: 0.4316836
Validation loss decreased (0.361722 --> 0.360118).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1166065
	speed: 1.5752s/iter; left time: 7286.9519s
Epoch: 24 cost time: 89.55604219436646
Epoch: 24, Steps: 175 | Train Loss: 0.1175869 Vali Loss: 0.3578281 Test Loss: 0.4299036
Validation loss decreased (0.360118 --> 0.357828).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1159884
	speed: 1.2952s/iter; left time: 5765.0135s
Epoch: 25 cost time: 82.63020610809326
Epoch: 25, Steps: 175 | Train Loss: 0.1163648 Vali Loss: 0.3562405 Test Loss: 0.4292841
Validation loss decreased (0.357828 --> 0.356241).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1184594
	speed: 1.4051s/iter; left time: 6008.3525s
Epoch: 26 cost time: 85.98924255371094
Epoch: 26, Steps: 175 | Train Loss: 0.1153648 Vali Loss: 0.3554322 Test Loss: 0.4277601
Validation loss decreased (0.356241 --> 0.355432).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1184373
	speed: 1.3831s/iter; left time: 5671.9409s
Epoch: 27 cost time: 82.77968049049377
Epoch: 27, Steps: 175 | Train Loss: 0.1145833 Vali Loss: 0.3542890 Test Loss: 0.4272728
Validation loss decreased (0.355432 --> 0.354289).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1150970
	speed: 1.4460s/iter; left time: 5677.0903s
Epoch: 28 cost time: 90.65923810005188
Epoch: 28, Steps: 175 | Train Loss: 0.1139384 Vali Loss: 0.3532490 Test Loss: 0.4265622
Validation loss decreased (0.354289 --> 0.353249).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1146048
	speed: 1.3883s/iter; left time: 5207.3938s
Epoch: 29 cost time: 82.03918170928955
Epoch: 29, Steps: 175 | Train Loss: 0.1134423 Vali Loss: 0.3528781 Test Loss: 0.4261141
Validation loss decreased (0.353249 --> 0.352878).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1112122
	speed: 1.3394s/iter; left time: 4789.5482s
Epoch: 30 cost time: 76.70503163337708
Epoch: 30, Steps: 175 | Train Loss: 0.1130229 Vali Loss: 0.3525937 Test Loss: 0.4256859
Validation loss decreased (0.352878 --> 0.352594).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1152660
	speed: 1.3922s/iter; left time: 4734.8230s
Epoch: 31 cost time: 93.42881560325623
Epoch: 31, Steps: 175 | Train Loss: 0.1127009 Vali Loss: 0.3519441 Test Loss: 0.4257608
Validation loss decreased (0.352594 --> 0.351944).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1119614
	speed: 1.5680s/iter; left time: 5058.3558s
Epoch: 32 cost time: 89.3801920413971
Epoch: 32, Steps: 175 | Train Loss: 0.1124438 Vali Loss: 0.3520017 Test Loss: 0.4254702
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1120260
	speed: 1.4073s/iter; left time: 4293.6367s
Epoch: 33 cost time: 85.47317051887512
Epoch: 33, Steps: 175 | Train Loss: 0.1122457 Vali Loss: 0.3514838 Test Loss: 0.4254775
Validation loss decreased (0.351944 --> 0.351484).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1153115
	speed: 1.3925s/iter; left time: 4004.7472s
Epoch: 34 cost time: 85.39390015602112
Epoch: 34, Steps: 175 | Train Loss: 0.1120784 Vali Loss: 0.3506694 Test Loss: 0.4249378
Validation loss decreased (0.351484 --> 0.350669).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1139517
	speed: 1.4783s/iter; left time: 3992.7915s
Epoch: 35 cost time: 99.26546096801758
Epoch: 35, Steps: 175 | Train Loss: 0.1119751 Vali Loss: 0.3509390 Test Loss: 0.4248726
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1131104
	speed: 1.5467s/iter; left time: 3906.9542s
Epoch: 36 cost time: 89.68104481697083
Epoch: 36, Steps: 175 | Train Loss: 0.1118739 Vali Loss: 0.3509095 Test Loss: 0.4251018
EarlyStopping counter: 2 out of 3
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1093696
	speed: 1.4150s/iter; left time: 3326.7239s
Epoch: 37 cost time: 85.54900860786438
Epoch: 37, Steps: 175 | Train Loss: 0.1118083 Vali Loss: 0.3502795 Test Loss: 0.4250500
Validation loss decreased (0.350669 --> 0.350279).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1145471
	speed: 1.4249s/iter; left time: 3100.5274s
Epoch: 38 cost time: 82.91709995269775
Epoch: 38, Steps: 175 | Train Loss: 0.1117479 Vali Loss: 0.3502597 Test Loss: 0.4249593
Validation loss decreased (0.350279 --> 0.350260).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1107513
	speed: 1.5295s/iter; left time: 3060.5105s
Epoch: 39 cost time: 105.66255712509155
Epoch: 39, Steps: 175 | Train Loss: 0.1117016 Vali Loss: 0.3504416 Test Loss: 0.4249585
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1127925
	speed: 1.5486s/iter; left time: 2827.7511s
Epoch: 40 cost time: 85.84493708610535
Epoch: 40, Steps: 175 | Train Loss: 0.1116591 Vali Loss: 0.3504061 Test Loss: 0.4248657
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1114938
	speed: 1.3839s/iter; left time: 2284.8915s
Epoch: 41 cost time: 84.93218064308167
Epoch: 41, Steps: 175 | Train Loss: 0.1116266 Vali Loss: 0.3495747 Test Loss: 0.4249786
Validation loss decreased (0.350260 --> 0.349575).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1145743
	speed: 1.3421s/iter; left time: 1980.9645s
Epoch: 42 cost time: 84.94518041610718
Epoch: 42, Steps: 175 | Train Loss: 0.1116151 Vali Loss: 0.3498605 Test Loss: 0.4249255
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1099520
	speed: 1.3560s/iter; left time: 1764.1451s
Epoch: 43 cost time: 85.88267827033997
Epoch: 43, Steps: 175 | Train Loss: 0.1115810 Vali Loss: 0.3492484 Test Loss: 0.4249302
Validation loss decreased (0.349575 --> 0.349248).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1110535
	speed: 1.5219s/iter; left time: 1713.6381s
Epoch: 44 cost time: 99.69979619979858
Epoch: 44, Steps: 175 | Train Loss: 0.1115921 Vali Loss: 0.3495804 Test Loss: 0.4247870
EarlyStopping counter: 1 out of 3
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1143597
	speed: 1.6533s/iter; left time: 1572.2987s
Epoch: 45 cost time: 92.2172155380249
Epoch: 45, Steps: 175 | Train Loss: 0.1115695 Vali Loss: 0.3497234 Test Loss: 0.4251287
EarlyStopping counter: 2 out of 3
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1124752
	speed: 1.3971s/iter; left time: 1084.1401s
Epoch: 46 cost time: 82.77573561668396
Epoch: 46, Steps: 175 | Train Loss: 0.1115421 Vali Loss: 0.3495835 Test Loss: 0.4249333
EarlyStopping counter: 3 out of 3
Early stopping
train 11225
val 1421
test 3173
Model(
  (freq_upsampler): Linear(in_features=165, out_features=241, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2193755520.0
params:  40006.0
Trainable parameters:  40006
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2572953
	speed: 0.4907s/iter; left time: 4245.3613s
Epoch: 1 cost time: 85.83505654335022
Epoch: 1, Steps: 175 | Train Loss: 0.2549015 Vali Loss: 0.3488382 Test Loss: 0.4242197
Validation loss decreased (inf --> 0.348838).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2473012
	speed: 1.4606s/iter; left time: 12379.8884s
Epoch: 2 cost time: 89.56498456001282
Epoch: 2, Steps: 175 | Train Loss: 0.2544635 Vali Loss: 0.3484601 Test Loss: 0.4236769
Validation loss decreased (0.348838 --> 0.348460).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2468597
	speed: 1.4289s/iter; left time: 11861.1388s
Epoch: 3 cost time: 87.50351572036743
Epoch: 3, Steps: 175 | Train Loss: 0.2543389 Vali Loss: 0.3485777 Test Loss: 0.4242501
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2655160
	speed: 1.4707s/iter; left time: 11951.1809s
Epoch: 4 cost time: 91.03957939147949
Epoch: 4, Steps: 175 | Train Loss: 0.2542551 Vali Loss: 0.3482074 Test Loss: 0.4239860
Validation loss decreased (0.348460 --> 0.348207).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2492310
	speed: 1.4248s/iter; left time: 11328.4388s
Epoch: 5 cost time: 86.47282099723816
Epoch: 5, Steps: 175 | Train Loss: 0.2541917 Vali Loss: 0.3478122 Test Loss: 0.4236985
Validation loss decreased (0.348207 --> 0.347812).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2408773
	speed: 1.4402s/iter; left time: 11198.7794s
Epoch: 6 cost time: 90.7070083618164
Epoch: 6, Steps: 175 | Train Loss: 0.2541489 Vali Loss: 0.3470425 Test Loss: 0.4230837
Validation loss decreased (0.347812 --> 0.347042).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2509153
	speed: 1.5988s/iter; left time: 12152.8238s
Epoch: 7 cost time: 93.5335464477539
Epoch: 7, Steps: 175 | Train Loss: 0.2541286 Vali Loss: 0.3477376 Test Loss: 0.4231878
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2556183
	speed: 1.4368s/iter; left time: 10669.6747s
Epoch: 8 cost time: 88.04732584953308
Epoch: 8, Steps: 175 | Train Loss: 0.2540177 Vali Loss: 0.3476344 Test Loss: 0.4228296
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2554245
	speed: 1.4679s/iter; left time: 10643.9274s
Epoch: 9 cost time: 90.88315010070801
Epoch: 9, Steps: 175 | Train Loss: 0.2539560 Vali Loss: 0.3473522 Test Loss: 0.4231522
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Traffic_720_j336_H5_FITS_custom_ftM_sl720_ll48_pl336_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3173
mse:0.42067739367485046, mae:0.29315492510795593, rse:0.5330572724342346, corr:[0.2818459  0.28943974 0.28930035 0.28839123 0.28766024 0.28717086
 0.28698796 0.28709525 0.287391   0.2877186  0.28795406 0.28806195
 0.28808546 0.28803375 0.28794125 0.2877576  0.28742278 0.28700003
 0.2867014  0.28672776 0.286979   0.28713128 0.28713584 0.2876424
 0.2886906  0.2889442  0.28902498 0.28911325 0.28889677 0.28841397
 0.28802225 0.28788012 0.28790256 0.28787914 0.2876185  0.2873272
 0.28734747 0.2876249  0.28788793 0.2879883  0.28802916 0.28813356
 0.28831574 0.28836447 0.28825963 0.288013   0.28772014 0.28770542
 0.28788894 0.28780568 0.2878512  0.28808525 0.28830898 0.28843376
 0.2884614  0.2883648  0.28813443 0.28790057 0.2877839  0.28778633
 0.28783494 0.28776535 0.28764006 0.28764793 0.2877428  0.28773606
 0.28766888 0.2873439  0.28692988 0.28661543 0.28644097 0.28649276
 0.2866533  0.28697345 0.28739628 0.28753078 0.2872788  0.28691968
 0.28678733 0.2869439  0.2872134  0.28742382 0.2875383  0.28760824
 0.2876717  0.2876365  0.28751463 0.28742394 0.28746307 0.28756016
 0.28755173 0.28723726 0.28684127 0.28667778 0.28679743 0.28701675
 0.28690806 0.28661484 0.28646317 0.28657392 0.28693408 0.28734076
 0.2874939  0.28724402 0.28675342 0.28635958 0.28630716 0.28656825
 0.2869253  0.28713033 0.28712696 0.28707796 0.28714314 0.28731745
 0.28743163 0.28725863 0.28686917 0.2864722  0.28641394 0.2866281
 0.286804   0.28696603 0.28714314 0.2872598  0.28747824 0.2877387
 0.28781417 0.28760958 0.28726754 0.28701583 0.28700233 0.28721812
 0.28751585 0.28778502 0.2880031  0.28812903 0.28808114 0.28777963
 0.28731167 0.28684992 0.28654417 0.2864717  0.28658542 0.28692108
 0.2874563  0.28791237 0.2881654  0.28810808 0.28778878 0.28742272
 0.28724134 0.2873616  0.2876881  0.28802165 0.2881993  0.2881907
 0.2880661  0.28792945 0.28784943 0.2878196  0.2877821  0.28765288
 0.28749606 0.28745535 0.28760853 0.28785846 0.28804556 0.28852898
 0.28948602 0.28961486 0.28928912 0.28880638 0.28812918 0.28751603
 0.28728923 0.28755102 0.28810474 0.28860465 0.2887857  0.2886847
 0.28849286 0.28824094 0.28797668 0.28774908 0.28766748 0.28781742
 0.28807908 0.28831112 0.2882881  0.28787225 0.28726718 0.28711665
 0.28760657 0.2878792  0.2880636  0.28825292 0.28829944 0.288171
 0.2879067  0.28756607 0.287265   0.28713274 0.28715482 0.2872752
 0.28736687 0.28720826 0.28683886 0.28646705 0.28628072 0.2863525
 0.28663182 0.2870333  0.28740916 0.28754935 0.2873236  0.2870451
 0.28702486 0.28706875 0.2870734  0.28690317 0.28659767 0.28646097
 0.2867004  0.2871624  0.28746822 0.28740025 0.28701884 0.2866096
 0.28647214 0.2865877  0.28677738 0.28684324 0.28673857 0.28657034
 0.28647333 0.28648305 0.28656697 0.28640658 0.28607407 0.2859184
 0.28613955 0.28661337 0.2870283  0.28699464 0.28657776 0.2862021
 0.2861287  0.28624696 0.28630808 0.2862324  0.28617534 0.2863426
 0.28674743 0.28710893 0.28716895 0.28694984 0.28673613 0.28679976
 0.28702712 0.28708956 0.28680316 0.28627482 0.2858258  0.28569984
 0.28576458 0.28597406 0.28620553 0.28627524 0.28629336 0.2864071
 0.28657195 0.28668293 0.28664938 0.28641513 0.28602368 0.28563422
 0.28548637 0.28562024 0.28584585 0.2859171  0.2857953  0.2856429
 0.28554404 0.2854261  0.28515214 0.28475288 0.2845114  0.2846632
 0.28521264 0.2860758  0.28677204 0.28686568 0.28655174 0.2863089
 0.2863833  0.28659505 0.28659165 0.28629866 0.28604573 0.2861634
 0.28659388 0.286991   0.28711864 0.28703743 0.28696698 0.28694704
 0.2868339  0.28650177 0.28603688 0.28563613 0.28550443 0.28576052
 0.2862133  0.28644282 0.2864638  0.28644305 0.2866234  0.2870313
 0.28736183 0.28728294 0.28677055 0.28611305 0.28565753 0.28555375
 0.2856907  0.28587452 0.286009   0.28607893 0.28609848 0.28603142
 0.28584138 0.28559119 0.2853715  0.28518483 0.28504154 0.28561592]
