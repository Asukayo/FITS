Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=320, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_720_j336_H10', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : Traffic_720_j336_H10_FITS_custom_ftM_sl720_ll48_pl336_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11225
val 1421
test 3173
Model(
  (freq_upsampler): Linear(in_features=320, out_features=469, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  8279613440.0
params:  150549.0
Trainable parameters:  150549
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.8053761
	speed: 0.4966s/iter; left time: 4296.2916s
Epoch: 1 cost time: 90.27165865898132
Epoch: 1, Steps: 175 | Train Loss: 0.8968366 Vali Loss: 0.9720692 Test Loss: 1.1316390
Validation loss decreased (inf --> 0.972069).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6153559
	speed: 1.5649s/iter; left time: 13264.2462s
Epoch: 2 cost time: 93.42583727836609
Epoch: 2, Steps: 175 | Train Loss: 0.6280201 Vali Loss: 0.8506649 Test Loss: 0.9898760
Validation loss decreased (0.972069 --> 0.850665).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5121892
	speed: 1.5356s/iter; left time: 12746.7103s
Epoch: 3 cost time: 98.64529323577881
Epoch: 3, Steps: 175 | Train Loss: 0.5086469 Vali Loss: 0.7564310 Test Loss: 0.8812737
Validation loss decreased (0.850665 --> 0.756431).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4254766
	speed: 1.6085s/iter; left time: 13070.7456s
Epoch: 4 cost time: 95.44500041007996
Epoch: 4, Steps: 175 | Train Loss: 0.4214588 Vali Loss: 0.6800361 Test Loss: 0.7931119
Validation loss decreased (0.756431 --> 0.680036).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3468071
	speed: 1.5153s/iter; left time: 12048.1188s
Epoch: 5 cost time: 90.47119092941284
Epoch: 5, Steps: 175 | Train Loss: 0.3546650 Vali Loss: 0.6175117 Test Loss: 0.7209202
Validation loss decreased (0.680036 --> 0.617512).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3010429
	speed: 1.4257s/iter; left time: 11086.4533s
Epoch: 6 cost time: 87.91756582260132
Epoch: 6, Steps: 175 | Train Loss: 0.3022691 Vali Loss: 0.5687619 Test Loss: 0.6649753
Validation loss decreased (0.617512 --> 0.568762).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2551738
	speed: 1.5426s/iter; left time: 11725.5953s
Epoch: 7 cost time: 99.57968521118164
Epoch: 7, Steps: 175 | Train Loss: 0.2606535 Vali Loss: 0.5273166 Test Loss: 0.6173910
Validation loss decreased (0.568762 --> 0.527317).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2241418
	speed: 1.6960s/iter; left time: 12594.3033s
Epoch: 8 cost time: 96.7467908859253
Epoch: 8, Steps: 175 | Train Loss: 0.2272620 Vali Loss: 0.4947994 Test Loss: 0.5797612
Validation loss decreased (0.527317 --> 0.494799).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1994520
	speed: 1.5287s/iter; left time: 11084.2975s
Epoch: 9 cost time: 91.62032175064087
Epoch: 9, Steps: 175 | Train Loss: 0.2002713 Vali Loss: 0.4676217 Test Loss: 0.5496202
Validation loss decreased (0.494799 --> 0.467622).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1754524
	speed: 1.5855s/iter; left time: 11218.7475s
Epoch: 10 cost time: 97.53653383255005
Epoch: 10, Steps: 175 | Train Loss: 0.1783797 Vali Loss: 0.4446096 Test Loss: 0.5226995
Validation loss decreased (0.467622 --> 0.444610).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1592519
	speed: 1.5499s/iter; left time: 10696.1112s
Epoch: 11 cost time: 90.24566602706909
Epoch: 11, Steps: 175 | Train Loss: 0.1605578 Vali Loss: 0.4263920 Test Loss: 0.5024311
Validation loss decreased (0.444610 --> 0.426392).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1471508
	speed: 1.5146s/iter; left time: 10186.8959s
Epoch: 12 cost time: 92.25467658042908
Epoch: 12, Steps: 175 | Train Loss: 0.1460379 Vali Loss: 0.4114007 Test Loss: 0.4852900
Validation loss decreased (0.426392 --> 0.411401).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1353063
	speed: 1.6018s/iter; left time: 10493.6591s
Epoch: 13 cost time: 99.67806434631348
Epoch: 13, Steps: 175 | Train Loss: 0.1341483 Vali Loss: 0.3989724 Test Loss: 0.4722421
Validation loss decreased (0.411401 --> 0.398972).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1248674
	speed: 1.5662s/iter; left time: 9986.2030s
Epoch: 14 cost time: 92.32063388824463
Epoch: 14, Steps: 175 | Train Loss: 0.1244553 Vali Loss: 0.3883596 Test Loss: 0.4600085
Validation loss decreased (0.398972 --> 0.388360).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1159554
	speed: 1.4720s/iter; left time: 9127.7950s
Epoch: 15 cost time: 93.44850945472717
Epoch: 15, Steps: 175 | Train Loss: 0.1165293 Vali Loss: 0.3806604 Test Loss: 0.4514852
Validation loss decreased (0.388360 --> 0.380660).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1103108
	speed: 1.6725s/iter; left time: 10078.2912s
Epoch: 16 cost time: 101.3095190525055
Epoch: 16, Steps: 175 | Train Loss: 0.1100631 Vali Loss: 0.3730610 Test Loss: 0.4440344
Validation loss decreased (0.380660 --> 0.373061).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1058060
	speed: 1.5219s/iter; left time: 8904.8040s
Epoch: 17 cost time: 83.50928997993469
Epoch: 17, Steps: 175 | Train Loss: 0.1048020 Vali Loss: 0.3669947 Test Loss: 0.4371937
Validation loss decreased (0.373061 --> 0.366995).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.0998690
	speed: 1.2507s/iter; left time: 7098.8366s
Epoch: 18 cost time: 75.4399802684784
Epoch: 18, Steps: 175 | Train Loss: 0.1005119 Vali Loss: 0.3627657 Test Loss: 0.4327651
Validation loss decreased (0.366995 --> 0.362766).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.0925438
	speed: 1.3467s/iter; left time: 7407.9258s
Epoch: 19 cost time: 80.94337892532349
Epoch: 19, Steps: 175 | Train Loss: 0.0970304 Vali Loss: 0.3584193 Test Loss: 0.4283878
Validation loss decreased (0.362766 --> 0.358419).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.0942530
	speed: 1.4885s/iter; left time: 7927.8911s
Epoch: 20 cost time: 92.58538913726807
Epoch: 20, Steps: 175 | Train Loss: 0.0942151 Vali Loss: 0.3559014 Test Loss: 0.4257776
Validation loss decreased (0.358419 --> 0.355901).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.0939422
	speed: 1.4863s/iter; left time: 7655.9014s
Epoch: 21 cost time: 94.75435161590576
Epoch: 21, Steps: 175 | Train Loss: 0.0919450 Vali Loss: 0.3529660 Test Loss: 0.4232951
Validation loss decreased (0.355901 --> 0.352966).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.0914661
	speed: 1.5046s/iter; left time: 7486.9721s
Epoch: 22 cost time: 90.06449723243713
Epoch: 22, Steps: 175 | Train Loss: 0.0901079 Vali Loss: 0.3510138 Test Loss: 0.4215957
Validation loss decreased (0.352966 --> 0.351014).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.0893570
	speed: 1.5276s/iter; left time: 7334.1185s
Epoch: 23 cost time: 95.11697483062744
Epoch: 23, Steps: 175 | Train Loss: 0.0886305 Vali Loss: 0.3493596 Test Loss: 0.4197888
Validation loss decreased (0.351014 --> 0.349360).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.0883153
	speed: 1.5498s/iter; left time: 7169.3202s
Epoch: 24 cost time: 101.32073783874512
Epoch: 24, Steps: 175 | Train Loss: 0.0874670 Vali Loss: 0.3479847 Test Loss: 0.4186689
Validation loss decreased (0.349360 --> 0.347985).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.0873391
	speed: 1.6014s/iter; left time: 7127.6659s
Epoch: 25 cost time: 88.52813720703125
Epoch: 25, Steps: 175 | Train Loss: 0.0865248 Vali Loss: 0.3466646 Test Loss: 0.4176912
Validation loss decreased (0.347985 --> 0.346665).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.0850493
	speed: 1.4561s/iter; left time: 6226.4700s
Epoch: 26 cost time: 95.93263864517212
Epoch: 26, Steps: 175 | Train Loss: 0.0857755 Vali Loss: 0.3456699 Test Loss: 0.4169268
Validation loss decreased (0.346665 --> 0.345670).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.0820817
	speed: 1.6024s/iter; left time: 6571.5045s
Epoch: 27 cost time: 102.28805994987488
Epoch: 27, Steps: 175 | Train Loss: 0.0852028 Vali Loss: 0.3449434 Test Loss: 0.4165864
Validation loss decreased (0.345670 --> 0.344943).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.0834694
	speed: 1.6996s/iter; left time: 6672.7276s
Epoch: 28 cost time: 106.94926023483276
Epoch: 28, Steps: 175 | Train Loss: 0.0847195 Vali Loss: 0.3440264 Test Loss: 0.4163291
Validation loss decreased (0.344943 --> 0.344026).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.0845289
	speed: 1.6279s/iter; left time: 6106.0932s
Epoch: 29 cost time: 96.45284795761108
Epoch: 29, Steps: 175 | Train Loss: 0.0843633 Vali Loss: 0.3438988 Test Loss: 0.4159466
Validation loss decreased (0.344026 --> 0.343899).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.0905738
	speed: 1.6306s/iter; left time: 5831.1084s
Epoch: 30 cost time: 99.7245945930481
Epoch: 30, Steps: 175 | Train Loss: 0.0840647 Vali Loss: 0.3434905 Test Loss: 0.4155308
Validation loss decreased (0.343899 --> 0.343490).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.0886616
	speed: 1.5900s/iter; left time: 5407.7426s
Epoch: 31 cost time: 100.11022520065308
Epoch: 31, Steps: 175 | Train Loss: 0.0838576 Vali Loss: 0.3427934 Test Loss: 0.4153235
Validation loss decreased (0.343490 --> 0.342793).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.0818752
	speed: 1.6957s/iter; left time: 5470.3688s
Epoch: 32 cost time: 100.47970032691956
Epoch: 32, Steps: 175 | Train Loss: 0.0836625 Vali Loss: 0.3428618 Test Loss: 0.4152182
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.0831715
	speed: 1.6510s/iter; left time: 5037.0772s
Epoch: 33 cost time: 105.37917590141296
Epoch: 33, Steps: 175 | Train Loss: 0.0835444 Vali Loss: 0.3422266 Test Loss: 0.4151833
Validation loss decreased (0.342793 --> 0.342227).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.0841198
	speed: 1.7092s/iter; left time: 4915.6036s
Epoch: 34 cost time: 99.49776816368103
Epoch: 34, Steps: 175 | Train Loss: 0.0834252 Vali Loss: 0.3421675 Test Loss: 0.4152420
Validation loss decreased (0.342227 --> 0.342167).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.0841158
	speed: 1.5444s/iter; left time: 4171.5209s
Epoch: 35 cost time: 101.36455821990967
Epoch: 35, Steps: 175 | Train Loss: 0.0833531 Vali Loss: 0.3425709 Test Loss: 0.4150615
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.0855235
	speed: 1.6044s/iter; left time: 4052.5950s
Epoch: 36 cost time: 95.88867211341858
Epoch: 36, Steps: 175 | Train Loss: 0.0832889 Vali Loss: 0.3421651 Test Loss: 0.4151987
Validation loss decreased (0.342167 --> 0.342165).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.0836544
	speed: 1.5420s/iter; left time: 3625.3458s
Epoch: 37 cost time: 99.3172869682312
Epoch: 37, Steps: 175 | Train Loss: 0.0832311 Vali Loss: 0.3418815 Test Loss: 0.4152306
Validation loss decreased (0.342165 --> 0.341881).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.0872441
	speed: 1.5429s/iter; left time: 3357.4039s
Epoch: 38 cost time: 94.58853077888489
Epoch: 38, Steps: 175 | Train Loss: 0.0831917 Vali Loss: 0.3417454 Test Loss: 0.4151221
Validation loss decreased (0.341881 --> 0.341745).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.0820063
	speed: 1.5830s/iter; left time: 3167.5842s
Epoch: 39 cost time: 99.94433808326721
Epoch: 39, Steps: 175 | Train Loss: 0.0831704 Vali Loss: 0.3416566 Test Loss: 0.4149421
Validation loss decreased (0.341745 --> 0.341657).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.0864582
	speed: 1.6363s/iter; left time: 2987.8657s
Epoch: 40 cost time: 104.26826047897339
Epoch: 40, Steps: 175 | Train Loss: 0.0831232 Vali Loss: 0.3415841 Test Loss: 0.4149078
Validation loss decreased (0.341657 --> 0.341584).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.0847919
	speed: 1.5657s/iter; left time: 2585.0482s
Epoch: 41 cost time: 93.42769479751587
Epoch: 41, Steps: 175 | Train Loss: 0.0831200 Vali Loss: 0.3417008 Test Loss: 0.4150730
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.0784784
	speed: 1.5496s/iter; left time: 2287.1730s
Epoch: 42 cost time: 95.63297319412231
Epoch: 42, Steps: 175 | Train Loss: 0.0831002 Vali Loss: 0.3413558 Test Loss: 0.4148650
Validation loss decreased (0.341584 --> 0.341356).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.0799855
	speed: 1.5850s/iter; left time: 2062.0406s
Epoch: 43 cost time: 99.65787053108215
Epoch: 43, Steps: 175 | Train Loss: 0.0830717 Vali Loss: 0.3416254 Test Loss: 0.4152038
EarlyStopping counter: 1 out of 3
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.0859852
	speed: 1.5625s/iter; left time: 1759.3891s
Epoch: 44 cost time: 96.52197575569153
Epoch: 44, Steps: 175 | Train Loss: 0.0830793 Vali Loss: 0.3413720 Test Loss: 0.4152017
EarlyStopping counter: 2 out of 3
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.0854301
	speed: 1.6352s/iter; left time: 1555.1159s
Epoch: 45 cost time: 95.02505040168762
Epoch: 45, Steps: 175 | Train Loss: 0.0830575 Vali Loss: 0.3416297 Test Loss: 0.4151680
EarlyStopping counter: 3 out of 3
Early stopping
train 11225
val 1421
test 3173
Model(
  (freq_upsampler): Linear(in_features=320, out_features=469, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  8279613440.0
params:  150549.0
Trainable parameters:  150549
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2487566
	speed: 0.5398s/iter; left time: 4670.1218s
Epoch: 1 cost time: 90.9437620639801
Epoch: 1, Steps: 175 | Train Loss: 0.2490304 Vali Loss: 0.3407696 Test Loss: 0.4155716
Validation loss decreased (inf --> 0.340770).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2539051
	speed: 1.4622s/iter; left time: 12393.5491s
Epoch: 2 cost time: 89.94940567016602
Epoch: 2, Steps: 175 | Train Loss: 0.2486992 Vali Loss: 0.3403725 Test Loss: 0.4152922
Validation loss decreased (0.340770 --> 0.340373).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2470017
	speed: 1.4483s/iter; left time: 12022.1865s
Epoch: 3 cost time: 85.72236132621765
Epoch: 3, Steps: 175 | Train Loss: 0.2485062 Vali Loss: 0.3405493 Test Loss: 0.4153793
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2434182
	speed: 1.5188s/iter; left time: 12342.0953s
Epoch: 4 cost time: 94.60534310340881
Epoch: 4, Steps: 175 | Train Loss: 0.2484063 Vali Loss: 0.3403134 Test Loss: 0.4138028
Validation loss decreased (0.340373 --> 0.340313).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2490914
	speed: 1.5000s/iter; left time: 11926.2674s
Epoch: 5 cost time: 86.16681146621704
Epoch: 5, Steps: 175 | Train Loss: 0.2483465 Vali Loss: 0.3403925 Test Loss: 0.4147986
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2448334
	speed: 1.4506s/iter; left time: 11279.8255s
Epoch: 6 cost time: 89.75977754592896
Epoch: 6, Steps: 175 | Train Loss: 0.2483226 Vali Loss: 0.3404483 Test Loss: 0.4138483
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2486329
	speed: 1.4735s/iter; left time: 11200.2414s
Epoch: 7 cost time: 88.33426904678345
Epoch: 7, Steps: 175 | Train Loss: 0.2482448 Vali Loss: 0.3399121 Test Loss: 0.4128774
Validation loss decreased (0.340313 --> 0.339912).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2506883
	speed: 1.6413s/iter; left time: 12188.1523s
Epoch: 8 cost time: 105.95841693878174
Epoch: 8, Steps: 175 | Train Loss: 0.2481341 Vali Loss: 0.3396617 Test Loss: 0.4134602
Validation loss decreased (0.339912 --> 0.339662).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2429650
	speed: 1.5676s/iter; left time: 11366.6821s
Epoch: 9 cost time: 91.57346820831299
Epoch: 9, Steps: 175 | Train Loss: 0.2481382 Vali Loss: 0.3401932 Test Loss: 0.4135128
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2720384
	speed: 1.5099s/iter; left time: 10683.9420s
Epoch: 10 cost time: 95.06390404701233
Epoch: 10, Steps: 175 | Train Loss: 0.2480471 Vali Loss: 0.3397215 Test Loss: 0.4137732
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2474711
	speed: 1.5429s/iter; left time: 10647.5665s
Epoch: 11 cost time: 96.13234210014343
Epoch: 11, Steps: 175 | Train Loss: 0.2480176 Vali Loss: 0.3392906 Test Loss: 0.4131022
Validation loss decreased (0.339662 --> 0.339291).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2346286
	speed: 1.5126s/iter; left time: 10173.9407s
Epoch: 12 cost time: 92.80283904075623
Epoch: 12, Steps: 175 | Train Loss: 0.2479880 Vali Loss: 0.3400240 Test Loss: 0.4140809
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2398720
	speed: 1.4805s/iter; left time: 9698.6211s
Epoch: 13 cost time: 88.22095131874084
Epoch: 13, Steps: 175 | Train Loss: 0.2479391 Vali Loss: 0.3396784 Test Loss: 0.4135955
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2437562
	speed: 1.4603s/iter; left time: 9311.0224s
Epoch: 14 cost time: 95.68890333175659
Epoch: 14, Steps: 175 | Train Loss: 0.2478625 Vali Loss: 0.3398933 Test Loss: 0.4142540
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Traffic_720_j336_H10_FITS_custom_ftM_sl720_ll48_pl336_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3173
mse:0.4106493294239044, mae:0.2793857157230377, rse:0.526665449142456, corr:[0.2683451  0.2838812  0.2855055  0.28475127 0.2844941  0.2839587
 0.28395703 0.28378013 0.2836568  0.28388545 0.28393778 0.28398225
 0.28336662 0.28282553 0.28350326 0.28370282 0.28351018 0.283869
 0.28374636 0.2835812  0.2837363  0.2837086  0.28369528 0.28405175
 0.28473493 0.2841381  0.28408232 0.28387997 0.2835722  0.28391582
 0.284483   0.28419894 0.28369972 0.28364992 0.28390005 0.28458804
 0.28443813 0.28377065 0.28387636 0.2843691  0.28443977 0.2836988
 0.2835597  0.28411764 0.28399414 0.2842688  0.28461283 0.28447783
 0.28506714 0.28489754 0.2848222  0.28514966 0.28489062 0.2846593
 0.28434342 0.2839126  0.28415367 0.2844468  0.2844529  0.28463286
 0.2846322  0.28445718 0.28465056 0.2849145  0.28456017 0.2838159
 0.2837374  0.28378412 0.28359526 0.28362614 0.28368393 0.28391874
 0.28414828 0.28402123 0.2842757  0.28462067 0.28469703 0.28477746
 0.28406346 0.28366286 0.28441975 0.2845247  0.2844283  0.28467178
 0.28429735 0.28408432 0.28436145 0.2844533  0.2842076  0.2838777
 0.2838738  0.2836405  0.28361687 0.28371394 0.2835208  0.28383902
 0.2837083  0.28351507 0.28332245 0.28349277 0.28435928 0.2842247
 0.28364015 0.2833     0.28290597 0.283064   0.28303513 0.28276628
 0.2827041  0.2826856  0.2832993  0.28341702 0.28289926 0.28323147
 0.2831216  0.28257596 0.2829749  0.28304458 0.28301886 0.28367543
 0.28367576 0.282987   0.2828658  0.28354502 0.28397375 0.2837828
 0.28344113 0.28363883 0.28373364 0.28329417 0.2834381  0.2839465
 0.28403336 0.28393695 0.2837224  0.28338793 0.28312942 0.2832939
 0.2833502  0.283188   0.28361768 0.28392926 0.2838474  0.28375578
 0.28384417 0.28404137 0.2843951  0.2850903  0.2849797  0.28412583
 0.28375763 0.28328088 0.28304774 0.28355587 0.28381354 0.2838104
 0.28373274 0.28417796 0.28459567 0.28375906 0.2832276  0.28380352
 0.28435934 0.28450495 0.28449726 0.28447527 0.28427434 0.28424263
 0.28478453 0.28405523 0.28422284 0.28466815 0.28472817 0.2848367
 0.28432354 0.2840891  0.2846544  0.28462392 0.2842807  0.28460214
 0.28502566 0.28502366 0.28480312 0.28466487 0.2844863  0.28418386
 0.2839133  0.28372145 0.28393123 0.284294   0.2841668  0.2840948
 0.2847877  0.28486925 0.28522298 0.2855675  0.28533635 0.28461224
 0.28421485 0.28446838 0.28424126 0.28389254 0.28440684 0.28456393
 0.28392792 0.28361174 0.28408906 0.28434378 0.28352708 0.28309125
 0.283496   0.28386933 0.2838885  0.28368336 0.28384078 0.28404823
 0.28428006 0.28501034 0.28551728 0.28510648 0.28511962 0.28461543
 0.28376082 0.28383777 0.28384948 0.283953   0.28414112 0.2841974
 0.28396845 0.2836452  0.2840778  0.28379613 0.28265792 0.28192016
 0.2816709  0.28226182 0.28296536 0.2831468  0.28355893 0.28366816
 0.28360915 0.28406748 0.28414854 0.2840888  0.2841569  0.28400147
 0.2835457  0.282912   0.2829652  0.28341547 0.2839515  0.28447643
 0.2840002  0.2830781  0.28281346 0.2828488  0.28338057 0.28398722
 0.28352204 0.2832061  0.28320983 0.28279766 0.28297558 0.2832149
 0.282666   0.28276768 0.28325084 0.28363627 0.28425598 0.28410128
 0.28321323 0.2830285  0.2831801  0.28325906 0.28345427 0.2836067
 0.28314498 0.2823169  0.28240854 0.28295127 0.28301665 0.28298846
 0.28262955 0.2822112  0.2820965  0.2815068  0.28158092 0.28274402
 0.2832031  0.28333473 0.2834961  0.2835232  0.283176   0.2825629
 0.2820061  0.28182063 0.28189233 0.28228033 0.28287354 0.2829839
 0.28264567 0.28207588 0.28214473 0.28252628 0.28219774 0.28225356
 0.28255737 0.28217956 0.28187925 0.2820111  0.28197384 0.28228274
 0.2832027  0.2835402  0.28333214 0.2826195  0.28249016 0.28303224
 0.28303978 0.28286576 0.28313887 0.28352168 0.28401932 0.28433415
 0.28340843 0.28223503 0.28237796 0.2832081  0.283036   0.28286964
 0.28307167 0.2823153  0.28195876 0.28316796 0.28367245 0.28285486]
