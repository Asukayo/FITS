Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=165, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_720_j192_H5', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : Traffic_720_j192_H5_FITS_custom_ftM_sl720_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11369
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=165, out_features=209, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1902468480.0
params:  34694.0
Trainable parameters:  34694
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.8999496
	speed: 0.5011s/iter; left time: 4385.0862s
Epoch: 1 cost time: 87.27292370796204
Epoch: 1, Steps: 177 | Train Loss: 0.9651092 Vali Loss: 1.0174904 Test Loss: 1.1682684
Validation loss decreased (inf --> 1.017490).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6643198
	speed: 1.3501s/iter; left time: 11575.8153s
Epoch: 2 cost time: 78.8106529712677
Epoch: 2, Steps: 177 | Train Loss: 0.6838008 Vali Loss: 0.8891252 Test Loss: 1.0201232
Validation loss decreased (1.017490 --> 0.889125).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5563519
	speed: 1.3543s/iter; left time: 11371.6596s
Epoch: 3 cost time: 89.04283809661865
Epoch: 3, Steps: 177 | Train Loss: 0.5585162 Vali Loss: 0.7973266 Test Loss: 0.9152636
Validation loss decreased (0.889125 --> 0.797327).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4568484
	speed: 1.6502s/iter; left time: 13564.9261s
Epoch: 4 cost time: 102.52201294898987
Epoch: 4, Steps: 177 | Train Loss: 0.4675848 Vali Loss: 0.7209923 Test Loss: 0.8283689
Validation loss decreased (0.797327 --> 0.720992).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3945254
	speed: 1.3522s/iter; left time: 10875.7399s
Epoch: 5 cost time: 68.4595079421997
Epoch: 5, Steps: 177 | Train Loss: 0.3968398 Vali Loss: 0.6585264 Test Loss: 0.7579796
Validation loss decreased (0.720992 --> 0.658526).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3325952
	speed: 1.0288s/iter; left time: 8092.1726s
Epoch: 6 cost time: 63.64273500442505
Epoch: 6, Steps: 177 | Train Loss: 0.3404626 Vali Loss: 0.6036291 Test Loss: 0.6948498
Validation loss decreased (0.658526 --> 0.603629).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2927653
	speed: 1.0640s/iter; left time: 8181.0214s
Epoch: 7 cost time: 62.8872230052948
Epoch: 7, Steps: 177 | Train Loss: 0.2949102 Vali Loss: 0.5605945 Test Loss: 0.6469539
Validation loss decreased (0.603629 --> 0.560594).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2556251
	speed: 0.9876s/iter; left time: 7418.8661s
Epoch: 8 cost time: 61.616063833236694
Epoch: 8, Steps: 177 | Train Loss: 0.2578734 Vali Loss: 0.5214950 Test Loss: 0.6022601
Validation loss decreased (0.560594 --> 0.521495).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2290071
	speed: 0.9537s/iter; left time: 6995.0569s
Epoch: 9 cost time: 70.35492444038391
Epoch: 9, Steps: 177 | Train Loss: 0.2275375 Vali Loss: 0.4930831 Test Loss: 0.5708703
Validation loss decreased (0.521495 --> 0.493083).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1967546
	speed: 1.3627s/iter; left time: 9754.2563s
Epoch: 10 cost time: 84.60935068130493
Epoch: 10, Steps: 177 | Train Loss: 0.2026013 Vali Loss: 0.4666078 Test Loss: 0.5420042
Validation loss decreased (0.493083 --> 0.466608).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1789600
	speed: 1.3711s/iter; left time: 9571.4213s
Epoch: 11 cost time: 84.87682366371155
Epoch: 11, Steps: 177 | Train Loss: 0.1821170 Vali Loss: 0.4450428 Test Loss: 0.5187099
Validation loss decreased (0.466608 --> 0.445043).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1630585
	speed: 1.4484s/iter; left time: 9855.1929s
Epoch: 12 cost time: 90.55361485481262
Epoch: 12, Steps: 177 | Train Loss: 0.1652129 Vali Loss: 0.4254478 Test Loss: 0.4971608
Validation loss decreased (0.445043 --> 0.425448).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1516293
	speed: 1.2871s/iter; left time: 8529.8803s
Epoch: 13 cost time: 72.1043598651886
Epoch: 13, Steps: 177 | Train Loss: 0.1512536 Vali Loss: 0.4121237 Test Loss: 0.4825410
Validation loss decreased (0.425448 --> 0.412124).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1430036
	speed: 1.2359s/iter; left time: 7971.7584s
Epoch: 14 cost time: 81.16009426116943
Epoch: 14, Steps: 177 | Train Loss: 0.1397261 Vali Loss: 0.3983919 Test Loss: 0.4680164
Validation loss decreased (0.412124 --> 0.398392).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1332402
	speed: 1.2903s/iter; left time: 8093.9237s
Epoch: 15 cost time: 82.17043161392212
Epoch: 15, Steps: 177 | Train Loss: 0.1301682 Vali Loss: 0.3887751 Test Loss: 0.4578348
Validation loss decreased (0.398392 --> 0.388775).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1200138
	speed: 1.4307s/iter; left time: 8721.5508s
Epoch: 16 cost time: 96.18137454986572
Epoch: 16, Steps: 177 | Train Loss: 0.1223261 Vali Loss: 0.3800159 Test Loss: 0.4489689
Validation loss decreased (0.388775 --> 0.380016).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1131167
	speed: 1.4815s/iter; left time: 8769.2848s
Epoch: 17 cost time: 80.98804831504822
Epoch: 17, Steps: 177 | Train Loss: 0.1158145 Vali Loss: 0.3740078 Test Loss: 0.4423002
Validation loss decreased (0.380016 --> 0.374008).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1146375
	speed: 1.2496s/iter; left time: 7175.2221s
Epoch: 18 cost time: 78.22434163093567
Epoch: 18, Steps: 177 | Train Loss: 0.1104710 Vali Loss: 0.3671425 Test Loss: 0.4354204
Validation loss decreased (0.374008 --> 0.367142).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1082944
	speed: 1.2991s/iter; left time: 7229.2625s
Epoch: 19 cost time: 87.50806641578674
Epoch: 19, Steps: 177 | Train Loss: 0.1060688 Vali Loss: 0.3627414 Test Loss: 0.4308617
Validation loss decreased (0.367142 --> 0.362741).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1039965
	speed: 1.4407s/iter; left time: 7762.4072s
Epoch: 20 cost time: 88.62203764915466
Epoch: 20, Steps: 177 | Train Loss: 0.1024446 Vali Loss: 0.3581324 Test Loss: 0.4268034
Validation loss decreased (0.362741 --> 0.358132).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.0985708
	speed: 1.3195s/iter; left time: 6875.7883s
Epoch: 21 cost time: 79.16384744644165
Epoch: 21, Steps: 177 | Train Loss: 0.0994843 Vali Loss: 0.3552056 Test Loss: 0.4237549
Validation loss decreased (0.358132 --> 0.355206).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.0959600
	speed: 1.3634s/iter; left time: 6863.5892s
Epoch: 22 cost time: 86.29685926437378
Epoch: 22, Steps: 177 | Train Loss: 0.0970504 Vali Loss: 0.3530906 Test Loss: 0.4213525
Validation loss decreased (0.355206 --> 0.353091).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.0958845
	speed: 1.3745s/iter; left time: 6675.8098s
Epoch: 23 cost time: 88.74062824249268
Epoch: 23, Steps: 177 | Train Loss: 0.0950691 Vali Loss: 0.3497303 Test Loss: 0.4193788
Validation loss decreased (0.353091 --> 0.349730).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.0948353
	speed: 1.4000s/iter; left time: 6552.1841s
Epoch: 24 cost time: 84.89298462867737
Epoch: 24, Steps: 177 | Train Loss: 0.0934789 Vali Loss: 0.3475221 Test Loss: 0.4174393
Validation loss decreased (0.349730 --> 0.347522).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.0931565
	speed: 1.3867s/iter; left time: 6244.3272s
Epoch: 25 cost time: 85.2451605796814
Epoch: 25, Steps: 177 | Train Loss: 0.0921418 Vali Loss: 0.3459315 Test Loss: 0.4160559
Validation loss decreased (0.347522 --> 0.345932).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.0913952
	speed: 1.3811s/iter; left time: 5974.4980s
Epoch: 26 cost time: 89.11992526054382
Epoch: 26, Steps: 177 | Train Loss: 0.0911017 Vali Loss: 0.3452483 Test Loss: 0.4151689
Validation loss decreased (0.345932 --> 0.345248).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.0893453
	speed: 1.3765s/iter; left time: 5711.2525s
Epoch: 27 cost time: 84.2609384059906
Epoch: 27, Steps: 177 | Train Loss: 0.0902754 Vali Loss: 0.3443843 Test Loss: 0.4144381
Validation loss decreased (0.345248 --> 0.344384).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.0912255
	speed: 1.3271s/iter; left time: 5271.4283s
Epoch: 28 cost time: 80.90186142921448
Epoch: 28, Steps: 177 | Train Loss: 0.0896004 Vali Loss: 0.3436290 Test Loss: 0.4138246
Validation loss decreased (0.344384 --> 0.343629).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.0904117
	speed: 1.2316s/iter; left time: 4674.0775s
Epoch: 29 cost time: 80.48844289779663
Epoch: 29, Steps: 177 | Train Loss: 0.0890629 Vali Loss: 0.3425452 Test Loss: 0.4132913
Validation loss decreased (0.343629 --> 0.342545).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.0881824
	speed: 1.4120s/iter; left time: 5108.6904s
Epoch: 30 cost time: 92.8408932685852
Epoch: 30, Steps: 177 | Train Loss: 0.0886348 Vali Loss: 0.3419974 Test Loss: 0.4128353
Validation loss decreased (0.342545 --> 0.341997).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.0876976
	speed: 1.5346s/iter; left time: 5280.5563s
Epoch: 31 cost time: 89.08672189712524
Epoch: 31, Steps: 177 | Train Loss: 0.0882962 Vali Loss: 0.3418489 Test Loss: 0.4125241
Validation loss decreased (0.341997 --> 0.341849).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.0887122
	speed: 1.3513s/iter; left time: 4410.6730s
Epoch: 32 cost time: 82.27505207061768
Epoch: 32, Steps: 177 | Train Loss: 0.0880307 Vali Loss: 0.3411763 Test Loss: 0.4123947
Validation loss decreased (0.341849 --> 0.341176).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.0876658
	speed: 1.3511s/iter; left time: 4170.8650s
Epoch: 33 cost time: 88.97869515419006
Epoch: 33, Steps: 177 | Train Loss: 0.0878333 Vali Loss: 0.3415122 Test Loss: 0.4122728
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.0887265
	speed: 1.4439s/iter; left time: 4201.7191s
Epoch: 34 cost time: 86.34615659713745
Epoch: 34, Steps: 177 | Train Loss: 0.0876866 Vali Loss: 0.3407694 Test Loss: 0.4122286
Validation loss decreased (0.341176 --> 0.340769).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.0862363
	speed: 1.3283s/iter; left time: 3630.2372s
Epoch: 35 cost time: 83.74431467056274
Epoch: 35, Steps: 177 | Train Loss: 0.0875396 Vali Loss: 0.3407983 Test Loss: 0.4122154
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.0866166
	speed: 1.3707s/iter; left time: 3503.4423s
Epoch: 36 cost time: 85.24520349502563
Epoch: 36, Steps: 177 | Train Loss: 0.0874521 Vali Loss: 0.3403302 Test Loss: 0.4120637
Validation loss decreased (0.340769 --> 0.340330).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.0883988
	speed: 1.4461s/iter; left time: 3440.3855s
Epoch: 37 cost time: 88.54161381721497
Epoch: 37, Steps: 177 | Train Loss: 0.0873874 Vali Loss: 0.3404766 Test Loss: 0.4122033
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.0884103
	speed: 1.4030s/iter; left time: 3089.3682s
Epoch: 38 cost time: 85.71829175949097
Epoch: 38, Steps: 177 | Train Loss: 0.0873325 Vali Loss: 0.3401904 Test Loss: 0.4119467
Validation loss decreased (0.340330 --> 0.340190).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.0825986
	speed: 1.3646s/iter; left time: 2763.2221s
Epoch: 39 cost time: 82.59248447418213
Epoch: 39, Steps: 177 | Train Loss: 0.0872686 Vali Loss: 0.3408891 Test Loss: 0.4122024
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.0850560
	speed: 1.4842s/iter; left time: 2742.8547s
Epoch: 40 cost time: 92.27631187438965
Epoch: 40, Steps: 177 | Train Loss: 0.0872741 Vali Loss: 0.3398482 Test Loss: 0.4119883
Validation loss decreased (0.340190 --> 0.339848).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.0872208
	speed: 1.4222s/iter; left time: 2376.4709s
Epoch: 41 cost time: 84.6272246837616
Epoch: 41, Steps: 177 | Train Loss: 0.0872430 Vali Loss: 0.3397832 Test Loss: 0.4122693
Validation loss decreased (0.339848 --> 0.339783).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.0855014
	speed: 1.2652s/iter; left time: 1890.2017s
Epoch: 42 cost time: 73.3364474773407
Epoch: 42, Steps: 177 | Train Loss: 0.0872212 Vali Loss: 0.3399173 Test Loss: 0.4119921
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.0873018
	speed: 1.2179s/iter; left time: 1604.0401s
Epoch: 43 cost time: 77.99601674079895
Epoch: 43, Steps: 177 | Train Loss: 0.0872183 Vali Loss: 0.3399751 Test Loss: 0.4119786
EarlyStopping counter: 2 out of 3
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.0867060
	speed: 1.2367s/iter; left time: 1409.8142s
Epoch: 44 cost time: 78.27310347557068
Epoch: 44, Steps: 177 | Train Loss: 0.0871918 Vali Loss: 0.3402128 Test Loss: 0.4122210
EarlyStopping counter: 3 out of 3
Early stopping
train 11369
val 1565
test 3317
Model(
  (freq_upsampler): Linear(in_features=165, out_features=209, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1902468480.0
params:  34694.0
Trainable parameters:  34694
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2351120
	speed: 0.4571s/iter; left time: 4000.0083s
Epoch: 1 cost time: 81.18414878845215
Epoch: 1, Steps: 177 | Train Loss: 0.2455065 Vali Loss: 0.3371992 Test Loss: 0.4103009
Validation loss decreased (inf --> 0.337199).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2440513
	speed: 1.3619s/iter; left time: 11676.6496s
Epoch: 2 cost time: 80.87257194519043
Epoch: 2, Steps: 177 | Train Loss: 0.2448541 Vali Loss: 0.3369517 Test Loss: 0.4098504
Validation loss decreased (0.337199 --> 0.336952).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2368703
	speed: 1.2925s/iter; left time: 10852.7319s
Epoch: 3 cost time: 77.92896628379822
Epoch: 3, Steps: 177 | Train Loss: 0.2446863 Vali Loss: 0.3374600 Test Loss: 0.4097035
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2419369
	speed: 1.3664s/iter; left time: 11231.7220s
Epoch: 4 cost time: 84.6283950805664
Epoch: 4, Steps: 177 | Train Loss: 0.2445610 Vali Loss: 0.3363645 Test Loss: 0.4090816
Validation loss decreased (0.336952 --> 0.336365).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2466107
	speed: 1.3363s/iter; left time: 10747.7143s
Epoch: 5 cost time: 88.84411001205444
Epoch: 5, Steps: 177 | Train Loss: 0.2444880 Vali Loss: 0.3376481 Test Loss: 0.4096125
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2457612
	speed: 1.4533s/iter; left time: 11432.0344s
Epoch: 6 cost time: 80.03029084205627
Epoch: 6, Steps: 177 | Train Loss: 0.2445197 Vali Loss: 0.3361504 Test Loss: 0.4095523
Validation loss decreased (0.336365 --> 0.336150).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2506463
	speed: 1.2339s/iter; left time: 9487.7969s
Epoch: 7 cost time: 79.19299793243408
Epoch: 7, Steps: 177 | Train Loss: 0.2444076 Vali Loss: 0.3358451 Test Loss: 0.4094730
Validation loss decreased (0.336150 --> 0.335845).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2348291
	speed: 1.3971s/iter; left time: 10494.8198s
Epoch: 8 cost time: 88.15476584434509
Epoch: 8, Steps: 177 | Train Loss: 0.2443317 Vali Loss: 0.3362519 Test Loss: 0.4097821
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2342588
	speed: 1.4198s/iter; left time: 10413.9618s
Epoch: 9 cost time: 88.01993656158447
Epoch: 9, Steps: 177 | Train Loss: 0.2442536 Vali Loss: 0.3358357 Test Loss: 0.4099624
Validation loss decreased (0.335845 --> 0.335836).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2473989
	speed: 1.4581s/iter; left time: 10436.9562s
Epoch: 10 cost time: 87.8655264377594
Epoch: 10, Steps: 177 | Train Loss: 0.2442728 Vali Loss: 0.3359818 Test Loss: 0.4092717
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2450915
	speed: 1.3985s/iter; left time: 9763.2185s
Epoch: 11 cost time: 87.781334400177
Epoch: 11, Steps: 177 | Train Loss: 0.2441968 Vali Loss: 0.3359810 Test Loss: 0.4094908
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2548134
	speed: 1.4312s/iter; left time: 9737.6234s
Epoch: 12 cost time: 85.28527116775513
Epoch: 12, Steps: 177 | Train Loss: 0.2441362 Vali Loss: 0.3355345 Test Loss: 0.4088118
Validation loss decreased (0.335836 --> 0.335534).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2491265
	speed: 1.3733s/iter; left time: 9100.8103s
Epoch: 13 cost time: 86.03661441802979
Epoch: 13, Steps: 177 | Train Loss: 0.2441579 Vali Loss: 0.3359583 Test Loss: 0.4092245
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2470199
	speed: 1.4493s/iter; left time: 9348.1656s
Epoch: 14 cost time: 86.48690629005432
Epoch: 14, Steps: 177 | Train Loss: 0.2440264 Vali Loss: 0.3363265 Test Loss: 0.4091630
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2324407
	speed: 1.4143s/iter; left time: 8871.8320s
Epoch: 15 cost time: 87.35795474052429
Epoch: 15, Steps: 177 | Train Loss: 0.2440905 Vali Loss: 0.3355174 Test Loss: 0.4088405
Validation loss decreased (0.335534 --> 0.335517).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2560726
	speed: 1.4532s/iter; left time: 8858.7284s
Epoch: 16 cost time: 90.47957706451416
Epoch: 16, Steps: 177 | Train Loss: 0.2441032 Vali Loss: 0.3361411 Test Loss: 0.4089512
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2384313
	speed: 1.3706s/iter; left time: 8112.6018s
Epoch: 17 cost time: 78.85857224464417
Epoch: 17, Steps: 177 | Train Loss: 0.2441030 Vali Loss: 0.3358854 Test Loss: 0.4091752
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2464192
	speed: 1.3902s/iter; left time: 7982.8097s
Epoch: 18 cost time: 91.66056203842163
Epoch: 18, Steps: 177 | Train Loss: 0.2440266 Vali Loss: 0.3358333 Test Loss: 0.4089743
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Traffic_720_j192_H5_FITS_custom_ftM_sl720_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3317
mse:0.40802791714668274, mae:0.28777816891670227, rse:0.5271982550621033, corr:[0.28577477 0.29381865 0.29404214 0.29412577 0.2943386  0.29414892
 0.29362005 0.29315138 0.29302984 0.2932305  0.2935439  0.29375082
 0.29376763 0.29364267 0.29357293 0.29364115 0.29374218 0.2936988
 0.29347786 0.29324785 0.29313093 0.2930308  0.2929     0.29323447
 0.29395437 0.2937464  0.29345942 0.29348105 0.29345477 0.29320386
 0.29290712 0.2928147  0.2929978  0.29323584 0.293244   0.29303578
 0.29290158 0.2929511  0.2931178  0.29324183 0.2932236  0.2930728
 0.29290462 0.29287606 0.29300168 0.29310402 0.29307738 0.2930891
 0.29298088 0.29239005 0.29182738 0.29158318 0.29169264 0.29204026
 0.29239488 0.2925581  0.29253307 0.29244244 0.29230943 0.2921197
 0.29198673 0.29199034 0.29218167 0.29241237 0.29243872 0.29216424
 0.29176718 0.29160035 0.29180366 0.29212427 0.2921259  0.29172617
 0.29108    0.29077625 0.2910887  0.29161784 0.29195288 0.29192057
 0.29159877 0.29123574 0.291064   0.2910957  0.29117277 0.29122755
 0.29135647 0.29159144 0.29184327 0.29192573 0.29176193 0.29144725
 0.2911547  0.29099125 0.29098183 0.29103366 0.29098368 0.29081967
 0.29049236 0.29034388 0.29053774 0.29084763 0.29107833 0.29119948
 0.29123968 0.2912363  0.29121882 0.2911811  0.2911212  0.2910471
 0.29096657 0.2908847  0.29087794 0.29097366 0.29108313 0.29108855
 0.29090387 0.2906456  0.29052165 0.29053178 0.29066008 0.29072902
 0.2906625  0.29073086 0.29092398 0.2909543  0.29090157 0.29092732
 0.29108623 0.29125604 0.29128253 0.29115367 0.2910198  0.2909939
 0.2910605  0.29119164 0.2914131  0.2917008  0.29189178 0.29179093
 0.2914787  0.29118192 0.29105332 0.29105628 0.2910361  0.29107326
 0.2912998  0.2915447  0.29172474 0.2917453  0.29169136 0.29171908
 0.2918724  0.29207584 0.29219162 0.2921834  0.29216358 0.29231307
 0.2926442  0.29294345 0.29300138 0.2928176  0.2926013  0.2924477
 0.2923346  0.2922463  0.29219714 0.29210898 0.29192272 0.2921272
 0.29279757 0.2927427  0.29269496 0.29284748 0.2928176  0.29256746
 0.2923339  0.292338   0.29260275 0.29303217 0.2934892  0.29389477
 0.29417518 0.29414406 0.29380244 0.29326227 0.29265833 0.2921664
 0.29188618 0.29194048 0.29215813 0.2921035  0.29172605 0.2919795 ]
