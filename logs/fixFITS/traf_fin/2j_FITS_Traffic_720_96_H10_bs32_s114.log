Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=320, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Traffic_720_j96_H10', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : Traffic_720_j96_H10_FITS_custom_ftM_sl720_ll48_pl96_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11465
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=320, out_features=362, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6390661120.0
params:  116202.0
Trainable parameters:  116202
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.8171050
	speed: 0.5374s/iter; left time: 4756.1461s
Epoch: 1 cost time: 99.16235327720642
Epoch: 1, Steps: 179 | Train Loss: 0.8792101 Vali Loss: 0.9837866 Test Loss: 1.1275336
Validation loss decreased (inf --> 0.983787).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6000310
	speed: 1.3331s/iter; left time: 11561.0058s
Epoch: 2 cost time: 70.1918740272522
Epoch: 2, Steps: 179 | Train Loss: 0.6232675 Vali Loss: 0.8669018 Test Loss: 0.9977461
Validation loss decreased (0.983787 --> 0.866902).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4920747
	speed: 1.3537s/iter; left time: 11497.0841s
Epoch: 3 cost time: 90.4785590171814
Epoch: 3, Steps: 179 | Train Loss: 0.4933508 Vali Loss: 0.7739626 Test Loss: 0.8894292
Validation loss decreased (0.866902 --> 0.773963).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3866864
	speed: 1.0627s/iter; left time: 8834.9705s
Epoch: 4 cost time: 59.52662658691406
Epoch: 4, Steps: 179 | Train Loss: 0.3970932 Vali Loss: 0.6887158 Test Loss: 0.7918550
Validation loss decreased (0.773963 --> 0.688716).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3187860
	speed: 0.9521s/iter; left time: 7745.6688s
Epoch: 5 cost time: 59.0328574180603
Epoch: 5, Steps: 179 | Train Loss: 0.3230624 Vali Loss: 0.6216184 Test Loss: 0.7155023
Validation loss decreased (0.688716 --> 0.621618).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2581949
	speed: 0.9654s/iter; left time: 7680.6438s
Epoch: 6 cost time: 63.82481932640076
Epoch: 6, Steps: 179 | Train Loss: 0.2651483 Vali Loss: 0.5710707 Test Loss: 0.6565654
Validation loss decreased (0.621618 --> 0.571071).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2174038
	speed: 1.0745s/iter; left time: 8356.7193s
Epoch: 7 cost time: 65.99682474136353
Epoch: 7, Steps: 179 | Train Loss: 0.2193326 Vali Loss: 0.5270132 Test Loss: 0.6074079
Validation loss decreased (0.571071 --> 0.527013).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1819674
	speed: 0.9887s/iter; left time: 7511.8660s
Epoch: 8 cost time: 57.84833860397339
Epoch: 8, Steps: 179 | Train Loss: 0.1828420 Vali Loss: 0.4909277 Test Loss: 0.5652966
Validation loss decreased (0.527013 --> 0.490928).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1513784
	speed: 0.9949s/iter; left time: 7381.2680s
Epoch: 9 cost time: 62.71986937522888
Epoch: 9, Steps: 179 | Train Loss: 0.1535715 Vali Loss: 0.4598282 Test Loss: 0.5302451
Validation loss decreased (0.490928 --> 0.459828).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1291935
	speed: 1.0344s/iter; left time: 7489.0254s
Epoch: 10 cost time: 69.98548769950867
Epoch: 10, Steps: 179 | Train Loss: 0.1300378 Vali Loss: 0.4341812 Test Loss: 0.5008023
Validation loss decreased (0.459828 --> 0.434181).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1097853
	speed: 1.0749s/iter; left time: 7589.6258s
Epoch: 11 cost time: 66.21321892738342
Epoch: 11, Steps: 179 | Train Loss: 0.1110263 Vali Loss: 0.4155549 Test Loss: 0.4799525
Validation loss decreased (0.434181 --> 0.415555).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.0942026
	speed: 1.0438s/iter; left time: 7183.1279s
Epoch: 12 cost time: 65.51596426963806
Epoch: 12, Steps: 179 | Train Loss: 0.0956774 Vali Loss: 0.3990374 Test Loss: 0.4616012
Validation loss decreased (0.415555 --> 0.399037).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.0835397
	speed: 1.0833s/iter; left time: 7261.5209s
Epoch: 13 cost time: 76.35003066062927
Epoch: 13, Steps: 179 | Train Loss: 0.0832506 Vali Loss: 0.3835524 Test Loss: 0.4457259
Validation loss decreased (0.399037 --> 0.383552).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.0741335
	speed: 1.1771s/iter; left time: 7679.5519s
Epoch: 14 cost time: 69.67199563980103
Epoch: 14, Steps: 179 | Train Loss: 0.0732027 Vali Loss: 0.3744696 Test Loss: 0.4344109
Validation loss decreased (0.383552 --> 0.374470).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.0634979
	speed: 1.2106s/iter; left time: 7681.0031s
Epoch: 15 cost time: 76.89585328102112
Epoch: 15, Steps: 179 | Train Loss: 0.0650792 Vali Loss: 0.3660039 Test Loss: 0.4251671
Validation loss decreased (0.374470 --> 0.366004).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.0586922
	speed: 1.2188s/iter; left time: 7514.9895s
Epoch: 16 cost time: 74.54675960540771
Epoch: 16, Steps: 179 | Train Loss: 0.0585150 Vali Loss: 0.3593827 Test Loss: 0.4180300
Validation loss decreased (0.366004 --> 0.359383).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.0538512
	speed: 1.1223s/iter; left time: 6718.9948s
Epoch: 17 cost time: 62.248695850372314
Epoch: 17, Steps: 179 | Train Loss: 0.0532188 Vali Loss: 0.3531937 Test Loss: 0.4112175
Validation loss decreased (0.359383 --> 0.353194).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.0505570
	speed: 1.0824s/iter; left time: 6286.8648s
Epoch: 18 cost time: 68.50083565711975
Epoch: 18, Steps: 179 | Train Loss: 0.0489726 Vali Loss: 0.3483302 Test Loss: 0.4067911
Validation loss decreased (0.353194 --> 0.348330).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.0435741
	speed: 0.9808s/iter; left time: 5520.8479s
Epoch: 19 cost time: 59.01780724525452
Epoch: 19, Steps: 179 | Train Loss: 0.0455640 Vali Loss: 0.3450869 Test Loss: 0.4032164
Validation loss decreased (0.348330 --> 0.345087).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.0401225
	speed: 0.9218s/iter; left time: 5023.7094s
Epoch: 20 cost time: 54.88751935958862
Epoch: 20, Steps: 179 | Train Loss: 0.0428327 Vali Loss: 0.3415420 Test Loss: 0.4001162
Validation loss decreased (0.345087 --> 0.341542).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.0392589
	speed: 0.9826s/iter; left time: 5179.0502s
Epoch: 21 cost time: 64.26953864097595
Epoch: 21, Steps: 179 | Train Loss: 0.0406720 Vali Loss: 0.3391551 Test Loss: 0.3971095
Validation loss decreased (0.341542 --> 0.339155).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.0387906
	speed: 1.0720s/iter; left time: 5458.5571s
Epoch: 22 cost time: 65.30374693870544
Epoch: 22, Steps: 179 | Train Loss: 0.0389474 Vali Loss: 0.3373859 Test Loss: 0.3957866
Validation loss decreased (0.339155 --> 0.337386).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.0373507
	speed: 1.0119s/iter; left time: 4971.5805s
Epoch: 23 cost time: 61.24564838409424
Epoch: 23, Steps: 179 | Train Loss: 0.0375943 Vali Loss: 0.3360499 Test Loss: 0.3948645
Validation loss decreased (0.337386 --> 0.336050).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.0356360
	speed: 1.0293s/iter; left time: 4872.6538s
Epoch: 24 cost time: 66.21048140525818
Epoch: 24, Steps: 179 | Train Loss: 0.0365353 Vali Loss: 0.3347382 Test Loss: 0.3933814
Validation loss decreased (0.336050 --> 0.334738).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.0346104
	speed: 1.0891s/iter; left time: 4960.6937s
Epoch: 25 cost time: 69.74328136444092
Epoch: 25, Steps: 179 | Train Loss: 0.0357077 Vali Loss: 0.3340435 Test Loss: 0.3929363
Validation loss decreased (0.334738 --> 0.334043).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.0348936
	speed: 1.1241s/iter; left time: 4919.0794s
Epoch: 26 cost time: 65.12169814109802
Epoch: 26, Steps: 179 | Train Loss: 0.0350595 Vali Loss: 0.3326630 Test Loss: 0.3922504
Validation loss decreased (0.334043 --> 0.332663).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.0339971
	speed: 0.9914s/iter; left time: 4160.9686s
Epoch: 27 cost time: 60.38344192504883
Epoch: 27, Steps: 179 | Train Loss: 0.0345655 Vali Loss: 0.3318668 Test Loss: 0.3918321
Validation loss decreased (0.332663 --> 0.331867).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.0373240
	speed: 1.0675s/iter; left time: 4289.1296s
Epoch: 28 cost time: 69.02068614959717
Epoch: 28, Steps: 179 | Train Loss: 0.0341942 Vali Loss: 0.3329963 Test Loss: 0.3917908
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.0323659
	speed: 1.0841s/iter; left time: 4161.9846s
Epoch: 29 cost time: 66.47710490226746
Epoch: 29, Steps: 179 | Train Loss: 0.0339043 Vali Loss: 0.3311853 Test Loss: 0.3914696
Validation loss decreased (0.331867 --> 0.331185).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.0340457
	speed: 1.0418s/iter; left time: 3812.8502s
Epoch: 30 cost time: 61.60981774330139
Epoch: 30, Steps: 179 | Train Loss: 0.0336901 Vali Loss: 0.3312247 Test Loss: 0.3914083
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.0326882
	speed: 1.0440s/iter; left time: 3634.3356s
Epoch: 31 cost time: 59.86052703857422
Epoch: 31, Steps: 179 | Train Loss: 0.0335277 Vali Loss: 0.3313096 Test Loss: 0.3912138
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.0338657
	speed: 0.9679s/iter; left time: 3196.0949s
Epoch: 32 cost time: 60.04528212547302
Epoch: 32, Steps: 179 | Train Loss: 0.0334054 Vali Loss: 0.3315395 Test Loss: 0.3913476
EarlyStopping counter: 3 out of 3
Early stopping
train 11465
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=320, out_features=362, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  6390661120.0
params:  116202.0
Trainable parameters:  116202
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2385579
	speed: 0.3816s/iter; left time: 3377.4703s
Epoch: 1 cost time: 67.98558354377747
Epoch: 1, Steps: 179 | Train Loss: 0.2333254 Vali Loss: 0.3270659 Test Loss: 0.3886881
Validation loss decreased (inf --> 0.327066).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2339080
	speed: 1.1003s/iter; left time: 9542.0699s
Epoch: 2 cost time: 69.31458568572998
Epoch: 2, Steps: 179 | Train Loss: 0.2322601 Vali Loss: 0.3258819 Test Loss: 0.3894067
Validation loss decreased (0.327066 --> 0.325882).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2236201
	speed: 1.2021s/iter; left time: 10209.5536s
Epoch: 3 cost time: 72.88049864768982
Epoch: 3, Steps: 179 | Train Loss: 0.2320413 Vali Loss: 0.3256765 Test Loss: 0.3884183
Validation loss decreased (0.325882 --> 0.325676).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2242280
	speed: 1.1018s/iter; left time: 9160.1051s
Epoch: 4 cost time: 66.88221073150635
Epoch: 4, Steps: 179 | Train Loss: 0.2318244 Vali Loss: 0.3259851 Test Loss: 0.3885904
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2328949
	speed: 1.0872s/iter; left time: 8844.3472s
Epoch: 5 cost time: 67.37231707572937
Epoch: 5, Steps: 179 | Train Loss: 0.2317767 Vali Loss: 0.3245719 Test Loss: 0.3885311
Validation loss decreased (0.325676 --> 0.324572).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2436208
	speed: 1.1380s/iter; left time: 9053.5992s
Epoch: 6 cost time: 69.3236231803894
Epoch: 6, Steps: 179 | Train Loss: 0.2315589 Vali Loss: 0.3245786 Test Loss: 0.3879043
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2210046
	speed: 1.1480s/iter; left time: 8928.2764s
Epoch: 7 cost time: 73.40492820739746
Epoch: 7, Steps: 179 | Train Loss: 0.2315303 Vali Loss: 0.3257384 Test Loss: 0.3884329
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2411595
	speed: 1.2074s/iter; left time: 9173.7309s
Epoch: 8 cost time: 67.87461447715759
Epoch: 8, Steps: 179 | Train Loss: 0.2314449 Vali Loss: 0.3242227 Test Loss: 0.3866673
Validation loss decreased (0.324572 --> 0.324223).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2248707
	speed: 1.1332s/iter; left time: 8407.5165s
Epoch: 9 cost time: 69.16934156417847
Epoch: 9, Steps: 179 | Train Loss: 0.2313900 Vali Loss: 0.3253018 Test Loss: 0.3880390
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2224860
	speed: 1.0349s/iter; left time: 7492.6559s
Epoch: 10 cost time: 63.84691143035889
Epoch: 10, Steps: 179 | Train Loss: 0.2312892 Vali Loss: 0.3248752 Test Loss: 0.3874868
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2304190
	speed: 1.1702s/iter; left time: 8262.9590s
Epoch: 11 cost time: 73.15388035774231
Epoch: 11, Steps: 179 | Train Loss: 0.2312005 Vali Loss: 0.3245528 Test Loss: 0.3876103
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Traffic_720_j96_H10_FITS_custom_ftM_sl720_ll48_pl96_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3413
mse:0.38639968633651733, mae:0.27096933126449585, rse:0.5147209167480469, corr:[0.27574074 0.29221535 0.29351443 0.2933129  0.29271832 0.29226536
 0.29233605 0.2926449  0.29269975 0.2928466  0.29324067 0.2926465
 0.29226798 0.29273856 0.2930003  0.29269013 0.29195687 0.2919254
 0.29230654 0.29189232 0.29195192 0.29283345 0.2921088  0.29071137
 0.29259068 0.29325628 0.29248577 0.2926838  0.29256174 0.29212785
 0.2919647  0.2913245  0.2914042  0.29192513 0.29238966 0.29233116
 0.29158565 0.29183707 0.292461   0.29230762 0.29221076 0.2921171
 0.29198918 0.2918373  0.29202187 0.2931501  0.2929479  0.29202032
 0.2922444  0.29236335 0.29316273 0.29319257 0.292686   0.29272383
 0.2921511  0.29203385 0.29246423 0.29180077 0.29111105 0.29070845
 0.29036447 0.29101384 0.29208878 0.29263857 0.29244137 0.29263598
 0.292824   0.29240146 0.29268396 0.29260015 0.29129362 0.2904368
 0.2911528  0.29260096 0.2929857  0.29252973 0.29217753 0.29222104
 0.29203558 0.29167247 0.2910516  0.29088637 0.29136756 0.29120466
 0.29099306 0.29117787 0.2917577  0.2918492  0.29120576 0.29166433
 0.2916088  0.291508   0.29254943 0.2918184  0.29172948 0.29181445]
