Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=512, c_out=7, checkpoints='./checkpoints/', cut_freq=165, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=7, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:7
>>>>>>>start training : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=165, out_features=187, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  110584320.0
params:  31042.0
Trainable parameters:  31042
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.0061588287353516
Epoch: 1, Steps: 15 | Train Loss: 0.6723849 Vali Loss: 1.5763063 Test Loss: 0.8611291
Validation loss decreased (inf --> 1.576306).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.1272034645080566
Epoch: 2, Steps: 15 | Train Loss: 0.6129278 Vali Loss: 1.4845279 Test Loss: 0.8266234
Validation loss decreased (1.576306 --> 1.484528).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.075752019882202
Epoch: 3, Steps: 15 | Train Loss: 0.5665288 Vali Loss: 1.4058781 Test Loss: 0.7989324
Validation loss decreased (1.484528 --> 1.405878).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.098724842071533
Epoch: 4, Steps: 15 | Train Loss: 0.5311621 Vali Loss: 1.3497084 Test Loss: 0.7790763
Validation loss decreased (1.405878 --> 1.349708).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.043250322341919
Epoch: 5, Steps: 15 | Train Loss: 0.5039528 Vali Loss: 1.3204824 Test Loss: 0.7641711
Validation loss decreased (1.349708 --> 1.320482).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.373246669769287
Epoch: 6, Steps: 15 | Train Loss: 0.4816241 Vali Loss: 1.2989243 Test Loss: 0.7540321
Validation loss decreased (1.320482 --> 1.298924).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.2322001457214355
Epoch: 7, Steps: 15 | Train Loss: 0.4640660 Vali Loss: 1.2746149 Test Loss: 0.7454222
Validation loss decreased (1.298924 --> 1.274615).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.404167890548706
Epoch: 8, Steps: 15 | Train Loss: 0.4495014 Vali Loss: 1.2543440 Test Loss: 0.7402343
Validation loss decreased (1.274615 --> 1.254344).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.1898322105407715
Epoch: 9, Steps: 15 | Train Loss: 0.4366768 Vali Loss: 1.2388309 Test Loss: 0.7355690
Validation loss decreased (1.254344 --> 1.238831).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.2493743896484375
Epoch: 10, Steps: 15 | Train Loss: 0.4264660 Vali Loss: 1.2267346 Test Loss: 0.7324048
Validation loss decreased (1.238831 --> 1.226735).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.006558656692505
Epoch: 11, Steps: 15 | Train Loss: 0.4168221 Vali Loss: 1.2251012 Test Loss: 0.7302994
Validation loss decreased (1.226735 --> 1.225101).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.1649701595306396
Epoch: 12, Steps: 15 | Train Loss: 0.4086978 Vali Loss: 1.2190707 Test Loss: 0.7285080
Validation loss decreased (1.225101 --> 1.219071).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.9761412143707275
Epoch: 13, Steps: 15 | Train Loss: 0.4019366 Vali Loss: 1.2176046 Test Loss: 0.7275297
Validation loss decreased (1.219071 --> 1.217605).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.8962011337280273
Epoch: 14, Steps: 15 | Train Loss: 0.3955041 Vali Loss: 1.2120647 Test Loss: 0.7270219
Validation loss decreased (1.217605 --> 1.212065).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.12807559967041
Epoch: 15, Steps: 15 | Train Loss: 0.3895854 Vali Loss: 1.2054378 Test Loss: 0.7256030
Validation loss decreased (1.212065 --> 1.205438).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.1944189071655273
Epoch: 16, Steps: 15 | Train Loss: 0.3845613 Vali Loss: 1.2092854 Test Loss: 0.7248251
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.9901838302612305
Epoch: 17, Steps: 15 | Train Loss: 0.3799323 Vali Loss: 1.1989347 Test Loss: 0.7236221
Validation loss decreased (1.205438 --> 1.198935).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.228489875793457
Epoch: 18, Steps: 15 | Train Loss: 0.3755317 Vali Loss: 1.1991966 Test Loss: 0.7235873
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 3.4641308784484863
Epoch: 19, Steps: 15 | Train Loss: 0.3720193 Vali Loss: 1.1978582 Test Loss: 0.7235640
Validation loss decreased (1.198935 --> 1.197858).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.318915367126465
Epoch: 20, Steps: 15 | Train Loss: 0.3677679 Vali Loss: 1.1923097 Test Loss: 0.7222982
Validation loss decreased (1.197858 --> 1.192310).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.1919665336608887
Epoch: 21, Steps: 15 | Train Loss: 0.3650465 Vali Loss: 1.1931345 Test Loss: 0.7217639
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.216398239135742
Epoch: 22, Steps: 15 | Train Loss: 0.3614434 Vali Loss: 1.1913155 Test Loss: 0.7219942
Validation loss decreased (1.192310 --> 1.191316).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.9938113689422607
Epoch: 23, Steps: 15 | Train Loss: 0.3589596 Vali Loss: 1.1925330 Test Loss: 0.7213920
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.270263671875
Epoch: 24, Steps: 15 | Train Loss: 0.3560733 Vali Loss: 1.1838609 Test Loss: 0.7212383
Validation loss decreased (1.191316 --> 1.183861).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 3.060573101043701
Epoch: 25, Steps: 15 | Train Loss: 0.3537568 Vali Loss: 1.1815935 Test Loss: 0.7208698
Validation loss decreased (1.183861 --> 1.181594).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.0739212036132812
Epoch: 26, Steps: 15 | Train Loss: 0.3514127 Vali Loss: 1.1795347 Test Loss: 0.7206278
Validation loss decreased (1.181594 --> 1.179535).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 3.15341854095459
Epoch: 27, Steps: 15 | Train Loss: 0.3491473 Vali Loss: 1.1842033 Test Loss: 0.7201049
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.344104766845703
Epoch: 28, Steps: 15 | Train Loss: 0.3468546 Vali Loss: 1.1861913 Test Loss: 0.7197690
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 3.10404109954834
Epoch: 29, Steps: 15 | Train Loss: 0.3451756 Vali Loss: 1.1765704 Test Loss: 0.7194099
Validation loss decreased (1.179535 --> 1.176570).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 3.4020800590515137
Epoch: 30, Steps: 15 | Train Loss: 0.3432031 Vali Loss: 1.1810812 Test Loss: 0.7192050
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 3.2919301986694336
Epoch: 31, Steps: 15 | Train Loss: 0.3414940 Vali Loss: 1.1853119 Test Loss: 0.7185535
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 3.182152509689331
Epoch: 32, Steps: 15 | Train Loss: 0.3401048 Vali Loss: 1.1736561 Test Loss: 0.7185295
Validation loss decreased (1.176570 --> 1.173656).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.3345720767974854
Epoch: 33, Steps: 15 | Train Loss: 0.3387423 Vali Loss: 1.1733847 Test Loss: 0.7181838
Validation loss decreased (1.173656 --> 1.173385).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.2277517318725586
Epoch: 34, Steps: 15 | Train Loss: 0.3371959 Vali Loss: 1.1751287 Test Loss: 0.7175314
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 3.3003878593444824
Epoch: 35, Steps: 15 | Train Loss: 0.3357152 Vali Loss: 1.1750910 Test Loss: 0.7175091
EarlyStopping counter: 2 out of 3
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 3.2434582710266113
Epoch: 36, Steps: 15 | Train Loss: 0.3346196 Vali Loss: 1.1684387 Test Loss: 0.7169703
Validation loss decreased (1.173385 --> 1.168439).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 3.328495979309082
Epoch: 37, Steps: 15 | Train Loss: 0.3333293 Vali Loss: 1.1728009 Test Loss: 0.7167897
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 3.035935640335083
Epoch: 38, Steps: 15 | Train Loss: 0.3321103 Vali Loss: 1.1731377 Test Loss: 0.7165621
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 3.314934253692627
Epoch: 39, Steps: 15 | Train Loss: 0.3311983 Vali Loss: 1.1687460 Test Loss: 0.7160478
EarlyStopping counter: 3 out of 3
Early stopping
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=165, out_features=187, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  110584320.0
params:  31042.0
Trainable parameters:  31042
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.402691602706909
Epoch: 1, Steps: 15 | Train Loss: 0.5060127 Vali Loss: 1.0294206 Test Loss: 0.6146258
Validation loss decreased (inf --> 1.029421).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.6527936458587646
Epoch: 2, Steps: 15 | Train Loss: 0.4531263 Vali Loss: 0.9395916 Test Loss: 0.5422372
Validation loss decreased (1.029421 --> 0.939592).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.3458380699157715
Epoch: 3, Steps: 15 | Train Loss: 0.4175409 Vali Loss: 0.8736842 Test Loss: 0.4926848
Validation loss decreased (0.939592 --> 0.873684).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.6824893951416016
Epoch: 4, Steps: 15 | Train Loss: 0.3935798 Vali Loss: 0.8328819 Test Loss: 0.4589272
Validation loss decreased (0.873684 --> 0.832882).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.6180901527404785
Epoch: 5, Steps: 15 | Train Loss: 0.3772247 Vali Loss: 0.8049728 Test Loss: 0.4360794
Validation loss decreased (0.832882 --> 0.804973).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.293596029281616
Epoch: 6, Steps: 15 | Train Loss: 0.3659637 Vali Loss: 0.7786745 Test Loss: 0.4212500
Validation loss decreased (0.804973 --> 0.778674).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.356916904449463
Epoch: 7, Steps: 15 | Train Loss: 0.3587307 Vali Loss: 0.7677085 Test Loss: 0.4111916
Validation loss decreased (0.778674 --> 0.767708).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.422264814376831
Epoch: 8, Steps: 15 | Train Loss: 0.3537812 Vali Loss: 0.7569194 Test Loss: 0.4043474
Validation loss decreased (0.767708 --> 0.756919).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.398036241531372
Epoch: 9, Steps: 15 | Train Loss: 0.3493943 Vali Loss: 0.7449684 Test Loss: 0.3996622
Validation loss decreased (0.756919 --> 0.744968).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.361281633377075
Epoch: 10, Steps: 15 | Train Loss: 0.3470899 Vali Loss: 0.7409636 Test Loss: 0.3964642
Validation loss decreased (0.744968 --> 0.740964).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.326364278793335
Epoch: 11, Steps: 15 | Train Loss: 0.3447095 Vali Loss: 0.7408339 Test Loss: 0.3945442
Validation loss decreased (0.740964 --> 0.740834).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.420889377593994
Epoch: 12, Steps: 15 | Train Loss: 0.3439259 Vali Loss: 0.7258531 Test Loss: 0.3929052
Validation loss decreased (0.740834 --> 0.725853).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.6835412979125977
Epoch: 13, Steps: 15 | Train Loss: 0.3422846 Vali Loss: 0.7302288 Test Loss: 0.3920051
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.687809944152832
Epoch: 14, Steps: 15 | Train Loss: 0.3419113 Vali Loss: 0.7256490 Test Loss: 0.3910750
Validation loss decreased (0.725853 --> 0.725649).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.592388868331909
Epoch: 15, Steps: 15 | Train Loss: 0.3410449 Vali Loss: 0.7226083 Test Loss: 0.3905209
Validation loss decreased (0.725649 --> 0.722608).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.284883737564087
Epoch: 16, Steps: 15 | Train Loss: 0.3405985 Vali Loss: 0.7262508 Test Loss: 0.3901913
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.446749210357666
Epoch: 17, Steps: 15 | Train Loss: 0.3391438 Vali Loss: 0.7229389 Test Loss: 0.3898242
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.4677083492279053
Epoch: 18, Steps: 15 | Train Loss: 0.3394744 Vali Loss: 0.7195934 Test Loss: 0.3894391
Validation loss decreased (0.722608 --> 0.719593).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 3.2952940464019775
Epoch: 19, Steps: 15 | Train Loss: 0.3382714 Vali Loss: 0.7173919 Test Loss: 0.3891068
Validation loss decreased (0.719593 --> 0.717392).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.3826744556427
Epoch: 20, Steps: 15 | Train Loss: 0.3374595 Vali Loss: 0.7198328 Test Loss: 0.3890332
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.3040871620178223
Epoch: 21, Steps: 15 | Train Loss: 0.3383915 Vali Loss: 0.7186051 Test Loss: 0.3887719
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.0351102352142334
Epoch: 22, Steps: 15 | Train Loss: 0.3374838 Vali Loss: 0.7147081 Test Loss: 0.3887244
Validation loss decreased (0.717392 --> 0.714708).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.8952250480651855
Epoch: 23, Steps: 15 | Train Loss: 0.3365323 Vali Loss: 0.7169495 Test Loss: 0.3885600
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.8395798206329346
Epoch: 24, Steps: 15 | Train Loss: 0.3374508 Vali Loss: 0.7159557 Test Loss: 0.3883760
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.9314961433410645
Epoch: 25, Steps: 15 | Train Loss: 0.3369885 Vali Loss: 0.7189138 Test Loss: 0.3883288
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.3809678554534912, mae:0.40500497817993164, rse:0.5862758159637451, corr:[0.27312148 0.28017414 0.27894923 0.27846724 0.2773981  0.2749264
 0.2727132  0.27229187 0.2724428  0.27258042 0.27220672 0.27150908
 0.27104327 0.27105042 0.2712691  0.271409   0.27113953 0.27075058
 0.2704541  0.27018452 0.26969165 0.26907012 0.26846266 0.2686238
 0.26903513 0.26894113 0.2684821  0.2682478  0.26849207 0.2686407
 0.26825255 0.26728058 0.26663893 0.26675448 0.26698962 0.26697615
 0.26673868 0.2665665  0.26663923 0.26685107 0.26731002 0.26775888
 0.26785558 0.2677277  0.26765892 0.2677331  0.2679194  0.26819882
 0.26807097 0.26778448 0.2671059  0.26609448 0.26483625 0.26332933
 0.26237687 0.262038   0.26179355 0.2614914  0.26098207 0.26099825
 0.26135433 0.26148874 0.26108983 0.26072043 0.26081544 0.26126358
 0.26176894 0.26165906 0.26120403 0.26099756 0.26108304 0.26087943
 0.26019746 0.25913554 0.2578868  0.25756726 0.25775737 0.2574221
 0.25622508 0.2548472  0.25415087 0.25417027 0.2537984  0.25284287
 0.25240624 0.2528418  0.25325835 0.25222805 0.25060037 0.2501242
 0.2503777  0.24890703 0.24536741 0.24274126 0.24400716 0.24124098]
