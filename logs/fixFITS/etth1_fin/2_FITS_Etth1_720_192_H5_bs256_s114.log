Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=512, c_out=7, checkpoints='./checkpoints/', cut_freq=165, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=7, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:7
>>>>>>>start training : ETTh1_720_192_FITS_ETTh1_ftM_sl720_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=165, out_features=209, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  123594240.0
params:  34694.0
Trainable parameters:  34694
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.9323785305023193
Epoch: 1, Steps: 15 | Train Loss: 0.7353246 Vali Loss: 1.8509376 Test Loss: 0.9746478
Validation loss decreased (inf --> 1.850938).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.867638349533081
Epoch: 2, Steps: 15 | Train Loss: 0.6695556 Vali Loss: 1.7394989 Test Loss: 0.9255376
Validation loss decreased (1.850938 --> 1.739499).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.1078362464904785
Epoch: 3, Steps: 15 | Train Loss: 0.6192392 Vali Loss: 1.6464674 Test Loss: 0.8862181
Validation loss decreased (1.739499 --> 1.646467).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.9983367919921875
Epoch: 4, Steps: 15 | Train Loss: 0.5804218 Vali Loss: 1.5902344 Test Loss: 0.8574081
Validation loss decreased (1.646467 --> 1.590234).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.0367283821105957
Epoch: 5, Steps: 15 | Train Loss: 0.5503565 Vali Loss: 1.5448010 Test Loss: 0.8369356
Validation loss decreased (1.590234 --> 1.544801).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.107229471206665
Epoch: 6, Steps: 15 | Train Loss: 0.5266134 Vali Loss: 1.5076401 Test Loss: 0.8208274
Validation loss decreased (1.544801 --> 1.507640).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.0697872638702393
Epoch: 7, Steps: 15 | Train Loss: 0.5071578 Vali Loss: 1.4838701 Test Loss: 0.8079843
Validation loss decreased (1.507640 --> 1.483870).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.9822745323181152
Epoch: 8, Steps: 15 | Train Loss: 0.4911077 Vali Loss: 1.4564736 Test Loss: 0.7991672
Validation loss decreased (1.483870 --> 1.456474).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.419741153717041
Epoch: 9, Steps: 15 | Train Loss: 0.4780212 Vali Loss: 1.4416909 Test Loss: 0.7922127
Validation loss decreased (1.456474 --> 1.441691).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.2358009815216064
Epoch: 10, Steps: 15 | Train Loss: 0.4663994 Vali Loss: 1.4236262 Test Loss: 0.7866666
Validation loss decreased (1.441691 --> 1.423626).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.2062315940856934
Epoch: 11, Steps: 15 | Train Loss: 0.4568245 Vali Loss: 1.4142162 Test Loss: 0.7819359
Validation loss decreased (1.423626 --> 1.414216).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.297956943511963
Epoch: 12, Steps: 15 | Train Loss: 0.4484564 Vali Loss: 1.4001449 Test Loss: 0.7781479
Validation loss decreased (1.414216 --> 1.400145).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.9606056213378906
Epoch: 13, Steps: 15 | Train Loss: 0.4408016 Vali Loss: 1.3883562 Test Loss: 0.7743477
Validation loss decreased (1.400145 --> 1.388356).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.9050791263580322
Epoch: 14, Steps: 15 | Train Loss: 0.4344762 Vali Loss: 1.3837140 Test Loss: 0.7714799
Validation loss decreased (1.388356 --> 1.383714).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.9799435138702393
Epoch: 15, Steps: 15 | Train Loss: 0.4284771 Vali Loss: 1.3800143 Test Loss: 0.7694444
Validation loss decreased (1.383714 --> 1.380014).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.158484935760498
Epoch: 16, Steps: 15 | Train Loss: 0.4229726 Vali Loss: 1.3719800 Test Loss: 0.7679555
Validation loss decreased (1.380014 --> 1.371980).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.881808042526245
Epoch: 17, Steps: 15 | Train Loss: 0.4182416 Vali Loss: 1.3642057 Test Loss: 0.7654166
Validation loss decreased (1.371980 --> 1.364206).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.1748929023742676
Epoch: 18, Steps: 15 | Train Loss: 0.4137961 Vali Loss: 1.3610487 Test Loss: 0.7639220
Validation loss decreased (1.364206 --> 1.361049).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.9744670391082764
Epoch: 19, Steps: 15 | Train Loss: 0.4096438 Vali Loss: 1.3574390 Test Loss: 0.7625613
Validation loss decreased (1.361049 --> 1.357439).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.864539623260498
Epoch: 20, Steps: 15 | Train Loss: 0.4058193 Vali Loss: 1.3542113 Test Loss: 0.7615035
Validation loss decreased (1.357439 --> 1.354211).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.085348606109619
Epoch: 21, Steps: 15 | Train Loss: 0.4025813 Vali Loss: 1.3513503 Test Loss: 0.7602529
Validation loss decreased (1.354211 --> 1.351350).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.319579839706421
Epoch: 22, Steps: 15 | Train Loss: 0.3992468 Vali Loss: 1.3467029 Test Loss: 0.7590825
Validation loss decreased (1.351350 --> 1.346703).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.0204715728759766
Epoch: 23, Steps: 15 | Train Loss: 0.3965243 Vali Loss: 1.3440446 Test Loss: 0.7582479
Validation loss decreased (1.346703 --> 1.344045).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.183845281600952
Epoch: 24, Steps: 15 | Train Loss: 0.3936386 Vali Loss: 1.3374650 Test Loss: 0.7567439
Validation loss decreased (1.344045 --> 1.337465).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 3.169058084487915
Epoch: 25, Steps: 15 | Train Loss: 0.3910712 Vali Loss: 1.3387817 Test Loss: 0.7560906
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.9189817905426025
Epoch: 26, Steps: 15 | Train Loss: 0.3884490 Vali Loss: 1.3363675 Test Loss: 0.7555299
Validation loss decreased (1.337465 --> 1.336367).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.667396306991577
Epoch: 27, Steps: 15 | Train Loss: 0.3863169 Vali Loss: 1.3350531 Test Loss: 0.7547464
Validation loss decreased (1.336367 --> 1.335053).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.9618494510650635
Epoch: 28, Steps: 15 | Train Loss: 0.3840097 Vali Loss: 1.3311932 Test Loss: 0.7536739
Validation loss decreased (1.335053 --> 1.331193).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 3.0397303104400635
Epoch: 29, Steps: 15 | Train Loss: 0.3824040 Vali Loss: 1.3333824 Test Loss: 0.7530127
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.871295690536499
Epoch: 30, Steps: 15 | Train Loss: 0.3805253 Vali Loss: 1.3310292 Test Loss: 0.7522867
Validation loss decreased (1.331193 --> 1.331029).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 3.001070022583008
Epoch: 31, Steps: 15 | Train Loss: 0.3786125 Vali Loss: 1.3314650 Test Loss: 0.7517083
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.8362975120544434
Epoch: 32, Steps: 15 | Train Loss: 0.3769372 Vali Loss: 1.3258777 Test Loss: 0.7513006
Validation loss decreased (1.331029 --> 1.325878).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.9622223377227783
Epoch: 33, Steps: 15 | Train Loss: 0.3753890 Vali Loss: 1.3226998 Test Loss: 0.7506468
Validation loss decreased (1.325878 --> 1.322700).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.059884786605835
Epoch: 34, Steps: 15 | Train Loss: 0.3736067 Vali Loss: 1.3210409 Test Loss: 0.7500065
Validation loss decreased (1.322700 --> 1.321041).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.9940435886383057
Epoch: 35, Steps: 15 | Train Loss: 0.3725187 Vali Loss: 1.3220809 Test Loss: 0.7495775
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 3.1869561672210693
Epoch: 36, Steps: 15 | Train Loss: 0.3711664 Vali Loss: 1.3240782 Test Loss: 0.7487944
EarlyStopping counter: 2 out of 3
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 3.0468788146972656
Epoch: 37, Steps: 15 | Train Loss: 0.3699017 Vali Loss: 1.3243624 Test Loss: 0.7484443
EarlyStopping counter: 3 out of 3
Early stopping
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=165, out_features=209, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  123594240.0
params:  34694.0
Trainable parameters:  34694
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.968325614929199
Epoch: 1, Steps: 15 | Train Loss: 0.5596950 Vali Loss: 1.2400637 Test Loss: 0.6863753
Validation loss decreased (inf --> 1.240064).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.087939500808716
Epoch: 2, Steps: 15 | Train Loss: 0.5236493 Vali Loss: 1.1820160 Test Loss: 0.6382277
Validation loss decreased (1.240064 --> 1.182016).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.9314334392547607
Epoch: 3, Steps: 15 | Train Loss: 0.4974158 Vali Loss: 1.1391269 Test Loss: 0.6004218
Validation loss decreased (1.182016 --> 1.139127).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.9670562744140625
Epoch: 4, Steps: 15 | Train Loss: 0.4773119 Vali Loss: 1.1047131 Test Loss: 0.5701897
Validation loss decreased (1.139127 --> 1.104713).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.2104718685150146
Epoch: 5, Steps: 15 | Train Loss: 0.4615710 Vali Loss: 1.0794430 Test Loss: 0.5454653
Validation loss decreased (1.104713 --> 1.079443).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.325326919555664
Epoch: 6, Steps: 15 | Train Loss: 0.4489164 Vali Loss: 1.0547618 Test Loss: 0.5256345
Validation loss decreased (1.079443 --> 1.054762).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.041736125946045
Epoch: 7, Steps: 15 | Train Loss: 0.4387911 Vali Loss: 1.0361540 Test Loss: 0.5096252
Validation loss decreased (1.054762 --> 1.036154).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.2809817790985107
Epoch: 8, Steps: 15 | Train Loss: 0.4306054 Vali Loss: 1.0250845 Test Loss: 0.4963474
Validation loss decreased (1.036154 --> 1.025084).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.0599863529205322
Epoch: 9, Steps: 15 | Train Loss: 0.4242414 Vali Loss: 1.0137446 Test Loss: 0.4854816
Validation loss decreased (1.025084 --> 1.013745).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.480940103530884
Epoch: 10, Steps: 15 | Train Loss: 0.4187593 Vali Loss: 1.0045216 Test Loss: 0.4766476
Validation loss decreased (1.013745 --> 1.004522).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.2169620990753174
Epoch: 11, Steps: 15 | Train Loss: 0.4141108 Vali Loss: 0.9957901 Test Loss: 0.4692556
Validation loss decreased (1.004522 --> 0.995790).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.1449506282806396
Epoch: 12, Steps: 15 | Train Loss: 0.4101982 Vali Loss: 0.9899355 Test Loss: 0.4631359
Validation loss decreased (0.995790 --> 0.989936).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.0344998836517334
Epoch: 13, Steps: 15 | Train Loss: 0.4066123 Vali Loss: 0.9824125 Test Loss: 0.4581805
Validation loss decreased (0.989936 --> 0.982413).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.3006303310394287
Epoch: 14, Steps: 15 | Train Loss: 0.4039747 Vali Loss: 0.9773337 Test Loss: 0.4539715
Validation loss decreased (0.982413 --> 0.977334).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.049757480621338
Epoch: 15, Steps: 15 | Train Loss: 0.4017822 Vali Loss: 0.9751953 Test Loss: 0.4504012
Validation loss decreased (0.977334 --> 0.975195).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.2263894081115723
Epoch: 16, Steps: 15 | Train Loss: 0.3999176 Vali Loss: 0.9741746 Test Loss: 0.4474267
Validation loss decreased (0.975195 --> 0.974175).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.0253782272338867
Epoch: 17, Steps: 15 | Train Loss: 0.3983647 Vali Loss: 0.9691340 Test Loss: 0.4449226
Validation loss decreased (0.974175 --> 0.969134).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.0980608463287354
Epoch: 18, Steps: 15 | Train Loss: 0.3969933 Vali Loss: 0.9659263 Test Loss: 0.4427251
Validation loss decreased (0.969134 --> 0.965926).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 3.351766586303711
Epoch: 19, Steps: 15 | Train Loss: 0.3954618 Vali Loss: 0.9630680 Test Loss: 0.4410096
Validation loss decreased (0.965926 --> 0.963068).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.132420301437378
Epoch: 20, Steps: 15 | Train Loss: 0.3942471 Vali Loss: 0.9610540 Test Loss: 0.4395421
Validation loss decreased (0.963068 --> 0.961054).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.3416006565093994
Epoch: 21, Steps: 15 | Train Loss: 0.3935865 Vali Loss: 0.9587053 Test Loss: 0.4381867
Validation loss decreased (0.961054 --> 0.958705).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.5406229496002197
Epoch: 22, Steps: 15 | Train Loss: 0.3925662 Vali Loss: 0.9600838 Test Loss: 0.4370146
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.2564449310302734
Epoch: 23, Steps: 15 | Train Loss: 0.3922827 Vali Loss: 0.9624251 Test Loss: 0.4360577
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.337636947631836
Epoch: 24, Steps: 15 | Train Loss: 0.3914283 Vali Loss: 0.9606503 Test Loss: 0.4352520
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh1_720_192_FITS_ETTh1_ftM_sl720_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.4205019176006317, mae:0.4287731647491455, rse:0.6158022880554199, corr:[0.26028043 0.27085158 0.267109   0.26688585 0.2679021  0.26616845
 0.26364866 0.26314178 0.2638094  0.26442534 0.26401615 0.2628627
 0.26181704 0.26137486 0.261468   0.2616093  0.26116014 0.2601811
 0.2593602  0.25916004 0.25906223 0.25845215 0.25756046 0.25748467
 0.25813836 0.25845492 0.25810128 0.25774845 0.25795153 0.25827318
 0.25814152 0.25742212 0.25692713 0.256962   0.2569824  0.25681567
 0.25659811 0.25645608 0.25634822 0.25639984 0.2568367  0.25734785
 0.25738373 0.25707215 0.2569578  0.25733414 0.25790712 0.2582226
 0.25802746 0.25789517 0.25768015 0.2569812  0.25570956 0.25402033
 0.2529535  0.25271535 0.25271085 0.25246647 0.25188515 0.25168228
 0.25194043 0.25210753 0.2517247  0.2512877  0.2513171  0.2519589
 0.25273752 0.25280824 0.25240666 0.25217712 0.25230876 0.25246128
 0.2522305  0.2514899  0.25049952 0.25015262 0.2502501  0.25019002
 0.24967672 0.24889635 0.24836177 0.24828508 0.24819323 0.24779047
 0.24733663 0.24714024 0.24726047 0.24733448 0.24716751 0.24692897
 0.24668458 0.2464306  0.24627413 0.24624003 0.24621765 0.2463291
 0.24684907 0.24769181 0.24833545 0.2485988  0.24837273 0.24774812
 0.24746166 0.2476663  0.247807   0.24752048 0.24697128 0.24666436
 0.24680841 0.24683695 0.24675785 0.24701291 0.24752837 0.24801816
 0.24817722 0.24794917 0.24773733 0.24776773 0.24788696 0.2479363
 0.24779063 0.2471411  0.24594377 0.24484195 0.24420856 0.24361621
 0.24306127 0.2426174  0.24230249 0.24232252 0.24206333 0.24130157
 0.24063253 0.24080306 0.24146625 0.24173589 0.24170916 0.24186976
 0.24237092 0.24255487 0.2421781  0.24163577 0.24130352 0.24100573
 0.24062188 0.23998052 0.2391028  0.23803529 0.23686716 0.23557931
 0.23486072 0.23495391 0.23536664 0.23550043 0.23529251 0.23546949
 0.2358356  0.23556896 0.2347362  0.23437886 0.23493414 0.2355371
 0.23514178 0.23425488 0.23411696 0.2344896  0.23431496 0.23309204
 0.23201193 0.23209919 0.23235153 0.2319761  0.23096304 0.22997987
 0.22937791 0.2292632  0.22926678 0.22957177 0.22935165 0.22847375
 0.22787805 0.22838658 0.22866964 0.22704615 0.22469187 0.22456914
 0.22609288 0.22407521 0.21696043 0.212429   0.21791507 0.2125119 ]
