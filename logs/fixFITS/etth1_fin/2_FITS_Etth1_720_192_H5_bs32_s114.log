Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=165, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=7, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:7
>>>>>>>start training : ETTh1_720_192_FITS_ETTh1_ftM_sl720_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=165, out_features=209, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  15449280.0
params:  34694.0
Trainable parameters:  34694
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5249048
	speed: 0.1439s/iter; left time: 848.8743s
Epoch: 1 cost time: 17.531168460845947
Epoch: 1, Steps: 120 | Train Loss: 0.5922064 Vali Loss: 1.4468725 Test Loss: 0.7433043
Validation loss decreased (inf --> 1.446872).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3777608
	speed: 0.3994s/iter; left time: 2308.8421s
Epoch: 2 cost time: 17.953744888305664
Epoch: 2, Steps: 120 | Train Loss: 0.4307607 Vali Loss: 1.3397936 Test Loss: 0.6989580
Validation loss decreased (1.446872 --> 1.339794).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3317853
	speed: 0.3925s/iter; left time: 2221.6976s
Epoch: 3 cost time: 18.64045763015747
Epoch: 3, Steps: 120 | Train Loss: 0.3635552 Vali Loss: 1.2870077 Test Loss: 0.6730011
Validation loss decreased (1.339794 --> 1.287008).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2953523
	speed: 0.3987s/iter; left time: 2208.9732s
Epoch: 4 cost time: 18.43617606163025
Epoch: 4, Steps: 120 | Train Loss: 0.3192408 Vali Loss: 1.2497410 Test Loss: 0.6518854
Validation loss decreased (1.287008 --> 1.249741).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2646062
	speed: 0.3942s/iter; left time: 2136.8258s
Epoch: 5 cost time: 18.859241724014282
Epoch: 5, Steps: 120 | Train Loss: 0.2849071 Vali Loss: 1.2141817 Test Loss: 0.6291431
Validation loss decreased (1.249741 --> 1.214182).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2530642
	speed: 0.3964s/iter; left time: 2101.1493s
Epoch: 6 cost time: 18.227378129959106
Epoch: 6, Steps: 120 | Train Loss: 0.2579179 Vali Loss: 1.1838615 Test Loss: 0.6084405
Validation loss decreased (1.214182 --> 1.183861).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2221489
	speed: 0.3768s/iter; left time: 1952.2886s
Epoch: 7 cost time: 17.095821619033813
Epoch: 7, Steps: 120 | Train Loss: 0.2358192 Vali Loss: 1.1596901 Test Loss: 0.5914136
Validation loss decreased (1.183861 --> 1.159690).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2097063
	speed: 0.3871s/iter; left time: 1959.1458s
Epoch: 8 cost time: 17.413060903549194
Epoch: 8, Steps: 120 | Train Loss: 0.2175997 Vali Loss: 1.1324387 Test Loss: 0.5704917
Validation loss decreased (1.159690 --> 1.132439).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2119101
	speed: 0.3104s/iter; left time: 1533.8072s
Epoch: 9 cost time: 13.369694471359253
Epoch: 9, Steps: 120 | Train Loss: 0.2022845 Vali Loss: 1.1115042 Test Loss: 0.5550292
Validation loss decreased (1.132439 --> 1.111504).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1840764
	speed: 0.3479s/iter; left time: 1677.1342s
Epoch: 10 cost time: 17.658035039901733
Epoch: 10, Steps: 120 | Train Loss: 0.1892703 Vali Loss: 1.0934287 Test Loss: 0.5406512
Validation loss decreased (1.111504 --> 1.093429).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1622400
	speed: 0.3785s/iter; left time: 1779.3307s
Epoch: 11 cost time: 17.34433650970459
Epoch: 11, Steps: 120 | Train Loss: 0.1784005 Vali Loss: 1.0776554 Test Loss: 0.5285192
Validation loss decreased (1.093429 --> 1.077655).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1580102
	speed: 0.3680s/iter; left time: 1685.6605s
Epoch: 12 cost time: 17.45032525062561
Epoch: 12, Steps: 120 | Train Loss: 0.1692299 Vali Loss: 1.0613793 Test Loss: 0.5163296
Validation loss decreased (1.077655 --> 1.061379).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1638039
	speed: 0.3984s/iter; left time: 1777.2978s
Epoch: 13 cost time: 18.443721532821655
Epoch: 13, Steps: 120 | Train Loss: 0.1613059 Vali Loss: 1.0511957 Test Loss: 0.5076636
Validation loss decreased (1.061379 --> 1.051196).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1519887
	speed: 0.3715s/iter; left time: 1612.8153s
Epoch: 14 cost time: 17.203856706619263
Epoch: 14, Steps: 120 | Train Loss: 0.1543504 Vali Loss: 1.0349509 Test Loss: 0.4947293
Validation loss decreased (1.051196 --> 1.034951).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1511222
	speed: 0.3770s/iter; left time: 1591.2338s
Epoch: 15 cost time: 17.58584189414978
Epoch: 15, Steps: 120 | Train Loss: 0.1485519 Vali Loss: 1.0280559 Test Loss: 0.4886851
Validation loss decreased (1.034951 --> 1.028056).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1458421
	speed: 0.3796s/iter; left time: 1556.6125s
Epoch: 16 cost time: 17.466341257095337
Epoch: 16, Steps: 120 | Train Loss: 0.1434012 Vali Loss: 1.0202403 Test Loss: 0.4825971
Validation loss decreased (1.028056 --> 1.020240).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1482008
	speed: 0.3815s/iter; left time: 1518.7366s
Epoch: 17 cost time: 18.155255794525146
Epoch: 17, Steps: 120 | Train Loss: 0.1388307 Vali Loss: 1.0113741 Test Loss: 0.4747672
Validation loss decreased (1.020240 --> 1.011374).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1353335
	speed: 0.3597s/iter; left time: 1388.7250s
Epoch: 18 cost time: 14.692911863327026
Epoch: 18, Steps: 120 | Train Loss: 0.1350835 Vali Loss: 1.0045234 Test Loss: 0.4692006
Validation loss decreased (1.011374 --> 1.004523).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1342920
	speed: 0.3028s/iter; left time: 1132.8249s
Epoch: 19 cost time: 16.502119779586792
Epoch: 19, Steps: 120 | Train Loss: 0.1315899 Vali Loss: 0.9987616 Test Loss: 0.4642583
Validation loss decreased (1.004523 --> 0.998762).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1343214
	speed: 0.3830s/iter; left time: 1386.9148s
Epoch: 20 cost time: 17.86948037147522
Epoch: 20, Steps: 120 | Train Loss: 0.1286107 Vali Loss: 0.9939734 Test Loss: 0.4596270
Validation loss decreased (0.998762 --> 0.993973).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1271225
	speed: 0.3387s/iter; left time: 1185.6397s
Epoch: 21 cost time: 14.316462993621826
Epoch: 21, Steps: 120 | Train Loss: 0.1258641 Vali Loss: 0.9900103 Test Loss: 0.4560131
Validation loss decreased (0.993973 --> 0.990010).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1140534
	speed: 0.3242s/iter; left time: 1096.1829s
Epoch: 22 cost time: 17.254982233047485
Epoch: 22, Steps: 120 | Train Loss: 0.1235096 Vali Loss: 0.9862517 Test Loss: 0.4525431
Validation loss decreased (0.990010 --> 0.986252).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1188658
	speed: 0.4049s/iter; left time: 1320.4402s
Epoch: 23 cost time: 18.691268920898438
Epoch: 23, Steps: 120 | Train Loss: 0.1214916 Vali Loss: 0.9840344 Test Loss: 0.4496953
Validation loss decreased (0.986252 --> 0.984034).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1148061
	speed: 0.3589s/iter; left time: 1127.2745s
Epoch: 24 cost time: 17.50234293937683
Epoch: 24, Steps: 120 | Train Loss: 0.1196129 Vali Loss: 0.9802001 Test Loss: 0.4464935
Validation loss decreased (0.984034 --> 0.980200).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1160536
	speed: 0.3945s/iter; left time: 1191.7614s
Epoch: 25 cost time: 18.47885251045227
Epoch: 25, Steps: 120 | Train Loss: 0.1178864 Vali Loss: 0.9775521 Test Loss: 0.4438251
Validation loss decreased (0.980200 --> 0.977552).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1163565
	speed: 0.3931s/iter; left time: 1140.4022s
Epoch: 26 cost time: 18.138431310653687
Epoch: 26, Steps: 120 | Train Loss: 0.1164642 Vali Loss: 0.9752433 Test Loss: 0.4414549
Validation loss decreased (0.977552 --> 0.975243).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1225920
	speed: 0.3863s/iter; left time: 1074.3011s
Epoch: 27 cost time: 17.767338037490845
Epoch: 27, Steps: 120 | Train Loss: 0.1151556 Vali Loss: 0.9736191 Test Loss: 0.4395548
Validation loss decreased (0.975243 --> 0.973619).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1307522
	speed: 0.3648s/iter; left time: 970.6826s
Epoch: 28 cost time: 15.748047351837158
Epoch: 28, Steps: 120 | Train Loss: 0.1139209 Vali Loss: 0.9727740 Test Loss: 0.4382727
Validation loss decreased (0.973619 --> 0.972774).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1076140
	speed: 0.2821s/iter; left time: 716.7004s
Epoch: 29 cost time: 15.14687466621399
Epoch: 29, Steps: 120 | Train Loss: 0.1127578 Vali Loss: 0.9711722 Test Loss: 0.4364303
Validation loss decreased (0.972774 --> 0.971172).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1064965
	speed: 0.3621s/iter; left time: 876.5844s
Epoch: 30 cost time: 16.998103857040405
Epoch: 30, Steps: 120 | Train Loss: 0.1118394 Vali Loss: 0.9688643 Test Loss: 0.4346903
Validation loss decreased (0.971172 --> 0.968864).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1179218
	speed: 0.3688s/iter; left time: 848.6678s
Epoch: 31 cost time: 17.151683568954468
Epoch: 31, Steps: 120 | Train Loss: 0.1109457 Vali Loss: 0.9688169 Test Loss: 0.4335452
Validation loss decreased (0.968864 --> 0.968817).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1127861
	speed: 0.3418s/iter; left time: 745.3797s
Epoch: 32 cost time: 16.314746856689453
Epoch: 32, Steps: 120 | Train Loss: 0.1102126 Vali Loss: 0.9680790 Test Loss: 0.4325765
Validation loss decreased (0.968817 --> 0.968079).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1045720
	speed: 0.3696s/iter; left time: 761.7674s
Epoch: 33 cost time: 17.939789533615112
Epoch: 33, Steps: 120 | Train Loss: 0.1094863 Vali Loss: 0.9669675 Test Loss: 0.4314002
Validation loss decreased (0.968079 --> 0.966968).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1154154
	speed: 0.3679s/iter; left time: 714.1754s
Epoch: 34 cost time: 16.946165561676025
Epoch: 34, Steps: 120 | Train Loss: 0.1088209 Vali Loss: 0.9672094 Test Loss: 0.4310131
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1057594
	speed: 0.3592s/iter; left time: 654.1619s
Epoch: 35 cost time: 16.883163928985596
Epoch: 35, Steps: 120 | Train Loss: 0.1082213 Vali Loss: 0.9659244 Test Loss: 0.4297025
Validation loss decreased (0.966968 --> 0.965924).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1089225
	speed: 0.3623s/iter; left time: 616.2866s
Epoch: 36 cost time: 15.976763010025024
Epoch: 36, Steps: 120 | Train Loss: 0.1076938 Vali Loss: 0.9656844 Test Loss: 0.4291589
Validation loss decreased (0.965924 --> 0.965684).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1081308
	speed: 0.2914s/iter; left time: 460.7359s
Epoch: 37 cost time: 13.46216368675232
Epoch: 37, Steps: 120 | Train Loss: 0.1071922 Vali Loss: 0.9651767 Test Loss: 0.4282982
Validation loss decreased (0.965684 --> 0.965177).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1039610
	speed: 0.3370s/iter; left time: 492.3677s
Epoch: 38 cost time: 17.954673290252686
Epoch: 38, Steps: 120 | Train Loss: 0.1067836 Vali Loss: 0.9648951 Test Loss: 0.4277484
Validation loss decreased (0.965177 --> 0.964895).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1093901
	speed: 0.3575s/iter; left time: 479.3522s
Epoch: 39 cost time: 14.746708631515503
Epoch: 39, Steps: 120 | Train Loss: 0.1063749 Vali Loss: 0.9650224 Test Loss: 0.4271221
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.0981566
	speed: 0.2772s/iter; left time: 338.5020s
Epoch: 40 cost time: 13.57187271118164
Epoch: 40, Steps: 120 | Train Loss: 0.1059943 Vali Loss: 0.9649375 Test Loss: 0.4264907
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1172874
	speed: 0.3207s/iter; left time: 353.0638s
Epoch: 41 cost time: 15.244102954864502
Epoch: 41, Steps: 120 | Train Loss: 0.1056263 Vali Loss: 0.9641910 Test Loss: 0.4261920
Validation loss decreased (0.964895 --> 0.964191).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1080846
	speed: 0.3567s/iter; left time: 349.9202s
Epoch: 42 cost time: 16.464726209640503
Epoch: 42, Steps: 120 | Train Loss: 0.1053594 Vali Loss: 0.9635785 Test Loss: 0.4257028
Validation loss decreased (0.964191 --> 0.963578).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.0980959
	speed: 0.3725s/iter; left time: 320.7602s
Epoch: 43 cost time: 17.48659586906433
Epoch: 43, Steps: 120 | Train Loss: 0.1050287 Vali Loss: 0.9634226 Test Loss: 0.4251482
Validation loss decreased (0.963578 --> 0.963423).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1041126
	speed: 0.3775s/iter; left time: 279.7467s
Epoch: 44 cost time: 17.502658128738403
Epoch: 44, Steps: 120 | Train Loss: 0.1047425 Vali Loss: 0.9640871 Test Loss: 0.4249417
EarlyStopping counter: 1 out of 3
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.0962082
	speed: 0.3720s/iter; left time: 231.0257s
Epoch: 45 cost time: 17.65412187576294
Epoch: 45, Steps: 120 | Train Loss: 0.1044831 Vali Loss: 0.9640120 Test Loss: 0.4244458
EarlyStopping counter: 2 out of 3
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1067595
	speed: 0.3854s/iter; left time: 193.0917s
Epoch: 46 cost time: 18.208351373672485
Epoch: 46, Steps: 120 | Train Loss: 0.1043196 Vali Loss: 0.9636836 Test Loss: 0.4241753
EarlyStopping counter: 3 out of 3
Early stopping
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=165, out_features=209, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  15449280.0
params:  34694.0
Trainable parameters:  34694
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4230431
	speed: 0.1450s/iter; left time: 855.5932s
Epoch: 1 cost time: 17.48074460029602
Epoch: 1, Steps: 120 | Train Loss: 0.3848414 Vali Loss: 0.9577293 Test Loss: 0.4188667
Validation loss decreased (inf --> 0.957729).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3701907
	speed: 0.3931s/iter; left time: 2272.5313s
Epoch: 2 cost time: 18.213046073913574
Epoch: 2, Steps: 120 | Train Loss: 0.3823756 Vali Loss: 0.9651061 Test Loss: 0.4196463
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3870420
	speed: 0.3047s/iter; left time: 1725.1653s
Epoch: 3 cost time: 14.45555067062378
Epoch: 3, Steps: 120 | Train Loss: 0.3813408 Vali Loss: 0.9648048 Test Loss: 0.4199654
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4149030
	speed: 0.3894s/iter; left time: 2157.4194s
Epoch: 4 cost time: 18.286023139953613
Epoch: 4, Steps: 120 | Train Loss: 0.3808118 Vali Loss: 0.9620433 Test Loss: 0.4191616
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh1_720_192_FITS_ETTh1_ftM_sl720_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.41703835129737854, mae:0.4255138337612152, rse:0.6132609844207764, corr:[0.2681014  0.27298    0.2723358  0.2698835  0.2681718  0.2667843
 0.26554564 0.26457524 0.26409557 0.26424518 0.2643453  0.26377133
 0.2633331  0.2633303  0.2636463  0.26368046 0.26332304 0.26296023
 0.26257432 0.2621374  0.26160005 0.26106197 0.26061642 0.2604529
 0.26050857 0.26065212 0.2607316  0.2606303  0.260359   0.26004216
 0.25987145 0.25983876 0.2599224  0.2599994  0.2599789  0.26009858
 0.26029846 0.26035744 0.26016146 0.25992024 0.26004812 0.26040846
 0.26066068 0.26059768 0.26035076 0.26016828 0.26032427 0.26060167
 0.26027754 0.25947386 0.2586456  0.2580016  0.25724703 0.2560871
 0.25501868 0.25448474 0.25427705 0.25394124 0.25307545 0.25241032
 0.252516   0.25313288 0.25327113 0.25275114 0.25213796 0.2521176
 0.25247973 0.25236058 0.25204846 0.25212535 0.25244305 0.25214764
 0.251218   0.25014848 0.24948211 0.24939157 0.24925081 0.24886386
 0.24868661 0.24876279 0.24844894 0.24757054 0.24655029 0.24623334
 0.24686967 0.24762456 0.24774471 0.24704179 0.24599165 0.24538854
 0.24560216 0.24644718 0.24720132 0.24715376 0.24646266 0.24613765
 0.24679978 0.24775104 0.24794145 0.24753086 0.24717966 0.24695617
 0.24677663 0.24657573 0.24632373 0.24605495 0.24552676 0.24507253
 0.24531798 0.24603131 0.2465692  0.24670637 0.24663158 0.24678381
 0.24692108 0.24646837 0.24571633 0.24539979 0.24568197 0.24591045
 0.24576463 0.24511498 0.24431308 0.2437012  0.24311937 0.24238023
 0.24181123 0.24139936 0.24069482 0.23992437 0.23920564 0.23860897
 0.2381934  0.2382372  0.23867345 0.23893727 0.23887302 0.23884286
 0.23951122 0.2403331  0.2400883  0.23844509 0.23661235 0.23623262
 0.23712146 0.23726958 0.23601902 0.23457828 0.23430374 0.23415051
 0.23318955 0.23224744 0.2325866  0.23369664 0.23372944 0.2328104
 0.23243907 0.23308147 0.2330811  0.23161998 0.22993891 0.22973569
 0.23048176 0.23043466 0.22956201 0.22903351 0.2294597  0.22983702
 0.22974227 0.22968861 0.22978589 0.22955015 0.2285596  0.22732572
 0.2265512  0.22629243 0.22573996 0.22550406 0.2255914  0.22535157
 0.22447988 0.22398883 0.22441524 0.22455579 0.22367886 0.22312574
 0.22414564 0.22468466 0.22250096 0.21992594 0.22117603 0.22063024]
