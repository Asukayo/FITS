Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=7, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:7
>>>>>>>start training : ETTh1_720_192_FITS_ETTh1_ftM_sl720_ll48_pl192_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=134, out_features=169, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  10145408.0
params:  22815.0
Trainable parameters:  22815
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4834117
	speed: 0.1436s/iter; left time: 847.6353s
Epoch: 1 cost time: 16.958396196365356
Epoch: 1, Steps: 120 | Train Loss: 0.5790482 Vali Loss: 1.4341360 Test Loss: 0.7414729
Validation loss decreased (inf --> 1.434136).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3541531
	speed: 0.3934s/iter; left time: 2274.1400s
Epoch: 2 cost time: 18.520273208618164
Epoch: 2, Steps: 120 | Train Loss: 0.4194558 Vali Loss: 1.3080477 Test Loss: 0.6804176
Validation loss decreased (1.434136 --> 1.308048).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3480071
	speed: 0.3985s/iter; left time: 2256.1079s
Epoch: 3 cost time: 18.186610460281372
Epoch: 3, Steps: 120 | Train Loss: 0.3533313 Vali Loss: 1.2602569 Test Loss: 0.6576231
Validation loss decreased (1.308048 --> 1.260257).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3142540
	speed: 0.3967s/iter; left time: 2198.1289s
Epoch: 4 cost time: 18.72409152984619
Epoch: 4, Steps: 120 | Train Loss: 0.3104164 Vali Loss: 1.2249308 Test Loss: 0.6375697
Validation loss decreased (1.260257 --> 1.224931).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2797922
	speed: 0.4064s/iter; left time: 2203.1342s
Epoch: 5 cost time: 20.15565824508667
Epoch: 5, Steps: 120 | Train Loss: 0.2779644 Vali Loss: 1.1923409 Test Loss: 0.6163733
Validation loss decreased (1.224931 --> 1.192341).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2557671
	speed: 0.3674s/iter; left time: 1947.8351s
Epoch: 6 cost time: 15.858444452285767
Epoch: 6, Steps: 120 | Train Loss: 0.2521259 Vali Loss: 1.1641273 Test Loss: 0.5962843
Validation loss decreased (1.192341 --> 1.164127).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2236426
	speed: 0.2888s/iter; left time: 1496.2722s
Epoch: 7 cost time: 13.61475133895874
Epoch: 7, Steps: 120 | Train Loss: 0.2310572 Vali Loss: 1.1393092 Test Loss: 0.5781544
Validation loss decreased (1.164127 --> 1.139309).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2045145
	speed: 0.3180s/iter; left time: 1609.3858s
Epoch: 8 cost time: 14.651089906692505
Epoch: 8, Steps: 120 | Train Loss: 0.2137245 Vali Loss: 1.1198092 Test Loss: 0.5627380
Validation loss decreased (1.139309 --> 1.119809).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1896942
	speed: 0.2901s/iter; left time: 1433.2098s
Epoch: 9 cost time: 12.814638614654541
Epoch: 9, Steps: 120 | Train Loss: 0.1992067 Vali Loss: 1.0962195 Test Loss: 0.5449417
Validation loss decreased (1.119809 --> 1.096220).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1886948
	speed: 0.2582s/iter; left time: 1244.5556s
Epoch: 10 cost time: 12.094363927841187
Epoch: 10, Steps: 120 | Train Loss: 0.1872524 Vali Loss: 1.0790985 Test Loss: 0.5308980
Validation loss decreased (1.096220 --> 1.079098).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1755723
	speed: 0.2629s/iter; left time: 1235.7485s
Epoch: 11 cost time: 13.74237585067749
Epoch: 11, Steps: 120 | Train Loss: 0.1770686 Vali Loss: 1.0653287 Test Loss: 0.5202563
Validation loss decreased (1.079098 --> 1.065329).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1697530
	speed: 0.3287s/iter; left time: 1505.7384s
Epoch: 12 cost time: 14.348113298416138
Epoch: 12, Steps: 120 | Train Loss: 0.1683610 Vali Loss: 1.0504755 Test Loss: 0.5078751
Validation loss decreased (1.065329 --> 1.050475).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1631684
	speed: 0.2922s/iter; left time: 1303.4322s
Epoch: 13 cost time: 12.881973505020142
Epoch: 13, Steps: 120 | Train Loss: 0.1609696 Vali Loss: 1.0400358 Test Loss: 0.4996209
Validation loss decreased (1.050475 --> 1.040036).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1549953
	speed: 0.2516s/iter; left time: 1092.0297s
Epoch: 14 cost time: 11.03539776802063
Epoch: 14, Steps: 120 | Train Loss: 0.1547565 Vali Loss: 1.0305558 Test Loss: 0.4911132
Validation loss decreased (1.040036 --> 1.030556).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1363616
	speed: 0.2930s/iter; left time: 1236.7723s
Epoch: 15 cost time: 15.618721961975098
Epoch: 15, Steps: 120 | Train Loss: 0.1492681 Vali Loss: 1.0192206 Test Loss: 0.4821582
Validation loss decreased (1.030556 --> 1.019221).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1272918
	speed: 0.3369s/iter; left time: 1381.6309s
Epoch: 16 cost time: 15.800625562667847
Epoch: 16, Steps: 120 | Train Loss: 0.1446420 Vali Loss: 1.0134996 Test Loss: 0.4764804
Validation loss decreased (1.019221 --> 1.013500).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1248644
	speed: 0.3595s/iter; left time: 1431.0516s
Epoch: 17 cost time: 17.36672592163086
Epoch: 17, Steps: 120 | Train Loss: 0.1404534 Vali Loss: 1.0071840 Test Loss: 0.4706484
Validation loss decreased (1.013500 --> 1.007184).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1305715
	speed: 0.3810s/iter; left time: 1471.0384s
Epoch: 18 cost time: 17.74680209159851
Epoch: 18, Steps: 120 | Train Loss: 0.1370572 Vali Loss: 1.0001879 Test Loss: 0.4647332
Validation loss decreased (1.007184 --> 1.000188).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1428954
	speed: 0.3563s/iter; left time: 1333.0063s
Epoch: 19 cost time: 14.651427507400513
Epoch: 19, Steps: 120 | Train Loss: 0.1339535 Vali Loss: 0.9955285 Test Loss: 0.4598874
Validation loss decreased (1.000188 --> 0.995529).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1339688
	speed: 0.2444s/iter; left time: 884.8305s
Epoch: 20 cost time: 11.94727373123169
Epoch: 20, Steps: 120 | Train Loss: 0.1311603 Vali Loss: 0.9918371 Test Loss: 0.4559962
Validation loss decreased (0.995529 --> 0.991837).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1197092
	speed: 0.2836s/iter; left time: 992.8087s
Epoch: 21 cost time: 11.631169557571411
Epoch: 21, Steps: 120 | Train Loss: 0.1288503 Vali Loss: 0.9884814 Test Loss: 0.4526040
Validation loss decreased (0.991837 --> 0.988481).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1234754
	speed: 0.2921s/iter; left time: 987.7160s
Epoch: 22 cost time: 15.069448232650757
Epoch: 22, Steps: 120 | Train Loss: 0.1267272 Vali Loss: 0.9857717 Test Loss: 0.4499995
Validation loss decreased (0.988481 --> 0.985772).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1230774
	speed: 0.3143s/iter; left time: 1024.9289s
Epoch: 23 cost time: 14.858386754989624
Epoch: 23, Steps: 120 | Train Loss: 0.1249701 Vali Loss: 0.9829664 Test Loss: 0.4471091
Validation loss decreased (0.985772 --> 0.982966).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1271101
	speed: 0.3197s/iter; left time: 1004.2776s
Epoch: 24 cost time: 14.89253044128418
Epoch: 24, Steps: 120 | Train Loss: 0.1233068 Vali Loss: 0.9800776 Test Loss: 0.4443460
Validation loss decreased (0.982966 --> 0.980078).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1164563
	speed: 0.3207s/iter; left time: 968.8360s
Epoch: 25 cost time: 15.243749618530273
Epoch: 25, Steps: 120 | Train Loss: 0.1218463 Vali Loss: 0.9786074 Test Loss: 0.4424466
Validation loss decreased (0.980078 --> 0.978607).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1319273
	speed: 0.3314s/iter; left time: 961.2677s
Epoch: 26 cost time: 15.145867586135864
Epoch: 26, Steps: 120 | Train Loss: 0.1205391 Vali Loss: 0.9769992 Test Loss: 0.4408935
Validation loss decreased (0.978607 --> 0.976999).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1324116
	speed: 0.3273s/iter; left time: 910.1076s
Epoch: 27 cost time: 15.285848617553711
Epoch: 27, Steps: 120 | Train Loss: 0.1194326 Vali Loss: 0.9751466 Test Loss: 0.4384815
Validation loss decreased (0.976999 --> 0.975147).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1213904
	speed: 0.3492s/iter; left time: 929.0951s
Epoch: 28 cost time: 16.812244653701782
Epoch: 28, Steps: 120 | Train Loss: 0.1184636 Vali Loss: 0.9736236 Test Loss: 0.4373378
Validation loss decreased (0.975147 --> 0.973624).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1182416
	speed: 0.3594s/iter; left time: 913.2222s
Epoch: 29 cost time: 17.195500135421753
Epoch: 29, Steps: 120 | Train Loss: 0.1174975 Vali Loss: 0.9723565 Test Loss: 0.4357036
Validation loss decreased (0.973624 --> 0.972356).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1084813
	speed: 0.3767s/iter; left time: 911.9837s
Epoch: 30 cost time: 16.941989421844482
Epoch: 30, Steps: 120 | Train Loss: 0.1166336 Vali Loss: 0.9724201 Test Loss: 0.4345583
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1153578
	speed: 0.3267s/iter; left time: 751.7386s
Epoch: 31 cost time: 15.207590818405151
Epoch: 31, Steps: 120 | Train Loss: 0.1159497 Vali Loss: 0.9715928 Test Loss: 0.4334469
Validation loss decreased (0.972356 --> 0.971593).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1203917
	speed: 0.3175s/iter; left time: 692.3900s
Epoch: 32 cost time: 14.940973043441772
Epoch: 32, Steps: 120 | Train Loss: 0.1153492 Vali Loss: 0.9705674 Test Loss: 0.4324548
Validation loss decreased (0.971593 --> 0.970567).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1135385
	speed: 0.3122s/iter; left time: 643.4952s
Epoch: 33 cost time: 14.616849899291992
Epoch: 33, Steps: 120 | Train Loss: 0.1146989 Vali Loss: 0.9704272 Test Loss: 0.4317130
Validation loss decreased (0.970567 --> 0.970427).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1100361
	speed: 0.2964s/iter; left time: 575.2842s
Epoch: 34 cost time: 14.248098373413086
Epoch: 34, Steps: 120 | Train Loss: 0.1141845 Vali Loss: 0.9691034 Test Loss: 0.4307219
Validation loss decreased (0.970427 --> 0.969103).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1168718
	speed: 0.2551s/iter; left time: 464.4895s
Epoch: 35 cost time: 10.734853506088257
Epoch: 35, Steps: 120 | Train Loss: 0.1136819 Vali Loss: 0.9694665 Test Loss: 0.4302672
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1171190
	speed: 0.1967s/iter; left time: 334.5184s
Epoch: 36 cost time: 10.144761323928833
Epoch: 36, Steps: 120 | Train Loss: 0.1131732 Vali Loss: 0.9693099 Test Loss: 0.4295239
EarlyStopping counter: 2 out of 3
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1171719
	speed: 0.2939s/iter; left time: 464.6411s
Epoch: 37 cost time: 15.408727169036865
Epoch: 37, Steps: 120 | Train Loss: 0.1128264 Vali Loss: 0.9690616 Test Loss: 0.4289479
Validation loss decreased (0.969103 --> 0.969062).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1092990
	speed: 0.3863s/iter; left time: 564.3656s
Epoch: 38 cost time: 18.42081069946289
Epoch: 38, Steps: 120 | Train Loss: 0.1125234 Vali Loss: 0.9679433 Test Loss: 0.4282730
Validation loss decreased (0.969062 --> 0.967943).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1139773
	speed: 0.3891s/iter; left time: 521.8289s
Epoch: 39 cost time: 18.328466176986694
Epoch: 39, Steps: 120 | Train Loss: 0.1120851 Vali Loss: 0.9683588 Test Loss: 0.4278608
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1102159
	speed: 0.4139s/iter; left time: 505.3710s
Epoch: 40 cost time: 19.45748734474182
Epoch: 40, Steps: 120 | Train Loss: 0.1118775 Vali Loss: 0.9678480 Test Loss: 0.4274173
Validation loss decreased (0.967943 --> 0.967848).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1088629
	speed: 0.4083s/iter; left time: 449.5288s
Epoch: 41 cost time: 18.635364770889282
Epoch: 41, Steps: 120 | Train Loss: 0.1115063 Vali Loss: 0.9676830 Test Loss: 0.4270327
Validation loss decreased (0.967848 --> 0.967683).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1103738
	speed: 0.3858s/iter; left time: 378.5088s
Epoch: 42 cost time: 17.49584650993347
Epoch: 42, Steps: 120 | Train Loss: 0.1112270 Vali Loss: 0.9679810 Test Loss: 0.4267511
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1120042
	speed: 0.3535s/iter; left time: 304.3298s
Epoch: 43 cost time: 15.440764904022217
Epoch: 43, Steps: 120 | Train Loss: 0.1110338 Vali Loss: 0.9678422 Test Loss: 0.4262941
EarlyStopping counter: 2 out of 3
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1169154
	speed: 0.3516s/iter; left time: 260.5115s
Epoch: 44 cost time: 17.400715589523315
Epoch: 44, Steps: 120 | Train Loss: 0.1108587 Vali Loss: 0.9668767 Test Loss: 0.4260520
Validation loss decreased (0.967683 --> 0.966877).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1081708
	speed: 0.3746s/iter; left time: 232.6043s
Epoch: 45 cost time: 17.79041576385498
Epoch: 45, Steps: 120 | Train Loss: 0.1107579 Vali Loss: 0.9675086 Test Loss: 0.4257935
EarlyStopping counter: 1 out of 3
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1099069
	speed: 0.3822s/iter; left time: 191.4665s
Epoch: 46 cost time: 17.79210638999939
Epoch: 46, Steps: 120 | Train Loss: 0.1105136 Vali Loss: 0.9674996 Test Loss: 0.4256017
EarlyStopping counter: 2 out of 3
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1054114
	speed: 0.3772s/iter; left time: 143.7002s
Epoch: 47 cost time: 17.347177743911743
Epoch: 47, Steps: 120 | Train Loss: 0.1103663 Vali Loss: 0.9675822 Test Loss: 0.4253280
EarlyStopping counter: 3 out of 3
Early stopping
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=134, out_features=169, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  10145408.0
params:  22815.0
Trainable parameters:  22815
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4151734
	speed: 0.1275s/iter; left time: 752.3723s
Epoch: 1 cost time: 15.462398529052734
Epoch: 1, Steps: 120 | Train Loss: 0.3870020 Vali Loss: 0.9631636 Test Loss: 0.4222683
Validation loss decreased (inf --> 0.963164).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3918166
	speed: 0.3763s/iter; left time: 2175.3622s
Epoch: 2 cost time: 18.58556818962097
Epoch: 2, Steps: 120 | Train Loss: 0.3849961 Vali Loss: 0.9643692 Test Loss: 0.4221642
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3965988
	speed: 0.4022s/iter; left time: 2277.1289s
Epoch: 3 cost time: 18.4268479347229
Epoch: 3, Steps: 120 | Train Loss: 0.3840896 Vali Loss: 0.9659522 Test Loss: 0.4224976
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3826646
	speed: 0.4090s/iter; left time: 2266.0766s
Epoch: 4 cost time: 19.33864140510559
Epoch: 4, Steps: 120 | Train Loss: 0.3831142 Vali Loss: 0.9684717 Test Loss: 0.4214261
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh1_720_192_FITS_ETTh1_ftM_sl720_ll48_pl192_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.4204513132572174, mae:0.4278305768966675, rse:0.6157652735710144, corr:[0.26725647 0.27142176 0.2711151  0.26831448 0.26550892 0.26361117
 0.26251227 0.26205194 0.26175115 0.26169732 0.261846   0.262022
 0.2621916  0.2622372  0.26215437 0.26196855 0.2615215  0.26093215
 0.26020357 0.25948995 0.25904483 0.2589735  0.25895146 0.25887203
 0.2587626  0.25891453 0.25930816 0.25959232 0.2596039  0.25933152
 0.2589341  0.25852543 0.25834438 0.25831378 0.25811303 0.25778502
 0.2574647  0.2573064  0.2573181  0.25743994 0.2575745  0.25755188
 0.25738546 0.2572877  0.25745058 0.25785357 0.25836396 0.2586852
 0.2583963  0.2576709  0.25651407 0.25518382 0.25392818 0.2527638
 0.2519228  0.25152436 0.25142023 0.2513893  0.25110003 0.25070482
 0.25031585 0.25002915 0.24988326 0.24986835 0.2497967  0.24980563
 0.25011683 0.25054204 0.25098845 0.25118443 0.25094754 0.25026217
 0.24950582 0.24887307 0.2483856  0.24800584 0.24741796 0.24655853
 0.2457382  0.24532211 0.24536824 0.24569103 0.245983   0.24611825
 0.24617288 0.24606735 0.24571423 0.24507485 0.2443036  0.24368581
 0.24332632 0.24329793 0.24351993 0.24379876 0.2439439  0.2439591
 0.24409868 0.2444083  0.2447177  0.24502018 0.24515215 0.24491991
 0.24450208 0.2442366  0.24432462 0.24474496 0.2449698  0.24477366
 0.24447377 0.24429409 0.24432668 0.2443858  0.24393636 0.24305038
 0.24237792 0.24239291 0.24305844 0.24375288 0.24384567 0.24319789
 0.2422025  0.24122772 0.24047647 0.23992886 0.23937358 0.23870972
 0.23827976 0.2381515  0.237843   0.23717877 0.23609966 0.23504809
 0.23463862 0.23503387 0.23565722 0.23595627 0.23599349 0.23588088
 0.23585388 0.23593672 0.236135   0.23625292 0.23613773 0.23564275
 0.2349669  0.23426713 0.23354882 0.23278278 0.23220383 0.23168176
 0.2312088  0.23082714 0.23064385 0.23082462 0.2310266  0.23099405
 0.23063818 0.2301037  0.22956412 0.22895111 0.22808084 0.22716047
 0.22628255 0.22579698 0.22601928 0.22660007 0.22699367 0.22665405
 0.2260497  0.225755   0.22553392 0.22499055 0.22394674 0.22297913
 0.22262979 0.22285919 0.2226173  0.22176562 0.2204579  0.21947263
 0.21927145 0.21931845 0.21891509 0.21837671 0.21852405 0.21949762
 0.22005336 0.21892884 0.21741617 0.2178494  0.21997127 0.21752916]
