Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=165, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=7, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:7
>>>>>>>start training : ETTh1_720_192_FITS_ETTh1_ftM_sl720_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=165, out_features=209, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  15449280.0
params:  34694.0
Trainable parameters:  34694
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5043418
	speed: 0.1274s/iter; left time: 751.8763s
Epoch: 1 cost time: 15.199712753295898
Epoch: 1, Steps: 120 | Train Loss: 0.5877551 Vali Loss: 1.0889379 Test Loss: 0.4844454
Validation loss decreased (inf --> 1.088938).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4007982
	speed: 0.3360s/iter; left time: 1942.4318s
Epoch: 2 cost time: 16.61769199371338
Epoch: 2, Steps: 120 | Train Loss: 0.4316994 Vali Loss: 0.9973380 Test Loss: 0.4244588
Validation loss decreased (1.088938 --> 0.997338).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4346249
	speed: 0.3425s/iter; left time: 1939.0136s
Epoch: 3 cost time: 15.330183029174805
Epoch: 3, Steps: 120 | Train Loss: 0.4043682 Vali Loss: 0.9783888 Test Loss: 0.4165019
Validation loss decreased (0.997338 --> 0.978389).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3585644
	speed: 0.3152s/iter; left time: 1746.5173s
Epoch: 4 cost time: 12.538475751876831
Epoch: 4, Steps: 120 | Train Loss: 0.3963276 Vali Loss: 0.9742208 Test Loss: 0.4158508
Validation loss decreased (0.978389 --> 0.974221).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3781142
	speed: 0.3291s/iter; left time: 1783.8386s
Epoch: 5 cost time: 16.93593740463257
Epoch: 5, Steps: 120 | Train Loss: 0.3919813 Vali Loss: 0.9717988 Test Loss: 0.4161744
Validation loss decreased (0.974221 --> 0.971799).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4465892
	speed: 0.3454s/iter; left time: 1831.0316s
Epoch: 6 cost time: 15.948976993560791
Epoch: 6, Steps: 120 | Train Loss: 0.3898390 Vali Loss: 0.9693347 Test Loss: 0.4169361
Validation loss decreased (0.971799 --> 0.969335).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3745617
	speed: 0.3409s/iter; left time: 1766.2462s
Epoch: 7 cost time: 15.844843864440918
Epoch: 7, Steps: 120 | Train Loss: 0.3878052 Vali Loss: 0.9681915 Test Loss: 0.4166337
Validation loss decreased (0.969335 --> 0.968192).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3827341
	speed: 0.3503s/iter; left time: 1773.0751s
Epoch: 8 cost time: 16.657929182052612
Epoch: 8, Steps: 120 | Train Loss: 0.3864153 Vali Loss: 0.9681489 Test Loss: 0.4166438
Validation loss decreased (0.968192 --> 0.968149).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3999163
	speed: 0.3382s/iter; left time: 1670.9788s
Epoch: 9 cost time: 15.453587293624878
Epoch: 9, Steps: 120 | Train Loss: 0.3854072 Vali Loss: 0.9675253 Test Loss: 0.4170921
Validation loss decreased (0.968149 --> 0.967525).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3955794
	speed: 0.3421s/iter; left time: 1649.0311s
Epoch: 10 cost time: 16.371512174606323
Epoch: 10, Steps: 120 | Train Loss: 0.3839867 Vali Loss: 0.9676474 Test Loss: 0.4166947
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3328550
	speed: 0.3452s/iter; left time: 1622.6700s
Epoch: 11 cost time: 15.356113195419312
Epoch: 11, Steps: 120 | Train Loss: 0.3834331 Vali Loss: 0.9672309 Test Loss: 0.4169796
Validation loss decreased (0.967525 --> 0.967231).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3780086
	speed: 0.3417s/iter; left time: 1565.4294s
Epoch: 12 cost time: 15.823375701904297
Epoch: 12, Steps: 120 | Train Loss: 0.3829205 Vali Loss: 0.9661385 Test Loss: 0.4175357
Validation loss decreased (0.967231 --> 0.966138).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4317222
	speed: 0.3391s/iter; left time: 1512.9190s
Epoch: 13 cost time: 16.324198246002197
Epoch: 13, Steps: 120 | Train Loss: 0.3827506 Vali Loss: 0.9669369 Test Loss: 0.4173712
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3872028
	speed: 0.3360s/iter; left time: 1458.4263s
Epoch: 14 cost time: 15.48762845993042
Epoch: 14, Steps: 120 | Train Loss: 0.3817228 Vali Loss: 0.9659389 Test Loss: 0.4173993
Validation loss decreased (0.966138 --> 0.965939).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4050463
	speed: 0.3347s/iter; left time: 1412.7728s
Epoch: 15 cost time: 15.482072114944458
Epoch: 15, Steps: 120 | Train Loss: 0.3817289 Vali Loss: 0.9665022 Test Loss: 0.4178142
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3853042
	speed: 0.3470s/iter; left time: 1422.9283s
Epoch: 16 cost time: 16.549049854278564
Epoch: 16, Steps: 120 | Train Loss: 0.3813967 Vali Loss: 0.9650100 Test Loss: 0.4178839
Validation loss decreased (0.965939 --> 0.965010).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4145841
	speed: 0.2965s/iter; left time: 1180.4167s
Epoch: 17 cost time: 13.171907186508179
Epoch: 17, Steps: 120 | Train Loss: 0.3810438 Vali Loss: 0.9652051 Test Loss: 0.4179338
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3540656
	speed: 0.2438s/iter; left time: 941.4679s
Epoch: 18 cost time: 12.475728034973145
Epoch: 18, Steps: 120 | Train Loss: 0.3811134 Vali Loss: 0.9642814 Test Loss: 0.4180934
Validation loss decreased (0.965010 --> 0.964281).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4243804
	speed: 0.3680s/iter; left time: 1376.7689s
Epoch: 19 cost time: 18.15725326538086
Epoch: 19, Steps: 120 | Train Loss: 0.3805177 Vali Loss: 0.9641831 Test Loss: 0.4179694
Validation loss decreased (0.964281 --> 0.964183).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3886012
	speed: 0.3615s/iter; left time: 1308.9339s
Epoch: 20 cost time: 15.840916156768799
Epoch: 20, Steps: 120 | Train Loss: 0.3806392 Vali Loss: 0.9642594 Test Loss: 0.4181118
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4028448
	speed: 0.3422s/iter; left time: 1198.0878s
Epoch: 21 cost time: 16.67255663871765
Epoch: 21, Steps: 120 | Train Loss: 0.3801999 Vali Loss: 0.9643269 Test Loss: 0.4180432
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3425064
	speed: 0.3666s/iter; left time: 1239.3870s
Epoch: 22 cost time: 16.516263246536255
Epoch: 22, Steps: 120 | Train Loss: 0.3799382 Vali Loss: 0.9638140 Test Loss: 0.4181238
Validation loss decreased (0.964183 --> 0.963814).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3758697
	speed: 0.3485s/iter; left time: 1136.6109s
Epoch: 23 cost time: 16.285199642181396
Epoch: 23, Steps: 120 | Train Loss: 0.3801550 Vali Loss: 0.9645490 Test Loss: 0.4180954
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3521711
	speed: 0.3604s/iter; left time: 1132.1227s
Epoch: 24 cost time: 17.018373012542725
Epoch: 24, Steps: 120 | Train Loss: 0.3799367 Vali Loss: 0.9640279 Test Loss: 0.4182822
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3794587
	speed: 0.3467s/iter; left time: 1047.3737s
Epoch: 25 cost time: 15.820294380187988
Epoch: 25, Steps: 120 | Train Loss: 0.3795488 Vali Loss: 0.9633540 Test Loss: 0.4180951
Validation loss decreased (0.963814 --> 0.963354).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3918653
	speed: 0.3524s/iter; left time: 1022.1976s
Epoch: 26 cost time: 16.64543604850769
Epoch: 26, Steps: 120 | Train Loss: 0.3798234 Vali Loss: 0.9633508 Test Loss: 0.4181371
Validation loss decreased (0.963354 --> 0.963351).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.4193529
	speed: 0.3682s/iter; left time: 1023.8291s
Epoch: 27 cost time: 16.99600577354431
Epoch: 27, Steps: 120 | Train Loss: 0.3796251 Vali Loss: 0.9632937 Test Loss: 0.4181429
Validation loss decreased (0.963351 --> 0.963294).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4643090
	speed: 0.2867s/iter; left time: 762.8628s
Epoch: 28 cost time: 14.732365131378174
Epoch: 28, Steps: 120 | Train Loss: 0.3794077 Vali Loss: 0.9631594 Test Loss: 0.4180836
Validation loss decreased (0.963294 --> 0.963159).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.3651461
	speed: 0.3524s/iter; left time: 895.3350s
Epoch: 29 cost time: 16.932892084121704
Epoch: 29, Steps: 120 | Train Loss: 0.3788455 Vali Loss: 0.9629328 Test Loss: 0.4180355
Validation loss decreased (0.963159 --> 0.962933).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.3481081
	speed: 0.3655s/iter; left time: 884.8202s
Epoch: 30 cost time: 16.468424320220947
Epoch: 30, Steps: 120 | Train Loss: 0.3789843 Vali Loss: 0.9624020 Test Loss: 0.4182876
Validation loss decreased (0.962933 --> 0.962402).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.4028062
	speed: 0.3416s/iter; left time: 786.1089s
Epoch: 31 cost time: 15.96978211402893
Epoch: 31, Steps: 120 | Train Loss: 0.3788063 Vali Loss: 0.9634719 Test Loss: 0.4183120
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3853168
	speed: 0.3568s/iter; left time: 778.2719s
Epoch: 32 cost time: 16.843129634857178
Epoch: 32, Steps: 120 | Train Loss: 0.3790742 Vali Loss: 0.9632169 Test Loss: 0.4182982
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.3632889
	speed: 0.3426s/iter; left time: 706.0252s
Epoch: 33 cost time: 15.179901838302612
Epoch: 33, Steps: 120 | Train Loss: 0.3788814 Vali Loss: 0.9626572 Test Loss: 0.4181895
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh1_720_192_FITS_ETTh1_ftM_sl720_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.416413277387619, mae:0.4243111312389374, rse:0.612801194190979, corr:[0.25807327 0.26841584 0.26832125 0.26732028 0.266116   0.26366425
 0.2618944  0.26186264 0.2623843  0.26245958 0.26209676 0.26190704
 0.26226398 0.26247096 0.26237074 0.26235124 0.2624852  0.26248485
 0.2620534  0.26146698 0.26130792 0.26155004 0.26150194 0.26140836
 0.26132107 0.26107848 0.26064205 0.26045132 0.26050693 0.26032192
 0.25974572 0.25909328 0.2588861  0.25907004 0.25909102 0.2590337
 0.25908557 0.25926334 0.2593182  0.25923687 0.2594103  0.25975886
 0.2599262  0.25982943 0.25979102 0.2599648  0.26033023 0.2604682
 0.25988024 0.25887802 0.25766224 0.2565716  0.2557401  0.25490582
 0.25408667 0.25339904 0.25293335 0.25292838 0.25300854 0.2529819
 0.25263336 0.2521916  0.25185496 0.25184697 0.2520491  0.25240958
 0.25289774 0.25298563 0.25267744 0.25239593 0.25238112 0.2522963
 0.25186628 0.2510315  0.2502688  0.25012225 0.25003976 0.24938703
 0.24853238 0.24819057 0.24832885 0.24824603 0.2475686  0.24682626
 0.24661139 0.24674481 0.24674436 0.24655153 0.24651363 0.24661419
 0.24637014 0.24588534 0.24572812 0.24617457 0.24683987 0.24723607
 0.24745482 0.2475249  0.24722332 0.24679656 0.24667355 0.24692652
 0.2472307  0.2470524  0.24646014 0.24622576 0.24644235 0.2465311
 0.24627216 0.24592729 0.24595965 0.24627508 0.24631521 0.24623089
 0.24642959 0.2466446  0.24638851 0.24582052 0.24553968 0.24564335
 0.24551971 0.244536   0.24316393 0.24221022 0.2416697  0.24111295
 0.24088241 0.24114625 0.2411743  0.24060012 0.23983152 0.23969303
 0.24015075 0.24032314 0.23981893 0.23941463 0.23993944 0.24057409
 0.24026531 0.23931804 0.23903134 0.23949447 0.23940134 0.23832686
 0.237274   0.23672917 0.23595655 0.23444396 0.23320118 0.23285113
 0.23282653 0.23225056 0.23156981 0.23182826 0.23245771 0.23221754
 0.23124395 0.23096639 0.23169506 0.23191515 0.23107176 0.23054838
 0.23116061 0.23171443 0.23099594 0.22987823 0.22996679 0.23068666
 0.23012464 0.22850795 0.227813   0.22873129 0.2287999  0.22702633
 0.22551273 0.22612621 0.22675882 0.22567919 0.22416425 0.2244118
 0.2252888  0.22431314 0.22276627 0.22368494 0.22571075 0.22507766
 0.22352746 0.22521432 0.22754711 0.22511648 0.22541559 0.23972686]
