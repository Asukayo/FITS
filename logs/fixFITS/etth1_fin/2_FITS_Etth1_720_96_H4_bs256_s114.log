Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=512, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=7, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:7
>>>>>>>start training : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=134, out_features=151, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  72518656.0
params:  20385.0
Trainable parameters:  20385
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.728935956954956
Epoch: 1, Steps: 15 | Train Loss: 0.6853327 Vali Loss: 1.6574724 Test Loss: 0.9568350
Validation loss decreased (inf --> 1.657472).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.966237783432007
Epoch: 2, Steps: 15 | Train Loss: 0.6300725 Vali Loss: 1.5460005 Test Loss: 0.9087746
Validation loss decreased (1.657472 --> 1.546000).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.9136722087860107
Epoch: 3, Steps: 15 | Train Loss: 0.5861572 Vali Loss: 1.4714816 Test Loss: 0.8734600
Validation loss decreased (1.546000 --> 1.471482).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.052307367324829
Epoch: 4, Steps: 15 | Train Loss: 0.5520155 Vali Loss: 1.4186308 Test Loss: 0.8481446
Validation loss decreased (1.471482 --> 1.418631).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.173429250717163
Epoch: 5, Steps: 15 | Train Loss: 0.5245097 Vali Loss: 1.3736711 Test Loss: 0.8277256
Validation loss decreased (1.418631 --> 1.373671).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.236090660095215
Epoch: 6, Steps: 15 | Train Loss: 0.5025027 Vali Loss: 1.3452111 Test Loss: 0.8105669
Validation loss decreased (1.373671 --> 1.345211).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.8450000286102295
Epoch: 7, Steps: 15 | Train Loss: 0.4839329 Vali Loss: 1.3130662 Test Loss: 0.7988784
Validation loss decreased (1.345211 --> 1.313066).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.78519868850708
Epoch: 8, Steps: 15 | Train Loss: 0.4688772 Vali Loss: 1.3053403 Test Loss: 0.7891002
Validation loss decreased (1.313066 --> 1.305340).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.2078726291656494
Epoch: 9, Steps: 15 | Train Loss: 0.4560763 Vali Loss: 1.2888314 Test Loss: 0.7826206
Validation loss decreased (1.305340 --> 1.288831).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.869126081466675
Epoch: 10, Steps: 15 | Train Loss: 0.4442048 Vali Loss: 1.2788880 Test Loss: 0.7763519
Validation loss decreased (1.288831 --> 1.278888).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.004530906677246
Epoch: 11, Steps: 15 | Train Loss: 0.4346218 Vali Loss: 1.2603910 Test Loss: 0.7713721
Validation loss decreased (1.278888 --> 1.260391).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.9388649463653564
Epoch: 12, Steps: 15 | Train Loss: 0.4259462 Vali Loss: 1.2515819 Test Loss: 0.7675300
Validation loss decreased (1.260391 --> 1.251582).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.926544427871704
Epoch: 13, Steps: 15 | Train Loss: 0.4187840 Vali Loss: 1.2476627 Test Loss: 0.7651947
Validation loss decreased (1.251582 --> 1.247663).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.021561622619629
Epoch: 14, Steps: 15 | Train Loss: 0.4119289 Vali Loss: 1.2414281 Test Loss: 0.7617181
Validation loss decreased (1.247663 --> 1.241428).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.1207115650177
Epoch: 15, Steps: 15 | Train Loss: 0.4061403 Vali Loss: 1.2344221 Test Loss: 0.7593427
Validation loss decreased (1.241428 --> 1.234422).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.7698330879211426
Epoch: 16, Steps: 15 | Train Loss: 0.4003349 Vali Loss: 1.2316816 Test Loss: 0.7575607
Validation loss decreased (1.234422 --> 1.231682).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.966336727142334
Epoch: 17, Steps: 15 | Train Loss: 0.3959858 Vali Loss: 1.2309427 Test Loss: 0.7556716
Validation loss decreased (1.231682 --> 1.230943).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.849148750305176
Epoch: 18, Steps: 15 | Train Loss: 0.3911098 Vali Loss: 1.2229054 Test Loss: 0.7545325
Validation loss decreased (1.230943 --> 1.222905).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 3.2355520725250244
Epoch: 19, Steps: 15 | Train Loss: 0.3873892 Vali Loss: 1.2235609 Test Loss: 0.7532623
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.3584532737731934
Epoch: 20, Steps: 15 | Train Loss: 0.3834127 Vali Loss: 1.2165937 Test Loss: 0.7521687
Validation loss decreased (1.222905 --> 1.216594).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.941455602645874
Epoch: 21, Steps: 15 | Train Loss: 0.3799499 Vali Loss: 1.2140580 Test Loss: 0.7510141
Validation loss decreased (1.216594 --> 1.214058).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.226325273513794
Epoch: 22, Steps: 15 | Train Loss: 0.3767421 Vali Loss: 1.2142060 Test Loss: 0.7503421
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.0478782653808594
Epoch: 23, Steps: 15 | Train Loss: 0.3738265 Vali Loss: 1.2047952 Test Loss: 0.7490094
Validation loss decreased (1.214058 --> 1.204795).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.210540771484375
Epoch: 24, Steps: 15 | Train Loss: 0.3709998 Vali Loss: 1.2084956 Test Loss: 0.7482433
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 3.1126537322998047
Epoch: 25, Steps: 15 | Train Loss: 0.3683716 Vali Loss: 1.2058672 Test Loss: 0.7480903
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.5234882831573486
Epoch: 26, Steps: 15 | Train Loss: 0.3661176 Vali Loss: 1.2046918 Test Loss: 0.7470215
Validation loss decreased (1.204795 --> 1.204692).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 3.2516911029815674
Epoch: 27, Steps: 15 | Train Loss: 0.3640295 Vali Loss: 1.2000749 Test Loss: 0.7464573
Validation loss decreased (1.204692 --> 1.200075).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.0644633769989014
Epoch: 28, Steps: 15 | Train Loss: 0.3613076 Vali Loss: 1.1993876 Test Loss: 0.7458752
Validation loss decreased (1.200075 --> 1.199388).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 3.246725082397461
Epoch: 29, Steps: 15 | Train Loss: 0.3596347 Vali Loss: 1.2041537 Test Loss: 0.7454144
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.792881488800049
Epoch: 30, Steps: 15 | Train Loss: 0.3581626 Vali Loss: 1.1992089 Test Loss: 0.7449443
Validation loss decreased (1.199388 --> 1.199209).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 3.1396822929382324
Epoch: 31, Steps: 15 | Train Loss: 0.3562701 Vali Loss: 1.1935914 Test Loss: 0.7442268
Validation loss decreased (1.199209 --> 1.193591).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 3.0744869709014893
Epoch: 32, Steps: 15 | Train Loss: 0.3545087 Vali Loss: 1.1954495 Test Loss: 0.7439733
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.1090590953826904
Epoch: 33, Steps: 15 | Train Loss: 0.3528701 Vali Loss: 1.1977456 Test Loss: 0.7429865
EarlyStopping counter: 2 out of 3
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.276183605194092
Epoch: 34, Steps: 15 | Train Loss: 0.3516612 Vali Loss: 1.1853011 Test Loss: 0.7428613
Validation loss decreased (1.193591 --> 1.185301).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 3.114041566848755
Epoch: 35, Steps: 15 | Train Loss: 0.3500867 Vali Loss: 1.1901869 Test Loss: 0.7425433
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 3.0083112716674805
Epoch: 36, Steps: 15 | Train Loss: 0.3485841 Vali Loss: 1.1951411 Test Loss: 0.7421790
EarlyStopping counter: 2 out of 3
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.8312160968780518
Epoch: 37, Steps: 15 | Train Loss: 0.3475316 Vali Loss: 1.1926129 Test Loss: 0.7415493
EarlyStopping counter: 3 out of 3
Early stopping
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=134, out_features=151, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  72518656.0
params:  20385.0
Trainable parameters:  20385
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.974579095840454
Epoch: 1, Steps: 15 | Train Loss: 0.5156189 Vali Loss: 1.0474799 Test Loss: 0.6386584
Validation loss decreased (inf --> 1.047480).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.3919928073883057
Epoch: 2, Steps: 15 | Train Loss: 0.4620302 Vali Loss: 0.9576317 Test Loss: 0.5632021
Validation loss decreased (1.047480 --> 0.957632).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.274730920791626
Epoch: 3, Steps: 15 | Train Loss: 0.4256077 Vali Loss: 0.8893224 Test Loss: 0.5101017
Validation loss decreased (0.957632 --> 0.889322).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.4055607318878174
Epoch: 4, Steps: 15 | Train Loss: 0.4002544 Vali Loss: 0.8380271 Test Loss: 0.4728248
Validation loss decreased (0.889322 --> 0.838027).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.2342140674591064
Epoch: 5, Steps: 15 | Train Loss: 0.3827521 Vali Loss: 0.8072698 Test Loss: 0.4475336
Validation loss decreased (0.838027 --> 0.807270).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.587129592895508
Epoch: 6, Steps: 15 | Train Loss: 0.3704986 Vali Loss: 0.7804751 Test Loss: 0.4301185
Validation loss decreased (0.807270 --> 0.780475).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.1815736293792725
Epoch: 7, Steps: 15 | Train Loss: 0.3624868 Vali Loss: 0.7680069 Test Loss: 0.4184616
Validation loss decreased (0.780475 --> 0.768007).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.4882450103759766
Epoch: 8, Steps: 15 | Train Loss: 0.3564848 Vali Loss: 0.7592615 Test Loss: 0.4102774
Validation loss decreased (0.768007 --> 0.759261).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.4307234287261963
Epoch: 9, Steps: 15 | Train Loss: 0.3525494 Vali Loss: 0.7465857 Test Loss: 0.4044848
Validation loss decreased (0.759261 --> 0.746586).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.5805606842041016
Epoch: 10, Steps: 15 | Train Loss: 0.3493520 Vali Loss: 0.7411609 Test Loss: 0.4007058
Validation loss decreased (0.746586 --> 0.741161).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.583987236022949
Epoch: 11, Steps: 15 | Train Loss: 0.3468372 Vali Loss: 0.7341706 Test Loss: 0.3982010
Validation loss decreased (0.741161 --> 0.734171).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.1308250427246094
Epoch: 12, Steps: 15 | Train Loss: 0.3456636 Vali Loss: 0.7303255 Test Loss: 0.3960918
Validation loss decreased (0.734171 --> 0.730325).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.327057123184204
Epoch: 13, Steps: 15 | Train Loss: 0.3446386 Vali Loss: 0.7245603 Test Loss: 0.3949630
Validation loss decreased (0.730325 --> 0.724560).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.431682586669922
Epoch: 14, Steps: 15 | Train Loss: 0.3436268 Vali Loss: 0.7210373 Test Loss: 0.3937808
Validation loss decreased (0.724560 --> 0.721037).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.4866347312927246
Epoch: 15, Steps: 15 | Train Loss: 0.3423212 Vali Loss: 0.7231752 Test Loss: 0.3930214
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.095202922821045
Epoch: 16, Steps: 15 | Train Loss: 0.3415485 Vali Loss: 0.7205330 Test Loss: 0.3925670
Validation loss decreased (0.721037 --> 0.720533).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.3867695331573486
Epoch: 17, Steps: 15 | Train Loss: 0.3416748 Vali Loss: 0.7228202 Test Loss: 0.3919492
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.448256731033325
Epoch: 18, Steps: 15 | Train Loss: 0.3409605 Vali Loss: 0.7177316 Test Loss: 0.3919339
Validation loss decreased (0.720533 --> 0.717732).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 3.2610573768615723
Epoch: 19, Steps: 15 | Train Loss: 0.3403761 Vali Loss: 0.7214485 Test Loss: 0.3916493
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.384922742843628
Epoch: 20, Steps: 15 | Train Loss: 0.3406302 Vali Loss: 0.7191863 Test Loss: 0.3914979
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.111154317855835
Epoch: 21, Steps: 15 | Train Loss: 0.3408519 Vali Loss: 0.7180816 Test Loss: 0.3912401
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.38404104113578796, mae:0.4073886275291443, rse:0.5886358022689819, corr:[0.27155373 0.28001797 0.27900532 0.27535313 0.27373347 0.27299607
 0.27246815 0.27194712 0.27126643 0.2707446  0.2701561  0.2695996
 0.26928994 0.2693066  0.269641   0.2697496  0.26934952 0.26871175
 0.26814035 0.26782215 0.26753518 0.267254   0.2667078  0.26635638
 0.26636788 0.26665455 0.26683018 0.2667064  0.26629746 0.26571816
 0.26520342 0.26475492 0.2646467  0.26477036 0.26481682 0.26479906
 0.2646761  0.26451838 0.26449308 0.26473376 0.26543248 0.26606882
 0.26610342 0.2656818  0.26530942 0.26539668 0.26593134 0.2664127
 0.2661652  0.2655948  0.26466963 0.2635411  0.26246193 0.2613304
 0.26038584 0.25962916 0.25900543 0.25876522 0.25867018 0.25882584
 0.25894302 0.2589435  0.258865   0.25897154 0.25909722 0.25910044
 0.25918123 0.25915024 0.25926903 0.25952533 0.25944307 0.25877163
 0.2578384  0.25697038 0.2563039  0.25595272 0.25538513 0.25440845
 0.25340974 0.2528951  0.25263274 0.25223556 0.25150168 0.2507718
 0.25066262 0.25079334 0.25056532 0.24994954 0.24947399 0.24926326
 0.24829511 0.24561688 0.24258466 0.24160719 0.24299482 0.2381274 ]
