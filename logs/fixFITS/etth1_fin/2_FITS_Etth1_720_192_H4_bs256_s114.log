Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=512, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=7, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:7
>>>>>>>start training : ETTh1_720_192_FITS_ETTh1_ftM_sl720_ll48_pl192_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=134, out_features=169, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  81163264.0
params:  22815.0
Trainable parameters:  22815
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.1499876976013184
Epoch: 1, Steps: 15 | Train Loss: 0.7143492 Vali Loss: 1.8709574 Test Loss: 1.0090927
Validation loss decreased (inf --> 1.870957).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.110522508621216
Epoch: 2, Steps: 15 | Train Loss: 0.6541521 Vali Loss: 1.7496178 Test Loss: 0.9519467
Validation loss decreased (1.870957 --> 1.749618).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.436030387878418
Epoch: 3, Steps: 15 | Train Loss: 0.6065350 Vali Loss: 1.6645155 Test Loss: 0.9084644
Validation loss decreased (1.749618 --> 1.664515).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.2788808345794678
Epoch: 4, Steps: 15 | Train Loss: 0.5694322 Vali Loss: 1.5975984 Test Loss: 0.8741837
Validation loss decreased (1.664515 --> 1.597598).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.240640878677368
Epoch: 5, Steps: 15 | Train Loss: 0.5406278 Vali Loss: 1.5456715 Test Loss: 0.8488090
Validation loss decreased (1.597598 --> 1.545671).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.297952651977539
Epoch: 6, Steps: 15 | Train Loss: 0.5171659 Vali Loss: 1.5052725 Test Loss: 0.8276432
Validation loss decreased (1.545671 --> 1.505273).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.088259220123291
Epoch: 7, Steps: 15 | Train Loss: 0.4976949 Vali Loss: 1.4742446 Test Loss: 0.8112673
Validation loss decreased (1.505273 --> 1.474245).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.341353416442871
Epoch: 8, Steps: 15 | Train Loss: 0.4817131 Vali Loss: 1.4481809 Test Loss: 0.7988870
Validation loss decreased (1.474245 --> 1.448181).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.7145025730133057
Epoch: 9, Steps: 15 | Train Loss: 0.4680989 Vali Loss: 1.4240230 Test Loss: 0.7883251
Validation loss decreased (1.448181 --> 1.424023).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.3021748065948486
Epoch: 10, Steps: 15 | Train Loss: 0.4564998 Vali Loss: 1.4133930 Test Loss: 0.7800825
Validation loss decreased (1.424023 --> 1.413393).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.1246426105499268
Epoch: 11, Steps: 15 | Train Loss: 0.4466308 Vali Loss: 1.3942475 Test Loss: 0.7730858
Validation loss decreased (1.413393 --> 1.394248).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.2469120025634766
Epoch: 12, Steps: 15 | Train Loss: 0.4378820 Vali Loss: 1.3814203 Test Loss: 0.7677490
Validation loss decreased (1.394248 --> 1.381420).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.3180105686187744
Epoch: 13, Steps: 15 | Train Loss: 0.4302458 Vali Loss: 1.3721764 Test Loss: 0.7629554
Validation loss decreased (1.381420 --> 1.372176).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.19401216506958
Epoch: 14, Steps: 15 | Train Loss: 0.4235737 Vali Loss: 1.3533375 Test Loss: 0.7592957
Validation loss decreased (1.372176 --> 1.353338).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.0058789253234863
Epoch: 15, Steps: 15 | Train Loss: 0.4172984 Vali Loss: 1.3456974 Test Loss: 0.7560940
Validation loss decreased (1.353338 --> 1.345697).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.1686511039733887
Epoch: 16, Steps: 15 | Train Loss: 0.4120577 Vali Loss: 1.3417839 Test Loss: 0.7534842
Validation loss decreased (1.345697 --> 1.341784).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.277308702468872
Epoch: 17, Steps: 15 | Train Loss: 0.4068450 Vali Loss: 1.3389953 Test Loss: 0.7505973
Validation loss decreased (1.341784 --> 1.338995).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.5443620681762695
Epoch: 18, Steps: 15 | Train Loss: 0.4023732 Vali Loss: 1.3369423 Test Loss: 0.7485713
Validation loss decreased (1.338995 --> 1.336942).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.7515077590942383
Epoch: 19, Steps: 15 | Train Loss: 0.3983254 Vali Loss: 1.3336166 Test Loss: 0.7466987
Validation loss decreased (1.336942 --> 1.333617).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.415686845779419
Epoch: 20, Steps: 15 | Train Loss: 0.3946679 Vali Loss: 1.3264158 Test Loss: 0.7450379
Validation loss decreased (1.333617 --> 1.326416).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.3947360515594482
Epoch: 21, Steps: 15 | Train Loss: 0.3912118 Vali Loss: 1.3263688 Test Loss: 0.7437041
Validation loss decreased (1.326416 --> 1.326369).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.293532371520996
Epoch: 22, Steps: 15 | Train Loss: 0.3876752 Vali Loss: 1.3202072 Test Loss: 0.7424520
Validation loss decreased (1.326369 --> 1.320207).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.308976411819458
Epoch: 23, Steps: 15 | Train Loss: 0.3850265 Vali Loss: 1.3199425 Test Loss: 0.7414209
Validation loss decreased (1.320207 --> 1.319942).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.54691481590271
Epoch: 24, Steps: 15 | Train Loss: 0.3821972 Vali Loss: 1.3170197 Test Loss: 0.7400858
Validation loss decreased (1.319942 --> 1.317020).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 3.6961655616760254
Epoch: 25, Steps: 15 | Train Loss: 0.3794841 Vali Loss: 1.3101720 Test Loss: 0.7392151
Validation loss decreased (1.317020 --> 1.310172).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 4.056543350219727
Epoch: 26, Steps: 15 | Train Loss: 0.3772270 Vali Loss: 1.3093849 Test Loss: 0.7380826
Validation loss decreased (1.310172 --> 1.309385).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 4.088060140609741
Epoch: 27, Steps: 15 | Train Loss: 0.3751143 Vali Loss: 1.3069572 Test Loss: 0.7373447
Validation loss decreased (1.309385 --> 1.306957).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.874846935272217
Epoch: 28, Steps: 15 | Train Loss: 0.3729241 Vali Loss: 1.3080322 Test Loss: 0.7363754
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 4.062952756881714
Epoch: 29, Steps: 15 | Train Loss: 0.3711099 Vali Loss: 1.3059767 Test Loss: 0.7357379
Validation loss decreased (1.306957 --> 1.305977).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 3.7491722106933594
Epoch: 30, Steps: 15 | Train Loss: 0.3691406 Vali Loss: 1.3015481 Test Loss: 0.7350406
Validation loss decreased (1.305977 --> 1.301548).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 4.161513805389404
Epoch: 31, Steps: 15 | Train Loss: 0.3673954 Vali Loss: 1.2998394 Test Loss: 0.7342284
Validation loss decreased (1.301548 --> 1.299839).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 3.6740541458129883
Epoch: 32, Steps: 15 | Train Loss: 0.3658884 Vali Loss: 1.2987506 Test Loss: 0.7339332
Validation loss decreased (1.299839 --> 1.298751).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 4.034221172332764
Epoch: 33, Steps: 15 | Train Loss: 0.3645223 Vali Loss: 1.3038969 Test Loss: 0.7332219
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.9219441413879395
Epoch: 34, Steps: 15 | Train Loss: 0.3630029 Vali Loss: 1.2945025 Test Loss: 0.7328302
Validation loss decreased (1.298751 --> 1.294502).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 4.1137378215789795
Epoch: 35, Steps: 15 | Train Loss: 0.3615546 Vali Loss: 1.2922201 Test Loss: 0.7322409
Validation loss decreased (1.294502 --> 1.292220).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 3.904153347015381
Epoch: 36, Steps: 15 | Train Loss: 0.3606231 Vali Loss: 1.2943743 Test Loss: 0.7318280
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 3.913752794265747
Epoch: 37, Steps: 15 | Train Loss: 0.3591356 Vali Loss: 1.2906890 Test Loss: 0.7312946
Validation loss decreased (1.292220 --> 1.290689).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 3.453232765197754
Epoch: 38, Steps: 15 | Train Loss: 0.3581099 Vali Loss: 1.2937285 Test Loss: 0.7308412
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 3.6913223266601562
Epoch: 39, Steps: 15 | Train Loss: 0.3571875 Vali Loss: 1.2912004 Test Loss: 0.7304371
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 4.100979804992676
Epoch: 40, Steps: 15 | Train Loss: 0.3559401 Vali Loss: 1.2893102 Test Loss: 0.7300063
Validation loss decreased (1.290689 --> 1.289310).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 3.7042078971862793
Epoch: 41, Steps: 15 | Train Loss: 0.3549819 Vali Loss: 1.2940280 Test Loss: 0.7297032
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 3.7755537033081055
Epoch: 42, Steps: 15 | Train Loss: 0.3541896 Vali Loss: 1.2867150 Test Loss: 0.7292736
Validation loss decreased (1.289310 --> 1.286715).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 3.8953001499176025
Epoch: 43, Steps: 15 | Train Loss: 0.3532430 Vali Loss: 1.2866918 Test Loss: 0.7289832
Validation loss decreased (1.286715 --> 1.286692).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.718493700027466
Epoch: 44, Steps: 15 | Train Loss: 0.3525308 Vali Loss: 1.2867212 Test Loss: 0.7286990
EarlyStopping counter: 1 out of 3
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 3.5857951641082764
Epoch: 45, Steps: 15 | Train Loss: 0.3516991 Vali Loss: 1.2892935 Test Loss: 0.7284823
EarlyStopping counter: 2 out of 3
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 3.7654824256896973
Epoch: 46, Steps: 15 | Train Loss: 0.3508106 Vali Loss: 1.2803732 Test Loss: 0.7280619
Validation loss decreased (1.286692 --> 1.280373).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 4.174217224121094
Epoch: 47, Steps: 15 | Train Loss: 0.3502538 Vali Loss: 1.2807811 Test Loss: 0.7278941
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.9498772621154785
Epoch: 48, Steps: 15 | Train Loss: 0.3496837 Vali Loss: 1.2819694 Test Loss: 0.7276588
EarlyStopping counter: 2 out of 3
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 3.5916709899902344
Epoch: 49, Steps: 15 | Train Loss: 0.3490668 Vali Loss: 1.2850450 Test Loss: 0.7273491
EarlyStopping counter: 3 out of 3
Early stopping
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=134, out_features=169, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  81163264.0
params:  22815.0
Trainable parameters:  22815
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.6614694595336914
Epoch: 1, Steps: 15 | Train Loss: 0.5406349 Vali Loss: 1.2106886 Test Loss: 0.6669720
Validation loss decreased (inf --> 1.210689).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.7173569202423096
Epoch: 2, Steps: 15 | Train Loss: 0.5084083 Vali Loss: 1.1518744 Test Loss: 0.6202539
Validation loss decreased (1.210689 --> 1.151874).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.7878081798553467
Epoch: 3, Steps: 15 | Train Loss: 0.4838474 Vali Loss: 1.1132393 Test Loss: 0.5842103
Validation loss decreased (1.151874 --> 1.113239).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.7904815673828125
Epoch: 4, Steps: 15 | Train Loss: 0.4652179 Vali Loss: 1.0806043 Test Loss: 0.5557250
Validation loss decreased (1.113239 --> 1.080604).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.7877542972564697
Epoch: 5, Steps: 15 | Train Loss: 0.4507453 Vali Loss: 1.0566502 Test Loss: 0.5326920
Validation loss decreased (1.080604 --> 1.056650).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.7789864540100098
Epoch: 6, Steps: 15 | Train Loss: 0.4398503 Vali Loss: 1.0364399 Test Loss: 0.5144506
Validation loss decreased (1.056650 --> 1.036440).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 4.145912170410156
Epoch: 7, Steps: 15 | Train Loss: 0.4311849 Vali Loss: 1.0230364 Test Loss: 0.4996773
Validation loss decreased (1.036440 --> 1.023036).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.960686445236206
Epoch: 8, Steps: 15 | Train Loss: 0.4235459 Vali Loss: 1.0091419 Test Loss: 0.4877697
Validation loss decreased (1.023036 --> 1.009142).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.101250648498535
Epoch: 9, Steps: 15 | Train Loss: 0.4176622 Vali Loss: 1.0031812 Test Loss: 0.4781178
Validation loss decreased (1.009142 --> 1.003181).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.8035974502563477
Epoch: 10, Steps: 15 | Train Loss: 0.4128904 Vali Loss: 0.9892273 Test Loss: 0.4701524
Validation loss decreased (1.003181 --> 0.989227).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.9118144512176514
Epoch: 11, Steps: 15 | Train Loss: 0.4090227 Vali Loss: 0.9863799 Test Loss: 0.4637298
Validation loss decreased (0.989227 --> 0.986380).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.208918333053589
Epoch: 12, Steps: 15 | Train Loss: 0.4060000 Vali Loss: 0.9810032 Test Loss: 0.4585204
Validation loss decreased (0.986380 --> 0.981003).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.721571922302246
Epoch: 13, Steps: 15 | Train Loss: 0.4034533 Vali Loss: 0.9748871 Test Loss: 0.4540985
Validation loss decreased (0.981003 --> 0.974887).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 4.2490763664245605
Epoch: 14, Steps: 15 | Train Loss: 0.4010361 Vali Loss: 0.9733236 Test Loss: 0.4505864
Validation loss decreased (0.974887 --> 0.973324).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 4.292748928070068
Epoch: 15, Steps: 15 | Train Loss: 0.3991859 Vali Loss: 0.9676481 Test Loss: 0.4475496
Validation loss decreased (0.973324 --> 0.967648).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 4.5231029987335205
Epoch: 16, Steps: 15 | Train Loss: 0.3975786 Vali Loss: 0.9648641 Test Loss: 0.4451332
Validation loss decreased (0.967648 --> 0.964864).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 4.20719838142395
Epoch: 17, Steps: 15 | Train Loss: 0.3962820 Vali Loss: 0.9665270 Test Loss: 0.4430868
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 4.487006187438965
Epoch: 18, Steps: 15 | Train Loss: 0.3950683 Vali Loss: 0.9647129 Test Loss: 0.4414117
Validation loss decreased (0.964864 --> 0.964713).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 4.217182159423828
Epoch: 19, Steps: 15 | Train Loss: 0.3941602 Vali Loss: 0.9612037 Test Loss: 0.4399530
Validation loss decreased (0.964713 --> 0.961204).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.720537185668945
Epoch: 20, Steps: 15 | Train Loss: 0.3932263 Vali Loss: 0.9578930 Test Loss: 0.4386123
Validation loss decreased (0.961204 --> 0.957893).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 4.608675718307495
Epoch: 21, Steps: 15 | Train Loss: 0.3925427 Vali Loss: 0.9631265 Test Loss: 0.4376504
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 4.526042699813843
Epoch: 22, Steps: 15 | Train Loss: 0.3922868 Vali Loss: 0.9583524 Test Loss: 0.4367647
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 4.2656941413879395
Epoch: 23, Steps: 15 | Train Loss: 0.3914448 Vali Loss: 0.9546686 Test Loss: 0.4360105
Validation loss decreased (0.957893 --> 0.954669).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.8035120964050293
Epoch: 24, Steps: 15 | Train Loss: 0.3910284 Vali Loss: 0.9582111 Test Loss: 0.4353777
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 3.8194501399993896
Epoch: 25, Steps: 15 | Train Loss: 0.3904525 Vali Loss: 0.9570608 Test Loss: 0.4348845
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.9647178649902344
Epoch: 26, Steps: 15 | Train Loss: 0.3900362 Vali Loss: 0.9570640 Test Loss: 0.4343446
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh1_720_192_FITS_ETTh1_ftM_sl720_ll48_pl192_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.41962286829948425, mae:0.42825889587402344, rse:0.6151583194732666, corr:[0.2581077  0.27072906 0.26971078 0.26499155 0.26375583 0.26411265
 0.2642286  0.26358554 0.26256776 0.26200217 0.26159346 0.261171
 0.26080033 0.26065245 0.2607785  0.26063108 0.25992483 0.25905132
 0.2585257  0.25855425 0.25864878 0.25848928 0.25781983 0.25730827
 0.25742915 0.25803128 0.25844654 0.258316   0.25773618 0.25710765
 0.25679895 0.25668713 0.25676635 0.2567718  0.25649953 0.2561758
 0.2559136  0.25580603 0.25585324 0.25612614 0.25674793 0.25726727
 0.25727612 0.25698975 0.2568096  0.25707886 0.2577514  0.25829476
 0.25810355 0.25752407 0.25664386 0.2556721  0.25479612 0.25383773
 0.2529613  0.25224045 0.25167295 0.25141314 0.251304   0.25135177
 0.25136757 0.25122175 0.25097188 0.25094464 0.2511182  0.25142443
 0.25184786 0.2520843  0.25223362 0.2523379  0.2522379  0.2518855
 0.2514648  0.25105864 0.2506582  0.25040373 0.24999042 0.24930744
 0.24859293 0.24814329 0.24798822 0.24786632 0.24753408 0.24707407
 0.24678323 0.24670595 0.24671595 0.24670215 0.24664049 0.24654888
 0.24636047 0.24605986 0.2457431  0.24570209 0.24608509 0.24668533
 0.24733077 0.24780826 0.247896   0.24774806 0.24761242 0.24757054
 0.24759538 0.2474634  0.24714868 0.24683927 0.24658296 0.24632792
 0.24618189 0.24612328 0.24625827 0.24666409 0.2469674  0.24705188
 0.24706985 0.24709085 0.24716443 0.24725096 0.24718446 0.24690935
 0.2464773  0.24575938 0.24481878 0.24394009 0.2431309  0.24228911
 0.24170414 0.24148773 0.24133617 0.24110028 0.2406256  0.24004604
 0.23959804 0.23953815 0.23975794 0.24003011 0.24045032 0.2408373
 0.24102193 0.24085455 0.24050966 0.24022228 0.24007574 0.23975857
 0.2392054  0.238278   0.23695162 0.23551127 0.23459882 0.23416263
 0.23389451 0.23351413 0.23312053 0.23305996 0.23321728 0.23338135
 0.23331957 0.23312701 0.23306489 0.23314431 0.23311523 0.23302963
 0.23280196 0.23263659 0.23279984 0.23289369 0.23239037 0.23108652
 0.22987223 0.22965358 0.23012654 0.23035623 0.2294764  0.22787336
 0.22669892 0.22689632 0.2275852  0.22794506 0.2274433  0.2265745
 0.22606362 0.22578128 0.22507763 0.22432125 0.22430804 0.2248256
 0.22401866 0.22034894 0.21633571 0.21633996 0.21976818 0.21157669]
