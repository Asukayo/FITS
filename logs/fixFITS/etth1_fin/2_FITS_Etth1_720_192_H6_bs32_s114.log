Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=7, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:7
>>>>>>>start training : ETTh1_720_192_FITS_ETTh1_ftM_sl720_ll48_pl192_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=196, out_features=248, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  21776384.0
params:  48856.0
Trainable parameters:  48856
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4993614
	speed: 0.0140s/iter; left time: 82.6141s
Epoch: 1 cost time: 1.6637468338012695
Epoch: 1, Steps: 120 | Train Loss: 0.5705367 Vali Loss: 1.3813373 Test Loss: 0.7193003
Validation loss decreased (inf --> 1.381337).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3717231
	speed: 0.0352s/iter; left time: 203.4584s
Epoch: 2 cost time: 1.7620129585266113
Epoch: 2, Steps: 120 | Train Loss: 0.4136972 Vali Loss: 1.2989992 Test Loss: 0.6856695
Validation loss decreased (1.381337 --> 1.298999).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3296578
	speed: 0.0351s/iter; left time: 198.8244s
Epoch: 3 cost time: 2.0100443363189697
Epoch: 3, Steps: 120 | Train Loss: 0.3500464 Vali Loss: 1.2556731 Test Loss: 0.6622277
Validation loss decreased (1.298999 --> 1.255673).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2979425
	speed: 0.0354s/iter; left time: 196.2921s
Epoch: 4 cost time: 1.566953182220459
Epoch: 4, Steps: 120 | Train Loss: 0.3069428 Vali Loss: 1.2244962 Test Loss: 0.6418918
Validation loss decreased (1.255673 --> 1.224496).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2392010
	speed: 0.0299s/iter; left time: 161.9000s
Epoch: 5 cost time: 1.6619064807891846
Epoch: 5, Steps: 120 | Train Loss: 0.2734695 Vali Loss: 1.1938982 Test Loss: 0.6201528
Validation loss decreased (1.224496 --> 1.193898).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2337398
	speed: 0.0346s/iter; left time: 183.6446s
Epoch: 6 cost time: 1.569448471069336
Epoch: 6, Steps: 120 | Train Loss: 0.2471901 Vali Loss: 1.1701177 Test Loss: 0.6023732
Validation loss decreased (1.193898 --> 1.170118).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2269332
	speed: 0.0326s/iter; left time: 168.8111s
Epoch: 7 cost time: 1.5977694988250732
Epoch: 7, Steps: 120 | Train Loss: 0.2252289 Vali Loss: 1.1382587 Test Loss: 0.5784463
Validation loss decreased (1.170118 --> 1.138259).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2008031
	speed: 0.0332s/iter; left time: 168.0197s
Epoch: 8 cost time: 1.7262332439422607
Epoch: 8, Steps: 120 | Train Loss: 0.2072762 Vali Loss: 1.1202120 Test Loss: 0.5647560
Validation loss decreased (1.138259 --> 1.120212).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1895225
	speed: 0.0330s/iter; left time: 163.1662s
Epoch: 9 cost time: 1.64510178565979
Epoch: 9, Steps: 120 | Train Loss: 0.1924012 Vali Loss: 1.0984865 Test Loss: 0.5472564
Validation loss decreased (1.120212 --> 1.098487).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1897124
	speed: 0.0378s/iter; left time: 182.2622s
Epoch: 10 cost time: 1.965324878692627
Epoch: 10, Steps: 120 | Train Loss: 0.1798117 Vali Loss: 1.0798833 Test Loss: 0.5320277
Validation loss decreased (1.098487 --> 1.079883).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1626002
	speed: 0.0388s/iter; left time: 182.2987s
Epoch: 11 cost time: 1.8608849048614502
Epoch: 11, Steps: 120 | Train Loss: 0.1692842 Vali Loss: 1.0660548 Test Loss: 0.5203310
Validation loss decreased (1.079883 --> 1.066055).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1540660
	speed: 0.0396s/iter; left time: 181.3630s
Epoch: 12 cost time: 1.9301726818084717
Epoch: 12, Steps: 120 | Train Loss: 0.1603058 Vali Loss: 1.0506201 Test Loss: 0.5087935
Validation loss decreased (1.066055 --> 1.050620).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1487551
	speed: 0.0365s/iter; left time: 162.9257s
Epoch: 13 cost time: 1.8162572383880615
Epoch: 13, Steps: 120 | Train Loss: 0.1527588 Vali Loss: 1.0377786 Test Loss: 0.4972011
Validation loss decreased (1.050620 --> 1.037779).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1415852
	speed: 0.0366s/iter; left time: 158.8952s
Epoch: 14 cost time: 1.913691759109497
Epoch: 14, Steps: 120 | Train Loss: 0.1460331 Vali Loss: 1.0296999 Test Loss: 0.4904278
Validation loss decreased (1.037779 --> 1.029700).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1259719
	speed: 0.0380s/iter; left time: 160.2759s
Epoch: 15 cost time: 2.0243947505950928
Epoch: 15, Steps: 120 | Train Loss: 0.1405008 Vali Loss: 1.0196577 Test Loss: 0.4821359
Validation loss decreased (1.029700 --> 1.019658).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1357695
	speed: 0.0321s/iter; left time: 131.6607s
Epoch: 16 cost time: 1.3190255165100098
Epoch: 16, Steps: 120 | Train Loss: 0.1356408 Vali Loss: 1.0132070 Test Loss: 0.4756990
Validation loss decreased (1.019658 --> 1.013207).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1389576
	speed: 0.0349s/iter; left time: 138.8625s
Epoch: 17 cost time: 1.493971824645996
Epoch: 17, Steps: 120 | Train Loss: 0.1314684 Vali Loss: 1.0067270 Test Loss: 0.4703235
Validation loss decreased (1.013207 --> 1.006727).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1317911
	speed: 0.0353s/iter; left time: 136.2600s
Epoch: 18 cost time: 1.724125623703003
Epoch: 18, Steps: 120 | Train Loss: 0.1277377 Vali Loss: 0.9997491 Test Loss: 0.4635003
Validation loss decreased (1.006727 --> 0.999749).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1203136
	speed: 0.0316s/iter; left time: 118.2739s
Epoch: 19 cost time: 1.666930913925171
Epoch: 19, Steps: 120 | Train Loss: 0.1245374 Vali Loss: 0.9951900 Test Loss: 0.4595533
Validation loss decreased (0.999749 --> 0.995190).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1183178
	speed: 0.0392s/iter; left time: 142.0442s
Epoch: 20 cost time: 1.8683977127075195
Epoch: 20, Steps: 120 | Train Loss: 0.1217043 Vali Loss: 0.9914216 Test Loss: 0.4556844
Validation loss decreased (0.995190 --> 0.991422).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1156123
	speed: 0.0297s/iter; left time: 104.0286s
Epoch: 21 cost time: 1.3068110942840576
Epoch: 21, Steps: 120 | Train Loss: 0.1192080 Vali Loss: 0.9857913 Test Loss: 0.4501711
Validation loss decreased (0.991422 --> 0.985791).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1043953
	speed: 0.0363s/iter; left time: 122.6304s
Epoch: 22 cost time: 1.5176913738250732
Epoch: 22, Steps: 120 | Train Loss: 0.1170515 Vali Loss: 0.9835989 Test Loss: 0.4478416
Validation loss decreased (0.985791 --> 0.983599).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1218504
	speed: 0.0362s/iter; left time: 118.1443s
Epoch: 23 cost time: 1.8694336414337158
Epoch: 23, Steps: 120 | Train Loss: 0.1151577 Vali Loss: 0.9812815 Test Loss: 0.4454631
Validation loss decreased (0.983599 --> 0.981281).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1178517
	speed: 0.0308s/iter; left time: 96.7945s
Epoch: 24 cost time: 1.5348780155181885
Epoch: 24, Steps: 120 | Train Loss: 0.1135262 Vali Loss: 0.9785771 Test Loss: 0.4427025
Validation loss decreased (0.981281 --> 0.978577).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1195796
	speed: 0.0389s/iter; left time: 117.5412s
Epoch: 25 cost time: 2.2105660438537598
Epoch: 25, Steps: 120 | Train Loss: 0.1118282 Vali Loss: 0.9765951 Test Loss: 0.4403632
Validation loss decreased (0.978577 --> 0.976595).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1172923
	speed: 0.0371s/iter; left time: 107.5498s
Epoch: 26 cost time: 2.0628628730773926
Epoch: 26, Steps: 120 | Train Loss: 0.1106431 Vali Loss: 0.9761056 Test Loss: 0.4392970
Validation loss decreased (0.976595 --> 0.976106).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1197869
	speed: 0.0359s/iter; left time: 99.8829s
Epoch: 27 cost time: 1.6310553550720215
Epoch: 27, Steps: 120 | Train Loss: 0.1093018 Vali Loss: 0.9742740 Test Loss: 0.4369462
Validation loss decreased (0.976106 --> 0.974274).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1136779
	speed: 0.0368s/iter; left time: 98.0173s
Epoch: 28 cost time: 1.6873507499694824
Epoch: 28, Steps: 120 | Train Loss: 0.1082598 Vali Loss: 0.9720494 Test Loss: 0.4352608
Validation loss decreased (0.974274 --> 0.972049).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1019281
	speed: 0.0239s/iter; left time: 60.7529s
Epoch: 29 cost time: 1.0229825973510742
Epoch: 29, Steps: 120 | Train Loss: 0.1072589 Vali Loss: 0.9714885 Test Loss: 0.4338867
Validation loss decreased (0.972049 --> 0.971488).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1117763
	speed: 0.0223s/iter; left time: 54.0249s
Epoch: 30 cost time: 0.9876315593719482
Epoch: 30, Steps: 120 | Train Loss: 0.1064702 Vali Loss: 0.9701591 Test Loss: 0.4324132
Validation loss decreased (0.971488 --> 0.970159).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.0983946
	speed: 0.0247s/iter; left time: 56.7384s
Epoch: 31 cost time: 1.1926929950714111
Epoch: 31, Steps: 120 | Train Loss: 0.1057292 Vali Loss: 0.9693192 Test Loss: 0.4313799
Validation loss decreased (0.970159 --> 0.969319).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.0950233
	speed: 0.0233s/iter; left time: 50.8151s
Epoch: 32 cost time: 0.9335238933563232
Epoch: 32, Steps: 120 | Train Loss: 0.1050001 Vali Loss: 0.9686338 Test Loss: 0.4302174
Validation loss decreased (0.969319 --> 0.968634).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1107235
	speed: 0.0216s/iter; left time: 44.4890s
Epoch: 33 cost time: 0.9671628475189209
Epoch: 33, Steps: 120 | Train Loss: 0.1043578 Vali Loss: 0.9679170 Test Loss: 0.4292800
Validation loss decreased (0.968634 --> 0.967917).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.0971026
	speed: 0.0249s/iter; left time: 48.3512s
Epoch: 34 cost time: 1.1284911632537842
Epoch: 34, Steps: 120 | Train Loss: 0.1038278 Vali Loss: 0.9675738 Test Loss: 0.4284196
Validation loss decreased (0.967917 --> 0.967574).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1114592
	speed: 0.0229s/iter; left time: 41.6233s
Epoch: 35 cost time: 1.010115385055542
Epoch: 35, Steps: 120 | Train Loss: 0.1032961 Vali Loss: 0.9663222 Test Loss: 0.4276638
Validation loss decreased (0.967574 --> 0.966322).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1004485
	speed: 0.0213s/iter; left time: 36.1897s
Epoch: 36 cost time: 0.8840086460113525
Epoch: 36, Steps: 120 | Train Loss: 0.1028484 Vali Loss: 0.9661661 Test Loss: 0.4267571
Validation loss decreased (0.966322 --> 0.966166).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1020241
	speed: 0.0216s/iter; left time: 34.1742s
Epoch: 37 cost time: 0.9649021625518799
Epoch: 37, Steps: 120 | Train Loss: 0.1023704 Vali Loss: 0.9661202 Test Loss: 0.4263570
Validation loss decreased (0.966166 --> 0.966120).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.0989756
	speed: 0.0226s/iter; left time: 33.0283s
Epoch: 38 cost time: 1.0378139019012451
Epoch: 38, Steps: 120 | Train Loss: 0.1020189 Vali Loss: 0.9658255 Test Loss: 0.4256365
Validation loss decreased (0.966120 --> 0.965825).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1075925
	speed: 0.0227s/iter; left time: 30.4942s
Epoch: 39 cost time: 0.9424343109130859
Epoch: 39, Steps: 120 | Train Loss: 0.1016354 Vali Loss: 0.9651240 Test Loss: 0.4250889
Validation loss decreased (0.965825 --> 0.965124).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.0974386
	speed: 0.0212s/iter; left time: 25.8574s
Epoch: 40 cost time: 0.9562995433807373
Epoch: 40, Steps: 120 | Train Loss: 0.1013635 Vali Loss: 0.9647636 Test Loss: 0.4244955
Validation loss decreased (0.965124 --> 0.964764).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1033974
	speed: 0.0220s/iter; left time: 24.2523s
Epoch: 41 cost time: 1.053969383239746
Epoch: 41, Steps: 120 | Train Loss: 0.1009646 Vali Loss: 0.9652336 Test Loss: 0.4242489
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1036551
	speed: 0.0217s/iter; left time: 21.3121s
Epoch: 42 cost time: 1.0042393207550049
Epoch: 42, Steps: 120 | Train Loss: 0.1007404 Vali Loss: 0.9645484 Test Loss: 0.4237449
Validation loss decreased (0.964764 --> 0.964548).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.0971792
	speed: 0.0234s/iter; left time: 20.1821s
Epoch: 43 cost time: 1.0045616626739502
Epoch: 43, Steps: 120 | Train Loss: 0.1005295 Vali Loss: 0.9644834 Test Loss: 0.4234200
Validation loss decreased (0.964548 --> 0.964483).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.0961486
	speed: 0.0230s/iter; left time: 17.0394s
Epoch: 44 cost time: 0.9592947959899902
Epoch: 44, Steps: 120 | Train Loss: 0.1004155 Vali Loss: 0.9643681 Test Loss: 0.4230928
Validation loss decreased (0.964483 --> 0.964368).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.0914813
	speed: 0.0233s/iter; left time: 14.4728s
Epoch: 45 cost time: 1.082442045211792
Epoch: 45, Steps: 120 | Train Loss: 0.1001183 Vali Loss: 0.9642733 Test Loss: 0.4227157
Validation loss decreased (0.964368 --> 0.964273).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.0982537
	speed: 0.0221s/iter; left time: 11.0948s
Epoch: 46 cost time: 0.985476016998291
Epoch: 46, Steps: 120 | Train Loss: 0.0998990 Vali Loss: 0.9643000 Test Loss: 0.4224508
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1090272
	speed: 0.0223s/iter; left time: 8.4957s
Epoch: 47 cost time: 0.9624080657958984
Epoch: 47, Steps: 120 | Train Loss: 0.0998348 Vali Loss: 0.9641255 Test Loss: 0.4222172
Validation loss decreased (0.964273 --> 0.964126).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1025358
	speed: 0.0215s/iter; left time: 5.6044s
Epoch: 48 cost time: 0.9584310054779053
Epoch: 48, Steps: 120 | Train Loss: 0.0995993 Vali Loss: 0.9640797 Test Loss: 0.4220360
Validation loss decreased (0.964126 --> 0.964080).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1039549
	speed: 0.0227s/iter; left time: 3.2009s
Epoch: 49 cost time: 0.9969158172607422
Epoch: 49, Steps: 120 | Train Loss: 0.0994750 Vali Loss: 0.9639457 Test Loss: 0.4217347
Validation loss decreased (0.964080 --> 0.963946).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.0976620
	speed: 0.0219s/iter; left time: 0.4600s
Epoch: 50 cost time: 0.9382319450378418
Epoch: 50, Steps: 120 | Train Loss: 0.0992442 Vali Loss: 0.9640142 Test Loss: 0.4215440
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.0497355408796396e-05
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=196, out_features=248, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  21776384.0
params:  48856.0
Trainable parameters:  48856
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3593990
	speed: 0.0172s/iter; left time: 101.2105s
Epoch: 1 cost time: 1.872189998626709
Epoch: 1, Steps: 120 | Train Loss: 0.3839710 Vali Loss: 0.9608026 Test Loss: 0.4178117
Validation loss decreased (inf --> 0.960803).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3740068
	speed: 0.0391s/iter; left time: 226.1468s
Epoch: 2 cost time: 2.0368521213531494
Epoch: 2, Steps: 120 | Train Loss: 0.3816897 Vali Loss: 0.9608182 Test Loss: 0.4185450
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4228308
	speed: 0.0391s/iter; left time: 221.0794s
Epoch: 3 cost time: 2.0165207386016846
Epoch: 3, Steps: 120 | Train Loss: 0.3807899 Vali Loss: 0.9623893 Test Loss: 0.4183539
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4028967
	speed: 0.0397s/iter; left time: 220.2094s
Epoch: 4 cost time: 1.9363157749176025
Epoch: 4, Steps: 120 | Train Loss: 0.3799847 Vali Loss: 0.9627828 Test Loss: 0.4182533
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh1_720_192_FITS_ETTh1_ftM_sl720_ll48_pl192_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.4162866771221161, mae:0.42431825399398804, rse:0.6127080321311951, corr:[0.26870364 0.27404955 0.2732887  0.27172384 0.26969835 0.2675949
 0.26637313 0.2659126  0.26553556 0.2652795  0.26526552 0.2655365
 0.2655976  0.26507404 0.26430416 0.26397514 0.2640107  0.26394728
 0.26326752 0.26207986 0.26099637 0.2605968  0.26092243 0.26108333
 0.26042593 0.259629   0.25949505 0.2596627  0.25990525 0.26028913
 0.2606081  0.26039544 0.2600209  0.26004353 0.26031557 0.2604825
 0.26033542 0.26005003 0.2597342  0.2596647  0.25993225 0.26011974
 0.26015532 0.2601882  0.26016745 0.2601359  0.26042268 0.26090783
 0.26085344 0.25970906 0.25786987 0.25640425 0.25534686 0.25423336
 0.2537059  0.25393885 0.25408286 0.2536058  0.2528589  0.25270382
 0.2526479  0.2526127  0.2531212  0.25387648 0.25376144 0.25290668
 0.25249493 0.2526416  0.2525484  0.25200558 0.2515392  0.25150862
 0.25196734 0.25217965 0.25147524 0.2503188  0.2494049  0.24910085
 0.24894655 0.24851488 0.24818309 0.24842142 0.2485718  0.24816509
 0.24775425 0.24755006 0.24721234 0.24660686 0.24628423 0.24640168
 0.24647802 0.24653551 0.24689238 0.24732222 0.2474337  0.2476591
 0.24821194 0.24854472 0.24845318 0.24851787 0.2486903  0.24842374
 0.24797219 0.24782804 0.24760862 0.24689943 0.24609831 0.2458551
 0.24594021 0.24571429 0.24540465 0.24526857 0.24508235 0.24518956
 0.24574749 0.2459769  0.24537799 0.2444187  0.24367279 0.24320985
 0.24300633 0.24274945 0.24205737 0.24106663 0.24023183 0.23974544
 0.23955593 0.23961534 0.24022497 0.24130891 0.24132112 0.2402429
 0.23959827 0.23999529 0.24003132 0.23912744 0.23872118 0.23946156
 0.24032201 0.24015792 0.239506   0.23912118 0.23867978 0.23782532
 0.23704574 0.23675023 0.2368244  0.2363763  0.23490307 0.23299207
 0.23225282 0.23264642 0.23270787 0.23214608 0.23153643 0.23133558
 0.23121564 0.23125814 0.23136938 0.23077974 0.2300165  0.23055278
 0.23190154 0.23180217 0.23022673 0.22927104 0.22961442 0.22957332
 0.22922643 0.22978728 0.23023158 0.22937779 0.22823815 0.22804281
 0.22760995 0.2269704  0.22719713 0.2281525  0.22781403 0.22687697
 0.22681499 0.2263515  0.22432043 0.2230106  0.22343433 0.2232786
 0.22279666 0.22414729 0.22452882 0.22199784 0.22249073 0.22478366]
