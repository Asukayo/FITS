Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=7, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:7
>>>>>>>start training : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=196, out_features=222, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  77973504.0
params:  43734.0
Trainable parameters:  43734
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 4.980067014694214
Epoch: 1, Steps: 30 | Train Loss: 0.6707836 Vali Loss: 1.5406855 Test Loss: 0.8681238
Validation loss decreased (inf --> 1.540686).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.986924886703491
Epoch: 2, Steps: 30 | Train Loss: 0.5715690 Vali Loss: 1.3787796 Test Loss: 0.8021042
Validation loss decreased (1.540686 --> 1.378780).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 5.3225157260894775
Epoch: 3, Steps: 30 | Train Loss: 0.5110052 Vali Loss: 1.3092961 Test Loss: 0.7727113
Validation loss decreased (1.378780 --> 1.309296).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 5.3326215744018555
Epoch: 4, Steps: 30 | Train Loss: 0.4710627 Vali Loss: 1.2746077 Test Loss: 0.7575386
Validation loss decreased (1.309296 --> 1.274608).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 5.808281421661377
Epoch: 5, Steps: 30 | Train Loss: 0.4437096 Vali Loss: 1.2571819 Test Loss: 0.7518076
Validation loss decreased (1.274608 --> 1.257182).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 5.748666286468506
Epoch: 6, Steps: 30 | Train Loss: 0.4236022 Vali Loss: 1.2431459 Test Loss: 0.7487650
Validation loss decreased (1.257182 --> 1.243146).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 5.742789268493652
Epoch: 7, Steps: 30 | Train Loss: 0.4070457 Vali Loss: 1.2380645 Test Loss: 0.7472705
Validation loss decreased (1.243146 --> 1.238065).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 5.695458889007568
Epoch: 8, Steps: 30 | Train Loss: 0.3933695 Vali Loss: 1.2278118 Test Loss: 0.7461207
Validation loss decreased (1.238065 --> 1.227812).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 5.481686592102051
Epoch: 9, Steps: 30 | Train Loss: 0.3812669 Vali Loss: 1.2238016 Test Loss: 0.7450071
Validation loss decreased (1.227812 --> 1.223802).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 5.42012619972229
Epoch: 10, Steps: 30 | Train Loss: 0.3701913 Vali Loss: 1.2151457 Test Loss: 0.7415121
Validation loss decreased (1.223802 --> 1.215146).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 5.580896377563477
Epoch: 11, Steps: 30 | Train Loss: 0.3610108 Vali Loss: 1.2110425 Test Loss: 0.7389059
Validation loss decreased (1.215146 --> 1.211043).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 5.81917142868042
Epoch: 12, Steps: 30 | Train Loss: 0.3523243 Vali Loss: 1.2102535 Test Loss: 0.7381138
Validation loss decreased (1.211043 --> 1.210253).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 6.3229897022247314
Epoch: 13, Steps: 30 | Train Loss: 0.3445665 Vali Loss: 1.1972188 Test Loss: 0.7344656
Validation loss decreased (1.210253 --> 1.197219).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 6.382606267929077
Epoch: 14, Steps: 30 | Train Loss: 0.3375516 Vali Loss: 1.1974002 Test Loss: 0.7302575
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 6.243600606918335
Epoch: 15, Steps: 30 | Train Loss: 0.3306027 Vali Loss: 1.1922308 Test Loss: 0.7271193
Validation loss decreased (1.197219 --> 1.192231).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 6.415273189544678
Epoch: 16, Steps: 30 | Train Loss: 0.3248346 Vali Loss: 1.1893036 Test Loss: 0.7249064
Validation loss decreased (1.192231 --> 1.189304).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 6.340749263763428
Epoch: 17, Steps: 30 | Train Loss: 0.3190334 Vali Loss: 1.1784556 Test Loss: 0.7208586
Validation loss decreased (1.189304 --> 1.178456).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 6.433373689651489
Epoch: 18, Steps: 30 | Train Loss: 0.3139213 Vali Loss: 1.1833320 Test Loss: 0.7176315
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 6.304409742355347
Epoch: 19, Steps: 30 | Train Loss: 0.3087947 Vali Loss: 1.1769966 Test Loss: 0.7147193
Validation loss decreased (1.178456 --> 1.176997).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 6.301087141036987
Epoch: 20, Steps: 30 | Train Loss: 0.3046673 Vali Loss: 1.1674099 Test Loss: 0.7124174
Validation loss decreased (1.176997 --> 1.167410).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 5.763830184936523
Epoch: 21, Steps: 30 | Train Loss: 0.3001514 Vali Loss: 1.1612502 Test Loss: 0.7083901
Validation loss decreased (1.167410 --> 1.161250).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 5.571120262145996
Epoch: 22, Steps: 30 | Train Loss: 0.2959270 Vali Loss: 1.1602858 Test Loss: 0.7064535
Validation loss decreased (1.161250 --> 1.160286).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 6.369210720062256
Epoch: 23, Steps: 30 | Train Loss: 0.2926170 Vali Loss: 1.1497838 Test Loss: 0.7028385
Validation loss decreased (1.160286 --> 1.149784).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 6.482312917709351
Epoch: 24, Steps: 30 | Train Loss: 0.2888715 Vali Loss: 1.1482328 Test Loss: 0.7006010
Validation loss decreased (1.149784 --> 1.148233).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 5.91787052154541
Epoch: 25, Steps: 30 | Train Loss: 0.2856828 Vali Loss: 1.1481721 Test Loss: 0.6967298
Validation loss decreased (1.148233 --> 1.148172).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 5.83371114730835
Epoch: 26, Steps: 30 | Train Loss: 0.2823775 Vali Loss: 1.1371129 Test Loss: 0.6953817
Validation loss decreased (1.148172 --> 1.137113).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 6.3857080936431885
Epoch: 27, Steps: 30 | Train Loss: 0.2797113 Vali Loss: 1.1397340 Test Loss: 0.6928083
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 6.096009254455566
Epoch: 28, Steps: 30 | Train Loss: 0.2769999 Vali Loss: 1.1338021 Test Loss: 0.6896117
Validation loss decreased (1.137113 --> 1.133802).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 5.808003664016724
Epoch: 29, Steps: 30 | Train Loss: 0.2744458 Vali Loss: 1.1285789 Test Loss: 0.6882519
Validation loss decreased (1.133802 --> 1.128579).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 5.922712087631226
Epoch: 30, Steps: 30 | Train Loss: 0.2723601 Vali Loss: 1.1243534 Test Loss: 0.6851553
Validation loss decreased (1.128579 --> 1.124353).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 5.720827102661133
Epoch: 31, Steps: 30 | Train Loss: 0.2698203 Vali Loss: 1.1299090 Test Loss: 0.6841114
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 6.037154197692871
Epoch: 32, Steps: 30 | Train Loss: 0.2674738 Vali Loss: 1.1183890 Test Loss: 0.6824284
Validation loss decreased (1.124353 --> 1.118389).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 5.502825736999512
Epoch: 33, Steps: 30 | Train Loss: 0.2655816 Vali Loss: 1.1137159 Test Loss: 0.6801011
Validation loss decreased (1.118389 --> 1.113716).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 6.285409927368164
Epoch: 34, Steps: 30 | Train Loss: 0.2636240 Vali Loss: 1.1169273 Test Loss: 0.6778128
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 5.955404043197632
Epoch: 35, Steps: 30 | Train Loss: 0.2620160 Vali Loss: 1.1086847 Test Loss: 0.6764159
Validation loss decreased (1.113716 --> 1.108685).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 5.706051826477051
Epoch: 36, Steps: 30 | Train Loss: 0.2600482 Vali Loss: 1.1071873 Test Loss: 0.6746426
Validation loss decreased (1.108685 --> 1.107187).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 5.866153955459595
Epoch: 37, Steps: 30 | Train Loss: 0.2586259 Vali Loss: 1.1036621 Test Loss: 0.6728535
Validation loss decreased (1.107187 --> 1.103662).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 5.569453477859497
Epoch: 38, Steps: 30 | Train Loss: 0.2569642 Vali Loss: 1.1032752 Test Loss: 0.6717730
Validation loss decreased (1.103662 --> 1.103275).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 5.354520797729492
Epoch: 39, Steps: 30 | Train Loss: 0.2554000 Vali Loss: 1.0998900 Test Loss: 0.6700025
Validation loss decreased (1.103275 --> 1.099890).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 5.78399133682251
Epoch: 40, Steps: 30 | Train Loss: 0.2544388 Vali Loss: 1.0977536 Test Loss: 0.6689864
Validation loss decreased (1.099890 --> 1.097754).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 5.5418548583984375
Epoch: 41, Steps: 30 | Train Loss: 0.2530180 Vali Loss: 1.0933428 Test Loss: 0.6681726
Validation loss decreased (1.097754 --> 1.093343).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 6.052278995513916
Epoch: 42, Steps: 30 | Train Loss: 0.2519954 Vali Loss: 1.0935756 Test Loss: 0.6662621
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 6.185932874679565
Epoch: 43, Steps: 30 | Train Loss: 0.2506791 Vali Loss: 1.0923355 Test Loss: 0.6652674
Validation loss decreased (1.093343 --> 1.092335).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 5.780963182449341
Epoch: 44, Steps: 30 | Train Loss: 0.2496335 Vali Loss: 1.0945913 Test Loss: 0.6641106
EarlyStopping counter: 1 out of 3
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 6.039489507675171
Epoch: 45, Steps: 30 | Train Loss: 0.2486036 Vali Loss: 1.0794437 Test Loss: 0.6632296
Validation loss decreased (1.092335 --> 1.079444).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 5.7712390422821045
Epoch: 46, Steps: 30 | Train Loss: 0.2475095 Vali Loss: 1.0960648 Test Loss: 0.6623111
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 4.9610443115234375
Epoch: 47, Steps: 30 | Train Loss: 0.2466140 Vali Loss: 1.0849570 Test Loss: 0.6608801
EarlyStopping counter: 2 out of 3
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 5.385958909988403
Epoch: 48, Steps: 30 | Train Loss: 0.2459726 Vali Loss: 1.0920020 Test Loss: 0.6599495
EarlyStopping counter: 3 out of 3
Early stopping
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=196, out_features=222, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  77973504.0
params:  43734.0
Trainable parameters:  43734
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 5.888333082199097
Epoch: 1, Steps: 30 | Train Loss: 0.4568591 Vali Loss: 0.8831968 Test Loss: 0.5060278
Validation loss decreased (inf --> 0.883197).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.3035383224487305
Epoch: 2, Steps: 30 | Train Loss: 0.3890885 Vali Loss: 0.7831634 Test Loss: 0.4297268
Validation loss decreased (0.883197 --> 0.783163).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.9652061462402344
Epoch: 3, Steps: 30 | Train Loss: 0.3585700 Vali Loss: 0.7422535 Test Loss: 0.3988878
Validation loss decreased (0.783163 --> 0.742253).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.683655261993408
Epoch: 4, Steps: 30 | Train Loss: 0.3456792 Vali Loss: 0.7226761 Test Loss: 0.3867603
Validation loss decreased (0.742253 --> 0.722676).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.358910083770752
Epoch: 5, Steps: 30 | Train Loss: 0.3398054 Vali Loss: 0.7166410 Test Loss: 0.3827830
Validation loss decreased (0.722676 --> 0.716641).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.2598235607147217
Epoch: 6, Steps: 30 | Train Loss: 0.3375877 Vali Loss: 0.7050527 Test Loss: 0.3809771
Validation loss decreased (0.716641 --> 0.705053).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.955503225326538
Epoch: 7, Steps: 30 | Train Loss: 0.3358864 Vali Loss: 0.7072837 Test Loss: 0.3809487
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.9368438720703125
Epoch: 8, Steps: 30 | Train Loss: 0.3351715 Vali Loss: 0.7008108 Test Loss: 0.3804169
Validation loss decreased (0.705053 --> 0.700811).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 5.745898723602295
Epoch: 9, Steps: 30 | Train Loss: 0.3346900 Vali Loss: 0.7061496 Test Loss: 0.3803367
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 5.491310119628906
Epoch: 10, Steps: 30 | Train Loss: 0.3345411 Vali Loss: 0.7002314 Test Loss: 0.3802496
Validation loss decreased (0.700811 --> 0.700231).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 5.4980995655059814
Epoch: 11, Steps: 30 | Train Loss: 0.3339467 Vali Loss: 0.6992226 Test Loss: 0.3805429
Validation loss decreased (0.700231 --> 0.699223).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 5.321061372756958
Epoch: 12, Steps: 30 | Train Loss: 0.3331151 Vali Loss: 0.7071691 Test Loss: 0.3803490
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 5.7162556648254395
Epoch: 13, Steps: 30 | Train Loss: 0.3322690 Vali Loss: 0.7019551 Test Loss: 0.3803066
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 5.60293436050415
Epoch: 14, Steps: 30 | Train Loss: 0.3329720 Vali Loss: 0.7008334 Test Loss: 0.3802072
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.37974756956100464, mae:0.4029353857040405, rse:0.5853361487388611, corr:[0.2726129  0.27895623 0.27916548 0.27978235 0.2775753  0.27432993
 0.27311966 0.2733584  0.27289084 0.2719992  0.27173567 0.2718717
 0.27173463 0.27126738 0.27112064 0.27122027 0.27103    0.27064785
 0.2703535  0.2701205  0.26978272 0.26940352 0.26914337 0.2695691
 0.2696777  0.2692348  0.2689564  0.26901463 0.26891407 0.2683967
 0.26790804 0.26767412 0.26759598 0.2673174  0.26670855 0.2665214
 0.26683438 0.26715758 0.26726928 0.2672148  0.26742676 0.2676788
 0.2676486  0.26738527 0.26720715 0.26738226 0.26790804 0.26843452
 0.26827475 0.2676396  0.26661938 0.2655924  0.26447365 0.26302046
 0.2619797  0.2611651  0.26036835 0.26019907 0.26014066 0.26023647
 0.2600537  0.259939   0.25992227 0.2599239  0.25989404 0.26006442
 0.26070744 0.2607367  0.2600424  0.25962457 0.26004317 0.2602906
 0.25945157 0.258077   0.25718212 0.2573247  0.25684416 0.25561553
 0.25477177 0.25417063 0.25314093 0.2525867  0.2527957  0.25238758
 0.25099304 0.24995348 0.25025666 0.25052938 0.2504182  0.24997915
 0.24902645 0.24797185 0.2466614  0.24341714 0.24197695 0.24606007]
