Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=7, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:7
>>>>>>>start training : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=196, out_features=222, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  19493376.0
params:  43734.0
Trainable parameters:  43734
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4837140
	speed: 0.0082s/iter; left time: 49.0074s
Epoch: 1 cost time: 0.9942195415496826
Epoch: 1, Steps: 122 | Train Loss: 0.5634642 Vali Loss: 1.2701588 Test Loss: 0.7452188
Validation loss decreased (inf --> 1.270159).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3915865
	speed: 0.0243s/iter; left time: 142.9560s
Epoch: 2 cost time: 1.1594128608703613
Epoch: 2, Steps: 122 | Train Loss: 0.4125182 Vali Loss: 1.2042037 Test Loss: 0.7243385
Validation loss decreased (1.270159 --> 1.204204).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3083470
	speed: 0.0254s/iter; left time: 146.3548s
Epoch: 3 cost time: 1.1873583793640137
Epoch: 3, Steps: 122 | Train Loss: 0.3475434 Vali Loss: 1.1700743 Test Loss: 0.7043669
Validation loss decreased (1.204204 --> 1.170074).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2983066
	speed: 0.0243s/iter; left time: 136.7111s
Epoch: 4 cost time: 1.0437512397766113
Epoch: 4, Steps: 122 | Train Loss: 0.3023587 Vali Loss: 1.1311448 Test Loss: 0.6814422
Validation loss decreased (1.170074 --> 1.131145).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2494810
	speed: 0.0243s/iter; left time: 133.8660s
Epoch: 5 cost time: 1.117457628250122
Epoch: 5, Steps: 122 | Train Loss: 0.2669219 Vali Loss: 1.0889001 Test Loss: 0.6555174
Validation loss decreased (1.131145 --> 1.088900).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2263887
	speed: 0.0250s/iter; left time: 134.9360s
Epoch: 6 cost time: 1.0973761081695557
Epoch: 6, Steps: 122 | Train Loss: 0.2380071 Vali Loss: 1.0489757 Test Loss: 0.6293056
Validation loss decreased (1.088900 --> 1.048976).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2179542
	speed: 0.0250s/iter; left time: 131.6832s
Epoch: 7 cost time: 1.1971349716186523
Epoch: 7, Steps: 122 | Train Loss: 0.2139417 Vali Loss: 1.0067830 Test Loss: 0.6000817
Validation loss decreased (1.048976 --> 1.006783).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1848768
	speed: 0.0259s/iter; left time: 133.2084s
Epoch: 8 cost time: 1.1637165546417236
Epoch: 8, Steps: 122 | Train Loss: 0.1937390 Vali Loss: 0.9688318 Test Loss: 0.5739145
Validation loss decreased (1.006783 --> 0.968832).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1658328
	speed: 0.0242s/iter; left time: 121.6977s
Epoch: 9 cost time: 1.1122584342956543
Epoch: 9, Steps: 122 | Train Loss: 0.1766947 Vali Loss: 0.9439473 Test Loss: 0.5554795
Validation loss decreased (0.968832 --> 0.943947).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1656189
	speed: 0.0244s/iter; left time: 119.4598s
Epoch: 10 cost time: 1.0710628032684326
Epoch: 10, Steps: 122 | Train Loss: 0.1620544 Vali Loss: 0.9109068 Test Loss: 0.5350656
Validation loss decreased (0.943947 --> 0.910907).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1436290
	speed: 0.0235s/iter; left time: 112.2580s
Epoch: 11 cost time: 1.0423071384429932
Epoch: 11, Steps: 122 | Train Loss: 0.1497083 Vali Loss: 0.8960631 Test Loss: 0.5214655
Validation loss decreased (0.910907 --> 0.896063).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1565382
	speed: 0.0227s/iter; left time: 105.6066s
Epoch: 12 cost time: 1.0393528938293457
Epoch: 12, Steps: 122 | Train Loss: 0.1389973 Vali Loss: 0.8688700 Test Loss: 0.5047028
Validation loss decreased (0.896063 --> 0.868870).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1374270
	speed: 0.0232s/iter; left time: 105.1167s
Epoch: 13 cost time: 1.044494390487671
Epoch: 13, Steps: 122 | Train Loss: 0.1297983 Vali Loss: 0.8583538 Test Loss: 0.4957153
Validation loss decreased (0.868870 --> 0.858354).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1260601
	speed: 0.0256s/iter; left time: 113.0033s
Epoch: 14 cost time: 1.1783010959625244
Epoch: 14, Steps: 122 | Train Loss: 0.1218075 Vali Loss: 0.8398545 Test Loss: 0.4829499
Validation loss decreased (0.858354 --> 0.839854).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1153040
	speed: 0.0236s/iter; left time: 101.1563s
Epoch: 15 cost time: 1.056797981262207
Epoch: 15, Steps: 122 | Train Loss: 0.1149078 Vali Loss: 0.8221927 Test Loss: 0.4702387
Validation loss decreased (0.839854 --> 0.822193).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1075119
	speed: 0.0238s/iter; left time: 99.3549s
Epoch: 16 cost time: 0.989302396774292
Epoch: 16, Steps: 122 | Train Loss: 0.1088096 Vali Loss: 0.8125210 Test Loss: 0.4627914
Validation loss decreased (0.822193 --> 0.812521).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1023619
	speed: 0.0244s/iter; left time: 98.8071s
Epoch: 17 cost time: 1.0463175773620605
Epoch: 17, Steps: 122 | Train Loss: 0.1035655 Vali Loss: 0.7981562 Test Loss: 0.4545322
Validation loss decreased (0.812521 --> 0.798156).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.0920738
	speed: 0.0240s/iter; left time: 94.2231s
Epoch: 18 cost time: 1.105989933013916
Epoch: 18, Steps: 122 | Train Loss: 0.0989119 Vali Loss: 0.7880028 Test Loss: 0.4482918
Validation loss decreased (0.798156 --> 0.788003).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.0947233
	speed: 0.0241s/iter; left time: 91.8463s
Epoch: 19 cost time: 1.0352096557617188
Epoch: 19, Steps: 122 | Train Loss: 0.0948640 Vali Loss: 0.7791423 Test Loss: 0.4404792
Validation loss decreased (0.788003 --> 0.779142).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.0946127
	speed: 0.0244s/iter; left time: 89.7456s
Epoch: 20 cost time: 1.064744234085083
Epoch: 20, Steps: 122 | Train Loss: 0.0913020 Vali Loss: 0.7736008 Test Loss: 0.4381683
Validation loss decreased (0.779142 --> 0.773601).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.0902638
	speed: 0.0236s/iter; left time: 83.9608s
Epoch: 21 cost time: 0.9902164936065674
Epoch: 21, Steps: 122 | Train Loss: 0.0880918 Vali Loss: 0.7642196 Test Loss: 0.4301560
Validation loss decreased (0.773601 --> 0.764220).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.0840662
	speed: 0.0241s/iter; left time: 82.9046s
Epoch: 22 cost time: 1.0715279579162598
Epoch: 22, Steps: 122 | Train Loss: 0.0852579 Vali Loss: 0.7608810 Test Loss: 0.4264846
Validation loss decreased (0.764220 --> 0.760881).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.0808215
	speed: 0.0244s/iter; left time: 81.0211s
Epoch: 23 cost time: 1.068286418914795
Epoch: 23, Steps: 122 | Train Loss: 0.0827519 Vali Loss: 0.7539588 Test Loss: 0.4223535
Validation loss decreased (0.760881 --> 0.753959).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.0799286
	speed: 0.0240s/iter; left time: 76.5673s
Epoch: 24 cost time: 1.1028599739074707
Epoch: 24, Steps: 122 | Train Loss: 0.0805162 Vali Loss: 0.7512618 Test Loss: 0.4193565
Validation loss decreased (0.753959 --> 0.751262).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.0757279
	speed: 0.0232s/iter; left time: 71.3950s
Epoch: 25 cost time: 1.089637279510498
Epoch: 25, Steps: 122 | Train Loss: 0.0785262 Vali Loss: 0.7479648 Test Loss: 0.4165483
Validation loss decreased (0.751262 --> 0.747965).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.0823430
	speed: 0.0229s/iter; left time: 67.5364s
Epoch: 26 cost time: 0.990321159362793
Epoch: 26, Steps: 122 | Train Loss: 0.0767438 Vali Loss: 0.7401899 Test Loss: 0.4133730
Validation loss decreased (0.747965 --> 0.740190).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.0693849
	speed: 0.0231s/iter; left time: 65.4091s
Epoch: 27 cost time: 1.0549349784851074
Epoch: 27, Steps: 122 | Train Loss: 0.0751203 Vali Loss: 0.7382120 Test Loss: 0.4103096
Validation loss decreased (0.740190 --> 0.738212).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.0698265
	speed: 0.0236s/iter; left time: 63.8441s
Epoch: 28 cost time: 1.138465404510498
Epoch: 28, Steps: 122 | Train Loss: 0.0736702 Vali Loss: 0.7341135 Test Loss: 0.4078499
Validation loss decreased (0.738212 --> 0.734113).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.0744984
	speed: 0.0239s/iter; left time: 61.8513s
Epoch: 29 cost time: 1.129422903060913
Epoch: 29, Steps: 122 | Train Loss: 0.0724172 Vali Loss: 0.7324117 Test Loss: 0.4054676
Validation loss decreased (0.734113 --> 0.732412).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.0646742
	speed: 0.0248s/iter; left time: 61.0169s
Epoch: 30 cost time: 1.0662429332733154
Epoch: 30, Steps: 122 | Train Loss: 0.0712384 Vali Loss: 0.7287503 Test Loss: 0.4046426
Validation loss decreased (0.732412 --> 0.728750).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.0639043
	speed: 0.0253s/iter; left time: 59.1958s
Epoch: 31 cost time: 1.1284611225128174
Epoch: 31, Steps: 122 | Train Loss: 0.0701830 Vali Loss: 0.7270025 Test Loss: 0.4026326
Validation loss decreased (0.728750 --> 0.727003).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.0644403
	speed: 0.0270s/iter; left time: 59.8179s
Epoch: 32 cost time: 1.266913890838623
Epoch: 32, Steps: 122 | Train Loss: 0.0692131 Vali Loss: 0.7252496 Test Loss: 0.4011024
Validation loss decreased (0.727003 --> 0.725250).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.0702127
	speed: 0.0235s/iter; left time: 49.2173s
Epoch: 33 cost time: 0.991750955581665
Epoch: 33, Steps: 122 | Train Loss: 0.0683671 Vali Loss: 0.7221293 Test Loss: 0.4003305
Validation loss decreased (0.725250 --> 0.722129).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.0665527
	speed: 0.0229s/iter; left time: 45.2857s
Epoch: 34 cost time: 1.042586088180542
Epoch: 34, Steps: 122 | Train Loss: 0.0675898 Vali Loss: 0.7235819 Test Loss: 0.3993083
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.0593593
	speed: 0.0231s/iter; left time: 42.8362s
Epoch: 35 cost time: 1.0930514335632324
Epoch: 35, Steps: 122 | Train Loss: 0.0668488 Vali Loss: 0.7208487 Test Loss: 0.3978506
Validation loss decreased (0.722129 --> 0.720849).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.0632342
	speed: 0.0240s/iter; left time: 41.5706s
Epoch: 36 cost time: 1.0871660709381104
Epoch: 36, Steps: 122 | Train Loss: 0.0661968 Vali Loss: 0.7187868 Test Loss: 0.3966398
Validation loss decreased (0.720849 --> 0.718787).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.0689033
	speed: 0.0241s/iter; left time: 38.7845s
Epoch: 37 cost time: 1.00425386428833
Epoch: 37, Steps: 122 | Train Loss: 0.0655957 Vali Loss: 0.7182757 Test Loss: 0.3958558
Validation loss decreased (0.718787 --> 0.718276).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.0687043
	speed: 0.0249s/iter; left time: 37.0283s
Epoch: 38 cost time: 1.1179261207580566
Epoch: 38, Steps: 122 | Train Loss: 0.0650758 Vali Loss: 0.7166566 Test Loss: 0.3954610
Validation loss decreased (0.718276 --> 0.716657).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.0659843
	speed: 0.0262s/iter; left time: 35.8129s
Epoch: 39 cost time: 1.1773779392242432
Epoch: 39, Steps: 122 | Train Loss: 0.0645854 Vali Loss: 0.7148938 Test Loss: 0.3942406
Validation loss decreased (0.716657 --> 0.714894).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.0659268
	speed: 0.0246s/iter; left time: 30.5879s
Epoch: 40 cost time: 1.0779054164886475
Epoch: 40, Steps: 122 | Train Loss: 0.0641443 Vali Loss: 0.7156536 Test Loss: 0.3934179
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.0630117
	speed: 0.0237s/iter; left time: 26.5327s
Epoch: 41 cost time: 1.0990605354309082
Epoch: 41, Steps: 122 | Train Loss: 0.0637075 Vali Loss: 0.7141982 Test Loss: 0.3926871
Validation loss decreased (0.714894 --> 0.714198).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.0609646
	speed: 0.0241s/iter; left time: 24.1096s
Epoch: 42 cost time: 1.0324785709381104
Epoch: 42, Steps: 122 | Train Loss: 0.0633397 Vali Loss: 0.7131922 Test Loss: 0.3922091
Validation loss decreased (0.714198 --> 0.713192).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.0707249
	speed: 0.0276s/iter; left time: 24.2329s
Epoch: 43 cost time: 1.1619510650634766
Epoch: 43, Steps: 122 | Train Loss: 0.0629747 Vali Loss: 0.7132762 Test Loss: 0.3917552
EarlyStopping counter: 1 out of 3
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.0635764
	speed: 0.0239s/iter; left time: 18.0119s
Epoch: 44 cost time: 1.0746958255767822
Epoch: 44, Steps: 122 | Train Loss: 0.0626584 Vali Loss: 0.7121521 Test Loss: 0.3912679
Validation loss decreased (0.713192 --> 0.712152).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.0618749
	speed: 0.0230s/iter; left time: 14.5444s
Epoch: 45 cost time: 0.9647476673126221
Epoch: 45, Steps: 122 | Train Loss: 0.0623654 Vali Loss: 0.7120343 Test Loss: 0.3907140
Validation loss decreased (0.712152 --> 0.712034).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.0616743
	speed: 0.0232s/iter; left time: 11.8485s
Epoch: 46 cost time: 1.0524020195007324
Epoch: 46, Steps: 122 | Train Loss: 0.0620935 Vali Loss: 0.7108923 Test Loss: 0.3904905
Validation loss decreased (0.712034 --> 0.710892).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.0629525
	speed: 0.0246s/iter; left time: 9.5548s
Epoch: 47 cost time: 1.1353583335876465
Epoch: 47, Steps: 122 | Train Loss: 0.0618570 Vali Loss: 0.7103313 Test Loss: 0.3899660
Validation loss decreased (0.710892 --> 0.710331).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.0653894
	speed: 0.0259s/iter; left time: 6.9176s
Epoch: 48 cost time: 1.3559672832489014
Epoch: 48, Steps: 122 | Train Loss: 0.0615927 Vali Loss: 0.7104986 Test Loss: 0.3896263
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.0613392
	speed: 0.0357s/iter; left time: 5.1721s
Epoch: 49 cost time: 1.5945031642913818
Epoch: 49, Steps: 122 | Train Loss: 0.0614161 Vali Loss: 0.7061381 Test Loss: 0.3891963
Validation loss decreased (0.710331 --> 0.706138).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.0563533
	speed: 0.0382s/iter; left time: 0.8797s
Epoch: 50 cost time: 1.6273396015167236
Epoch: 50, Steps: 122 | Train Loss: 0.0612170 Vali Loss: 0.7093844 Test Loss: 0.3889245
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.0497355408796396e-05
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=196, out_features=222, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  19493376.0
params:  43734.0
Trainable parameters:  43734
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3733857
	speed: 0.0178s/iter; left time: 106.8172s
Epoch: 1 cost time: 1.9896292686462402
Epoch: 1, Steps: 122 | Train Loss: 0.3370875 Vali Loss: 0.7052736 Test Loss: 0.3852830
Validation loss decreased (inf --> 0.705274).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3344457
	speed: 0.0408s/iter; left time: 239.8158s
Epoch: 2 cost time: 2.128655433654785
Epoch: 2, Steps: 122 | Train Loss: 0.3350327 Vali Loss: 0.6974018 Test Loss: 0.3835000
Validation loss decreased (0.705274 --> 0.697402).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3248504
	speed: 0.0408s/iter; left time: 234.6947s
Epoch: 3 cost time: 1.9018585681915283
Epoch: 3, Steps: 122 | Train Loss: 0.3338657 Vali Loss: 0.7012785 Test Loss: 0.3827586
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3775904
	speed: 0.0420s/iter; left time: 236.5409s
Epoch: 4 cost time: 1.8772096633911133
Epoch: 4, Steps: 122 | Train Loss: 0.3332450 Vali Loss: 0.6903408 Test Loss: 0.3811332
Validation loss decreased (0.697402 --> 0.690341).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3128597
	speed: 0.0383s/iter; left time: 210.8877s
Epoch: 5 cost time: 1.7832207679748535
Epoch: 5, Steps: 122 | Train Loss: 0.3327087 Vali Loss: 0.7010770 Test Loss: 0.3824582
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3237746
	speed: 0.0392s/iter; left time: 211.1848s
Epoch: 6 cost time: 2.0043528079986572
Epoch: 6, Steps: 122 | Train Loss: 0.3323853 Vali Loss: 0.6961514 Test Loss: 0.3829816
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3558752
	speed: 0.0404s/iter; left time: 212.8007s
Epoch: 7 cost time: 2.1511127948760986
Epoch: 7, Steps: 122 | Train Loss: 0.3321603 Vali Loss: 0.6965515 Test Loss: 0.3818877
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.380662202835083, mae:0.40397921204566956, rse:0.5860406756401062, corr:[0.27243072 0.28100538 0.2811087  0.27977797 0.27780402 0.27545184
 0.27417114 0.27402776 0.27343845 0.27250072 0.27213225 0.27208778
 0.2717238  0.2713067  0.27129206 0.2712814  0.27082828 0.27068764
 0.27069882 0.2700305  0.2688693  0.2683318  0.26855773 0.269007
 0.26882282 0.2681534  0.2678166  0.2678749  0.26763466 0.26687655
 0.26625615 0.26611096 0.2663691  0.26637328 0.2658435  0.26556727
 0.26583478 0.26624838 0.26651114 0.2666077  0.26693088 0.26744366
 0.2678021  0.267544   0.26676467 0.2662659  0.26662967 0.26702252
 0.26626766 0.2649353  0.26401213 0.26357293 0.26253957 0.26039612
 0.25840876 0.25738788 0.25729486 0.25766143 0.2574073  0.25739717
 0.25792906 0.2582148  0.2572367  0.25599676 0.25571486 0.25636214
 0.25740063 0.25785217 0.25753626 0.2568721  0.25695026 0.2577801
 0.2580242  0.25669768 0.25499967 0.25477904 0.25514135 0.2548425
 0.25391087 0.25277537 0.2517644  0.2513294  0.25091246 0.24977529
 0.24859588 0.2481499  0.24779147 0.24681534 0.24689062 0.24776162
 0.24704973 0.24601379 0.24724567 0.24764131 0.2476378  0.25269166]
