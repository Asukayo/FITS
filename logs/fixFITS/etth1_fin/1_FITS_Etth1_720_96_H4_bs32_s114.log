Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=7, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:7
>>>>>>>start training : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=134, out_features=151, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  9064832.0
params:  20385.0
Trainable parameters:  20385
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4057910
	speed: 0.1509s/iter; left time: 905.5971s
Epoch: 1 cost time: 18.24077582359314
Epoch: 1, Steps: 122 | Train Loss: 0.4907297 Vali Loss: 0.8157874 Test Loss: 0.4113430
Validation loss decreased (inf --> 0.815787).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3055824
	speed: 0.4093s/iter; left time: 2406.1674s
Epoch: 2 cost time: 18.93467617034912
Epoch: 2, Steps: 122 | Train Loss: 0.3598126 Vali Loss: 0.7546530 Test Loss: 0.3852354
Validation loss decreased (0.815787 --> 0.754653).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3606025
	speed: 0.4009s/iter; left time: 2308.2646s
Epoch: 3 cost time: 18.576131343841553
Epoch: 3, Steps: 122 | Train Loss: 0.3483909 Vali Loss: 0.7358576 Test Loss: 0.3845728
Validation loss decreased (0.754653 --> 0.735858).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3425117
	speed: 0.4101s/iter; left time: 2311.1257s
Epoch: 4 cost time: 19.189435243606567
Epoch: 4, Steps: 122 | Train Loss: 0.3442087 Vali Loss: 0.7255233 Test Loss: 0.3837639
Validation loss decreased (0.735858 --> 0.725523).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3762176
	speed: 0.4282s/iter; left time: 2360.4599s
Epoch: 5 cost time: 20.02692198753357
Epoch: 5, Steps: 122 | Train Loss: 0.3421755 Vali Loss: 0.7172052 Test Loss: 0.3845182
Validation loss decreased (0.725523 --> 0.717205).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3591647
	speed: 0.4395s/iter; left time: 2369.2333s
Epoch: 6 cost time: 21.149493932724
Epoch: 6, Steps: 122 | Train Loss: 0.3404964 Vali Loss: 0.7145142 Test Loss: 0.3848409
Validation loss decreased (0.717205 --> 0.714514).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3376422
	speed: 0.4576s/iter; left time: 2410.9351s
Epoch: 7 cost time: 20.463644981384277
Epoch: 7, Steps: 122 | Train Loss: 0.3395173 Vali Loss: 0.7133272 Test Loss: 0.3842582
Validation loss decreased (0.714514 --> 0.713327).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3083291
	speed: 0.4054s/iter; left time: 2086.6773s
Epoch: 8 cost time: 19.000847339630127
Epoch: 8, Steps: 122 | Train Loss: 0.3387588 Vali Loss: 0.7135609 Test Loss: 0.3834261
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3921851
	speed: 0.3902s/iter; left time: 1960.5763s
Epoch: 9 cost time: 18.632470846176147
Epoch: 9, Steps: 122 | Train Loss: 0.3379845 Vali Loss: 0.7113962 Test Loss: 0.3843884
Validation loss decreased (0.713327 --> 0.711396).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3987005
	speed: 0.4045s/iter; left time: 1983.4378s
Epoch: 10 cost time: 18.486207723617554
Epoch: 10, Steps: 122 | Train Loss: 0.3376440 Vali Loss: 0.7071546 Test Loss: 0.3837687
Validation loss decreased (0.711396 --> 0.707155).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3016706
	speed: 0.3996s/iter; left time: 1910.3122s
Epoch: 11 cost time: 18.182050943374634
Epoch: 11, Steps: 122 | Train Loss: 0.3374042 Vali Loss: 0.7072874 Test Loss: 0.3837314
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3477648
	speed: 0.3988s/iter; left time: 1858.0870s
Epoch: 12 cost time: 18.91094398498535
Epoch: 12, Steps: 122 | Train Loss: 0.3368504 Vali Loss: 0.7057354 Test Loss: 0.3843426
Validation loss decreased (0.707155 --> 0.705735).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3820703
	speed: 0.3993s/iter; left time: 1811.7793s
Epoch: 13 cost time: 18.443803787231445
Epoch: 13, Steps: 122 | Train Loss: 0.3364547 Vali Loss: 0.7047284 Test Loss: 0.3841453
Validation loss decreased (0.705735 --> 0.704728).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3199583
	speed: 0.4099s/iter; left time: 1809.5375s
Epoch: 14 cost time: 19.781037092208862
Epoch: 14, Steps: 122 | Train Loss: 0.3361577 Vali Loss: 0.7049362 Test Loss: 0.3841648
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3624443
	speed: 0.4433s/iter; left time: 1903.2545s
Epoch: 15 cost time: 20.699397087097168
Epoch: 15, Steps: 122 | Train Loss: 0.3360263 Vali Loss: 0.7042312 Test Loss: 0.3837983
Validation loss decreased (0.704728 --> 0.704231).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3169815
	speed: 0.4506s/iter; left time: 1879.5578s
Epoch: 16 cost time: 20.749622106552124
Epoch: 16, Steps: 122 | Train Loss: 0.3359207 Vali Loss: 0.7057504 Test Loss: 0.3838846
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3102138
	speed: 0.4039s/iter; left time: 1635.2003s
Epoch: 17 cost time: 18.80574607849121
Epoch: 17, Steps: 122 | Train Loss: 0.3357214 Vali Loss: 0.7035567 Test Loss: 0.3840659
Validation loss decreased (0.704231 --> 0.703557).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3002122
	speed: 0.4008s/iter; left time: 1574.0384s
Epoch: 18 cost time: 18.86730694770813
Epoch: 18, Steps: 122 | Train Loss: 0.3355009 Vali Loss: 0.7014152 Test Loss: 0.3831963
Validation loss decreased (0.703557 --> 0.701415).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3373985
	speed: 0.3378s/iter; left time: 1285.2159s
Epoch: 19 cost time: 16.72557783126831
Epoch: 19, Steps: 122 | Train Loss: 0.3354509 Vali Loss: 0.7034745 Test Loss: 0.3836441
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3649308
	speed: 0.3668s/iter; left time: 1350.9159s
Epoch: 20 cost time: 17.365203142166138
Epoch: 20, Steps: 122 | Train Loss: 0.3351846 Vali Loss: 0.7019022 Test Loss: 0.3835044
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.3009264
	speed: 0.3773s/iter; left time: 1343.5758s
Epoch: 21 cost time: 17.879117250442505
Epoch: 21, Steps: 122 | Train Loss: 0.3350686 Vali Loss: 0.6991927 Test Loss: 0.3839117
Validation loss decreased (0.701415 --> 0.699193).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3543788
	speed: 0.3706s/iter; left time: 1274.5170s
Epoch: 22 cost time: 17.050395250320435
Epoch: 22, Steps: 122 | Train Loss: 0.3351720 Vali Loss: 0.6998268 Test Loss: 0.3838123
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3777702
	speed: 0.3740s/iter; left time: 1240.5797s
Epoch: 23 cost time: 17.188572883605957
Epoch: 23, Steps: 122 | Train Loss: 0.3349327 Vali Loss: 0.6983756 Test Loss: 0.3839624
Validation loss decreased (0.699193 --> 0.698376).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.3465974
	speed: 0.4015s/iter; left time: 1282.8156s
Epoch: 24 cost time: 18.917083740234375
Epoch: 24, Steps: 122 | Train Loss: 0.3347815 Vali Loss: 0.6990151 Test Loss: 0.3839601
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3444351
	speed: 0.4181s/iter; left time: 1284.7301s
Epoch: 25 cost time: 19.77632784843445
Epoch: 25, Steps: 122 | Train Loss: 0.3349590 Vali Loss: 0.7017965 Test Loss: 0.3839794
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3065620
	speed: 0.3942s/iter; left time: 1163.1578s
Epoch: 26 cost time: 17.994135856628418
Epoch: 26, Steps: 122 | Train Loss: 0.3347301 Vali Loss: 0.7020580 Test Loss: 0.3836899
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.38345879316329956, mae:0.405778169631958, rse:0.588189423084259, corr:[0.26836812 0.27702248 0.27770022 0.2751516  0.27278754 0.27124053
 0.2701032  0.2692661  0.26864076 0.26870397 0.26912737 0.26910242
 0.26860982 0.26801595 0.26782078 0.26818082 0.26858965 0.26877177
 0.2684915  0.26791605 0.2674901  0.26746297 0.2673694  0.26732457
 0.26725957 0.2671874  0.26698363 0.26653144 0.26597553 0.26545456
 0.26511002 0.26483342 0.26472148 0.26469746 0.2645311  0.26436716
 0.26433137 0.26443642 0.2645997  0.26473445 0.2650294  0.26533154
 0.26546896 0.26556093 0.2657506  0.26600525 0.26629308 0.2663976
 0.2658035  0.2648768  0.26362503 0.26227382 0.26101124 0.2597974
 0.25896165 0.25857878 0.25836772 0.25823316 0.25785017 0.2574714
 0.25717035 0.2570672  0.2570942  0.25728387 0.2574852  0.25757223
 0.25763687 0.25750765 0.25739735 0.25747332 0.25751814 0.25696912
 0.25588948 0.25455898 0.25334004 0.25279158 0.25268075 0.25247285
 0.2519103  0.25115216 0.2503725  0.24970306 0.24895996 0.24828136
 0.24805185 0.24819258 0.24819574 0.24738108 0.24623886 0.24579777
 0.24626379 0.24633579 0.24483286 0.24335125 0.24556802 0.25112644]
