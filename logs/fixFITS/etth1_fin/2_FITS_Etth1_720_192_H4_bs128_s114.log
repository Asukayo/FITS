Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=7, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:7
>>>>>>>start training : ETTh1_720_192_FITS_ETTh1_ftM_sl720_ll48_pl192_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=134, out_features=169, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  40581632.0
params:  22815.0
Trainable parameters:  22815
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 4.2271623611450195
Epoch: 1, Steps: 30 | Train Loss: 0.6861005 Vali Loss: 1.7605131 Test Loss: 0.9255504
Validation loss decreased (inf --> 1.760513).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.893073558807373
Epoch: 2, Steps: 30 | Train Loss: 0.5887303 Vali Loss: 1.5919611 Test Loss: 0.8425035
Validation loss decreased (1.760513 --> 1.591961).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 5.165966987609863
Epoch: 3, Steps: 30 | Train Loss: 0.5250798 Vali Loss: 1.4930483 Test Loss: 0.7901543
Validation loss decreased (1.591961 --> 1.493048).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 5.250023603439331
Epoch: 4, Steps: 30 | Train Loss: 0.4821397 Vali Loss: 1.4270389 Test Loss: 0.7582012
Validation loss decreased (1.493048 --> 1.427039).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 4.7012810707092285
Epoch: 5, Steps: 30 | Train Loss: 0.4516057 Vali Loss: 1.3875401 Test Loss: 0.7386434
Validation loss decreased (1.427039 --> 1.387540).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 4.8767595291137695
Epoch: 6, Steps: 30 | Train Loss: 0.4286949 Vali Loss: 1.3560953 Test Loss: 0.7247222
Validation loss decreased (1.387540 --> 1.356095).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 4.7266786098480225
Epoch: 7, Steps: 30 | Train Loss: 0.4107404 Vali Loss: 1.3417556 Test Loss: 0.7170566
Validation loss decreased (1.356095 --> 1.341756).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 5.238534688949585
Epoch: 8, Steps: 30 | Train Loss: 0.3961016 Vali Loss: 1.3238075 Test Loss: 0.7112296
Validation loss decreased (1.341756 --> 1.323807).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 5.353801012039185
Epoch: 9, Steps: 30 | Train Loss: 0.3835443 Vali Loss: 1.3097625 Test Loss: 0.7054511
Validation loss decreased (1.323807 --> 1.309762).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 5.754328012466431
Epoch: 10, Steps: 30 | Train Loss: 0.3728411 Vali Loss: 1.3022261 Test Loss: 0.7012699
Validation loss decreased (1.309762 --> 1.302226).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 5.593743801116943
Epoch: 11, Steps: 30 | Train Loss: 0.3633403 Vali Loss: 1.2895478 Test Loss: 0.6980149
Validation loss decreased (1.302226 --> 1.289548).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 4.660496950149536
Epoch: 12, Steps: 30 | Train Loss: 0.3553070 Vali Loss: 1.2847855 Test Loss: 0.6951838
Validation loss decreased (1.289548 --> 1.284786).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 4.814223051071167
Epoch: 13, Steps: 30 | Train Loss: 0.3475837 Vali Loss: 1.2800620 Test Loss: 0.6917225
Validation loss decreased (1.284786 --> 1.280062).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 4.401962757110596
Epoch: 14, Steps: 30 | Train Loss: 0.3408976 Vali Loss: 1.2697501 Test Loss: 0.6885164
Validation loss decreased (1.280062 --> 1.269750).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 4.799250841140747
Epoch: 15, Steps: 30 | Train Loss: 0.3343789 Vali Loss: 1.2622424 Test Loss: 0.6856156
Validation loss decreased (1.269750 --> 1.262242).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 4.699190378189087
Epoch: 16, Steps: 30 | Train Loss: 0.3286475 Vali Loss: 1.2626166 Test Loss: 0.6833818
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 4.518054246902466
Epoch: 17, Steps: 30 | Train Loss: 0.3233614 Vali Loss: 1.2580955 Test Loss: 0.6807773
Validation loss decreased (1.262242 --> 1.258096).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 4.499301195144653
Epoch: 18, Steps: 30 | Train Loss: 0.3182560 Vali Loss: 1.2557822 Test Loss: 0.6780136
Validation loss decreased (1.258096 --> 1.255782).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 4.622056007385254
Epoch: 19, Steps: 30 | Train Loss: 0.3138499 Vali Loss: 1.2487117 Test Loss: 0.6754240
Validation loss decreased (1.255782 --> 1.248712).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.867436647415161
Epoch: 20, Steps: 30 | Train Loss: 0.3094933 Vali Loss: 1.2395800 Test Loss: 0.6725971
Validation loss decreased (1.248712 --> 1.239580).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 4.352196455001831
Epoch: 21, Steps: 30 | Train Loss: 0.3056204 Vali Loss: 1.2360262 Test Loss: 0.6703396
Validation loss decreased (1.239580 --> 1.236026).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 4.4447877407073975
Epoch: 22, Steps: 30 | Train Loss: 0.3021815 Vali Loss: 1.2382797 Test Loss: 0.6685421
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 4.709210395812988
Epoch: 23, Steps: 30 | Train Loss: 0.2985648 Vali Loss: 1.2319438 Test Loss: 0.6661229
Validation loss decreased (1.236026 --> 1.231944).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 4.607419490814209
Epoch: 24, Steps: 30 | Train Loss: 0.2955065 Vali Loss: 1.2289560 Test Loss: 0.6640115
Validation loss decreased (1.231944 --> 1.228956).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 4.623861074447632
Epoch: 25, Steps: 30 | Train Loss: 0.2924483 Vali Loss: 1.2236506 Test Loss: 0.6621069
Validation loss decreased (1.228956 --> 1.223651).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 4.194982051849365
Epoch: 26, Steps: 30 | Train Loss: 0.2894621 Vali Loss: 1.2236412 Test Loss: 0.6600649
Validation loss decreased (1.223651 --> 1.223641).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 4.534978866577148
Epoch: 27, Steps: 30 | Train Loss: 0.2868564 Vali Loss: 1.2238147 Test Loss: 0.6582350
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 4.379600286483765
Epoch: 28, Steps: 30 | Train Loss: 0.2845096 Vali Loss: 1.2179581 Test Loss: 0.6569837
Validation loss decreased (1.223641 --> 1.217958).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 4.632594108581543
Epoch: 29, Steps: 30 | Train Loss: 0.2821129 Vali Loss: 1.2148732 Test Loss: 0.6551381
Validation loss decreased (1.217958 --> 1.214873).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 4.665281057357788
Epoch: 30, Steps: 30 | Train Loss: 0.2799188 Vali Loss: 1.2111577 Test Loss: 0.6533175
Validation loss decreased (1.214873 --> 1.211158).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 4.369906187057495
Epoch: 31, Steps: 30 | Train Loss: 0.2778367 Vali Loss: 1.2091777 Test Loss: 0.6522034
Validation loss decreased (1.211158 --> 1.209178).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 4.026048898696899
Epoch: 32, Steps: 30 | Train Loss: 0.2758238 Vali Loss: 1.2120385 Test Loss: 0.6504574
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 4.102700710296631
Epoch: 33, Steps: 30 | Train Loss: 0.2740626 Vali Loss: 1.2075375 Test Loss: 0.6490689
Validation loss decreased (1.209178 --> 1.207538).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 4.1223366260528564
Epoch: 34, Steps: 30 | Train Loss: 0.2723664 Vali Loss: 1.2038100 Test Loss: 0.6480364
Validation loss decreased (1.207538 --> 1.203810).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 4.244682312011719
Epoch: 35, Steps: 30 | Train Loss: 0.2707965 Vali Loss: 1.2000802 Test Loss: 0.6466740
Validation loss decreased (1.203810 --> 1.200080).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 4.283210754394531
Epoch: 36, Steps: 30 | Train Loss: 0.2692223 Vali Loss: 1.2013986 Test Loss: 0.6454808
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 3.9905035495758057
Epoch: 37, Steps: 30 | Train Loss: 0.2677679 Vali Loss: 1.1993694 Test Loss: 0.6442896
Validation loss decreased (1.200080 --> 1.199369).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 4.068962574005127
Epoch: 38, Steps: 30 | Train Loss: 0.2662927 Vali Loss: 1.2017256 Test Loss: 0.6432478
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 4.0044941902160645
Epoch: 39, Steps: 30 | Train Loss: 0.2651020 Vali Loss: 1.2001450 Test Loss: 0.6419532
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 4.021979331970215
Epoch: 40, Steps: 30 | Train Loss: 0.2638612 Vali Loss: 1.1963961 Test Loss: 0.6412857
Validation loss decreased (1.199369 --> 1.196396).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 3.960878849029541
Epoch: 41, Steps: 30 | Train Loss: 0.2626855 Vali Loss: 1.1927624 Test Loss: 0.6401539
Validation loss decreased (1.196396 --> 1.192762).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 3.932497262954712
Epoch: 42, Steps: 30 | Train Loss: 0.2615664 Vali Loss: 1.1963863 Test Loss: 0.6392027
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 3.901747465133667
Epoch: 43, Steps: 30 | Train Loss: 0.2606428 Vali Loss: 1.1925560 Test Loss: 0.6385744
Validation loss decreased (1.192762 --> 1.192556).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 3.9399325847625732
Epoch: 44, Steps: 30 | Train Loss: 0.2596582 Vali Loss: 1.1905336 Test Loss: 0.6376626
Validation loss decreased (1.192556 --> 1.190534).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 4.258676767349243
Epoch: 45, Steps: 30 | Train Loss: 0.2587734 Vali Loss: 1.1898700 Test Loss: 0.6368811
Validation loss decreased (1.190534 --> 1.189870).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 3.954993724822998
Epoch: 46, Steps: 30 | Train Loss: 0.2578389 Vali Loss: 1.1911209 Test Loss: 0.6361215
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 3.8190550804138184
Epoch: 47, Steps: 30 | Train Loss: 0.2569393 Vali Loss: 1.1923053 Test Loss: 0.6353896
EarlyStopping counter: 2 out of 3
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 4.099815368652344
Epoch: 48, Steps: 30 | Train Loss: 0.2562343 Vali Loss: 1.1868219 Test Loss: 0.6348539
Validation loss decreased (1.189870 --> 1.186822).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 4.073656320571899
Epoch: 49, Steps: 30 | Train Loss: 0.2555392 Vali Loss: 1.1898202 Test Loss: 0.6339750
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 4.5281922817230225
Epoch: 50, Steps: 30 | Train Loss: 0.2547535 Vali Loss: 1.1908247 Test Loss: 0.6334320
EarlyStopping counter: 2 out of 3
Updating learning rate to 4.0497355408796396e-05
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=134, out_features=169, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  40581632.0
params:  22815.0
Trainable parameters:  22815
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 4.320098161697388
Epoch: 1, Steps: 30 | Train Loss: 0.4851799 Vali Loss: 1.0818138 Test Loss: 0.5486903
Validation loss decreased (inf --> 1.081814).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.629201889038086
Epoch: 2, Steps: 30 | Train Loss: 0.4444707 Vali Loss: 1.0249579 Test Loss: 0.4948516
Validation loss decreased (1.081814 --> 1.024958).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 4.351485013961792
Epoch: 3, Steps: 30 | Train Loss: 0.4203839 Vali Loss: 0.9912634 Test Loss: 0.4631837
Validation loss decreased (1.024958 --> 0.991263).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 4.241504430770874
Epoch: 4, Steps: 30 | Train Loss: 0.4065091 Vali Loss: 0.9736576 Test Loss: 0.4445322
Validation loss decreased (0.991263 --> 0.973658).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 4.315776348114014
Epoch: 5, Steps: 30 | Train Loss: 0.3980078 Vali Loss: 0.9596094 Test Loss: 0.4340065
Validation loss decreased (0.973658 --> 0.959609).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 4.442925930023193
Epoch: 6, Steps: 30 | Train Loss: 0.3930825 Vali Loss: 0.9563025 Test Loss: 0.4279386
Validation loss decreased (0.959609 --> 0.956303).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 4.320385217666626
Epoch: 7, Steps: 30 | Train Loss: 0.3898690 Vali Loss: 0.9523836 Test Loss: 0.4246234
Validation loss decreased (0.956303 --> 0.952384).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 4.183051586151123
Epoch: 8, Steps: 30 | Train Loss: 0.3880811 Vali Loss: 0.9499631 Test Loss: 0.4230110
Validation loss decreased (0.952384 --> 0.949963).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.557487726211548
Epoch: 9, Steps: 30 | Train Loss: 0.3874166 Vali Loss: 0.9524962 Test Loss: 0.4223318
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 4.211240768432617
Epoch: 10, Steps: 30 | Train Loss: 0.3863739 Vali Loss: 0.9548451 Test Loss: 0.4218283
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 4.730999708175659
Epoch: 11, Steps: 30 | Train Loss: 0.3856435 Vali Loss: 0.9508677 Test Loss: 0.4216739
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh1_720_192_FITS_ETTh1_ftM_sl720_ll48_pl192_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.41749444603919983, mae:0.42659813165664673, rse:0.6135962605476379, corr:[0.26055047 0.27122095 0.2707381  0.26631257 0.26440164 0.2642412
 0.2641804  0.26365143 0.2626248  0.2620021  0.26171675 0.2615072
 0.26132664 0.26114866 0.26112807 0.26104945 0.26062185 0.26006454
 0.25957397 0.25935367 0.25924334 0.25906935 0.25854015 0.25816628
 0.25825903 0.25877124 0.25919363 0.25912488 0.25854635 0.25781322
 0.25740346 0.25729907 0.25752518 0.25775525 0.25761136 0.25732285
 0.25709015 0.25701857 0.25706697 0.25720018 0.25756857 0.25791487
 0.25792554 0.25777617 0.25777516 0.2580885  0.25868982 0.25916183
 0.2589101  0.25828686 0.25735247 0.2563524  0.25552416 0.25464922
 0.25378224 0.252948   0.2521486  0.25165835 0.25144437 0.2515781
 0.2517844  0.25181267 0.25167048 0.25168702 0.2518485  0.2520435
 0.2522369  0.25218523 0.25206694 0.25201905 0.2519216  0.25165227
 0.25133622 0.25099733 0.25057375 0.2502106  0.24967746 0.24893649
 0.24830008 0.24806046 0.24811906 0.24805377 0.24757232 0.2468732
 0.24644801 0.24648683 0.24681823 0.24709758 0.2471932  0.2471672
 0.24702525 0.24679106 0.24647748 0.24626401 0.24638857 0.24679834
 0.24739517 0.24790795 0.24799646 0.24777952 0.24749194 0.2472875
 0.24727218 0.24721754 0.2469838  0.24673572 0.24651541 0.2463272
 0.24629684 0.2463001  0.24640921 0.24674417 0.2470216  0.2471431
 0.24717523 0.24707904 0.24688844 0.2466556  0.24635977 0.24599275
 0.2455986  0.24507353 0.24443968 0.24383844 0.24314228 0.24221143
 0.24139296 0.24096422 0.24080871 0.24081007 0.24056824 0.24004535
 0.23943706 0.2391129  0.23914905 0.23932253 0.23964153 0.239928
 0.24011642 0.24012832 0.24005993 0.23994546 0.23980835 0.23942547
 0.23885421 0.23804379 0.23692267 0.23561063 0.23460306 0.23386165
 0.23328912 0.23276006 0.23233241 0.23224695 0.23226789 0.23222351
 0.2320135  0.23179719 0.23182257 0.23207335 0.2322996  0.23248872
 0.23242705 0.23225671 0.2322727  0.23218973 0.23167314 0.23046514
 0.22937033 0.22936787 0.23017523 0.23069395 0.22990343 0.22814073
 0.22662179 0.22654833 0.22726215 0.22784725 0.22746989 0.22645631
 0.22567528 0.22535338 0.22491938 0.2244192  0.22435464 0.22479373
 0.22467117 0.22250652 0.21968324 0.219148   0.22094172 0.21577996]
