Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=7, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:7
>>>>>>>start training : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=134, out_features=151, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  18129664.0
params:  20385.0
Trainable parameters:  20385
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 5.531513929367065
Epoch: 1, Steps: 61 | Train Loss: 0.6164906 Vali Loss: 1.4141291 Test Loss: 0.8169180
Validation loss decreased (inf --> 1.414129).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.296891212463379
Epoch: 2, Steps: 61 | Train Loss: 0.4896572 Vali Loss: 1.2741957 Test Loss: 0.7418745
Validation loss decreased (1.414129 --> 1.274196).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 8.213119983673096
Epoch: 3, Steps: 61 | Train Loss: 0.4236337 Vali Loss: 1.2187822 Test Loss: 0.7169297
Validation loss decreased (1.274196 --> 1.218782).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 6.82292366027832
Epoch: 4, Steps: 61 | Train Loss: 0.3832356 Vali Loss: 1.1890166 Test Loss: 0.7013232
Validation loss decreased (1.218782 --> 1.189017).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 7.374436855316162
Epoch: 5, Steps: 61 | Train Loss: 0.3543584 Vali Loss: 1.1731737 Test Loss: 0.6968397
Validation loss decreased (1.189017 --> 1.173174).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 7.701218843460083
Epoch: 6, Steps: 61 | Train Loss: 0.3312928 Vali Loss: 1.1504186 Test Loss: 0.6860556
Validation loss decreased (1.173174 --> 1.150419).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 7.827744960784912
Epoch: 7, Steps: 61 | Train Loss: 0.3120282 Vali Loss: 1.1338766 Test Loss: 0.6747703
Validation loss decreased (1.150419 --> 1.133877).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 7.520641803741455
Epoch: 8, Steps: 61 | Train Loss: 0.2953194 Vali Loss: 1.1153837 Test Loss: 0.6683132
Validation loss decreased (1.133877 --> 1.115384).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 8.359852313995361
Epoch: 9, Steps: 61 | Train Loss: 0.2806530 Vali Loss: 1.0973253 Test Loss: 0.6570510
Validation loss decreased (1.115384 --> 1.097325).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 8.291406869888306
Epoch: 10, Steps: 61 | Train Loss: 0.2677180 Vali Loss: 1.0824839 Test Loss: 0.6458697
Validation loss decreased (1.097325 --> 1.082484).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 7.520153284072876
Epoch: 11, Steps: 61 | Train Loss: 0.2560740 Vali Loss: 1.0646766 Test Loss: 0.6372109
Validation loss decreased (1.082484 --> 1.064677).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 7.004449844360352
Epoch: 12, Steps: 61 | Train Loss: 0.2455255 Vali Loss: 1.0489771 Test Loss: 0.6265013
Validation loss decreased (1.064677 --> 1.048977).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 6.061226844787598
Epoch: 13, Steps: 61 | Train Loss: 0.2361148 Vali Loss: 1.0350641 Test Loss: 0.6182439
Validation loss decreased (1.048977 --> 1.035064).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 5.5525267124176025
Epoch: 14, Steps: 61 | Train Loss: 0.2276172 Vali Loss: 1.0181227 Test Loss: 0.6080246
Validation loss decreased (1.035064 --> 1.018123).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 7.917462587356567
Epoch: 15, Steps: 61 | Train Loss: 0.2198658 Vali Loss: 1.0089185 Test Loss: 0.6005039
Validation loss decreased (1.018123 --> 1.008919).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 8.194271802902222
Epoch: 16, Steps: 61 | Train Loss: 0.2127367 Vali Loss: 0.9995019 Test Loss: 0.5936158
Validation loss decreased (1.008919 --> 0.999502).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 8.696613311767578
Epoch: 17, Steps: 61 | Train Loss: 0.2062746 Vali Loss: 0.9836947 Test Loss: 0.5835284
Validation loss decreased (0.999502 --> 0.983695).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 8.672137975692749
Epoch: 18, Steps: 61 | Train Loss: 0.2003034 Vali Loss: 0.9768943 Test Loss: 0.5772418
Validation loss decreased (0.983695 --> 0.976894).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 5.997581243515015
Epoch: 19, Steps: 61 | Train Loss: 0.1948461 Vali Loss: 0.9643439 Test Loss: 0.5709447
Validation loss decreased (0.976894 --> 0.964344).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 7.6113927364349365
Epoch: 20, Steps: 61 | Train Loss: 0.1898192 Vali Loss: 0.9551814 Test Loss: 0.5638732
Validation loss decreased (0.964344 --> 0.955181).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 7.775946617126465
Epoch: 21, Steps: 61 | Train Loss: 0.1851269 Vali Loss: 0.9455762 Test Loss: 0.5579399
Validation loss decreased (0.955181 --> 0.945576).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 7.647601127624512
Epoch: 22, Steps: 61 | Train Loss: 0.1808220 Vali Loss: 0.9362682 Test Loss: 0.5530930
Validation loss decreased (0.945576 --> 0.936268).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 7.4692604541778564
Epoch: 23, Steps: 61 | Train Loss: 0.1768893 Vali Loss: 0.9280871 Test Loss: 0.5480986
Validation loss decreased (0.936268 --> 0.928087).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 7.575824737548828
Epoch: 24, Steps: 61 | Train Loss: 0.1732348 Vali Loss: 0.9221386 Test Loss: 0.5436229
Validation loss decreased (0.928087 --> 0.922139).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 7.613710165023804
Epoch: 25, Steps: 61 | Train Loss: 0.1697865 Vali Loss: 0.9190508 Test Loss: 0.5390535
Validation loss decreased (0.922139 --> 0.919051).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 7.7836480140686035
Epoch: 26, Steps: 61 | Train Loss: 0.1666215 Vali Loss: 0.9107836 Test Loss: 0.5340834
Validation loss decreased (0.919051 --> 0.910784).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 7.589741945266724
Epoch: 27, Steps: 61 | Train Loss: 0.1636845 Vali Loss: 0.9036406 Test Loss: 0.5307033
Validation loss decreased (0.910784 --> 0.903641).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 7.0020928382873535
Epoch: 28, Steps: 61 | Train Loss: 0.1609449 Vali Loss: 0.8968109 Test Loss: 0.5269740
Validation loss decreased (0.903641 --> 0.896811).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 7.501025438308716
Epoch: 29, Steps: 61 | Train Loss: 0.1583619 Vali Loss: 0.8942009 Test Loss: 0.5235390
Validation loss decreased (0.896811 --> 0.894201).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 7.333361864089966
Epoch: 30, Steps: 61 | Train Loss: 0.1559288 Vali Loss: 0.8930690 Test Loss: 0.5202121
Validation loss decreased (0.894201 --> 0.893069).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 5.6390697956085205
Epoch: 31, Steps: 61 | Train Loss: 0.1537585 Vali Loss: 0.8871505 Test Loss: 0.5171234
Validation loss decreased (0.893069 --> 0.887150).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 5.702026605606079
Epoch: 32, Steps: 61 | Train Loss: 0.1516302 Vali Loss: 0.8826036 Test Loss: 0.5142695
Validation loss decreased (0.887150 --> 0.882604).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 4.962629079818726
Epoch: 33, Steps: 61 | Train Loss: 0.1496216 Vali Loss: 0.8779120 Test Loss: 0.5112898
Validation loss decreased (0.882604 --> 0.877912).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 6.496806859970093
Epoch: 34, Steps: 61 | Train Loss: 0.1478410 Vali Loss: 0.8752803 Test Loss: 0.5092331
Validation loss decreased (0.877912 --> 0.875280).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 6.977357864379883
Epoch: 35, Steps: 61 | Train Loss: 0.1461343 Vali Loss: 0.8719717 Test Loss: 0.5062687
Validation loss decreased (0.875280 --> 0.871972).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 5.259361267089844
Epoch: 36, Steps: 61 | Train Loss: 0.1445252 Vali Loss: 0.8679163 Test Loss: 0.5041754
Validation loss decreased (0.871972 --> 0.867916).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 5.511836528778076
Epoch: 37, Steps: 61 | Train Loss: 0.1429884 Vali Loss: 0.8660346 Test Loss: 0.5017405
Validation loss decreased (0.867916 --> 0.866035).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 7.879689455032349
Epoch: 38, Steps: 61 | Train Loss: 0.1415080 Vali Loss: 0.8621356 Test Loss: 0.5001913
Validation loss decreased (0.866035 --> 0.862136).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 6.289537191390991
Epoch: 39, Steps: 61 | Train Loss: 0.1401642 Vali Loss: 0.8594670 Test Loss: 0.4978479
Validation loss decreased (0.862136 --> 0.859467).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 6.217365741729736
Epoch: 40, Steps: 61 | Train Loss: 0.1388866 Vali Loss: 0.8580377 Test Loss: 0.4962070
Validation loss decreased (0.859467 --> 0.858038).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 7.73492693901062
Epoch: 41, Steps: 61 | Train Loss: 0.1376779 Vali Loss: 0.8502423 Test Loss: 0.4945578
Validation loss decreased (0.858038 --> 0.850242).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 8.369891881942749
Epoch: 42, Steps: 61 | Train Loss: 0.1366147 Vali Loss: 0.8498973 Test Loss: 0.4928301
Validation loss decreased (0.850242 --> 0.849897).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 8.219520092010498
Epoch: 43, Steps: 61 | Train Loss: 0.1355130 Vali Loss: 0.8470297 Test Loss: 0.4910680
Validation loss decreased (0.849897 --> 0.847030).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 7.9940102100372314
Epoch: 44, Steps: 61 | Train Loss: 0.1345383 Vali Loss: 0.8435199 Test Loss: 0.4900949
Validation loss decreased (0.847030 --> 0.843520).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 8.15840196609497
Epoch: 45, Steps: 61 | Train Loss: 0.1335366 Vali Loss: 0.8419006 Test Loss: 0.4882669
Validation loss decreased (0.843520 --> 0.841901).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 8.976623058319092
Epoch: 46, Steps: 61 | Train Loss: 0.1326503 Vali Loss: 0.8460697 Test Loss: 0.4871012
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 9.417664527893066
Epoch: 47, Steps: 61 | Train Loss: 0.1317944 Vali Loss: 0.8434865 Test Loss: 0.4857806
EarlyStopping counter: 2 out of 3
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 9.161056518554688
Epoch: 48, Steps: 61 | Train Loss: 0.1309541 Vali Loss: 0.8424528 Test Loss: 0.4847703
EarlyStopping counter: 3 out of 3
Early stopping
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=134, out_features=151, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  18129664.0
params:  20385.0
Trainable parameters:  20385
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 9.098682880401611
Epoch: 1, Steps: 61 | Train Loss: 0.3674896 Vali Loss: 0.7138789 Test Loss: 0.3899357
Validation loss decreased (inf --> 0.713879).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 9.141249895095825
Epoch: 2, Steps: 61 | Train Loss: 0.3422769 Vali Loss: 0.7033746 Test Loss: 0.3850769
Validation loss decreased (0.713879 --> 0.703375).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 9.556984424591064
Epoch: 3, Steps: 61 | Train Loss: 0.3394843 Vali Loss: 0.7027262 Test Loss: 0.3847897
Validation loss decreased (0.703375 --> 0.702726).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 8.8529794216156
Epoch: 4, Steps: 61 | Train Loss: 0.3380830 Vali Loss: 0.6996611 Test Loss: 0.3848372
Validation loss decreased (0.702726 --> 0.699661).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 8.857498407363892
Epoch: 5, Steps: 61 | Train Loss: 0.3374694 Vali Loss: 0.7031153 Test Loss: 0.3851528
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 9.971067428588867
Epoch: 6, Steps: 61 | Train Loss: 0.3368651 Vali Loss: 0.7020743 Test Loss: 0.3846468
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 9.89293909072876
Epoch: 7, Steps: 61 | Train Loss: 0.3365024 Vali Loss: 0.7009116 Test Loss: 0.3840812
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.38446199893951416, mae:0.4070739150047302, rse:0.5889582633972168, corr:[0.27439532 0.27974942 0.2801064  0.277493   0.27492884 0.27299315
 0.27177584 0.27111202 0.27060384 0.2705462  0.2706996  0.27069774
 0.27041414 0.26995364 0.26969263 0.269666   0.26956946 0.26928166
 0.2687022  0.2679884  0.2673621  0.26715618 0.26706553 0.26705536
 0.26689222 0.2667389  0.26668513 0.26657382 0.26628548 0.2658061
 0.2653132  0.26483285 0.26465225 0.2646854  0.26460332 0.26449904
 0.26445124 0.26449    0.26460707 0.2648306  0.26538494 0.26594666
 0.26611203 0.2659156  0.26567167 0.26567313 0.26603225 0.26643893
 0.26616076 0.26543057 0.26418832 0.26267746 0.2612191  0.2598371
 0.25879785 0.25806773 0.25753757 0.25746518 0.2575474  0.25778136
 0.25780395 0.2576445  0.2575033  0.25770548 0.25797865 0.2578926
 0.2575304  0.25688106 0.2565092  0.25679594 0.25732857 0.25737318
 0.25696868 0.25624633 0.25519228 0.2541506  0.25303242 0.2518997
 0.25112507 0.25086394 0.25049224 0.24960545 0.24843271 0.24773191
 0.24811816 0.24882634 0.2486696  0.24744143 0.2463083  0.2463981
 0.24697934 0.24603702 0.24378146 0.24206434 0.24336258 0.2442619 ]
