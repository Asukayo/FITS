Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=7, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:7
>>>>>>>start training : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=134, out_features=151, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  36259328.0
params:  20385.0
Trainable parameters:  20385
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.971444606781006
Epoch: 1, Steps: 30 | Train Loss: 0.6595426 Vali Loss: 1.1452426 Test Loss: 0.6288363
Validation loss decreased (inf --> 1.145243).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.027141332626343
Epoch: 2, Steps: 30 | Train Loss: 0.4736990 Vali Loss: 0.9396337 Test Loss: 0.4979394
Validation loss decreased (1.145243 --> 0.939634).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 4.158641576766968
Epoch: 3, Steps: 30 | Train Loss: 0.4096199 Vali Loss: 0.8566621 Test Loss: 0.4420122
Validation loss decreased (0.939634 --> 0.856662).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 4.13139796257019
Epoch: 4, Steps: 30 | Train Loss: 0.3815586 Vali Loss: 0.8107093 Test Loss: 0.4135033
Validation loss decreased (0.856662 --> 0.810709).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 4.179759502410889
Epoch: 5, Steps: 30 | Train Loss: 0.3663414 Vali Loss: 0.7796735 Test Loss: 0.3989936
Validation loss decreased (0.810709 --> 0.779673).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 4.398670196533203
Epoch: 6, Steps: 30 | Train Loss: 0.3584163 Vali Loss: 0.7705029 Test Loss: 0.3915668
Validation loss decreased (0.779673 --> 0.770503).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 4.858023643493652
Epoch: 7, Steps: 30 | Train Loss: 0.3535032 Vali Loss: 0.7602078 Test Loss: 0.3886500
Validation loss decreased (0.770503 --> 0.760208).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 4.566729545593262
Epoch: 8, Steps: 30 | Train Loss: 0.3505073 Vali Loss: 0.7479386 Test Loss: 0.3864966
Validation loss decreased (0.760208 --> 0.747939).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.682557582855225
Epoch: 9, Steps: 30 | Train Loss: 0.3477034 Vali Loss: 0.7473189 Test Loss: 0.3858427
Validation loss decreased (0.747939 --> 0.747319).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 4.67362642288208
Epoch: 10, Steps: 30 | Train Loss: 0.3466628 Vali Loss: 0.7447287 Test Loss: 0.3850420
Validation loss decreased (0.747319 --> 0.744729).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 4.815471410751343
Epoch: 11, Steps: 30 | Train Loss: 0.3458557 Vali Loss: 0.7327562 Test Loss: 0.3846425
Validation loss decreased (0.744729 --> 0.732756).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 4.865734100341797
Epoch: 12, Steps: 30 | Train Loss: 0.3443425 Vali Loss: 0.7334698 Test Loss: 0.3845368
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 4.899832010269165
Epoch: 13, Steps: 30 | Train Loss: 0.3436194 Vali Loss: 0.7284693 Test Loss: 0.3844631
Validation loss decreased (0.732756 --> 0.728469).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 4.9846765995025635
Epoch: 14, Steps: 30 | Train Loss: 0.3427932 Vali Loss: 0.7288885 Test Loss: 0.3843841
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 4.527004241943359
Epoch: 15, Steps: 30 | Train Loss: 0.3423062 Vali Loss: 0.7237063 Test Loss: 0.3841200
Validation loss decreased (0.728469 --> 0.723706).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 4.6865785121917725
Epoch: 16, Steps: 30 | Train Loss: 0.3423581 Vali Loss: 0.7220346 Test Loss: 0.3841338
Validation loss decreased (0.723706 --> 0.722035).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 4.534676790237427
Epoch: 17, Steps: 30 | Train Loss: 0.3416681 Vali Loss: 0.7235565 Test Loss: 0.3840275
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 4.519062757492065
Epoch: 18, Steps: 30 | Train Loss: 0.3409388 Vali Loss: 0.7182872 Test Loss: 0.3839259
Validation loss decreased (0.722035 --> 0.718287).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 4.437197685241699
Epoch: 19, Steps: 30 | Train Loss: 0.3403634 Vali Loss: 0.7210721 Test Loss: 0.3840250
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.394404172897339
Epoch: 20, Steps: 30 | Train Loss: 0.3399954 Vali Loss: 0.7227189 Test Loss: 0.3839278
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 4.5243141651153564
Epoch: 21, Steps: 30 | Train Loss: 0.3395908 Vali Loss: 0.7177801 Test Loss: 0.3838606
Validation loss decreased (0.718287 --> 0.717780).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 4.308348655700684
Epoch: 22, Steps: 30 | Train Loss: 0.3400340 Vali Loss: 0.7219345 Test Loss: 0.3839349
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 4.439298868179321
Epoch: 23, Steps: 30 | Train Loss: 0.3391541 Vali Loss: 0.7217466 Test Loss: 0.3839469
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 4.358726263046265
Epoch: 24, Steps: 30 | Train Loss: 0.3381661 Vali Loss: 0.7246076 Test Loss: 0.3839610
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.3830500543117523, mae:0.40597960352897644, rse:0.5878758430480957, corr:[0.26927185 0.2796523  0.28012615 0.27650574 0.27430362 0.27315718
 0.27254912 0.27200463 0.27138823 0.27087906 0.27032068 0.26978657
 0.2693604  0.26927778 0.26958817 0.26982328 0.26968443 0.2692004
 0.26865184 0.26836047 0.26828954 0.26833743 0.26813084 0.26781332
 0.26765344 0.26759237 0.26746532 0.26721054 0.26681128 0.26637286
 0.26600954 0.26568937 0.2656192  0.26563463 0.26555303 0.26545405
 0.26534256 0.2653154  0.26539224 0.265602   0.26608017 0.26652905
 0.26670966 0.26669592 0.26659596 0.2666154  0.26682404 0.26692915
 0.2665262  0.26583877 0.26477692 0.2634748  0.2622101  0.2610704
 0.2602908  0.25983384 0.2594581  0.2592509  0.25915498 0.25923645
 0.25926563 0.25919813 0.25904763 0.25908965 0.25919047 0.25919408
 0.2592402  0.2592188  0.25933474 0.25950375 0.25926635 0.25838497
 0.2572853  0.25634295 0.255676   0.25523782 0.2545686  0.2535414
 0.25257704 0.252107   0.25171292 0.25104624 0.25015417 0.24962762
 0.24999095 0.25020158 0.24937242 0.247865   0.24683987 0.2468839
 0.2461583  0.24272251 0.23823439 0.23682652 0.23982525 0.23386028]
