Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=165, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=7, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:7
>>>>>>>start training : ETTh1_720_192_FITS_ETTh1_ftM_sl720_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=165, out_features=209, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  61797120.0
params:  34694.0
Trainable parameters:  34694
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 5.14593505859375
Epoch: 1, Steps: 30 | Train Loss: 0.7047553 Vali Loss: 1.7341160 Test Loss: 0.8953198
Validation loss decreased (inf --> 1.734116).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.792092561721802
Epoch: 2, Steps: 30 | Train Loss: 0.6008504 Vali Loss: 1.5852083 Test Loss: 0.8251798
Validation loss decreased (1.734116 --> 1.585208).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 4.809014081954956
Epoch: 3, Steps: 30 | Train Loss: 0.5351419 Vali Loss: 1.4968746 Test Loss: 0.7845877
Validation loss decreased (1.585208 --> 1.496875).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.9066529273986816
Epoch: 4, Steps: 30 | Train Loss: 0.4919914 Vali Loss: 1.4469649 Test Loss: 0.7616327
Validation loss decreased (1.496875 --> 1.446965).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 4.8359105587005615
Epoch: 5, Steps: 30 | Train Loss: 0.4619971 Vali Loss: 1.4028347 Test Loss: 0.7475046
Validation loss decreased (1.446965 --> 1.402835).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 4.924777984619141
Epoch: 6, Steps: 30 | Train Loss: 0.4396891 Vali Loss: 1.3774030 Test Loss: 0.7389640
Validation loss decreased (1.402835 --> 1.377403).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 5.118225812911987
Epoch: 7, Steps: 30 | Train Loss: 0.4216028 Vali Loss: 1.3610829 Test Loss: 0.7314671
Validation loss decreased (1.377403 --> 1.361083).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 5.121549367904663
Epoch: 8, Steps: 30 | Train Loss: 0.4072804 Vali Loss: 1.3469771 Test Loss: 0.7272128
Validation loss decreased (1.361083 --> 1.346977).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 5.051538944244385
Epoch: 9, Steps: 30 | Train Loss: 0.3950013 Vali Loss: 1.3415374 Test Loss: 0.7227980
Validation loss decreased (1.346977 --> 1.341537).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 4.799770355224609
Epoch: 10, Steps: 30 | Train Loss: 0.3840760 Vali Loss: 1.3267722 Test Loss: 0.7191614
Validation loss decreased (1.341537 --> 1.326772).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 5.05302357673645
Epoch: 11, Steps: 30 | Train Loss: 0.3745312 Vali Loss: 1.3197205 Test Loss: 0.7149424
Validation loss decreased (1.326772 --> 1.319721).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 4.776142358779907
Epoch: 12, Steps: 30 | Train Loss: 0.3655771 Vali Loss: 1.3169439 Test Loss: 0.7119759
Validation loss decreased (1.319721 --> 1.316944).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 4.703546524047852
Epoch: 13, Steps: 30 | Train Loss: 0.3579983 Vali Loss: 1.3053900 Test Loss: 0.7086130
Validation loss decreased (1.316944 --> 1.305390).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 4.915451288223267
Epoch: 14, Steps: 30 | Train Loss: 0.3507963 Vali Loss: 1.2992065 Test Loss: 0.7051587
Validation loss decreased (1.305390 --> 1.299206).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 5.486224174499512
Epoch: 15, Steps: 30 | Train Loss: 0.3441488 Vali Loss: 1.2901061 Test Loss: 0.7027124
Validation loss decreased (1.299206 --> 1.290106).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 5.027862310409546
Epoch: 16, Steps: 30 | Train Loss: 0.3381697 Vali Loss: 1.2861608 Test Loss: 0.6994105
Validation loss decreased (1.290106 --> 1.286161).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 4.99061131477356
Epoch: 17, Steps: 30 | Train Loss: 0.3326677 Vali Loss: 1.2786468 Test Loss: 0.6969309
Validation loss decreased (1.286161 --> 1.278647).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 4.446954727172852
Epoch: 18, Steps: 30 | Train Loss: 0.3276636 Vali Loss: 1.2828400 Test Loss: 0.6945977
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 4.745584487915039
Epoch: 19, Steps: 30 | Train Loss: 0.3226537 Vali Loss: 1.2766426 Test Loss: 0.6913896
Validation loss decreased (1.278647 --> 1.276643).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.601619005203247
Epoch: 20, Steps: 30 | Train Loss: 0.3182378 Vali Loss: 1.2733622 Test Loss: 0.6888817
Validation loss decreased (1.276643 --> 1.273362).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 4.917754411697388
Epoch: 21, Steps: 30 | Train Loss: 0.3141929 Vali Loss: 1.2644527 Test Loss: 0.6868911
Validation loss decreased (1.273362 --> 1.264453).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 4.702430725097656
Epoch: 22, Steps: 30 | Train Loss: 0.3102499 Vali Loss: 1.2613794 Test Loss: 0.6844191
Validation loss decreased (1.264453 --> 1.261379).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.8378024101257324
Epoch: 23, Steps: 30 | Train Loss: 0.3066239 Vali Loss: 1.2586081 Test Loss: 0.6818345
Validation loss decreased (1.261379 --> 1.258608).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.9458298683166504
Epoch: 24, Steps: 30 | Train Loss: 0.3033641 Vali Loss: 1.2579367 Test Loss: 0.6801373
Validation loss decreased (1.258608 --> 1.257937).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 4.622759103775024
Epoch: 25, Steps: 30 | Train Loss: 0.3002395 Vali Loss: 1.2532570 Test Loss: 0.6777011
Validation loss decreased (1.257937 --> 1.253257).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 4.5513739585876465
Epoch: 26, Steps: 30 | Train Loss: 0.2972536 Vali Loss: 1.2472622 Test Loss: 0.6756205
Validation loss decreased (1.253257 --> 1.247262).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 4.586463212966919
Epoch: 27, Steps: 30 | Train Loss: 0.2944799 Vali Loss: 1.2407309 Test Loss: 0.6740343
Validation loss decreased (1.247262 --> 1.240731).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 4.331002235412598
Epoch: 28, Steps: 30 | Train Loss: 0.2919208 Vali Loss: 1.2443489 Test Loss: 0.6724957
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 4.2029383182525635
Epoch: 29, Steps: 30 | Train Loss: 0.2895223 Vali Loss: 1.2399404 Test Loss: 0.6704514
Validation loss decreased (1.240731 --> 1.239940).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 4.369892835617065
Epoch: 30, Steps: 30 | Train Loss: 0.2870398 Vali Loss: 1.2371266 Test Loss: 0.6687145
Validation loss decreased (1.239940 --> 1.237127).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 4.225604057312012
Epoch: 31, Steps: 30 | Train Loss: 0.2850091 Vali Loss: 1.2370306 Test Loss: 0.6672722
Validation loss decreased (1.237127 --> 1.237031).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 3.7839903831481934
Epoch: 32, Steps: 30 | Train Loss: 0.2829412 Vali Loss: 1.2364588 Test Loss: 0.6660411
Validation loss decreased (1.237031 --> 1.236459).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 3.9046356678009033
Epoch: 33, Steps: 30 | Train Loss: 0.2811650 Vali Loss: 1.2275741 Test Loss: 0.6644555
Validation loss decreased (1.236459 --> 1.227574).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.85957670211792
Epoch: 34, Steps: 30 | Train Loss: 0.2791461 Vali Loss: 1.2300941 Test Loss: 0.6630512
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 3.7139251232147217
Epoch: 35, Steps: 30 | Train Loss: 0.2774981 Vali Loss: 1.2259095 Test Loss: 0.6615641
Validation loss decreased (1.227574 --> 1.225909).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 4.279217004776001
Epoch: 36, Steps: 30 | Train Loss: 0.2758129 Vali Loss: 1.2290291 Test Loss: 0.6603805
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 4.49437403678894
Epoch: 37, Steps: 30 | Train Loss: 0.2743996 Vali Loss: 1.2287245 Test Loss: 0.6591977
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 4.854270935058594
Epoch: 38, Steps: 30 | Train Loss: 0.2729707 Vali Loss: 1.2239187 Test Loss: 0.6580778
Validation loss decreased (1.225909 --> 1.223919).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 5.062727212905884
Epoch: 39, Steps: 30 | Train Loss: 0.2717075 Vali Loss: 1.2182778 Test Loss: 0.6569329
Validation loss decreased (1.223919 --> 1.218278).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 5.194190740585327
Epoch: 40, Steps: 30 | Train Loss: 0.2704518 Vali Loss: 1.2182865 Test Loss: 0.6560408
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 4.8712568283081055
Epoch: 41, Steps: 30 | Train Loss: 0.2691043 Vali Loss: 1.2191617 Test Loss: 0.6551803
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 4.8921732902526855
Epoch: 42, Steps: 30 | Train Loss: 0.2679864 Vali Loss: 1.2168124 Test Loss: 0.6542243
Validation loss decreased (1.218278 --> 1.216812).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 5.19169807434082
Epoch: 43, Steps: 30 | Train Loss: 0.2668342 Vali Loss: 1.2163347 Test Loss: 0.6531935
Validation loss decreased (1.216812 --> 1.216335).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 5.201769828796387
Epoch: 44, Steps: 30 | Train Loss: 0.2658255 Vali Loss: 1.2150093 Test Loss: 0.6524329
Validation loss decreased (1.216335 --> 1.215009).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 5.156040906906128
Epoch: 45, Steps: 30 | Train Loss: 0.2648696 Vali Loss: 1.2129864 Test Loss: 0.6514978
Validation loss decreased (1.215009 --> 1.212986).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 4.973357677459717
Epoch: 46, Steps: 30 | Train Loss: 0.2639948 Vali Loss: 1.2147381 Test Loss: 0.6506927
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 4.9741551876068115
Epoch: 47, Steps: 30 | Train Loss: 0.2629183 Vali Loss: 1.2099915 Test Loss: 0.6499317
Validation loss decreased (1.212986 --> 1.209991).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 5.072255611419678
Epoch: 48, Steps: 30 | Train Loss: 0.2621599 Vali Loss: 1.2078887 Test Loss: 0.6494247
Validation loss decreased (1.209991 --> 1.207889).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 5.02960729598999
Epoch: 49, Steps: 30 | Train Loss: 0.2613920 Vali Loss: 1.2107155 Test Loss: 0.6486667
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 5.443984270095825
Epoch: 50, Steps: 30 | Train Loss: 0.2607897 Vali Loss: 1.2092967 Test Loss: 0.6479757
EarlyStopping counter: 2 out of 3
Updating learning rate to 4.0497355408796396e-05
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=165, out_features=209, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  61797120.0
params:  34694.0
Trainable parameters:  34694
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 5.558838129043579
Epoch: 1, Steps: 30 | Train Loss: 0.4941383 Vali Loss: 1.0955099 Test Loss: 0.5584956
Validation loss decreased (inf --> 1.095510).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 5.099853992462158
Epoch: 2, Steps: 30 | Train Loss: 0.4507388 Vali Loss: 1.0330131 Test Loss: 0.5022984
Validation loss decreased (1.095510 --> 1.033013).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 5.258690595626831
Epoch: 3, Steps: 30 | Train Loss: 0.4241519 Vali Loss: 0.9985290 Test Loss: 0.4672891
Validation loss decreased (1.033013 --> 0.998529).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 5.062325954437256
Epoch: 4, Steps: 30 | Train Loss: 0.4083366 Vali Loss: 0.9766663 Test Loss: 0.4468127
Validation loss decreased (0.998529 --> 0.976666).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 5.070773601531982
Epoch: 5, Steps: 30 | Train Loss: 0.3989906 Vali Loss: 0.9600857 Test Loss: 0.4346354
Validation loss decreased (0.976666 --> 0.960086).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 5.30709171295166
Epoch: 6, Steps: 30 | Train Loss: 0.3933610 Vali Loss: 0.9582524 Test Loss: 0.4273342
Validation loss decreased (0.960086 --> 0.958252).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 5.660655736923218
Epoch: 7, Steps: 30 | Train Loss: 0.3892948 Vali Loss: 0.9534948 Test Loss: 0.4235462
Validation loss decreased (0.958252 --> 0.953495).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 5.447073221206665
Epoch: 8, Steps: 30 | Train Loss: 0.3871489 Vali Loss: 0.9483322 Test Loss: 0.4213650
Validation loss decreased (0.953495 --> 0.948332).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 5.449885129928589
Epoch: 9, Steps: 30 | Train Loss: 0.3855124 Vali Loss: 0.9491282 Test Loss: 0.4203295
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 5.16139817237854
Epoch: 10, Steps: 30 | Train Loss: 0.3844789 Vali Loss: 0.9505566 Test Loss: 0.4194211
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 4.8147594928741455
Epoch: 11, Steps: 30 | Train Loss: 0.3831382 Vali Loss: 0.9513978 Test Loss: 0.4191849
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh1_720_192_FITS_ETTh1_ftM_sl720_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.41567832231521606, mae:0.42525699734687805, rse:0.6122602224349976, corr:[0.2627572  0.27143642 0.26910868 0.26807216 0.26826382 0.26677585
 0.26462588 0.26380318 0.26404098 0.26470515 0.2647185  0.26390564
 0.26301557 0.26249674 0.26235184 0.262392   0.26214972 0.26153323
 0.26080668 0.26039556 0.26032314 0.2601715  0.2596695  0.2594974
 0.25976622 0.2599709  0.259739   0.25944546 0.2595172  0.25966793
 0.25950518 0.25883803 0.2583896  0.25852126 0.2586517  0.25850642
 0.25815    0.25790575 0.25787953 0.25801408 0.25841686 0.2588936
 0.25906643 0.25899294 0.25894505 0.2590588  0.25929385 0.25948653
 0.2592693  0.25901583 0.25864813 0.2579535  0.25681347 0.25518677
 0.2540828  0.25384474 0.25390384 0.2537988  0.2533047  0.253127
 0.2533552  0.25345734 0.2529289  0.25231475 0.25228205 0.25301635
 0.25396648 0.25419125 0.25383267 0.25349057 0.25336546 0.2532053
 0.25280756 0.25207934 0.25111148 0.25068262 0.25075778 0.25084904
 0.2506018  0.24998812 0.24940054 0.24919473 0.24905658 0.24867375
 0.24827102 0.24819179 0.24854335 0.24882549 0.248698   0.24834292
 0.24792938 0.24751748 0.24724825 0.24726634 0.24755965 0.24804412
 0.24863109 0.24910669 0.24916385 0.24912007 0.24911317 0.24877878
 0.24844249 0.24836624 0.24841075 0.24835126 0.24798475 0.24754396
 0.24745254 0.24748279 0.24756742 0.24786474 0.24826553 0.24867795
 0.24891134 0.24874571 0.2484413  0.24838027 0.24863675 0.24892673
 0.24882562 0.24780512 0.24597925 0.24439563 0.24365905 0.24330671
 0.24308413 0.2428018  0.24233961 0.2420249  0.24152505 0.2408643
 0.24060774 0.24121523 0.24199335 0.24198593 0.24160884 0.24161193
 0.24223293 0.24260105 0.24232328 0.24194796 0.241925   0.24186295
 0.24135083 0.24019718 0.23880355 0.23771381 0.23694138 0.23580362
 0.23473276 0.23444143 0.23499197 0.23548846 0.23522009 0.234899
 0.23499334 0.23509349 0.23467895 0.2341789  0.23430978 0.23485279
 0.23475969 0.23395765 0.23352182 0.23377079 0.23394363 0.23301773
 0.23164105 0.23110433 0.23130934 0.2313966  0.23053968 0.22913343
 0.22827911 0.2285414  0.22894937 0.22915964 0.22865756 0.22791322
 0.22761199 0.22788829 0.22760884 0.22613254 0.22470169 0.225118
 0.22641277 0.2247906  0.21952222 0.21608602 0.22008504 0.21904084]
