Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=165, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=7, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh1_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:7
>>>>>>>start training : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=165, out_features=187, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  55292160.0
params:  31042.0
Trainable parameters:  31042
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 5.0786988735198975
Epoch: 1, Steps: 30 | Train Loss: 0.6444590 Vali Loss: 1.4763448 Test Loss: 0.7982692
Validation loss decreased (inf --> 1.476345).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 5.049800157546997
Epoch: 2, Steps: 30 | Train Loss: 0.5495384 Vali Loss: 1.3490212 Test Loss: 0.7511032
Validation loss decreased (1.476345 --> 1.349021).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 4.98850679397583
Epoch: 3, Steps: 30 | Train Loss: 0.4895468 Vali Loss: 1.2798524 Test Loss: 0.7218382
Validation loss decreased (1.349021 --> 1.279852).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 5.572728395462036
Epoch: 4, Steps: 30 | Train Loss: 0.4497720 Vali Loss: 1.2428097 Test Loss: 0.7074657
Validation loss decreased (1.279852 --> 1.242810).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 5.438302516937256
Epoch: 5, Steps: 30 | Train Loss: 0.4214966 Vali Loss: 1.2192260 Test Loss: 0.6990230
Validation loss decreased (1.242810 --> 1.219226).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 4.377995491027832
Epoch: 6, Steps: 30 | Train Loss: 0.4002342 Vali Loss: 1.2065492 Test Loss: 0.6956850
Validation loss decreased (1.219226 --> 1.206549).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.7143380641937256
Epoch: 7, Steps: 30 | Train Loss: 0.3834820 Vali Loss: 1.1945707 Test Loss: 0.6924936
Validation loss decreased (1.206549 --> 1.194571).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 4.130300045013428
Epoch: 8, Steps: 30 | Train Loss: 0.3693083 Vali Loss: 1.1810642 Test Loss: 0.6902643
Validation loss decreased (1.194571 --> 1.181064).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.912821292877197
Epoch: 9, Steps: 30 | Train Loss: 0.3571549 Vali Loss: 1.1757486 Test Loss: 0.6885018
Validation loss decreased (1.181064 --> 1.175749).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 4.904748916625977
Epoch: 10, Steps: 30 | Train Loss: 0.3470286 Vali Loss: 1.1646956 Test Loss: 0.6866503
Validation loss decreased (1.175749 --> 1.164696).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 5.0947041511535645
Epoch: 11, Steps: 30 | Train Loss: 0.3374944 Vali Loss: 1.1757343 Test Loss: 0.6848435
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 5.143409967422485
Epoch: 12, Steps: 30 | Train Loss: 0.3291716 Vali Loss: 1.1602930 Test Loss: 0.6812851
Validation loss decreased (1.164696 --> 1.160293).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 5.302016019821167
Epoch: 13, Steps: 30 | Train Loss: 0.3215869 Vali Loss: 1.1534833 Test Loss: 0.6786625
Validation loss decreased (1.160293 --> 1.153483).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 5.09944486618042
Epoch: 14, Steps: 30 | Train Loss: 0.3145653 Vali Loss: 1.1503742 Test Loss: 0.6757411
Validation loss decreased (1.153483 --> 1.150374).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 4.930901288986206
Epoch: 15, Steps: 30 | Train Loss: 0.3079770 Vali Loss: 1.1390076 Test Loss: 0.6737346
Validation loss decreased (1.150374 --> 1.139008).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 4.754453182220459
Epoch: 16, Steps: 30 | Train Loss: 0.3021961 Vali Loss: 1.1409895 Test Loss: 0.6711712
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 4.615476369857788
Epoch: 17, Steps: 30 | Train Loss: 0.2968638 Vali Loss: 1.1261798 Test Loss: 0.6673683
Validation loss decreased (1.139008 --> 1.126180).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 4.746796369552612
Epoch: 18, Steps: 30 | Train Loss: 0.2917921 Vali Loss: 1.1200945 Test Loss: 0.6649646
Validation loss decreased (1.126180 --> 1.120095).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 4.623987913131714
Epoch: 19, Steps: 30 | Train Loss: 0.2871843 Vali Loss: 1.1174405 Test Loss: 0.6613019
Validation loss decreased (1.120095 --> 1.117440).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.9837327003479
Epoch: 20, Steps: 30 | Train Loss: 0.2828545 Vali Loss: 1.1100827 Test Loss: 0.6594442
Validation loss decreased (1.117440 --> 1.110083).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 4.91139817237854
Epoch: 21, Steps: 30 | Train Loss: 0.2789982 Vali Loss: 1.1056341 Test Loss: 0.6570464
Validation loss decreased (1.110083 --> 1.105634).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 5.137229919433594
Epoch: 22, Steps: 30 | Train Loss: 0.2747636 Vali Loss: 1.0988436 Test Loss: 0.6539533
Validation loss decreased (1.105634 --> 1.098844).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 4.931112766265869
Epoch: 23, Steps: 30 | Train Loss: 0.2712515 Vali Loss: 1.1020703 Test Loss: 0.6524584
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 4.683761835098267
Epoch: 24, Steps: 30 | Train Loss: 0.2677928 Vali Loss: 1.0947154 Test Loss: 0.6488283
Validation loss decreased (1.098844 --> 1.094715).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 4.8475282192230225
Epoch: 25, Steps: 30 | Train Loss: 0.2649184 Vali Loss: 1.0898693 Test Loss: 0.6471865
Validation loss decreased (1.094715 --> 1.089869).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 4.827518939971924
Epoch: 26, Steps: 30 | Train Loss: 0.2620741 Vali Loss: 1.0854199 Test Loss: 0.6455004
Validation loss decreased (1.089869 --> 1.085420).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 4.58177375793457
Epoch: 27, Steps: 30 | Train Loss: 0.2594196 Vali Loss: 1.0843966 Test Loss: 0.6424720
Validation loss decreased (1.085420 --> 1.084397).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 4.758177280426025
Epoch: 28, Steps: 30 | Train Loss: 0.2566480 Vali Loss: 1.0758687 Test Loss: 0.6409148
Validation loss decreased (1.084397 --> 1.075869).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 4.780810594558716
Epoch: 29, Steps: 30 | Train Loss: 0.2542211 Vali Loss: 1.0741061 Test Loss: 0.6388062
Validation loss decreased (1.075869 --> 1.074106).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 5.075624942779541
Epoch: 30, Steps: 30 | Train Loss: 0.2519613 Vali Loss: 1.0760885 Test Loss: 0.6366557
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 4.995881795883179
Epoch: 31, Steps: 30 | Train Loss: 0.2499162 Vali Loss: 1.0692025 Test Loss: 0.6349863
Validation loss decreased (1.074106 --> 1.069203).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 5.068925142288208
Epoch: 32, Steps: 30 | Train Loss: 0.2479932 Vali Loss: 1.0713371 Test Loss: 0.6334168
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 4.652035474777222
Epoch: 33, Steps: 30 | Train Loss: 0.2460151 Vali Loss: 1.0604502 Test Loss: 0.6313146
Validation loss decreased (1.069203 --> 1.060450).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.9892263412475586
Epoch: 34, Steps: 30 | Train Loss: 0.2441364 Vali Loss: 1.0600464 Test Loss: 0.6292778
Validation loss decreased (1.060450 --> 1.060046).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 4.8166399002075195
Epoch: 35, Steps: 30 | Train Loss: 0.2423734 Vali Loss: 1.0611889 Test Loss: 0.6282002
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 4.461336851119995
Epoch: 36, Steps: 30 | Train Loss: 0.2408635 Vali Loss: 1.0556806 Test Loss: 0.6262362
Validation loss decreased (1.060046 --> 1.055681).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 4.664069175720215
Epoch: 37, Steps: 30 | Train Loss: 0.2392264 Vali Loss: 1.0538719 Test Loss: 0.6251273
Validation loss decreased (1.055681 --> 1.053872).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 4.999732971191406
Epoch: 38, Steps: 30 | Train Loss: 0.2380836 Vali Loss: 1.0541216 Test Loss: 0.6238074
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 5.0415027141571045
Epoch: 39, Steps: 30 | Train Loss: 0.2365264 Vali Loss: 1.0487126 Test Loss: 0.6226847
Validation loss decreased (1.053872 --> 1.048713).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 5.073304891586304
Epoch: 40, Steps: 30 | Train Loss: 0.2351165 Vali Loss: 1.0435914 Test Loss: 0.6211830
Validation loss decreased (1.048713 --> 1.043591).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 4.762104034423828
Epoch: 41, Steps: 30 | Train Loss: 0.2339607 Vali Loss: 1.0465628 Test Loss: 0.6202107
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 4.8419435024261475
Epoch: 42, Steps: 30 | Train Loss: 0.2331433 Vali Loss: 1.0466743 Test Loss: 0.6191458
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 4.914240837097168
Epoch: 43, Steps: 30 | Train Loss: 0.2318360 Vali Loss: 1.0416355 Test Loss: 0.6178638
Validation loss decreased (1.043591 --> 1.041636).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 4.45181131362915
Epoch: 44, Steps: 30 | Train Loss: 0.2307668 Vali Loss: 1.0408647 Test Loss: 0.6171268
Validation loss decreased (1.041636 --> 1.040865).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 5.041335344314575
Epoch: 45, Steps: 30 | Train Loss: 0.2298624 Vali Loss: 1.0352001 Test Loss: 0.6160364
Validation loss decreased (1.040865 --> 1.035200).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 4.993268966674805
Epoch: 46, Steps: 30 | Train Loss: 0.2289433 Vali Loss: 1.0355833 Test Loss: 0.6150971
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 4.916877508163452
Epoch: 47, Steps: 30 | Train Loss: 0.2281910 Vali Loss: 1.0344727 Test Loss: 0.6141703
Validation loss decreased (1.035200 --> 1.034473).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 5.2964441776275635
Epoch: 48, Steps: 30 | Train Loss: 0.2276791 Vali Loss: 1.0379812 Test Loss: 0.6132293
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 5.380532503128052
Epoch: 49, Steps: 30 | Train Loss: 0.2263633 Vali Loss: 1.0318047 Test Loss: 0.6123284
Validation loss decreased (1.034473 --> 1.031805).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 4.810684442520142
Epoch: 50, Steps: 30 | Train Loss: 0.2256551 Vali Loss: 1.0348364 Test Loss: 0.6116543
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.0497355408796396e-05
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=165, out_features=187, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  55292160.0
params:  31042.0
Trainable parameters:  31042
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 5.077901601791382
Epoch: 1, Steps: 30 | Train Loss: 0.4394333 Vali Loss: 0.8518919 Test Loss: 0.4749632
Validation loss decreased (inf --> 0.851892).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 5.276317119598389
Epoch: 2, Steps: 30 | Train Loss: 0.3803108 Vali Loss: 0.7678887 Test Loss: 0.4144086
Validation loss decreased (0.851892 --> 0.767889).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 5.005290508270264
Epoch: 3, Steps: 30 | Train Loss: 0.3564630 Vali Loss: 0.7343327 Test Loss: 0.3929323
Validation loss decreased (0.767889 --> 0.734333).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 5.405582427978516
Epoch: 4, Steps: 30 | Train Loss: 0.3460802 Vali Loss: 0.7242972 Test Loss: 0.3856000
Validation loss decreased (0.734333 --> 0.724297).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 5.145728349685669
Epoch: 5, Steps: 30 | Train Loss: 0.3418284 Vali Loss: 0.7124945 Test Loss: 0.3829459
Validation loss decreased (0.724297 --> 0.712494).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 5.1755030155181885
Epoch: 6, Steps: 30 | Train Loss: 0.3397645 Vali Loss: 0.7085989 Test Loss: 0.3821169
Validation loss decreased (0.712494 --> 0.708599).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 5.225968599319458
Epoch: 7, Steps: 30 | Train Loss: 0.3382232 Vali Loss: 0.7135395 Test Loss: 0.3819958
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 4.861020088195801
Epoch: 8, Steps: 30 | Train Loss: 0.3373443 Vali Loss: 0.7053425 Test Loss: 0.3821646
Validation loss decreased (0.708599 --> 0.705343).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 5.01847767829895
Epoch: 9, Steps: 30 | Train Loss: 0.3359559 Vali Loss: 0.7117850 Test Loss: 0.3821837
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 4.867023468017578
Epoch: 10, Steps: 30 | Train Loss: 0.3352506 Vali Loss: 0.7049468 Test Loss: 0.3818235
Validation loss decreased (0.705343 --> 0.704947).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 4.766669750213623
Epoch: 11, Steps: 30 | Train Loss: 0.3351832 Vali Loss: 0.7066007 Test Loss: 0.3816598
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 5.330664873123169
Epoch: 12, Steps: 30 | Train Loss: 0.3346922 Vali Loss: 0.7038898 Test Loss: 0.3820119
Validation loss decreased (0.704947 --> 0.703890).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 5.158697605133057
Epoch: 13, Steps: 30 | Train Loss: 0.3340157 Vali Loss: 0.7023748 Test Loss: 0.3819394
Validation loss decreased (0.703890 --> 0.702375).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 5.325193166732788
Epoch: 14, Steps: 30 | Train Loss: 0.3331892 Vali Loss: 0.6985728 Test Loss: 0.3818198
Validation loss decreased (0.702375 --> 0.698573).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 4.899054527282715
Epoch: 15, Steps: 30 | Train Loss: 0.3340115 Vali Loss: 0.7002240 Test Loss: 0.3814929
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 5.2299721240997314
Epoch: 16, Steps: 30 | Train Loss: 0.3335780 Vali Loss: 0.6991860 Test Loss: 0.3817778
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 4.819590091705322
Epoch: 17, Steps: 30 | Train Loss: 0.3340325 Vali Loss: 0.6956214 Test Loss: 0.3814011
Validation loss decreased (0.698573 --> 0.695621).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 4.942492485046387
Epoch: 18, Steps: 30 | Train Loss: 0.3324357 Vali Loss: 0.7035460 Test Loss: 0.3816755
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 4.799830913543701
Epoch: 19, Steps: 30 | Train Loss: 0.3333032 Vali Loss: 0.6999675 Test Loss: 0.3815565
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 5.122791290283203
Epoch: 20, Steps: 30 | Train Loss: 0.3326267 Vali Loss: 0.6965261 Test Loss: 0.3813995
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh1_720_96_FITS_ETTh1_ftM_sl720_ll48_pl96_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.3806248605251312, mae:0.40404367446899414, rse:0.5860118865966797, corr:[0.2715116  0.27887118 0.27941963 0.27843374 0.2765088  0.2741723
 0.272356   0.27182177 0.27172053 0.27180794 0.27150935 0.2709318
 0.27072725 0.27092716 0.27113488 0.27116787 0.27092668 0.27077928
 0.27061754 0.27022913 0.26962966 0.26919344 0.26873532 0.26877353
 0.26894835 0.26901075 0.268846   0.268594   0.2684393  0.2682243
 0.26781982 0.26709092 0.26661226 0.26665685 0.2667166  0.266617
 0.2664138  0.2663029  0.26637128 0.26650462 0.26689106 0.26728162
 0.26740304 0.26734754 0.26742518 0.26763228 0.2678683  0.2680426
 0.26762196 0.26696986 0.2660096  0.26479775 0.2634149  0.26200667
 0.26131147 0.26111248 0.26068836 0.26015368 0.25956616 0.25957814
 0.25978717 0.2598593  0.25971797 0.25975797 0.25995243 0.2601524
 0.26043633 0.26033503 0.25989905 0.25946483 0.25934634 0.25925276
 0.25888768 0.25791535 0.25638077 0.25556853 0.25544053 0.255061
 0.25409505 0.25311655 0.25261626 0.25242427 0.25188786 0.25122386
 0.25110272 0.2512315  0.25117525 0.25045326 0.24952886 0.24894422
 0.24859908 0.24776734 0.24600086 0.24405809 0.24489954 0.2474161 ]
