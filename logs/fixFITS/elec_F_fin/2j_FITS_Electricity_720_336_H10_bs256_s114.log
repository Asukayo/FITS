Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=512, c_out=7, checkpoints='./checkpoints/', cut_freq=320, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=4, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_720_j336_H10', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:4
>>>>>>>start training : Electricity_720_j336_H10_FITS_custom_ftM_sl720_ll48_pl336_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17357
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=320, out_features=469, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  24665948160.0
params:  150549.0
Trainable parameters:  150549
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 54.83569312095642
Epoch: 1, Steps: 33 | Train Loss: 1.0533276 Vali Loss: 0.8271139 Test Loss: 0.9521928
Validation loss decreased (inf --> 0.827114).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 55.303868532180786
Epoch: 2, Steps: 33 | Train Loss: 0.8403029 Vali Loss: 0.7164431 Test Loss: 0.8297256
Validation loss decreased (0.827114 --> 0.716443).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 49.33364152908325
Epoch: 3, Steps: 33 | Train Loss: 0.7435078 Vali Loss: 0.6631634 Test Loss: 0.7697913
Validation loss decreased (0.716443 --> 0.663163).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 46.39891695976257
Epoch: 4, Steps: 33 | Train Loss: 0.6944741 Vali Loss: 0.6347020 Test Loss: 0.7372406
Validation loss decreased (0.663163 --> 0.634702).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 55.581456422805786
Epoch: 5, Steps: 33 | Train Loss: 0.6632894 Vali Loss: 0.6139084 Test Loss: 0.7142240
Validation loss decreased (0.634702 --> 0.613908).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 55.69177746772766
Epoch: 6, Steps: 33 | Train Loss: 0.6392023 Vali Loss: 0.5975421 Test Loss: 0.6961733
Validation loss decreased (0.613908 --> 0.597542).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 56.70128035545349
Epoch: 7, Steps: 33 | Train Loss: 0.6184987 Vali Loss: 0.5851995 Test Loss: 0.6815268
Validation loss decreased (0.597542 --> 0.585200).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 53.80615448951721
Epoch: 8, Steps: 33 | Train Loss: 0.6003739 Vali Loss: 0.5698834 Test Loss: 0.6643453
Validation loss decreased (0.585200 --> 0.569883).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 52.64830493927002
Epoch: 9, Steps: 33 | Train Loss: 0.5834379 Vali Loss: 0.5593764 Test Loss: 0.6521240
Validation loss decreased (0.569883 --> 0.559376).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 55.33645725250244
Epoch: 10, Steps: 33 | Train Loss: 0.5682719 Vali Loss: 0.5479659 Test Loss: 0.6396704
Validation loss decreased (0.559376 --> 0.547966).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 53.38317513465881
Epoch: 11, Steps: 33 | Train Loss: 0.5541587 Vali Loss: 0.5379995 Test Loss: 0.6286449
Validation loss decreased (0.547966 --> 0.538000).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 48.314316272735596
Epoch: 12, Steps: 33 | Train Loss: 0.5410189 Vali Loss: 0.5285952 Test Loss: 0.6172417
Validation loss decreased (0.538000 --> 0.528595).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 56.99417018890381
Epoch: 13, Steps: 33 | Train Loss: 0.5288508 Vali Loss: 0.5203023 Test Loss: 0.6079199
Validation loss decreased (0.528595 --> 0.520302).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 56.864806175231934
Epoch: 14, Steps: 33 | Train Loss: 0.5178207 Vali Loss: 0.5117892 Test Loss: 0.5987381
Validation loss decreased (0.520302 --> 0.511789).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 57.33963966369629
Epoch: 15, Steps: 33 | Train Loss: 0.5072068 Vali Loss: 0.5041553 Test Loss: 0.5901996
Validation loss decreased (0.511789 --> 0.504155).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 59.01643919944763
Epoch: 16, Steps: 33 | Train Loss: 0.4975688 Vali Loss: 0.4970745 Test Loss: 0.5827345
Validation loss decreased (0.504155 --> 0.497075).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 56.70671534538269
Epoch: 17, Steps: 33 | Train Loss: 0.4886187 Vali Loss: 0.4912897 Test Loss: 0.5750742
Validation loss decreased (0.497075 --> 0.491290).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 56.50511121749878
Epoch: 18, Steps: 33 | Train Loss: 0.4802165 Vali Loss: 0.4841875 Test Loss: 0.5679536
Validation loss decreased (0.491290 --> 0.484187).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 61.788360357284546
Epoch: 19, Steps: 33 | Train Loss: 0.4722599 Vali Loss: 0.4782257 Test Loss: 0.5612544
Validation loss decreased (0.484187 --> 0.478226).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 58.61862015724182
Epoch: 20, Steps: 33 | Train Loss: 0.4647686 Vali Loss: 0.4727327 Test Loss: 0.5548636
Validation loss decreased (0.478226 --> 0.472733).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 60.542810678482056
Epoch: 21, Steps: 33 | Train Loss: 0.4578613 Vali Loss: 0.4673110 Test Loss: 0.5489730
Validation loss decreased (0.472733 --> 0.467311).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 55.68849968910217
Epoch: 22, Steps: 33 | Train Loss: 0.4514570 Vali Loss: 0.4627445 Test Loss: 0.5437166
Validation loss decreased (0.467311 --> 0.462744).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 47.77166175842285
Epoch: 23, Steps: 33 | Train Loss: 0.4454349 Vali Loss: 0.4578406 Test Loss: 0.5383792
Validation loss decreased (0.462744 --> 0.457841).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 55.544636964797974
Epoch: 24, Steps: 33 | Train Loss: 0.4397860 Vali Loss: 0.4541500 Test Loss: 0.5337310
Validation loss decreased (0.457841 --> 0.454150).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 58.50860357284546
Epoch: 25, Steps: 33 | Train Loss: 0.4340806 Vali Loss: 0.4493584 Test Loss: 0.5287687
Validation loss decreased (0.454150 --> 0.449358).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 60.753971338272095
Epoch: 26, Steps: 33 | Train Loss: 0.4291455 Vali Loss: 0.4458940 Test Loss: 0.5246409
Validation loss decreased (0.449358 --> 0.445894).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 59.430766582489014
Epoch: 27, Steps: 33 | Train Loss: 0.4244493 Vali Loss: 0.4423914 Test Loss: 0.5207511
Validation loss decreased (0.445894 --> 0.442391).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 60.20041489601135
Epoch: 28, Steps: 33 | Train Loss: 0.4197274 Vali Loss: 0.4380993 Test Loss: 0.5166324
Validation loss decreased (0.442391 --> 0.438099).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 56.75470232963562
Epoch: 29, Steps: 33 | Train Loss: 0.4158032 Vali Loss: 0.4351406 Test Loss: 0.5127395
Validation loss decreased (0.438099 --> 0.435141).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 59.28490447998047
Epoch: 30, Steps: 33 | Train Loss: 0.4117051 Vali Loss: 0.4322478 Test Loss: 0.5098650
Validation loss decreased (0.435141 --> 0.432248).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 57.48885250091553
Epoch: 31, Steps: 33 | Train Loss: 0.4078054 Vali Loss: 0.4293991 Test Loss: 0.5060988
Validation loss decreased (0.432248 --> 0.429399).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 61.564626932144165
Epoch: 32, Steps: 33 | Train Loss: 0.4044966 Vali Loss: 0.4266919 Test Loss: 0.5033062
Validation loss decreased (0.429399 --> 0.426692).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 57.966285705566406
Epoch: 33, Steps: 33 | Train Loss: 0.4009225 Vali Loss: 0.4244052 Test Loss: 0.5002841
Validation loss decreased (0.426692 --> 0.424405).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 59.1292998790741
Epoch: 34, Steps: 33 | Train Loss: 0.3979282 Vali Loss: 0.4212688 Test Loss: 0.4972663
Validation loss decreased (0.424405 --> 0.421269).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 54.6136999130249
Epoch: 35, Steps: 33 | Train Loss: 0.3948790 Vali Loss: 0.4192927 Test Loss: 0.4950271
Validation loss decreased (0.421269 --> 0.419293).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 52.75977659225464
Epoch: 36, Steps: 33 | Train Loss: 0.3920461 Vali Loss: 0.4173580 Test Loss: 0.4926250
Validation loss decreased (0.419293 --> 0.417358).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 54.04716920852661
Epoch: 37, Steps: 33 | Train Loss: 0.3894371 Vali Loss: 0.4150405 Test Loss: 0.4900003
Validation loss decreased (0.417358 --> 0.415041).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 54.19726371765137
Epoch: 38, Steps: 33 | Train Loss: 0.3867389 Vali Loss: 0.4130951 Test Loss: 0.4879003
Validation loss decreased (0.415041 --> 0.413095).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 55.150803565979004
Epoch: 39, Steps: 33 | Train Loss: 0.3844604 Vali Loss: 0.4115696 Test Loss: 0.4858661
Validation loss decreased (0.413095 --> 0.411570).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 66.30283975601196
Epoch: 40, Steps: 33 | Train Loss: 0.3821859 Vali Loss: 0.4092316 Test Loss: 0.4836712
Validation loss decreased (0.411570 --> 0.409232).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 60.21468925476074
Epoch: 41, Steps: 33 | Train Loss: 0.3800769 Vali Loss: 0.4077637 Test Loss: 0.4820745
Validation loss decreased (0.409232 --> 0.407764).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 54.76935529708862
Epoch: 42, Steps: 33 | Train Loss: 0.3780620 Vali Loss: 0.4062594 Test Loss: 0.4801029
Validation loss decreased (0.407764 --> 0.406259).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 57.316251039505005
Epoch: 43, Steps: 33 | Train Loss: 0.3761370 Vali Loss: 0.4047409 Test Loss: 0.4785106
Validation loss decreased (0.406259 --> 0.404741).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 57.80702185630798
Epoch: 44, Steps: 33 | Train Loss: 0.3744058 Vali Loss: 0.4032485 Test Loss: 0.4768193
Validation loss decreased (0.404741 --> 0.403248).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 53.881653785705566
Epoch: 45, Steps: 33 | Train Loss: 0.3724914 Vali Loss: 0.4021747 Test Loss: 0.4753414
Validation loss decreased (0.403248 --> 0.402175).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 57.21545743942261
Epoch: 46, Steps: 33 | Train Loss: 0.3709386 Vali Loss: 0.4009888 Test Loss: 0.4738873
Validation loss decreased (0.402175 --> 0.400989).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 58.592283725738525
Epoch: 47, Steps: 33 | Train Loss: 0.3693453 Vali Loss: 0.3995249 Test Loss: 0.4726166
Validation loss decreased (0.400989 --> 0.399525).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 57.22181558609009
Epoch: 48, Steps: 33 | Train Loss: 0.3678515 Vali Loss: 0.3979023 Test Loss: 0.4711348
Validation loss decreased (0.399525 --> 0.397902).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 56.42778539657593
Epoch: 49, Steps: 33 | Train Loss: 0.3664928 Vali Loss: 0.3974092 Test Loss: 0.4701094
Validation loss decreased (0.397902 --> 0.397409).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 57.84867572784424
Epoch: 50, Steps: 33 | Train Loss: 0.3651171 Vali Loss: 0.3963338 Test Loss: 0.4688171
Validation loss decreased (0.397409 --> 0.396334).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
train 17357
val 2297
test 4925
Model(
  (freq_upsampler): Linear(in_features=320, out_features=469, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  24665948160.0
params:  150549.0
Trainable parameters:  150549
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 52.20416522026062
Epoch: 1, Steps: 33 | Train Loss: 0.4150902 Vali Loss: 0.3007240 Test Loss: 0.3599196
Validation loss decreased (inf --> 0.300724).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 52.55926156044006
Epoch: 2, Steps: 33 | Train Loss: 0.3288379 Vali Loss: 0.2426474 Test Loss: 0.2930266
Validation loss decreased (0.300724 --> 0.242647).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 50.51601791381836
Epoch: 3, Steps: 33 | Train Loss: 0.2738962 Vali Loss: 0.2060630 Test Loss: 0.2502673
Validation loss decreased (0.242647 --> 0.206063).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 54.558016538619995
Epoch: 4, Steps: 33 | Train Loss: 0.2385963 Vali Loss: 0.1825019 Test Loss: 0.2221228
Validation loss decreased (0.206063 --> 0.182502).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 48.17926740646362
Epoch: 5, Steps: 33 | Train Loss: 0.2153187 Vali Loss: 0.1673156 Test Loss: 0.2035852
Validation loss decreased (0.182502 --> 0.167316).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 47.23850631713867
Epoch: 6, Steps: 33 | Train Loss: 0.1999907 Vali Loss: 0.1570401 Test Loss: 0.1914133
Validation loss decreased (0.167316 --> 0.157040).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 48.07539677619934
Epoch: 7, Steps: 33 | Train Loss: 0.1902698 Vali Loss: 0.1511897 Test Loss: 0.1834705
Validation loss decreased (0.157040 --> 0.151190).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 45.37081503868103
Epoch: 8, Steps: 33 | Train Loss: 0.1839851 Vali Loss: 0.1476265 Test Loss: 0.1783206
Validation loss decreased (0.151190 --> 0.147626).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 42.44595408439636
Epoch: 9, Steps: 33 | Train Loss: 0.1798574 Vali Loss: 0.1449690 Test Loss: 0.1749878
Validation loss decreased (0.147626 --> 0.144969).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 41.17932367324829
Epoch: 10, Steps: 33 | Train Loss: 0.1775513 Vali Loss: 0.1436199 Test Loss: 0.1728288
Validation loss decreased (0.144969 --> 0.143620).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 40.19784426689148
Epoch: 11, Steps: 33 | Train Loss: 0.1759397 Vali Loss: 0.1425807 Test Loss: 0.1714215
Validation loss decreased (0.143620 --> 0.142581).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 50.01237988471985
Epoch: 12, Steps: 33 | Train Loss: 0.1746946 Vali Loss: 0.1423481 Test Loss: 0.1704915
Validation loss decreased (0.142581 --> 0.142348).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 55.41457676887512
Epoch: 13, Steps: 33 | Train Loss: 0.1740581 Vali Loss: 0.1419320 Test Loss: 0.1698636
Validation loss decreased (0.142348 --> 0.141932).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 44.98682618141174
Epoch: 14, Steps: 33 | Train Loss: 0.1733646 Vali Loss: 0.1417620 Test Loss: 0.1694365
Validation loss decreased (0.141932 --> 0.141762).  Saving model ...
Updating learning rate to 0.0002566710416397524
