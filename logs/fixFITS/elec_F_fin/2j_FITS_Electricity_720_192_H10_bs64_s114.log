Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=320, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=4, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_720_j192_H10', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:4
>>>>>>>start training : Electricity_720_j192_H10_FITS_custom_ftM_sl720_ll48_pl192_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17501
val 2441
test 5069
Model(
  (freq_upsampler): Linear(in_features=320, out_features=405, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  5325004800.0
params:  130005.0
Trainable parameters:  130005
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.7419030
	speed: 0.3263s/iter; left time: 2186.3079s
Epoch: 1 cost time: 44.40413689613342
Epoch: 1, Steps: 136 | Train Loss: 0.8722703 Vali Loss: 0.6603276 Test Loss: 0.7617604
Validation loss decreased (inf --> 0.660328).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6589561
	speed: 0.6976s/iter; left time: 4579.8504s
Epoch: 2 cost time: 40.81973886489868
Epoch: 2, Steps: 136 | Train Loss: 0.6621996 Vali Loss: 0.5846944 Test Loss: 0.6755649
Validation loss decreased (0.660328 --> 0.584694).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5512269
	speed: 0.7239s/iter; left time: 4654.0490s
Epoch: 3 cost time: 45.644144773483276
Epoch: 3, Steps: 136 | Train Loss: 0.5667901 Vali Loss: 0.5219904 Test Loss: 0.6050304
Validation loss decreased (0.584694 --> 0.521990).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4793968
	speed: 0.7956s/iter; left time: 5006.7882s
Epoch: 4 cost time: 48.12828183174133
Epoch: 4, Steps: 136 | Train Loss: 0.4904177 Vali Loss: 0.4716236 Test Loss: 0.5489656
Validation loss decreased (0.521990 --> 0.471624).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4190193
	speed: 0.7387s/iter; left time: 4548.1528s
Epoch: 5 cost time: 43.86858367919922
Epoch: 5, Steps: 136 | Train Loss: 0.4273834 Vali Loss: 0.4273337 Test Loss: 0.4995571
Validation loss decreased (0.471624 --> 0.427334).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3630379
	speed: 0.7138s/iter; left time: 4297.5677s
Epoch: 6 cost time: 41.18986916542053
Epoch: 6, Steps: 136 | Train Loss: 0.3743683 Vali Loss: 0.3864696 Test Loss: 0.4540264
Validation loss decreased (0.427334 --> 0.386470).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3149460
	speed: 0.6969s/iter; left time: 4101.2658s
Epoch: 7 cost time: 40.54128575325012
Epoch: 7, Steps: 136 | Train Loss: 0.3295419 Vali Loss: 0.3533413 Test Loss: 0.4166767
Validation loss decreased (0.386470 --> 0.353341).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2849030
	speed: 0.6769s/iter; left time: 3891.7342s
Epoch: 8 cost time: 42.833341121673584
Epoch: 8, Steps: 136 | Train Loss: 0.2913328 Vali Loss: 0.3249632 Test Loss: 0.3849299
Validation loss decreased (0.353341 --> 0.324963).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2554870
	speed: 0.6935s/iter; left time: 3892.5661s
Epoch: 9 cost time: 39.55521082878113
Epoch: 9, Steps: 136 | Train Loss: 0.2585641 Vali Loss: 0.2992975 Test Loss: 0.3558782
Validation loss decreased (0.324963 --> 0.299297).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2273937
	speed: 0.6415s/iter; left time: 3513.4238s
Epoch: 10 cost time: 41.80972766876221
Epoch: 10, Steps: 136 | Train Loss: 0.2304270 Vali Loss: 0.2778710 Test Loss: 0.3316899
Validation loss decreased (0.299297 --> 0.277871).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2050191
	speed: 0.6976s/iter; left time: 3726.0224s
Epoch: 11 cost time: 43.541022062301636
Epoch: 11, Steps: 136 | Train Loss: 0.2061735 Vali Loss: 0.2602644 Test Loss: 0.3118135
Validation loss decreased (0.277871 --> 0.260264).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1821692
	speed: 0.6917s/iter; left time: 3600.2418s
Epoch: 12 cost time: 41.74412417411804
Epoch: 12, Steps: 136 | Train Loss: 0.1852096 Vali Loss: 0.2429370 Test Loss: 0.2921384
Validation loss decreased (0.260264 --> 0.242937).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1614143
	speed: 0.7040s/iter; left time: 3568.4095s
Epoch: 13 cost time: 43.83250093460083
Epoch: 13, Steps: 136 | Train Loss: 0.1670283 Vali Loss: 0.2281547 Test Loss: 0.2752567
Validation loss decreased (0.242937 --> 0.228155).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1494322
	speed: 0.6895s/iter; left time: 3401.4420s
Epoch: 14 cost time: 42.21101522445679
Epoch: 14, Steps: 136 | Train Loss: 0.1512253 Vali Loss: 0.2165538 Test Loss: 0.2619779
Validation loss decreased (0.228155 --> 0.216554).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1381214
	speed: 0.6804s/iter; left time: 3263.8949s
Epoch: 15 cost time: 40.41933846473694
Epoch: 15, Steps: 136 | Train Loss: 0.1374584 Vali Loss: 0.2055417 Test Loss: 0.2493145
Validation loss decreased (0.216554 --> 0.205542).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1212506
	speed: 0.6748s/iter; left time: 3145.0141s
Epoch: 16 cost time: 41.045371770858765
Epoch: 16, Steps: 136 | Train Loss: 0.1254422 Vali Loss: 0.1953672 Test Loss: 0.2375712
Validation loss decreased (0.205542 --> 0.195367).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1116756
	speed: 0.7469s/iter; left time: 3379.5754s
Epoch: 17 cost time: 44.453348875045776
Epoch: 17, Steps: 136 | Train Loss: 0.1148963 Vali Loss: 0.1872570 Test Loss: 0.2282473
Validation loss decreased (0.195367 --> 0.187257).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1011770
	speed: 0.7020s/iter; left time: 3081.1491s
Epoch: 18 cost time: 42.57558560371399
Epoch: 18, Steps: 136 | Train Loss: 0.1057037 Vali Loss: 0.1803945 Test Loss: 0.2202319
Validation loss decreased (0.187257 --> 0.180395).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.0948080
	speed: 0.6868s/iter; left time: 2921.1323s
Epoch: 19 cost time: 40.04311013221741
Epoch: 19, Steps: 136 | Train Loss: 0.0976112 Vali Loss: 0.1742856 Test Loss: 0.2129489
Validation loss decreased (0.180395 --> 0.174286).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.0902878
	speed: 0.6321s/iter; left time: 2602.2945s
Epoch: 20 cost time: 36.622194051742554
Epoch: 20, Steps: 136 | Train Loss: 0.0904916 Vali Loss: 0.1688444 Test Loss: 0.2065829
Validation loss decreased (0.174286 --> 0.168844).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.0834262
	speed: 0.6984s/iter; left time: 2780.2493s
Epoch: 21 cost time: 44.11204695701599
Epoch: 21, Steps: 136 | Train Loss: 0.0842730 Vali Loss: 0.1638095 Test Loss: 0.2007180
Validation loss decreased (0.168844 --> 0.163810).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.0802985
	speed: 0.7159s/iter; left time: 2752.7695s
Epoch: 22 cost time: 44.15805006027222
Epoch: 22, Steps: 136 | Train Loss: 0.0787560 Vali Loss: 0.1596615 Test Loss: 0.1958627
Validation loss decreased (0.163810 --> 0.159661).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.0718721
	speed: 0.7283s/iter; left time: 2701.4468s
Epoch: 23 cost time: 43.845282554626465
Epoch: 23, Steps: 136 | Train Loss: 0.0738984 Vali Loss: 0.1549670 Test Loss: 0.1902187
Validation loss decreased (0.159661 --> 0.154967).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.0667995
	speed: 0.7330s/iter; left time: 2619.0694s
Epoch: 24 cost time: 45.8529634475708
Epoch: 24, Steps: 136 | Train Loss: 0.0695884 Vali Loss: 0.1520732 Test Loss: 0.1867887
Validation loss decreased (0.154967 --> 0.152073).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.0635645
	speed: 0.7393s/iter; left time: 2540.9845s
Epoch: 25 cost time: 42.73374795913696
Epoch: 25, Steps: 136 | Train Loss: 0.0657990 Vali Loss: 0.1493612 Test Loss: 0.1834483
Validation loss decreased (0.152073 --> 0.149361).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.0604021
	speed: 0.7355s/iter; left time: 2428.0416s
Epoch: 26 cost time: 45.34280848503113
Epoch: 26, Steps: 136 | Train Loss: 0.0624491 Vali Loss: 0.1468793 Test Loss: 0.1804561
Validation loss decreased (0.149361 --> 0.146879).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.0587453
	speed: 0.7187s/iter; left time: 2274.5294s
Epoch: 27 cost time: 42.62603163719177
Epoch: 27, Steps: 136 | Train Loss: 0.0594764 Vali Loss: 0.1446453 Test Loss: 0.1777699
Validation loss decreased (0.146879 --> 0.144645).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.0575346
	speed: 0.7047s/iter; left time: 2134.6168s
Epoch: 28 cost time: 42.145670652389526
Epoch: 28, Steps: 136 | Train Loss: 0.0568392 Vali Loss: 0.1427003 Test Loss: 0.1754793
Validation loss decreased (0.144645 --> 0.142700).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.0523844
	speed: 0.6977s/iter; left time: 2018.5877s
Epoch: 29 cost time: 41.61074376106262
Epoch: 29, Steps: 136 | Train Loss: 0.0544852 Vali Loss: 0.1407390 Test Loss: 0.1729452
Validation loss decreased (0.142700 --> 0.140739).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.0506366
	speed: 0.7049s/iter; left time: 1943.4508s
Epoch: 30 cost time: 42.625404596328735
Epoch: 30, Steps: 136 | Train Loss: 0.0524309 Vali Loss: 0.1394300 Test Loss: 0.1713232
Validation loss decreased (0.140739 --> 0.139430).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.0490129
	speed: 0.7068s/iter; left time: 1852.4425s
Epoch: 31 cost time: 42.539302587509155
Epoch: 31, Steps: 136 | Train Loss: 0.0505694 Vali Loss: 0.1378713 Test Loss: 0.1693564
Validation loss decreased (0.139430 --> 0.137871).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.0512857
	speed: 0.7125s/iter; left time: 1770.6420s
Epoch: 32 cost time: 46.11772418022156
Epoch: 32, Steps: 136 | Train Loss: 0.0489414 Vali Loss: 0.1368027 Test Loss: 0.1681165
Validation loss decreased (0.137871 --> 0.136803).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.0482705
	speed: 0.7616s/iter; left time: 1788.9886s
Epoch: 33 cost time: 46.861223459243774
Epoch: 33, Steps: 136 | Train Loss: 0.0474571 Vali Loss: 0.1355152 Test Loss: 0.1663277
Validation loss decreased (0.136803 --> 0.135515).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.0476350
	speed: 0.7302s/iter; left time: 1615.8830s
Epoch: 34 cost time: 42.51433086395264
Epoch: 34, Steps: 136 | Train Loss: 0.0461535 Vali Loss: 0.1345432 Test Loss: 0.1650266
Validation loss decreased (0.135515 --> 0.134543).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.0459429
	speed: 0.6977s/iter; left time: 1449.1229s
Epoch: 35 cost time: 42.07083868980408
Epoch: 35, Steps: 136 | Train Loss: 0.0449939 Vali Loss: 0.1337163 Test Loss: 0.1640570
Validation loss decreased (0.134543 --> 0.133716).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.0478940
	speed: 0.6967s/iter; left time: 1352.3205s
Epoch: 36 cost time: 42.2353093624115
Epoch: 36, Steps: 136 | Train Loss: 0.0439610 Vali Loss: 0.1332043 Test Loss: 0.1633776
Validation loss decreased (0.133716 --> 0.133204).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.0408213
	speed: 0.6658s/iter; left time: 1201.7748s
Epoch: 37 cost time: 36.975526094436646
Epoch: 37, Steps: 136 | Train Loss: 0.0430451 Vali Loss: 0.1324025 Test Loss: 0.1624121
Validation loss decreased (0.133204 --> 0.132402).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.0407876
	speed: 0.6405s/iter; left time: 1068.9837s
Epoch: 38 cost time: 43.87803649902344
Epoch: 38, Steps: 136 | Train Loss: 0.0422340 Vali Loss: 0.1316477 Test Loss: 0.1613618
Validation loss decreased (0.132402 --> 0.131648).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.0423016
	speed: 0.7640s/iter; left time: 1171.1411s
Epoch: 39 cost time: 46.08600449562073
Epoch: 39, Steps: 136 | Train Loss: 0.0414888 Vali Loss: 0.1312297 Test Loss: 0.1608386
Validation loss decreased (0.131648 --> 0.131230).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.0398839
	speed: 0.7563s/iter; left time: 1056.5297s
Epoch: 40 cost time: 44.71647071838379
Epoch: 40, Steps: 136 | Train Loss: 0.0408320 Vali Loss: 0.1307674 Test Loss: 0.1602294
Validation loss decreased (0.131230 --> 0.130767).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.0391514
	speed: 0.7763s/iter; left time: 978.8974s
Epoch: 41 cost time: 48.06874990463257
Epoch: 41, Steps: 136 | Train Loss: 0.0402554 Vali Loss: 0.1304751 Test Loss: 0.1596858
Validation loss decreased (0.130767 --> 0.130475).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.0396427
	speed: 0.7883s/iter; left time: 886.8868s
Epoch: 42 cost time: 47.72708773612976
Epoch: 42, Steps: 136 | Train Loss: 0.0397197 Vali Loss: 0.1301212 Test Loss: 0.1592683
Validation loss decreased (0.130475 --> 0.130121).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.0379254
	speed: 0.7257s/iter; left time: 717.7425s
Epoch: 43 cost time: 44.112809896469116
Epoch: 43, Steps: 136 | Train Loss: 0.0392411 Vali Loss: 0.1297853 Test Loss: 0.1588443
Validation loss decreased (0.130121 --> 0.129785).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.0409732
	speed: 0.7174s/iter; left time: 611.9815s
Epoch: 44 cost time: 43.62820792198181
Epoch: 44, Steps: 136 | Train Loss: 0.0388265 Vali Loss: 0.1293940 Test Loss: 0.1583667
Validation loss decreased (0.129785 --> 0.129394).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.0389441
	speed: 0.7082s/iter; left time: 507.8017s
Epoch: 45 cost time: 42.101651668548584
Epoch: 45, Steps: 136 | Train Loss: 0.0384570 Vali Loss: 0.1291506 Test Loss: 0.1580294
Validation loss decreased (0.129394 --> 0.129151).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.0393122
	speed: 0.6975s/iter; left time: 405.2665s
Epoch: 46 cost time: 42.468650579452515
Epoch: 46, Steps: 136 | Train Loss: 0.0381098 Vali Loss: 0.1290886 Test Loss: 0.1577668
Validation loss decreased (0.129151 --> 0.129089).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.0410955
	speed: 0.6412s/iter; left time: 285.3250s
Epoch: 47 cost time: 36.95688557624817
Epoch: 47, Steps: 136 | Train Loss: 0.0378244 Vali Loss: 0.1288674 Test Loss: 0.1574639
Validation loss decreased (0.129089 --> 0.128867).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.0401687
	speed: 0.5980s/iter; left time: 184.7764s
Epoch: 48 cost time: 36.68462777137756
Epoch: 48, Steps: 136 | Train Loss: 0.0375334 Vali Loss: 0.1285665 Test Loss: 0.1570525
Validation loss decreased (0.128867 --> 0.128567).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.0352637
	speed: 0.6752s/iter; left time: 116.8051s
Epoch: 49 cost time: 41.32597637176514
Epoch: 49, Steps: 136 | Train Loss: 0.0373036 Vali Loss: 0.1283828 Test Loss: 0.1569043
Validation loss decreased (0.128567 --> 0.128383).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.0357330
	speed: 0.6923s/iter; left time: 25.6147s
Epoch: 50 cost time: 42.68233132362366
Epoch: 50, Steps: 136 | Train Loss: 0.0370994 Vali Loss: 0.1283735 Test Loss: 0.1567442
Validation loss decreased (0.128383 --> 0.128374).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
train 17501
val 2441
test 5069
Model(
  (freq_upsampler): Linear(in_features=320, out_features=405, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  5325004800.0
params:  130005.0
Trainable parameters:  130005
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.1474032
	speed: 0.3985s/iter; left time: 2670.5140s
Epoch: 1 cost time: 54.03533172607422
Epoch: 1, Steps: 136 | Train Loss: 0.1513867 Vali Loss: 0.1260372 Test Loss: 0.1528287
Validation loss decreased (inf --> 0.126037).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1496611
	speed: 0.8595s/iter; left time: 5642.5246s
Epoch: 2 cost time: 48.76811647415161
Epoch: 2, Steps: 136 | Train Loss: 0.1506850 Vali Loss: 0.1259019 Test Loss: 0.1526840
Validation loss decreased (0.126037 --> 0.125902).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1611261
	speed: 0.7737s/iter; left time: 4974.4248s
Epoch: 3 cost time: 48.081998109817505
Epoch: 3, Steps: 136 | Train Loss: 0.1505297 Vali Loss: 0.1258741 Test Loss: 0.1524969
Validation loss decreased (0.125902 --> 0.125874).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1472420
	speed: 0.7903s/iter; left time: 4973.0742s
Epoch: 4 cost time: 49.05820298194885
Epoch: 4, Steps: 136 | Train Loss: 0.1503510 Vali Loss: 0.1257935 Test Loss: 0.1524784
Validation loss decreased (0.125874 --> 0.125794).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1426718
	speed: 0.7780s/iter; left time: 4789.9456s
Epoch: 5 cost time: 50.020946741104126
Epoch: 5, Steps: 136 | Train Loss: 0.1503501 Vali Loss: 0.1256825 Test Loss: 0.1523713
Validation loss decreased (0.125794 --> 0.125682).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1415906
	speed: 0.7330s/iter; left time: 4413.6226s
Epoch: 6 cost time: 42.02850675582886
Epoch: 6, Steps: 136 | Train Loss: 0.1502789 Vali Loss: 0.1255877 Test Loss: 0.1522831
Validation loss decreased (0.125682 --> 0.125588).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1409016
	speed: 0.7376s/iter; left time: 4340.7823s
Epoch: 7 cost time: 44.811641454696655
Epoch: 7, Steps: 136 | Train Loss: 0.1502380 Vali Loss: 0.1255425 Test Loss: 0.1521930
Validation loss decreased (0.125588 --> 0.125542).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1591590
	speed: 0.7419s/iter; left time: 4264.9711s
Epoch: 8 cost time: 45.38030481338501
Epoch: 8, Steps: 136 | Train Loss: 0.1502480 Vali Loss: 0.1255347 Test Loss: 0.1522562
Validation loss decreased (0.125542 --> 0.125535).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1497954
	speed: 0.7732s/iter; left time: 4340.1625s
Epoch: 9 cost time: 52.279114961624146
Epoch: 9, Steps: 136 | Train Loss: 0.1502282 Vali Loss: 0.1254077 Test Loss: 0.1521964
Validation loss decreased (0.125535 --> 0.125408).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1577214
	speed: 0.7994s/iter; left time: 4378.3753s
Epoch: 10 cost time: 44.84074592590332
Epoch: 10, Steps: 136 | Train Loss: 0.1501788 Vali Loss: 0.1254964 Test Loss: 0.1522538
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1420420
	speed: 0.7146s/iter; left time: 3816.8921s
Epoch: 11 cost time: 42.88466453552246
Epoch: 11, Steps: 136 | Train Loss: 0.1501239 Vali Loss: 0.1255909 Test Loss: 0.1522866
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1418704
	speed: 0.7108s/iter; left time: 3699.6857s
Epoch: 12 cost time: 41.50762605667114
Epoch: 12, Steps: 136 | Train Loss: 0.1501638 Vali Loss: 0.1252949 Test Loss: 0.1522621
Validation loss decreased (0.125408 --> 0.125295).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1509454
	speed: 0.7035s/iter; left time: 3565.8552s
Epoch: 13 cost time: 41.50965929031372
Epoch: 13, Steps: 136 | Train Loss: 0.1501288 Vali Loss: 0.1254863 Test Loss: 0.1522042
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1557939
	speed: 0.6888s/iter; left time: 3397.8276s
Epoch: 14 cost time: 42.768290758132935
Epoch: 14, Steps: 136 | Train Loss: 0.1500365 Vali Loss: 0.1254494 Test Loss: 0.1522482
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1553250
	speed: 0.7214s/iter; left time: 3460.4823s
Epoch: 15 cost time: 43.2943971157074
Epoch: 15, Steps: 136 | Train Loss: 0.1500713 Vali Loss: 0.1254451 Test Loss: 0.1521766
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Electricity_720_j192_H10_FITS_custom_ftM_sl720_ll48_pl192_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5069
mse:0.14937838912010193, mae:0.2445669025182724, rse:0.38427865505218506, corr:[0.4630099  0.46652278 0.4679515  0.46831384 0.46856585 0.46854994
 0.46871296 0.4684359  0.46862513 0.46850452 0.46847752 0.4684287
 0.46839476 0.4684151  0.46839115 0.46823066 0.46839762 0.46831745
 0.46799582 0.46769524 0.46763507 0.46772662 0.4676904  0.4678752
 0.4680011  0.4684338  0.46866295 0.46857366 0.4684418  0.4682568
 0.4682989  0.46834308 0.4680939  0.4678103  0.46768653 0.46761218
 0.46750695 0.46741    0.46731934 0.4671786  0.467165   0.4669867
 0.46670547 0.46654803 0.4664084  0.4664265  0.4664083  0.4665259
 0.46669832 0.4668685  0.4670386  0.4671099  0.46705008 0.46690032
 0.46690103 0.4668258  0.46667284 0.46659306 0.46661276 0.46654305
 0.46658543 0.46654558 0.46638423 0.4665253  0.4664988  0.46649078
 0.4664936  0.46635574 0.4663216  0.46612605 0.46597198 0.46610412
 0.46629828 0.4664593  0.46643448 0.46632752 0.4662152  0.4661498
 0.46625528 0.46604714 0.4658916  0.4659349  0.4658303  0.46583223
 0.46584097 0.46587762 0.46583545 0.4658475  0.4658986  0.46592045
 0.46591562 0.46559542 0.46544942 0.46542075 0.46521282 0.46531513
 0.46562657 0.46574613 0.46586558 0.46579975 0.46569544 0.4657359
 0.465531   0.46542534 0.4653047  0.4652349  0.46527022 0.4651819
 0.46515346 0.46519428 0.4652152  0.4652409  0.46531045 0.46522993
 0.46525177 0.46526554 0.46525145 0.4654145  0.46533516 0.4653496
 0.46559742 0.46574512 0.46588448 0.4659492  0.46573985 0.46565902
 0.46577892 0.46573278 0.4655393  0.46539688 0.46550947 0.46549696
 0.46548054 0.46548897 0.4655146  0.46560228 0.46555522 0.4656061
 0.46552563 0.4654808  0.46549734 0.4653689  0.46517992 0.4651017
 0.46517393 0.4653585  0.46539927 0.46520102 0.46519187 0.46524674
 0.465339   0.4652125  0.46501598 0.4649942  0.46498126 0.46500167
 0.46496275 0.46511957 0.4651528  0.46517026 0.46526426 0.4653473
 0.46537486 0.46514785 0.46496984 0.46473238 0.46462208 0.4646419
 0.46452528 0.46462762 0.46481246 0.46456978 0.46435717 0.46420333
 0.4641276  0.4639873  0.46371952 0.46372795 0.46352583 0.4635871
 0.46349898 0.463562   0.46355906 0.46338564 0.46356001 0.46346804
 0.46338218 0.46313137 0.46325472 0.4634012  0.46362537 0.46344367]
