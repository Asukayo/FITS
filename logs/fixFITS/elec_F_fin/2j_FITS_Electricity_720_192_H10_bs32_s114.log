Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=320, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=4, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_720_j192_H10', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:4
>>>>>>>start training : Electricity_720_j192_H10_FITS_custom_ftM_sl720_ll48_pl192_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17501
val 2441
test 5069
Model(
  (freq_upsampler): Linear(in_features=320, out_features=405, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2662502400.0
params:  130005.0
Trainable parameters:  130005
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.7596585
	speed: 0.2686s/iter; left time: 3640.1801s
	iters: 200, epoch: 1 | loss: 0.6395709
	speed: 0.2624s/iter; left time: 3529.8085s
Epoch: 1 cost time: 71.90409135818481
Epoch: 1, Steps: 273 | Train Loss: 0.7681227 Vali Loss: 0.5856949 Test Loss: 0.6767032
Validation loss decreased (inf --> 0.585695).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5390791
	speed: 0.9099s/iter; left time: 12081.3473s
	iters: 200, epoch: 2 | loss: 0.4866447
	speed: 0.2428s/iter; left time: 3200.2608s
Epoch: 2 cost time: 67.19057083129883
Epoch: 2, Steps: 273 | Train Loss: 0.5235193 Vali Loss: 0.4631897 Test Loss: 0.5396320
Validation loss decreased (0.585695 --> 0.463190).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4074087
	speed: 0.8107s/iter; left time: 10543.4869s
	iters: 200, epoch: 3 | loss: 0.3519509
	speed: 0.2185s/iter; left time: 2820.1851s
Epoch: 3 cost time: 59.59807825088501
Epoch: 3, Steps: 273 | Train Loss: 0.3852959 Vali Loss: 0.3678978 Test Loss: 0.4330893
Validation loss decreased (0.463190 --> 0.367898).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2983607
	speed: 0.7893s/iter; left time: 10049.9462s
	iters: 200, epoch: 4 | loss: 0.2694046
	speed: 0.2244s/iter; left time: 2834.7239s
Epoch: 4 cost time: 61.86393761634827
Epoch: 4, Steps: 273 | Train Loss: 0.2859202 Vali Loss: 0.3039503 Test Loss: 0.3616279
Validation loss decreased (0.367898 --> 0.303950).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2198957
	speed: 0.7985s/iter; left time: 9948.1349s
	iters: 200, epoch: 5 | loss: 0.1975084
	speed: 0.2163s/iter; left time: 2673.2972s
Epoch: 5 cost time: 61.12859296798706
Epoch: 5, Steps: 273 | Train Loss: 0.2134408 Vali Loss: 0.2487292 Test Loss: 0.2987273
Validation loss decreased (0.303950 --> 0.248729).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1643653
	speed: 0.7723s/iter; left time: 9410.8741s
	iters: 200, epoch: 6 | loss: 0.1504469
	speed: 0.2214s/iter; left time: 2675.8365s
Epoch: 6 cost time: 63.22993564605713
Epoch: 6, Steps: 273 | Train Loss: 0.1604900 Vali Loss: 0.2120226 Test Loss: 0.2569507
Validation loss decreased (0.248729 --> 0.212023).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1248253
	speed: 0.8542s/iter; left time: 10176.5544s
	iters: 200, epoch: 7 | loss: 0.1166910
	speed: 0.2631s/iter; left time: 3107.7067s
Epoch: 7 cost time: 73.32636642456055
Epoch: 7, Steps: 273 | Train Loss: 0.1220077 Vali Loss: 0.1837774 Test Loss: 0.2242991
Validation loss decreased (0.212023 --> 0.183777).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.0930873
	speed: 0.8907s/iter; left time: 10367.5069s
	iters: 200, epoch: 8 | loss: 0.0862588
	speed: 0.2110s/iter; left time: 2434.4495s
Epoch: 8 cost time: 60.25233030319214
Epoch: 8, Steps: 273 | Train Loss: 0.0943382 Vali Loss: 0.1650741 Test Loss: 0.2022908
Validation loss decreased (0.183777 --> 0.165074).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.0752218
	speed: 0.7279s/iter; left time: 8274.2608s
	iters: 200, epoch: 9 | loss: 0.0740769
	speed: 0.2099s/iter; left time: 2364.8267s
Epoch: 9 cost time: 58.850563764572144
Epoch: 9, Steps: 273 | Train Loss: 0.0746794 Vali Loss: 0.1522725 Test Loss: 0.1871240
Validation loss decreased (0.165074 --> 0.152272).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.0612653
	speed: 0.7798s/iter; left time: 8650.7658s
	iters: 200, epoch: 10 | loss: 0.0611574
	speed: 0.2148s/iter; left time: 2361.8495s
Epoch: 10 cost time: 60.83618950843811
Epoch: 10, Steps: 273 | Train Loss: 0.0609447 Vali Loss: 0.1431203 Test Loss: 0.1761682
Validation loss decreased (0.152272 --> 0.143120).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.0489716
	speed: 0.7565s/iter; left time: 8186.5988s
	iters: 200, epoch: 11 | loss: 0.0516935
	speed: 0.2100s/iter; left time: 2251.6967s
Epoch: 11 cost time: 57.91976809501648
Epoch: 11, Steps: 273 | Train Loss: 0.0515345 Vali Loss: 0.1364402 Test Loss: 0.1676611
Validation loss decreased (0.143120 --> 0.136440).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.0448301
	speed: 0.8444s/iter; left time: 8906.7424s
	iters: 200, epoch: 12 | loss: 0.0469428
	speed: 0.2514s/iter; left time: 2627.0998s
Epoch: 12 cost time: 70.4559531211853
Epoch: 12, Steps: 273 | Train Loss: 0.0452661 Vali Loss: 0.1326260 Test Loss: 0.1627800
Validation loss decreased (0.136440 --> 0.132626).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.0450063
	speed: 0.8598s/iter; left time: 8834.6974s
	iters: 200, epoch: 13 | loss: 0.0375995
	speed: 0.2228s/iter; left time: 2267.2179s
Epoch: 13 cost time: 64.44409966468811
Epoch: 13, Steps: 273 | Train Loss: 0.0411909 Vali Loss: 0.1301070 Test Loss: 0.1593185
Validation loss decreased (0.132626 --> 0.130107).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.0376717
	speed: 0.8924s/iter; left time: 8926.2483s
	iters: 200, epoch: 14 | loss: 0.0373196
	speed: 0.2372s/iter; left time: 2349.0229s
Epoch: 14 cost time: 67.84261393547058
Epoch: 14, Steps: 273 | Train Loss: 0.0386549 Vali Loss: 0.1289395 Test Loss: 0.1578585
Validation loss decreased (0.130107 --> 0.128940).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.0356038
	speed: 0.8167s/iter; left time: 7945.6135s
	iters: 200, epoch: 15 | loss: 0.0349661
	speed: 0.2232s/iter; left time: 2149.1945s
Epoch: 15 cost time: 63.774529695510864
Epoch: 15, Steps: 273 | Train Loss: 0.0371101 Vali Loss: 0.1281662 Test Loss: 0.1565755
Validation loss decreased (0.128940 --> 0.128166).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.0394869
	speed: 0.8222s/iter; left time: 7774.3712s
	iters: 200, epoch: 16 | loss: 0.0367765
	speed: 0.2371s/iter; left time: 2218.1456s
Epoch: 16 cost time: 67.0806531906128
Epoch: 16, Steps: 273 | Train Loss: 0.0362268 Vali Loss: 0.1278091 Test Loss: 0.1557542
Validation loss decreased (0.128166 --> 0.127809).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.0394901
	speed: 0.9412s/iter; left time: 8642.7280s
	iters: 200, epoch: 17 | loss: 0.0380511
	speed: 0.2592s/iter; left time: 2354.4231s
Epoch: 17 cost time: 72.64985275268555
Epoch: 17, Steps: 273 | Train Loss: 0.0357294 Vali Loss: 0.1277158 Test Loss: 0.1555688
Validation loss decreased (0.127809 --> 0.127716).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.0343627
	speed: 0.7682s/iter; left time: 6845.0215s
	iters: 200, epoch: 18 | loss: 0.0349739
	speed: 0.1933s/iter; left time: 1703.1228s
Epoch: 18 cost time: 53.615078926086426
Epoch: 18, Steps: 273 | Train Loss: 0.0354853 Vali Loss: 0.1276034 Test Loss: 0.1553305
Validation loss decreased (0.127716 --> 0.127603).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.0358125
	speed: 0.7181s/iter; left time: 6202.1468s
	iters: 200, epoch: 19 | loss: 0.0352707
	speed: 0.2224s/iter; left time: 1898.6718s
Epoch: 19 cost time: 60.37090730667114
Epoch: 19, Steps: 273 | Train Loss: 0.0353584 Vali Loss: 0.1276251 Test Loss: 0.1550876
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.0386257
	speed: 0.8037s/iter; left time: 6722.1423s
	iters: 200, epoch: 20 | loss: 0.0387089
	speed: 0.2272s/iter; left time: 1877.4853s
Epoch: 20 cost time: 63.58925676345825
Epoch: 20, Steps: 273 | Train Loss: 0.0353028 Vali Loss: 0.1276515 Test Loss: 0.1551062
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.0371561
	speed: 0.8001s/iter; left time: 6473.6711s
	iters: 200, epoch: 21 | loss: 0.0341118
	speed: 0.2282s/iter; left time: 1823.5150s
Epoch: 21 cost time: 63.521230936050415
Epoch: 21, Steps: 273 | Train Loss: 0.0352766 Vali Loss: 0.1276083 Test Loss: 0.1551804
EarlyStopping counter: 3 out of 3
Early stopping
train 17501
val 2441
test 5069
Model(
  (freq_upsampler): Linear(in_features=320, out_features=405, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2662502400.0
params:  130005.0
Trainable parameters:  130005
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.1400924
	speed: 0.2605s/iter; left time: 3529.4037s
	iters: 200, epoch: 1 | loss: 0.1619620
	speed: 0.2306s/iter; left time: 3102.1992s
Epoch: 1 cost time: 67.31641411781311
Epoch: 1, Steps: 273 | Train Loss: 0.1513554 Vali Loss: 0.1259651 Test Loss: 0.1530217
Validation loss decreased (inf --> 0.125965).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1405822
	speed: 0.8749s/iter; left time: 11616.7225s
	iters: 200, epoch: 2 | loss: 0.1587592
	speed: 0.2402s/iter; left time: 3165.8214s
Epoch: 2 cost time: 65.9375672340393
Epoch: 2, Steps: 273 | Train Loss: 0.1507269 Vali Loss: 0.1261068 Test Loss: 0.1528861
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1395260
	speed: 0.7593s/iter; left time: 9875.2594s
	iters: 200, epoch: 3 | loss: 0.1357194
	speed: 0.2250s/iter; left time: 2903.1957s
Epoch: 3 cost time: 61.23897886276245
Epoch: 3, Steps: 273 | Train Loss: 0.1505774 Vali Loss: 0.1258658 Test Loss: 0.1526479
Validation loss decreased (0.125965 --> 0.125866).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1508520
	speed: 0.7689s/iter; left time: 9790.1754s
	iters: 200, epoch: 4 | loss: 0.1448842
	speed: 0.2067s/iter; left time: 2610.9887s
Epoch: 4 cost time: 56.7275333404541
Epoch: 4, Steps: 273 | Train Loss: 0.1505106 Vali Loss: 0.1258491 Test Loss: 0.1526921
Validation loss decreased (0.125866 --> 0.125849).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1513837
	speed: 0.7655s/iter; left time: 9537.1057s
	iters: 200, epoch: 5 | loss: 0.1459849
	speed: 0.2149s/iter; left time: 2655.8719s
Epoch: 5 cost time: 60.45097875595093
Epoch: 5, Steps: 273 | Train Loss: 0.1504397 Vali Loss: 0.1257582 Test Loss: 0.1527553
Validation loss decreased (0.125849 --> 0.125758).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1528964
	speed: 0.8525s/iter; left time: 10388.3516s
	iters: 200, epoch: 6 | loss: 0.1428601
	speed: 0.2498s/iter; left time: 3019.0668s
Epoch: 6 cost time: 71.60591053962708
Epoch: 6, Steps: 273 | Train Loss: 0.1504202 Vali Loss: 0.1256088 Test Loss: 0.1524139
Validation loss decreased (0.125758 --> 0.125609).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1393066
	speed: 0.8873s/iter; left time: 10569.8155s
	iters: 200, epoch: 7 | loss: 0.1420092
	speed: 0.2372s/iter; left time: 2801.6465s
Epoch: 7 cost time: 66.26594996452332
Epoch: 7, Steps: 273 | Train Loss: 0.1503424 Vali Loss: 0.1255896 Test Loss: 0.1525162
Validation loss decreased (0.125609 --> 0.125590).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1538729
	speed: 0.8059s/iter; left time: 9380.1735s
	iters: 200, epoch: 8 | loss: 0.1416110
	speed: 0.2167s/iter; left time: 2500.3296s
Epoch: 8 cost time: 60.83843541145325
Epoch: 8, Steps: 273 | Train Loss: 0.1502834 Vali Loss: 0.1255355 Test Loss: 0.1524250
Validation loss decreased (0.125590 --> 0.125536).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1432460
	speed: 0.8063s/iter; left time: 9165.3995s
	iters: 200, epoch: 9 | loss: 0.1359335
	speed: 0.2161s/iter; left time: 2435.2238s
Epoch: 9 cost time: 63.82879638671875
Epoch: 9, Steps: 273 | Train Loss: 0.1503246 Vali Loss: 0.1256474 Test Loss: 0.1524571
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1419299
	speed: 0.8264s/iter; left time: 9167.8390s
	iters: 200, epoch: 10 | loss: 0.1529663
	speed: 0.2145s/iter; left time: 2358.0437s
Epoch: 10 cost time: 60.73299241065979
Epoch: 10, Steps: 273 | Train Loss: 0.1502712 Vali Loss: 0.1256156 Test Loss: 0.1524867
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1406787
	speed: 0.8317s/iter; left time: 8999.6404s
	iters: 200, epoch: 11 | loss: 0.1638765
	speed: 0.2543s/iter; left time: 2726.7920s
Epoch: 11 cost time: 70.20529866218567
Epoch: 11, Steps: 273 | Train Loss: 0.1502684 Vali Loss: 0.1254355 Test Loss: 0.1525435
Validation loss decreased (0.125536 --> 0.125435).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1388174
	speed: 0.9007s/iter; left time: 9500.8355s
	iters: 200, epoch: 12 | loss: 0.1541318
	speed: 0.2470s/iter; left time: 2580.6826s
Epoch: 12 cost time: 69.31199073791504
Epoch: 12, Steps: 273 | Train Loss: 0.1502208 Vali Loss: 0.1257676 Test Loss: 0.1526226
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1396600
	speed: 0.8651s/iter; left time: 8889.2150s
	iters: 200, epoch: 13 | loss: 0.1514051
	speed: 0.2310s/iter; left time: 2350.8583s
Epoch: 13 cost time: 65.3384325504303
Epoch: 13, Steps: 273 | Train Loss: 0.1502448 Vali Loss: 0.1257845 Test Loss: 0.1524280
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1508123
	speed: 0.8127s/iter; left time: 8128.5021s
	iters: 200, epoch: 14 | loss: 0.1579592
	speed: 0.2201s/iter; left time: 2178.9875s
Epoch: 14 cost time: 63.062642335891724
Epoch: 14, Steps: 273 | Train Loss: 0.1501936 Vali Loss: 0.1257266 Test Loss: 0.1523016
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Electricity_720_j192_H10_FITS_custom_ftM_sl720_ll48_pl192_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5069
mse:0.14949917793273926, mae:0.24476121366024017, rse:0.38443395495414734, corr:[0.4633674  0.4666916  0.4679879  0.46820077 0.46858367 0.46871576
 0.46838275 0.46816793 0.4682566  0.46815112 0.46786875 0.46807083
 0.46829635 0.46800146 0.4679328  0.4680535  0.46796504 0.46796376
 0.46817225 0.46795538 0.46767098 0.46761534 0.46786615 0.46807593
 0.46820873 0.46853614 0.46853927 0.4684345  0.4683423  0.46813726
 0.46798277 0.46799886 0.46782622 0.46770307 0.46762878 0.4674641
 0.4673999  0.46722266 0.46715376 0.46708632 0.46704683 0.46684042
 0.46654564 0.46676505 0.46677154 0.46653047 0.46665233 0.46673906
 0.46691212 0.4672111  0.4672137  0.46718666 0.46722254 0.46712664
 0.46703047 0.46690404 0.46680194 0.4666973  0.46644565 0.46619323
 0.46631828 0.46621093 0.4660975  0.46622568 0.46615973 0.46624416
 0.46627268 0.4660887  0.4659518  0.46610442 0.46614498 0.4661607
 0.46630374 0.46647507 0.46683258 0.4668167  0.4666487  0.4666396
 0.4666589  0.4664097  0.4661717  0.46632528 0.4661516  0.46592298
 0.46605808 0.4659352  0.4657321  0.46583587 0.46583286 0.46588925
 0.4657904  0.46552417 0.46548504 0.46516475 0.46529227 0.46564338
 0.46556744 0.46576342 0.4657552  0.46570835 0.46581554 0.46566454
 0.46552107 0.46547496 0.46538734 0.4653448  0.46514294 0.46495846
 0.4650862  0.46514833 0.4650498  0.4649356  0.4650233  0.4649864
 0.46487913 0.46511787 0.4652697  0.46536586 0.46556482 0.46586162
 0.46612567 0.46618682 0.4661739  0.46608138 0.4661642  0.466054
 0.46582815 0.46585327 0.4658608  0.46568924 0.46556097 0.46538326
 0.4652578  0.46521476 0.46513566 0.4651781  0.46528402 0.4653337
 0.46517953 0.46519765 0.46512118 0.46494684 0.46510687 0.46527013
 0.465457   0.46545115 0.4653905  0.4654479  0.4656231  0.46556994
 0.46546486 0.46538725 0.46527866 0.46540767 0.46530482 0.46519473
 0.4649713  0.464779   0.46477142 0.46479443 0.46498778 0.46493015
 0.46477666 0.46481827 0.46475178 0.4645299  0.4645383  0.4645502
 0.46466845 0.4647702  0.46460596 0.46459308 0.46449003 0.4643665
 0.46419927 0.4640863  0.46393782 0.46374226 0.4636939  0.46371835
 0.4635829  0.46355918 0.46366474 0.46338454 0.4635427  0.46332186
 0.46320543 0.4633486  0.4632884  0.46345478 0.46352148 0.46333417]
