Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=320, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, features='M', freq='h', gpu=4, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Electricity_720_j96_H10', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:4
>>>>>>>start training : Electricity_720_j96_H10_FITS_custom_ftM_sl720_ll48_pl96_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17597
val 2537
test 5165
Model(
  (freq_upsampler): Linear(in_features=320, out_features=362, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4759633920.0
params:  116202.0
Trainable parameters:  116202
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6835456
	speed: 0.3423s/iter; left time: 2310.8782s
Epoch: 1 cost time: 47.1661639213562
Epoch: 1, Steps: 137 | Train Loss: 0.7997956 Vali Loss: 0.6162416 Test Loss: 0.7025751
Validation loss decreased (inf --> 0.616242).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5786738
	speed: 0.6965s/iter; left time: 4606.7357s
Epoch: 2 cost time: 39.67405462265015
Epoch: 2, Steps: 137 | Train Loss: 0.6048377 Vali Loss: 0.5456864 Test Loss: 0.6233726
Validation loss decreased (0.616242 --> 0.545686).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4985931
	speed: 0.6411s/iter; left time: 4152.3888s
Epoch: 3 cost time: 40.72926044464111
Epoch: 3, Steps: 137 | Train Loss: 0.5125161 Vali Loss: 0.4879408 Test Loss: 0.5597465
Validation loss decreased (0.545686 --> 0.487941).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4284152
	speed: 0.7190s/iter; left time: 4558.4180s
Epoch: 4 cost time: 45.99601173400879
Epoch: 4, Steps: 137 | Train Loss: 0.4384507 Vali Loss: 0.4350681 Test Loss: 0.5018928
Validation loss decreased (0.487941 --> 0.435068).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3630741
	speed: 0.7171s/iter; left time: 4448.3366s
Epoch: 5 cost time: 42.31697344779968
Epoch: 5, Steps: 137 | Train Loss: 0.3772267 Vali Loss: 0.3928449 Test Loss: 0.4549495
Validation loss decreased (0.435068 --> 0.392845).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3161327
	speed: 0.6491s/iter; left time: 3937.5417s
Epoch: 6 cost time: 39.39265704154968
Epoch: 6, Steps: 137 | Train Loss: 0.3260507 Vali Loss: 0.3553197 Test Loss: 0.4131527
Validation loss decreased (0.392845 --> 0.355320).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2712013
	speed: 0.6313s/iter; left time: 3742.6944s
Epoch: 7 cost time: 38.35895752906799
Epoch: 7, Steps: 137 | Train Loss: 0.2830291 Vali Loss: 0.3231977 Test Loss: 0.3778318
Validation loss decreased (0.355320 --> 0.323198).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2425064
	speed: 0.6466s/iter; left time: 3745.2921s
Epoch: 8 cost time: 39.60066890716553
Epoch: 8, Steps: 137 | Train Loss: 0.2466168 Vali Loss: 0.2942048 Test Loss: 0.3448838
Validation loss decreased (0.323198 --> 0.294205).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2074736
	speed: 0.6572s/iter; left time: 3716.1854s
Epoch: 9 cost time: 41.42887544631958
Epoch: 9, Steps: 137 | Train Loss: 0.2156812 Vali Loss: 0.2699882 Test Loss: 0.3180736
Validation loss decreased (0.294205 --> 0.269988).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1870712
	speed: 0.6733s/iter; left time: 3715.3058s
Epoch: 10 cost time: 41.34636974334717
Epoch: 10, Steps: 137 | Train Loss: 0.1893072 Vali Loss: 0.2499270 Test Loss: 0.2952986
Validation loss decreased (0.269988 --> 0.249927).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1601352
	speed: 0.6484s/iter; left time: 3489.1000s
Epoch: 11 cost time: 39.06500005722046
Epoch: 11, Steps: 137 | Train Loss: 0.1667208 Vali Loss: 0.2345891 Test Loss: 0.2779006
Validation loss decreased (0.249927 --> 0.234589).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1414521
	speed: 0.6443s/iter; left time: 3378.8376s
Epoch: 12 cost time: 40.28281259536743
Epoch: 12, Steps: 137 | Train Loss: 0.1473338 Vali Loss: 0.2169405 Test Loss: 0.2580387
Validation loss decreased (0.234589 --> 0.216940).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1299871
	speed: 0.6575s/iter; left time: 3357.7207s
Epoch: 13 cost time: 41.37059020996094
Epoch: 13, Steps: 137 | Train Loss: 0.1306903 Vali Loss: 0.2040059 Test Loss: 0.2432056
Validation loss decreased (0.216940 --> 0.204006).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1154811
	speed: 0.6579s/iter; left time: 3269.8469s
Epoch: 14 cost time: 40.52149271965027
Epoch: 14, Steps: 137 | Train Loss: 0.1163189 Vali Loss: 0.1921018 Test Loss: 0.2296668
Validation loss decreased (0.204006 --> 0.192102).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1017566
	speed: 0.6612s/iter; left time: 3195.3885s
Epoch: 15 cost time: 39.032623529434204
Epoch: 15, Steps: 137 | Train Loss: 0.1039396 Vali Loss: 0.1820412 Test Loss: 0.2181684
Validation loss decreased (0.192102 --> 0.182041).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.0903374
	speed: 0.6366s/iter; left time: 2989.4901s
Epoch: 16 cost time: 38.2657573223114
Epoch: 16, Steps: 137 | Train Loss: 0.0931965 Vali Loss: 0.1740023 Test Loss: 0.2090272
Validation loss decreased (0.182041 --> 0.174002).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.0819121
	speed: 0.5884s/iter; left time: 2682.5191s
Epoch: 17 cost time: 37.475789308547974
Epoch: 17, Steps: 137 | Train Loss: 0.0838934 Vali Loss: 0.1666745 Test Loss: 0.2003370
Validation loss decreased (0.174002 --> 0.166674).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.0730060
	speed: 0.7324s/iter; left time: 3238.5280s
Epoch: 18 cost time: 46.185749530792236
Epoch: 18, Steps: 137 | Train Loss: 0.0758060 Vali Loss: 0.1603582 Test Loss: 0.1929199
Validation loss decreased (0.166674 --> 0.160358).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.0664281
	speed: 0.7874s/iter; left time: 3374.0351s
Epoch: 19 cost time: 51.855361223220825
Epoch: 19, Steps: 137 | Train Loss: 0.0688007 Vali Loss: 0.1541036 Test Loss: 0.1861401
Validation loss decreased (0.160358 --> 0.154104).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.0610712
	speed: 0.8091s/iter; left time: 3356.1156s
Epoch: 20 cost time: 50.13380146026611
Epoch: 20, Steps: 137 | Train Loss: 0.0626837 Vali Loss: 0.1506520 Test Loss: 0.1817770
Validation loss decreased (0.154104 --> 0.150652).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.0562670
	speed: 0.7071s/iter; left time: 2836.1103s
Epoch: 21 cost time: 40.616848945617676
Epoch: 21, Steps: 137 | Train Loss: 0.0573585 Vali Loss: 0.1454160 Test Loss: 0.1758212
Validation loss decreased (0.150652 --> 0.145416).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.0538116
	speed: 0.6481s/iter; left time: 2510.5657s
Epoch: 22 cost time: 40.39059567451477
Epoch: 22, Steps: 137 | Train Loss: 0.0527158 Vali Loss: 0.1419473 Test Loss: 0.1717087
Validation loss decreased (0.145416 --> 0.141947).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.0474533
	speed: 0.6260s/iter; left time: 2339.4825s
Epoch: 23 cost time: 39.67188620567322
Epoch: 23, Steps: 137 | Train Loss: 0.0486707 Vali Loss: 0.1385798 Test Loss: 0.1678145
Validation loss decreased (0.141947 --> 0.138580).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.0458730
	speed: 0.6557s/iter; left time: 2360.5398s
Epoch: 24 cost time: 41.9351372718811
Epoch: 24, Steps: 137 | Train Loss: 0.0451212 Vali Loss: 0.1358657 Test Loss: 0.1643845
Validation loss decreased (0.138580 --> 0.135866).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.0412729
	speed: 0.7186s/iter; left time: 2488.3613s
Epoch: 25 cost time: 45.12835931777954
Epoch: 25, Steps: 137 | Train Loss: 0.0420206 Vali Loss: 0.1340225 Test Loss: 0.1623732
Validation loss decreased (0.135866 --> 0.134023).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.0395037
	speed: 0.7866s/iter; left time: 2616.3596s
Epoch: 26 cost time: 49.84354090690613
Epoch: 26, Steps: 137 | Train Loss: 0.0393102 Vali Loss: 0.1316271 Test Loss: 0.1592343
Validation loss decreased (0.134023 --> 0.131627).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.0374709
	speed: 0.7763s/iter; left time: 2475.7585s
Epoch: 27 cost time: 48.08257722854614
Epoch: 27, Steps: 137 | Train Loss: 0.0369269 Vali Loss: 0.1297595 Test Loss: 0.1568758
Validation loss decreased (0.131627 --> 0.129760).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.0339732
	speed: 0.7069s/iter; left time: 2157.5889s
Epoch: 28 cost time: 44.29888558387756
Epoch: 28, Steps: 137 | Train Loss: 0.0348467 Vali Loss: 0.1275766 Test Loss: 0.1545858
Validation loss decreased (0.129760 --> 0.127577).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.0343516
	speed: 0.7209s/iter; left time: 2101.3442s
Epoch: 29 cost time: 47.617828607559204
Epoch: 29, Steps: 137 | Train Loss: 0.0330221 Vali Loss: 0.1262534 Test Loss: 0.1530563
Validation loss decreased (0.127577 --> 0.126253).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.0315344
	speed: 0.7321s/iter; left time: 2033.8399s
Epoch: 30 cost time: 46.106178283691406
Epoch: 30, Steps: 137 | Train Loss: 0.0314181 Vali Loss: 0.1255588 Test Loss: 0.1519179
Validation loss decreased (0.126253 --> 0.125559).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.0292774
	speed: 0.6973s/iter; left time: 1841.6320s
Epoch: 31 cost time: 42.722571849823
Epoch: 31, Steps: 137 | Train Loss: 0.0300035 Vali Loss: 0.1239546 Test Loss: 0.1505374
Validation loss decreased (0.125559 --> 0.123955).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.0283062
	speed: 0.7265s/iter; left time: 1819.2649s
Epoch: 32 cost time: 47.837225675582886
Epoch: 32, Steps: 137 | Train Loss: 0.0287624 Vali Loss: 0.1234413 Test Loss: 0.1491433
Validation loss decreased (0.123955 --> 0.123441).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.0270307
	speed: 0.7475s/iter; left time: 1769.2465s
Epoch: 33 cost time: 47.10211229324341
Epoch: 33, Steps: 137 | Train Loss: 0.0276899 Vali Loss: 0.1224348 Test Loss: 0.1482536
Validation loss decreased (0.123441 --> 0.122435).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.0255596
	speed: 0.7860s/iter; left time: 1752.8691s
Epoch: 34 cost time: 47.26751351356506
Epoch: 34, Steps: 137 | Train Loss: 0.0267349 Vali Loss: 0.1219234 Test Loss: 0.1475184
Validation loss decreased (0.122435 --> 0.121923).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.0264963
	speed: 0.7460s/iter; left time: 1561.3886s
Epoch: 35 cost time: 45.73006510734558
Epoch: 35, Steps: 137 | Train Loss: 0.0259051 Vali Loss: 0.1210721 Test Loss: 0.1466884
Validation loss decreased (0.121923 --> 0.121072).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.0241176
	speed: 0.6746s/iter; left time: 1319.5826s
Epoch: 36 cost time: 42.3423125743866
Epoch: 36, Steps: 137 | Train Loss: 0.0251628 Vali Loss: 0.1202468 Test Loss: 0.1456061
Validation loss decreased (0.121072 --> 0.120247).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.0253251
	speed: 0.6851s/iter; left time: 1246.1957s
Epoch: 37 cost time: 44.63736414909363
Epoch: 37, Steps: 137 | Train Loss: 0.0245172 Vali Loss: 0.1200553 Test Loss: 0.1450941
Validation loss decreased (0.120247 --> 0.120055).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.0235327
	speed: 0.7256s/iter; left time: 1220.3756s
Epoch: 38 cost time: 46.58043384552002
Epoch: 38, Steps: 137 | Train Loss: 0.0239499 Vali Loss: 0.1199435 Test Loss: 0.1446121
Validation loss decreased (0.120055 --> 0.119944).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.0247432
	speed: 0.7132s/iter; left time: 1101.8511s
Epoch: 39 cost time: 41.999138832092285
Epoch: 39, Steps: 137 | Train Loss: 0.0234489 Vali Loss: 0.1193748 Test Loss: 0.1440852
Validation loss decreased (0.119944 --> 0.119375).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.0231098
	speed: 0.6234s/iter; left time: 877.8088s
Epoch: 40 cost time: 40.12738275527954
Epoch: 40, Steps: 137 | Train Loss: 0.0230092 Vali Loss: 0.1189212 Test Loss: 0.1435886
Validation loss decreased (0.119375 --> 0.118921).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.0217601
	speed: 0.6886s/iter; left time: 875.2593s
Epoch: 41 cost time: 45.77808928489685
Epoch: 41, Steps: 137 | Train Loss: 0.0226270 Vali Loss: 0.1190454 Test Loss: 0.1432247
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.0236463
	speed: 0.7546s/iter; left time: 855.6923s
Epoch: 42 cost time: 48.48549294471741
Epoch: 42, Steps: 137 | Train Loss: 0.0222905 Vali Loss: 0.1183944 Test Loss: 0.1428476
Validation loss decreased (0.118921 --> 0.118394).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.0224060
	speed: 0.7206s/iter; left time: 718.4874s
Epoch: 43 cost time: 42.87977886199951
Epoch: 43, Steps: 137 | Train Loss: 0.0219910 Vali Loss: 0.1181744 Test Loss: 0.1424685
Validation loss decreased (0.118394 --> 0.118174).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.0201884
	speed: 0.6912s/iter; left time: 594.4040s
Epoch: 44 cost time: 43.32695722579956
Epoch: 44, Steps: 137 | Train Loss: 0.0217221 Vali Loss: 0.1181742 Test Loss: 0.1422537
Validation loss decreased (0.118174 --> 0.118174).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.0211522
	speed: 0.6718s/iter; left time: 485.7174s
Epoch: 45 cost time: 43.360371828079224
Epoch: 45, Steps: 137 | Train Loss: 0.0215012 Vali Loss: 0.1181065 Test Loss: 0.1421746
Validation loss decreased (0.118174 --> 0.118106).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.0205089
	speed: 0.7453s/iter; left time: 436.7458s
Epoch: 46 cost time: 46.731059551239014
Epoch: 46, Steps: 137 | Train Loss: 0.0212969 Vali Loss: 0.1176818 Test Loss: 0.1417765
Validation loss decreased (0.118106 --> 0.117682).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.0226807
	speed: 0.7601s/iter; left time: 341.2966s
Epoch: 47 cost time: 49.318886280059814
Epoch: 47, Steps: 137 | Train Loss: 0.0211210 Vali Loss: 0.1177304 Test Loss: 0.1416249
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.0220251
	speed: 0.7945s/iter; left time: 247.8792s
Epoch: 48 cost time: 48.06588006019592
Epoch: 48, Steps: 137 | Train Loss: 0.0209589 Vali Loss: 0.1175442 Test Loss: 0.1414303
Validation loss decreased (0.117682 --> 0.117544).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.0215326
	speed: 0.7603s/iter; left time: 133.0573s
Epoch: 49 cost time: 46.978657484054565
Epoch: 49, Steps: 137 | Train Loss: 0.0208278 Vali Loss: 0.1174008 Test Loss: 0.1413596
Validation loss decreased (0.117544 --> 0.117401).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.0201549
	speed: 0.7362s/iter; left time: 27.9771s
Epoch: 50 cost time: 46.82733130455017
Epoch: 50, Steps: 137 | Train Loss: 0.0207107 Vali Loss: 0.1173776 Test Loss: 0.1411511
Validation loss decreased (0.117401 --> 0.117378).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
train 17597
val 2537
test 5165
Model(
  (freq_upsampler): Linear(in_features=320, out_features=362, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4759633920.0
params:  116202.0
Trainable parameters:  116202
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.1479578
	speed: 0.3656s/iter; left time: 2468.1390s
Epoch: 1 cost time: 49.28285241127014
Epoch: 1, Steps: 137 | Train Loss: 0.1368436 Vali Loss: 0.1139842 Test Loss: 0.1363074
Validation loss decreased (inf --> 0.113984).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1313406
	speed: 0.7451s/iter; left time: 4927.9606s
Epoch: 2 cost time: 45.5486786365509
Epoch: 2, Steps: 137 | Train Loss: 0.1357185 Vali Loss: 0.1138012 Test Loss: 0.1357546
Validation loss decreased (0.113984 --> 0.113801).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1302758
	speed: 0.7223s/iter; left time: 4678.5790s
Epoch: 3 cost time: 44.09094572067261
Epoch: 3, Steps: 137 | Train Loss: 0.1354414 Vali Loss: 0.1136318 Test Loss: 0.1357160
Validation loss decreased (0.113801 --> 0.113632).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1341349
	speed: 0.7028s/iter; left time: 4455.8361s
Epoch: 4 cost time: 42.639665603637695
Epoch: 4, Steps: 137 | Train Loss: 0.1352888 Vali Loss: 0.1136596 Test Loss: 0.1356272
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1454206
	speed: 0.6911s/iter; left time: 4287.0548s
Epoch: 5 cost time: 43.67048358917236
Epoch: 5, Steps: 137 | Train Loss: 0.1351650 Vali Loss: 0.1134822 Test Loss: 0.1355318
Validation loss decreased (0.113632 --> 0.113482).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1242124
	speed: 0.7134s/iter; left time: 4327.1924s
Epoch: 6 cost time: 43.81508255004883
Epoch: 6, Steps: 137 | Train Loss: 0.1351572 Vali Loss: 0.1137205 Test Loss: 0.1355016
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1277755
	speed: 0.7215s/iter; left time: 4277.5583s
Epoch: 7 cost time: 44.25575613975525
Epoch: 7, Steps: 137 | Train Loss: 0.1350311 Vali Loss: 0.1134464 Test Loss: 0.1354862
Validation loss decreased (0.113482 --> 0.113446).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1209277
	speed: 0.7316s/iter; left time: 4237.5172s
Epoch: 8 cost time: 46.88858938217163
Epoch: 8, Steps: 137 | Train Loss: 0.1351133 Vali Loss: 0.1130654 Test Loss: 0.1354717
Validation loss decreased (0.113446 --> 0.113065).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1408345
	speed: 0.7279s/iter; left time: 4116.2881s
Epoch: 9 cost time: 43.71402025222778
Epoch: 9, Steps: 137 | Train Loss: 0.1349395 Vali Loss: 0.1135198 Test Loss: 0.1354353
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1335392
	speed: 0.7354s/iter; left time: 4057.8878s
Epoch: 10 cost time: 43.576226234436035
Epoch: 10, Steps: 137 | Train Loss: 0.1349568 Vali Loss: 0.1132785 Test Loss: 0.1352449
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1345417
	speed: 0.6881s/iter; left time: 3702.8762s
Epoch: 11 cost time: 42.76509976387024
Epoch: 11, Steps: 137 | Train Loss: 0.1350036 Vali Loss: 0.1131956 Test Loss: 0.1354541
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Electricity_720_j96_H10_FITS_custom_ftM_sl720_ll48_pl96_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
mse:0.13488079607486725, mae:0.23197194933891296, rse:0.3650219142436981, corr:[0.46575016 0.4690895  0.4707215  0.47075927 0.47117636 0.47110584
 0.47119227 0.4712113  0.4714855  0.4710455  0.47115916 0.4707897
 0.47089922 0.47084406 0.4706307  0.47079477 0.47091067 0.47068766
 0.47071022 0.47080013 0.47081098 0.47082022 0.47047567 0.47087008
 0.4709435  0.4710635  0.47127452 0.47120818 0.4710311  0.47072798
 0.4705127  0.47038367 0.47032222 0.4701954  0.4702062  0.46988025
 0.46988273 0.47009337 0.46994925 0.46980157 0.46985    0.47003093
 0.4699556  0.47025245 0.47021052 0.46985558 0.46997657 0.47031552
 0.47036415 0.47042212 0.4707551  0.47081244 0.47070482 0.47040716
 0.47028762 0.47008148 0.46988496 0.4697     0.4696568  0.46975866
 0.46952683 0.46953115 0.46939918 0.46933752 0.4693528  0.46931943
 0.46926692 0.46909034 0.46906042 0.4690221  0.46896884 0.46886992
 0.46898672 0.46903694 0.46907848 0.4690635  0.46908814 0.4689728
 0.46901125 0.46913722 0.46888137 0.46886504 0.4687346  0.46873614
 0.4686172  0.46872413 0.46876898 0.4687052  0.4687263  0.4684781
 0.4686216  0.4687938  0.46867442 0.46889052 0.46907866 0.46899468]
