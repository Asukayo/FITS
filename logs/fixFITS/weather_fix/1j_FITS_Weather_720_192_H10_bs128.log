Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=144, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=70, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='weather.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=21, factor=1, features='M', freq='h', gpu=3, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=True, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Weather_720_j192_H10', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=2021, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:3
>>>>>>>start training : Weather_720_j192_H10_FITS_custom_ftM_sl720_ll48_pl192_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 35976
val 5079
test 10348
Model(
  (freq_upsampler): ModuleList(
    (0): Linear(in_features=70, out_features=88, bias=True)
    (1): Linear(in_features=70, out_features=88, bias=True)
    (2): Linear(in_features=70, out_features=88, bias=True)
    (3): Linear(in_features=70, out_features=88, bias=True)
    (4): Linear(in_features=70, out_features=88, bias=True)
    (5): Linear(in_features=70, out_features=88, bias=True)
    (6): Linear(in_features=70, out_features=88, bias=True)
    (7): Linear(in_features=70, out_features=88, bias=True)
    (8): Linear(in_features=70, out_features=88, bias=True)
    (9): Linear(in_features=70, out_features=88, bias=True)
    (10): Linear(in_features=70, out_features=88, bias=True)
    (11): Linear(in_features=70, out_features=88, bias=True)
    (12): Linear(in_features=70, out_features=88, bias=True)
    (13): Linear(in_features=70, out_features=88, bias=True)
    (14): Linear(in_features=70, out_features=88, bias=True)
    (15): Linear(in_features=70, out_features=88, bias=True)
    (16): Linear(in_features=70, out_features=88, bias=True)
    (17): Linear(in_features=70, out_features=88, bias=True)
    (18): Linear(in_features=70, out_features=88, bias=True)
    (19): Linear(in_features=70, out_features=88, bias=True)
    (20): Linear(in_features=70, out_features=88, bias=True)
  )
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  33116160.0
params:  131208.0
Trainable parameters:  131208
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6240156
	speed: 0.1567s/iter; left time: 1081.4430s
Epoch: 1 cost time: 21.413952589035034
Epoch: 1, Steps: 140 | Train Loss: 0.6425996 Vali Loss: 0.5181735 Test Loss: 0.2291265
Validation loss decreased (inf --> 0.518173).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4955586
	speed: 0.3489s/iter; left time: 2358.7204s
Epoch: 2 cost time: 23.270875215530396
Epoch: 2, Steps: 140 | Train Loss: 0.4939999 Vali Loss: 0.4734868 Test Loss: 0.2105615
Validation loss decreased (0.518173 --> 0.473487).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.6730143
	speed: 0.3660s/iter; left time: 2423.4440s
Epoch: 3 cost time: 22.41040277481079
Epoch: 3, Steps: 140 | Train Loss: 0.4680040 Vali Loss: 0.4629207 Test Loss: 0.2034459
Validation loss decreased (0.473487 --> 0.462921).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4297932
	speed: 0.3567s/iter; left time: 2311.9308s
Epoch: 4 cost time: 21.57893133163452
Epoch: 4, Steps: 140 | Train Loss: 0.4597498 Vali Loss: 0.4579380 Test Loss: 0.1996292
Validation loss decreased (0.462921 --> 0.457938).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3966064
	speed: 0.3515s/iter; left time: 2228.9943s
Epoch: 5 cost time: 21.590676307678223
Epoch: 5, Steps: 140 | Train Loss: 0.4552056 Vali Loss: 0.4504111 Test Loss: 0.1967083
Validation loss decreased (0.457938 --> 0.450411).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4086829
	speed: 0.3411s/iter; left time: 2114.8648s
Epoch: 6 cost time: 21.744401931762695
Epoch: 6, Steps: 140 | Train Loss: 0.4537206 Vali Loss: 0.4472583 Test Loss: 0.1948622
Validation loss decreased (0.450411 --> 0.447258).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4471175
	speed: 0.3568s/iter; left time: 2162.6091s
Epoch: 7 cost time: 22.74817681312561
Epoch: 7, Steps: 140 | Train Loss: 0.4516859 Vali Loss: 0.4494639 Test Loss: 0.1935127
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3860348
	speed: 0.4019s/iter; left time: 2379.5271s
Epoch: 8 cost time: 26.070296049118042
Epoch: 8, Steps: 140 | Train Loss: 0.4502932 Vali Loss: 0.4448872 Test Loss: 0.1922159
Validation loss decreased (0.447258 --> 0.444887).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4030872
	speed: 0.4198s/iter; left time: 2427.0073s
Epoch: 9 cost time: 24.553954362869263
Epoch: 9, Steps: 140 | Train Loss: 0.4496972 Vali Loss: 0.4436905 Test Loss: 0.1915527
Validation loss decreased (0.444887 --> 0.443691).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4584608
	speed: 0.3626s/iter; left time: 2045.3660s
Epoch: 10 cost time: 21.866497039794922
Epoch: 10, Steps: 140 | Train Loss: 0.4483637 Vali Loss: 0.4431829 Test Loss: 0.1905271
Validation loss decreased (0.443691 --> 0.443183).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.5135602
	speed: 0.3469s/iter; left time: 1908.1766s
Epoch: 11 cost time: 22.016066312789917
Epoch: 11, Steps: 140 | Train Loss: 0.4474676 Vali Loss: 0.4454603 Test Loss: 0.1901728
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4106106
	speed: 0.3386s/iter; left time: 1815.3710s
Epoch: 12 cost time: 20.67147970199585
Epoch: 12, Steps: 140 | Train Loss: 0.4472860 Vali Loss: 0.4398842 Test Loss: 0.1896658
Validation loss decreased (0.443183 --> 0.439884).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4698423
	speed: 0.3637s/iter; left time: 1898.8359s
Epoch: 13 cost time: 23.483317852020264
Epoch: 13, Steps: 140 | Train Loss: 0.4470038 Vali Loss: 0.4417284 Test Loss: 0.1892438
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4623292
	speed: 0.3787s/iter; left time: 1924.0991s
Epoch: 14 cost time: 23.349932432174683
Epoch: 14, Steps: 140 | Train Loss: 0.4468762 Vali Loss: 0.4388836 Test Loss: 0.1889291
Validation loss decreased (0.439884 --> 0.438884).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3645640
	speed: 0.3670s/iter; left time: 1813.2905s
Epoch: 15 cost time: 22.292335987091064
Epoch: 15, Steps: 140 | Train Loss: 0.4461513 Vali Loss: 0.4404221 Test Loss: 0.1886194
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4737518
	speed: 0.3479s/iter; left time: 1670.4420s
Epoch: 16 cost time: 21.08378267288208
Epoch: 16, Steps: 140 | Train Loss: 0.4455593 Vali Loss: 0.4406677 Test Loss: 0.1883156
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.5002620
	speed: 0.3424s/iter; left time: 1596.0197s
Epoch: 17 cost time: 20.92376136779785
Epoch: 17, Steps: 140 | Train Loss: 0.4458603 Vali Loss: 0.4384939 Test Loss: 0.1880552
Validation loss decreased (0.438884 --> 0.438494).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4916942
	speed: 0.3427s/iter; left time: 1549.4377s
Epoch: 18 cost time: 21.34222936630249
Epoch: 18, Steps: 140 | Train Loss: 0.4456128 Vali Loss: 0.4404717 Test Loss: 0.1878240
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4717718
	speed: 0.3298s/iter; left time: 1444.9163s
Epoch: 19 cost time: 21.31112241744995
Epoch: 19, Steps: 140 | Train Loss: 0.4448475 Vali Loss: 0.4379947 Test Loss: 0.1875561
Validation loss decreased (0.438494 --> 0.437995).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.5092301
	speed: 0.3545s/iter; left time: 1503.3165s
Epoch: 20 cost time: 21.131585359573364
Epoch: 20, Steps: 140 | Train Loss: 0.4451337 Vali Loss: 0.4354852 Test Loss: 0.1874155
Validation loss decreased (0.437995 --> 0.435485).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4262809
	speed: 0.3452s/iter; left time: 1415.6620s
Epoch: 21 cost time: 21.707319021224976
Epoch: 21, Steps: 140 | Train Loss: 0.4449305 Vali Loss: 0.4367673 Test Loss: 0.1872752
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.3786338
	speed: 0.3931s/iter; left time: 1557.1096s
Epoch: 22 cost time: 23.283809423446655
Epoch: 22, Steps: 140 | Train Loss: 0.4449493 Vali Loss: 0.4361549 Test Loss: 0.1870611
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4491520
	speed: 0.3674s/iter; left time: 1403.8111s
Epoch: 23 cost time: 22.883496284484863
Epoch: 23, Steps: 140 | Train Loss: 0.4437523 Vali Loss: 0.4382566 Test Loss: 0.1870316
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Weather_720_j192_H10_FITS_custom_ftM_sl720_ll48_pl192_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10348
mse:0.18934227526187897, mae:0.24150873720645905, rse:0.5727853775024414, corr:[0.47347373 0.477371   0.47807422 0.47702754 0.47544914 0.4741553
 0.47349063 0.47339433 0.47349146 0.47338867 0.47287223 0.4720164
 0.47101048 0.4700886  0.46946314 0.46908534 0.46889967 0.468622
 0.46814647 0.46734503 0.46633497 0.46525934 0.46431273 0.4635111
 0.46287417 0.4623454  0.46182108 0.46117252 0.4603816  0.45941353
 0.45840555 0.45747524 0.45678174 0.45628902 0.4560002  0.45575872
 0.4555339  0.4551707  0.4546143  0.453878   0.45308876 0.45238578
 0.45181718 0.45135623 0.45094764 0.4505162  0.45008484 0.4496192
 0.44899642 0.4482917  0.44759947 0.44687048 0.44623786 0.44567057
 0.44518316 0.4447161  0.444262   0.4438139  0.44340137 0.44303134
 0.44271004 0.44240692 0.44212288 0.44184753 0.44153735 0.44119942
 0.44080728 0.44039312 0.4399976  0.43963668 0.43935192 0.43903956
 0.43879107 0.4385691  0.4382951  0.43797943 0.4376299  0.43731636
 0.4370195  0.4367498  0.4365694  0.43643495 0.43627006 0.43608207
 0.43588287 0.4356626  0.4354323  0.43510282 0.4347837  0.43446016
 0.43421653 0.4340909  0.43401575 0.43401173 0.43405342 0.4340684
 0.43401313 0.43388164 0.4336473  0.4333566  0.4330368  0.43272352
 0.4324447  0.43219104 0.43196258 0.4317569  0.4315277  0.43131596
 0.43107128 0.43084636 0.43061298 0.43033955 0.43000567 0.42970878
 0.4294422  0.4291755  0.4289552  0.42879504 0.42866084 0.4284845
 0.42831162 0.4281162  0.42787704 0.42762387 0.4273557  0.42708868
 0.4268223  0.4265419  0.426278   0.42603552 0.4257788  0.4255091
 0.42524123 0.42495236 0.4246836  0.42438754 0.4240908  0.423822
 0.42350608 0.42324024 0.42304838 0.42294487 0.42286834 0.4227521
 0.4225844  0.42235056 0.42208475 0.4218084  0.42146984 0.4210397
 0.4205583  0.42009905 0.41962993 0.4191249  0.4186503  0.41814685
 0.41772196 0.4172195  0.4167192  0.41626024 0.41590738 0.41565907
 0.4154579  0.4152797  0.41500813 0.41464797 0.41413635 0.41353706
 0.41292804 0.41239235 0.41196612 0.4116398  0.41135833 0.41105753
 0.41059458 0.40996224 0.40915284 0.4083096  0.40755403 0.40701613
 0.4068002  0.40675217 0.40667647 0.4063919  0.40580553 0.40495974
 0.40401405 0.40327856 0.40310207 0.40345138 0.40359473 0.4019889 ]
