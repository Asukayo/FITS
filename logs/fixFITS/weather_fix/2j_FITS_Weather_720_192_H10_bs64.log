Args in experiment:
Namespace(H_order=10, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=144, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=70, d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='weather.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=21, factor=1, features='M', freq='h', gpu=3, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=True, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='Weather_720_j192_H10', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=2021, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:3
>>>>>>>start training : Weather_720_j192_H10_FITS_custom_ftM_sl720_ll48_pl192_H10_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 35976
val 5079
test 10348
Model(
  (freq_upsampler): ModuleList(
    (0): Linear(in_features=70, out_features=88, bias=True)
    (1): Linear(in_features=70, out_features=88, bias=True)
    (2): Linear(in_features=70, out_features=88, bias=True)
    (3): Linear(in_features=70, out_features=88, bias=True)
    (4): Linear(in_features=70, out_features=88, bias=True)
    (5): Linear(in_features=70, out_features=88, bias=True)
    (6): Linear(in_features=70, out_features=88, bias=True)
    (7): Linear(in_features=70, out_features=88, bias=True)
    (8): Linear(in_features=70, out_features=88, bias=True)
    (9): Linear(in_features=70, out_features=88, bias=True)
    (10): Linear(in_features=70, out_features=88, bias=True)
    (11): Linear(in_features=70, out_features=88, bias=True)
    (12): Linear(in_features=70, out_features=88, bias=True)
    (13): Linear(in_features=70, out_features=88, bias=True)
    (14): Linear(in_features=70, out_features=88, bias=True)
    (15): Linear(in_features=70, out_features=88, bias=True)
    (16): Linear(in_features=70, out_features=88, bias=True)
    (17): Linear(in_features=70, out_features=88, bias=True)
    (18): Linear(in_features=70, out_features=88, bias=True)
    (19): Linear(in_features=70, out_features=88, bias=True)
    (20): Linear(in_features=70, out_features=88, bias=True)
  )
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  16558080.0
params:  131208.0
Trainable parameters:  131208
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5585678
	speed: 0.1601s/iter; left time: 2232.9288s
	iters: 200, epoch: 1 | loss: 0.4368559
	speed: 0.1469s/iter; left time: 2035.2330s
Epoch: 1 cost time: 44.605185747146606
Epoch: 1, Steps: 281 | Train Loss: 0.5554809 Vali Loss: 0.5682625 Test Loss: 0.2458611
Validation loss decreased (inf --> 0.568262).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3500704
	speed: 0.5837s/iter; left time: 7979.8036s
	iters: 200, epoch: 2 | loss: 0.4719293
	speed: 0.1566s/iter; left time: 2124.7906s
Epoch: 2 cost time: 43.732094049453735
Epoch: 2, Steps: 281 | Train Loss: 0.3505108 Vali Loss: 0.5230956 Test Loss: 0.2255583
Validation loss decreased (0.568262 --> 0.523096).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2987859
	speed: 0.5752s/iter; left time: 7701.2242s
	iters: 200, epoch: 3 | loss: 0.3312921
	speed: 0.1658s/iter; left time: 2202.8201s
Epoch: 3 cost time: 47.09626889228821
Epoch: 3, Steps: 281 | Train Loss: 0.2717588 Vali Loss: 0.4977388 Test Loss: 0.2151705
Validation loss decreased (0.523096 --> 0.497739).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2158916
	speed: 0.6425s/iter; left time: 8422.0613s
	iters: 200, epoch: 4 | loss: 0.2367570
	speed: 0.2204s/iter; left time: 2866.3525s
Epoch: 4 cost time: 62.150904178619385
Epoch: 4, Steps: 281 | Train Loss: 0.2302604 Vali Loss: 0.4804408 Test Loss: 0.2081502
Validation loss decreased (0.497739 --> 0.480441).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1866039
	speed: 0.8642s/iter; left time: 11084.7469s
	iters: 200, epoch: 5 | loss: 0.2466513
	speed: 0.2414s/iter; left time: 3072.1470s
Epoch: 5 cost time: 67.85623335838318
Epoch: 5, Steps: 281 | Train Loss: 0.2071239 Vali Loss: 0.4702796 Test Loss: 0.2034094
Validation loss decreased (0.480441 --> 0.470280).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1982202
	speed: 0.6480s/iter; left time: 8130.1392s
	iters: 200, epoch: 6 | loss: 0.1556237
	speed: 0.2378s/iter; left time: 2959.3300s
Epoch: 6 cost time: 66.40166735649109
Epoch: 6, Steps: 281 | Train Loss: 0.1941122 Vali Loss: 0.4582348 Test Loss: 0.2000530
Validation loss decreased (0.470280 --> 0.458235).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1619150
	speed: 0.9918s/iter; left time: 12164.7804s
	iters: 200, epoch: 7 | loss: 0.1926232
	speed: 0.2531s/iter; left time: 3078.5020s
Epoch: 7 cost time: 73.61445951461792
Epoch: 7, Steps: 281 | Train Loss: 0.1867476 Vali Loss: 0.4531860 Test Loss: 0.1978940
Validation loss decreased (0.458235 --> 0.453186).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2451351
	speed: 0.6928s/iter; left time: 8302.3094s
	iters: 200, epoch: 8 | loss: 0.1679668
	speed: 0.2357s/iter; left time: 2800.7523s
Epoch: 8 cost time: 60.46711492538452
Epoch: 8, Steps: 281 | Train Loss: 0.1828104 Vali Loss: 0.4536437 Test Loss: 0.1967116
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1515741
	speed: 0.8513s/iter; left time: 9962.4492s
	iters: 200, epoch: 9 | loss: 0.1734126
	speed: 0.2298s/iter; left time: 2666.5672s
Epoch: 9 cost time: 64.88297629356384
Epoch: 9, Steps: 281 | Train Loss: 0.1806346 Vali Loss: 0.4509745 Test Loss: 0.1958006
Validation loss decreased (0.453186 --> 0.450975).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1976817
	speed: 0.7614s/iter; left time: 8696.9951s
	iters: 200, epoch: 10 | loss: 0.1452608
	speed: 0.2153s/iter; left time: 2437.7550s
Epoch: 10 cost time: 60.546542167663574
Epoch: 10, Steps: 281 | Train Loss: 0.1794743 Vali Loss: 0.4488473 Test Loss: 0.1951969
Validation loss decreased (0.450975 --> 0.448847).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1361309
	speed: 0.8196s/iter; left time: 9131.6150s
	iters: 200, epoch: 11 | loss: 0.1804304
	speed: 0.2581s/iter; left time: 2849.2298s
Epoch: 11 cost time: 86.45424175262451
Epoch: 11, Steps: 281 | Train Loss: 0.1788457 Vali Loss: 0.4483568 Test Loss: 0.1948283
Validation loss decreased (0.448847 --> 0.448357).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2189853
	speed: 1.1765s/iter; left time: 12776.7449s
	iters: 200, epoch: 12 | loss: 0.1774268
	speed: 0.2315s/iter; left time: 2490.5724s
Epoch: 12 cost time: 72.59057307243347
Epoch: 12, Steps: 281 | Train Loss: 0.1785546 Vali Loss: 0.4501634 Test Loss: 0.1946631
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1722155
	speed: 1.2643s/iter; left time: 13375.0498s
	iters: 200, epoch: 13 | loss: 0.1372057
	speed: 0.4785s/iter; left time: 5014.5310s
Epoch: 13 cost time: 122.60547041893005
Epoch: 13, Steps: 281 | Train Loss: 0.1784247 Vali Loss: 0.4466609 Test Loss: 0.1945716
Validation loss decreased (0.448357 --> 0.446661).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2251504
	speed: 0.9335s/iter; left time: 9612.9707s
	iters: 200, epoch: 14 | loss: 0.1971023
	speed: 0.2397s/iter; left time: 2444.9224s
Epoch: 14 cost time: 66.74779081344604
Epoch: 14, Steps: 281 | Train Loss: 0.1783441 Vali Loss: 0.4475741 Test Loss: 0.1941704
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1889503
	speed: 0.8779s/iter; left time: 8794.1134s
	iters: 200, epoch: 15 | loss: 0.1395353
	speed: 0.2399s/iter; left time: 2379.5251s
Epoch: 15 cost time: 68.60731911659241
Epoch: 15, Steps: 281 | Train Loss: 0.1782884 Vali Loss: 0.4479304 Test Loss: 0.1943809
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1480204
	speed: 0.8973s/iter; left time: 8735.8606s
	iters: 200, epoch: 16 | loss: 0.1682526
	speed: 0.2624s/iter; left time: 2528.1051s
Epoch: 16 cost time: 73.29782104492188
Epoch: 16, Steps: 281 | Train Loss: 0.1782465 Vali Loss: 0.4472157 Test Loss: 0.1939846
EarlyStopping counter: 3 out of 3
Early stopping
train 35976
val 5079
test 10348
Model(
  (freq_upsampler): ModuleList(
    (0): Linear(in_features=70, out_features=88, bias=True)
    (1): Linear(in_features=70, out_features=88, bias=True)
    (2): Linear(in_features=70, out_features=88, bias=True)
    (3): Linear(in_features=70, out_features=88, bias=True)
    (4): Linear(in_features=70, out_features=88, bias=True)
    (5): Linear(in_features=70, out_features=88, bias=True)
    (6): Linear(in_features=70, out_features=88, bias=True)
    (7): Linear(in_features=70, out_features=88, bias=True)
    (8): Linear(in_features=70, out_features=88, bias=True)
    (9): Linear(in_features=70, out_features=88, bias=True)
    (10): Linear(in_features=70, out_features=88, bias=True)
    (11): Linear(in_features=70, out_features=88, bias=True)
    (12): Linear(in_features=70, out_features=88, bias=True)
    (13): Linear(in_features=70, out_features=88, bias=True)
    (14): Linear(in_features=70, out_features=88, bias=True)
    (15): Linear(in_features=70, out_features=88, bias=True)
    (16): Linear(in_features=70, out_features=88, bias=True)
    (17): Linear(in_features=70, out_features=88, bias=True)
    (18): Linear(in_features=70, out_features=88, bias=True)
    (19): Linear(in_features=70, out_features=88, bias=True)
    (20): Linear(in_features=70, out_features=88, bias=True)
  )
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  16558080.0
params:  131208.0
Trainable parameters:  131208
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5937833
	speed: 0.2415s/iter; left time: 3369.3073s
	iters: 200, epoch: 1 | loss: 0.4328355
	speed: 0.2167s/iter; left time: 3001.2840s
Epoch: 1 cost time: 62.61839556694031
Epoch: 1, Steps: 281 | Train Loss: 0.4497063 Vali Loss: 0.4394806 Test Loss: 0.1904849
Validation loss decreased (inf --> 0.439481).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3557484
	speed: 0.7979s/iter; left time: 10906.9670s
	iters: 200, epoch: 2 | loss: 0.3704175
	speed: 0.2598s/iter; left time: 3525.6952s
Epoch: 2 cost time: 71.27118849754333
Epoch: 2, Steps: 281 | Train Loss: 0.4468050 Vali Loss: 0.4392186 Test Loss: 0.1892494
Validation loss decreased (0.439481 --> 0.439219).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3681382
	speed: 0.8921s/iter; left time: 11943.8205s
	iters: 200, epoch: 3 | loss: 0.6167859
	speed: 0.2512s/iter; left time: 3337.5646s
Epoch: 3 cost time: 72.66479110717773
Epoch: 3, Steps: 281 | Train Loss: 0.4454930 Vali Loss: 0.4369155 Test Loss: 0.1879885
Validation loss decreased (0.439219 --> 0.436915).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3439570
	speed: 0.9043s/iter; left time: 11854.0029s
	iters: 200, epoch: 4 | loss: 0.5883323
	speed: 0.2198s/iter; left time: 2859.6269s
Epoch: 4 cost time: 63.50101900100708
Epoch: 4, Steps: 281 | Train Loss: 0.4448181 Vali Loss: 0.4391024 Test Loss: 0.1879046
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3679735
	speed: 0.7326s/iter; left time: 9396.4713s
	iters: 200, epoch: 5 | loss: 0.4007928
	speed: 0.1864s/iter; left time: 2372.9255s
Epoch: 5 cost time: 54.70851683616638
Epoch: 5, Steps: 281 | Train Loss: 0.4442805 Vali Loss: 0.4357148 Test Loss: 0.1875613
Validation loss decreased (0.436915 --> 0.435715).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3656760
	speed: 0.7538s/iter; left time: 9457.4483s
	iters: 200, epoch: 6 | loss: 0.4024123
	speed: 0.2102s/iter; left time: 2616.5255s
Epoch: 6 cost time: 61.33693742752075
Epoch: 6, Steps: 281 | Train Loss: 0.4438433 Vali Loss: 0.4343437 Test Loss: 0.1875117
Validation loss decreased (0.435715 --> 0.434344).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4978342
	speed: 0.8126s/iter; left time: 9966.8519s
	iters: 200, epoch: 7 | loss: 0.3822316
	speed: 0.2084s/iter; left time: 2534.6059s
Epoch: 7 cost time: 59.511953353881836
Epoch: 7, Steps: 281 | Train Loss: 0.4431710 Vali Loss: 0.4333670 Test Loss: 0.1872454
Validation loss decreased (0.434344 --> 0.433367).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4772096
	speed: 0.7833s/iter; left time: 9387.0989s
	iters: 200, epoch: 8 | loss: 0.4779973
	speed: 0.2272s/iter; left time: 2699.4652s
Epoch: 8 cost time: 63.9542076587677
Epoch: 8, Steps: 281 | Train Loss: 0.4433258 Vali Loss: 0.4356613 Test Loss: 0.1869633
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.6111854
	speed: 0.8261s/iter; left time: 9667.9904s
	iters: 200, epoch: 9 | loss: 0.6287831
	speed: 0.2468s/iter; left time: 2864.1516s
Epoch: 9 cost time: 69.26577544212341
Epoch: 9, Steps: 281 | Train Loss: 0.4430781 Vali Loss: 0.4370370 Test Loss: 0.1869197
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3437565
	speed: 0.8665s/iter; left time: 9896.8569s
	iters: 200, epoch: 10 | loss: 0.3425537
	speed: 0.2472s/iter; left time: 2798.5796s
Epoch: 10 cost time: 70.30258679389954
Epoch: 10, Steps: 281 | Train Loss: 0.4428813 Vali Loss: 0.4341483 Test Loss: 0.1867601
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Weather_720_j192_H10_FITS_custom_ftM_sl720_ll48_pl192_H10_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10348
mse:0.18751123547554016, mae:0.23885855078697205, rse:0.5700090527534485, corr:[0.47086006 0.47597328 0.47760677 0.47724307 0.4759142  0.4744775
 0.47351244 0.47315028 0.47314045 0.47313285 0.47287983 0.4723602
 0.4716463  0.4708911  0.47026634 0.46977603 0.46942207 0.46896848
 0.46833208 0.46739206 0.4662654  0.4650881  0.4640518  0.46317238
 0.46246406 0.46185988 0.4612493  0.46049285 0.45957062 0.45847037
 0.4573693  0.45642042 0.45579886 0.4554402  0.45530182 0.45520103
 0.4550942  0.4548271  0.45434642 0.45367274 0.4529432  0.4522918
 0.45174697 0.45128325 0.45085016 0.4503833  0.44991064 0.44940054
 0.4487278  0.44797993 0.44726032 0.4465358  0.44594255 0.44543302
 0.44498444 0.44450024 0.44395012 0.4433388  0.4427206  0.44215113
 0.44168353 0.44132608 0.44110614 0.4409993  0.4409095  0.44077337
 0.44050652 0.44010347 0.43959725 0.4390247  0.4384843  0.43794557
 0.43756843 0.43735388 0.43721122 0.43710744 0.4369751  0.4368094
 0.4365529  0.43621477 0.43590727 0.43565097 0.43542758 0.43527856
 0.43522418 0.4352169  0.4352216  0.43510833 0.43493673 0.43466043
 0.43436182 0.43410528 0.43386227 0.43368438 0.43356654 0.43344778
 0.4332904  0.4330883  0.4328103  0.43249744 0.43217885 0.43188646
 0.43164888 0.4314544  0.43127763 0.43108833 0.43082413 0.43051848
 0.43013397 0.4297509  0.42937908 0.42902595 0.42870533 0.42850766
 0.4284047  0.42832136 0.42826536 0.42822227 0.42814228 0.42796478
 0.42776766 0.42756346 0.4273731  0.42724985 0.42717314 0.4271111
 0.42700863 0.42679533 0.42648083 0.4260946  0.42565584 0.4252344
 0.42490032 0.42465395 0.42452976 0.42444003 0.42436087 0.42426372
 0.42404693 0.4237847  0.42351538 0.4233073  0.42316058 0.4230539
 0.42297807 0.42288595 0.4227444  0.42251265 0.4221054  0.42146853
 0.42067158 0.41988426 0.41916704 0.4185564  0.41812578 0.41776308
 0.4175345  0.4172465  0.4169351  0.41660467 0.4163117  0.4160692
 0.41585934 0.41569975 0.41549152 0.41521937 0.4147797  0.4141994
 0.41353068 0.41286156 0.4122501  0.4117517  0.41139424 0.41116405
 0.41090232 0.41054344 0.41000494 0.4093533  0.4086533  0.40801722
 0.4076305  0.40747783 0.40747958 0.40746498 0.40721923 0.4065923
 0.40555578 0.4042199  0.40289885 0.4019002  0.40140194 0.40111727]
