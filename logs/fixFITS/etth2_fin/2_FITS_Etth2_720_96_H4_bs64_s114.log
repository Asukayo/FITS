Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=134, out_features=151, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  18129664.0
params:  20385.0
Trainable parameters:  20385
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 10.61768126487732
Epoch: 1, Steps: 61 | Train Loss: 0.5567964 Vali Loss: 0.3881299 Test Loss: 0.3922635
Validation loss decreased (inf --> 0.388130).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 11.566563844680786
Epoch: 2, Steps: 61 | Train Loss: 0.4346520 Vali Loss: 0.3417651 Test Loss: 0.3521745
Validation loss decreased (0.388130 --> 0.341765).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 11.068994283676147
Epoch: 3, Steps: 61 | Train Loss: 0.3694460 Vali Loss: 0.3231464 Test Loss: 0.3357202
Validation loss decreased (0.341765 --> 0.323146).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 11.876113176345825
Epoch: 4, Steps: 61 | Train Loss: 0.3289413 Vali Loss: 0.3140866 Test Loss: 0.3281066
Validation loss decreased (0.323146 --> 0.314087).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 11.55844235420227
Epoch: 5, Steps: 61 | Train Loss: 0.3005850 Vali Loss: 0.3097622 Test Loss: 0.3246930
Validation loss decreased (0.314087 --> 0.309762).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 10.693777799606323
Epoch: 6, Steps: 61 | Train Loss: 0.2785146 Vali Loss: 0.3067574 Test Loss: 0.3224631
Validation loss decreased (0.309762 --> 0.306757).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 8.7269446849823
Epoch: 7, Steps: 61 | Train Loss: 0.2609322 Vali Loss: 0.3047095 Test Loss: 0.3207133
Validation loss decreased (0.306757 --> 0.304710).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 10.560510158538818
Epoch: 8, Steps: 61 | Train Loss: 0.2458477 Vali Loss: 0.3010626 Test Loss: 0.3193302
Validation loss decreased (0.304710 --> 0.301063).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 10.712815761566162
Epoch: 9, Steps: 61 | Train Loss: 0.2326394 Vali Loss: 0.3000919 Test Loss: 0.3179016
Validation loss decreased (0.301063 --> 0.300092).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 10.519779920578003
Epoch: 10, Steps: 61 | Train Loss: 0.2215377 Vali Loss: 0.2981820 Test Loss: 0.3163748
Validation loss decreased (0.300092 --> 0.298182).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 10.797314643859863
Epoch: 11, Steps: 61 | Train Loss: 0.2115003 Vali Loss: 0.2950283 Test Loss: 0.3148956
Validation loss decreased (0.298182 --> 0.295028).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 10.755884408950806
Epoch: 12, Steps: 61 | Train Loss: 0.2023839 Vali Loss: 0.2928947 Test Loss: 0.3133477
Validation loss decreased (0.295028 --> 0.292895).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 10.261837005615234
Epoch: 13, Steps: 61 | Train Loss: 0.1943116 Vali Loss: 0.2902997 Test Loss: 0.3119439
Validation loss decreased (0.292895 --> 0.290300).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 10.146569013595581
Epoch: 14, Steps: 61 | Train Loss: 0.1873291 Vali Loss: 0.2882703 Test Loss: 0.3105422
Validation loss decreased (0.290300 --> 0.288270).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 10.6442289352417
Epoch: 15, Steps: 61 | Train Loss: 0.1808608 Vali Loss: 0.2863297 Test Loss: 0.3091026
Validation loss decreased (0.288270 --> 0.286330).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 10.543797254562378
Epoch: 16, Steps: 61 | Train Loss: 0.1750642 Vali Loss: 0.2833079 Test Loss: 0.3079427
Validation loss decreased (0.286330 --> 0.283308).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 10.478540182113647
Epoch: 17, Steps: 61 | Train Loss: 0.1696508 Vali Loss: 0.2827315 Test Loss: 0.3064566
Validation loss decreased (0.283308 --> 0.282732).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 11.412178993225098
Epoch: 18, Steps: 61 | Train Loss: 0.1648306 Vali Loss: 0.2812031 Test Loss: 0.3052169
Validation loss decreased (0.282732 --> 0.281203).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 11.557915687561035
Epoch: 19, Steps: 61 | Train Loss: 0.1604027 Vali Loss: 0.2789215 Test Loss: 0.3041390
Validation loss decreased (0.281203 --> 0.278922).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 11.498428106307983
Epoch: 20, Steps: 61 | Train Loss: 0.1563304 Vali Loss: 0.2774153 Test Loss: 0.3030385
Validation loss decreased (0.278922 --> 0.277415).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 9.16509747505188
Epoch: 21, Steps: 61 | Train Loss: 0.1526036 Vali Loss: 0.2755981 Test Loss: 0.3020203
Validation loss decreased (0.277415 --> 0.275598).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 10.694656133651733
Epoch: 22, Steps: 61 | Train Loss: 0.1490348 Vali Loss: 0.2747448 Test Loss: 0.3011125
Validation loss decreased (0.275598 --> 0.274745).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 10.377446413040161
Epoch: 23, Steps: 61 | Train Loss: 0.1460019 Vali Loss: 0.2721937 Test Loss: 0.3002147
Validation loss decreased (0.274745 --> 0.272194).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 9.673188924789429
Epoch: 24, Steps: 61 | Train Loss: 0.1430736 Vali Loss: 0.2706783 Test Loss: 0.2992783
Validation loss decreased (0.272194 --> 0.270678).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 9.567856788635254
Epoch: 25, Steps: 61 | Train Loss: 0.1402889 Vali Loss: 0.2711765 Test Loss: 0.2985198
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 9.602726459503174
Epoch: 26, Steps: 61 | Train Loss: 0.1379215 Vali Loss: 0.2692183 Test Loss: 0.2977346
Validation loss decreased (0.270678 --> 0.269218).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 9.173609256744385
Epoch: 27, Steps: 61 | Train Loss: 0.1356546 Vali Loss: 0.2683840 Test Loss: 0.2970012
Validation loss decreased (0.269218 --> 0.268384).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 9.424000024795532
Epoch: 28, Steps: 61 | Train Loss: 0.1335083 Vali Loss: 0.2666806 Test Loss: 0.2963858
Validation loss decreased (0.268384 --> 0.266681).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 9.756415843963623
Epoch: 29, Steps: 61 | Train Loss: 0.1314873 Vali Loss: 0.2656659 Test Loss: 0.2957056
Validation loss decreased (0.266681 --> 0.265666).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 8.876195192337036
Epoch: 30, Steps: 61 | Train Loss: 0.1295220 Vali Loss: 0.2647040 Test Loss: 0.2951591
Validation loss decreased (0.265666 --> 0.264704).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 9.532486200332642
Epoch: 31, Steps: 61 | Train Loss: 0.1279073 Vali Loss: 0.2641420 Test Loss: 0.2945988
Validation loss decreased (0.264704 --> 0.264142).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 9.452645063400269
Epoch: 32, Steps: 61 | Train Loss: 0.1263032 Vali Loss: 0.2638309 Test Loss: 0.2940956
Validation loss decreased (0.264142 --> 0.263831).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 9.61917519569397
Epoch: 33, Steps: 61 | Train Loss: 0.1247293 Vali Loss: 0.2627026 Test Loss: 0.2935678
Validation loss decreased (0.263831 --> 0.262703).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 10.671208381652832
Epoch: 34, Steps: 61 | Train Loss: 0.1234060 Vali Loss: 0.2620090 Test Loss: 0.2931744
Validation loss decreased (0.262703 --> 0.262009).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 10.115905523300171
Epoch: 35, Steps: 61 | Train Loss: 0.1220886 Vali Loss: 0.2616554 Test Loss: 0.2927141
Validation loss decreased (0.262009 --> 0.261655).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 10.153883457183838
Epoch: 36, Steps: 61 | Train Loss: 0.1208830 Vali Loss: 0.2610493 Test Loss: 0.2923257
Validation loss decreased (0.261655 --> 0.261049).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 10.164219617843628
Epoch: 37, Steps: 61 | Train Loss: 0.1196364 Vali Loss: 0.2601581 Test Loss: 0.2919138
Validation loss decreased (0.261049 --> 0.260158).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 10.378462553024292
Epoch: 38, Steps: 61 | Train Loss: 0.1186149 Vali Loss: 0.2591455 Test Loss: 0.2915778
Validation loss decreased (0.260158 --> 0.259145).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 8.062625169754028
Epoch: 39, Steps: 61 | Train Loss: 0.1176063 Vali Loss: 0.2592155 Test Loss: 0.2912108
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 9.563095092773438
Epoch: 40, Steps: 61 | Train Loss: 0.1165740 Vali Loss: 0.2580531 Test Loss: 0.2909131
Validation loss decreased (0.259145 --> 0.258053).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 9.518521070480347
Epoch: 41, Steps: 61 | Train Loss: 0.1156354 Vali Loss: 0.2578968 Test Loss: 0.2905669
Validation loss decreased (0.258053 --> 0.257897).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 7.960651397705078
Epoch: 42, Steps: 61 | Train Loss: 0.1149284 Vali Loss: 0.2573656 Test Loss: 0.2902589
Validation loss decreased (0.257897 --> 0.257366).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 8.592156410217285
Epoch: 43, Steps: 61 | Train Loss: 0.1140692 Vali Loss: 0.2576274 Test Loss: 0.2899973
EarlyStopping counter: 1 out of 3
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 8.673032522201538
Epoch: 44, Steps: 61 | Train Loss: 0.1133580 Vali Loss: 0.2562310 Test Loss: 0.2897469
Validation loss decreased (0.257366 --> 0.256231).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 8.569340705871582
Epoch: 45, Steps: 61 | Train Loss: 0.1126342 Vali Loss: 0.2559148 Test Loss: 0.2894807
Validation loss decreased (0.256231 --> 0.255915).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 8.902698278427124
Epoch: 46, Steps: 61 | Train Loss: 0.1119094 Vali Loss: 0.2566877 Test Loss: 0.2892646
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 6.987428903579712
Epoch: 47, Steps: 61 | Train Loss: 0.1113046 Vali Loss: 0.2550479 Test Loss: 0.2890522
Validation loss decreased (0.255915 --> 0.255048).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 7.887645959854126
Epoch: 48, Steps: 61 | Train Loss: 0.1104500 Vali Loss: 0.2550114 Test Loss: 0.2887995
Validation loss decreased (0.255048 --> 0.255011).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 8.690966844558716
Epoch: 49, Steps: 61 | Train Loss: 0.1100655 Vali Loss: 0.2545443 Test Loss: 0.2886400
Validation loss decreased (0.255011 --> 0.254544).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 9.019459009170532
Epoch: 50, Steps: 61 | Train Loss: 0.1095847 Vali Loss: 0.2541918 Test Loss: 0.2884575
Validation loss decreased (0.254544 --> 0.254192).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=134, out_features=151, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  18129664.0
params:  20385.0
Trainable parameters:  20385
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 9.399610042572021
Epoch: 1, Steps: 61 | Train Loss: 0.4304800 Vali Loss: 0.2281523 Test Loss: 0.2747529
Validation loss decreased (inf --> 0.228152).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 9.007673501968384
Epoch: 2, Steps: 61 | Train Loss: 0.4144208 Vali Loss: 0.2220601 Test Loss: 0.2738908
Validation loss decreased (0.228152 --> 0.222060).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 9.676235437393188
Epoch: 3, Steps: 61 | Train Loss: 0.4106551 Vali Loss: 0.2182178 Test Loss: 0.2739961
Validation loss decreased (0.222060 --> 0.218218).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 8.943828582763672
Epoch: 4, Steps: 61 | Train Loss: 0.4082756 Vali Loss: 0.2182483 Test Loss: 0.2737561
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 9.89865779876709
Epoch: 5, Steps: 61 | Train Loss: 0.4060994 Vali Loss: 0.2166967 Test Loss: 0.2733558
Validation loss decreased (0.218218 --> 0.216697).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 8.953537702560425
Epoch: 6, Steps: 61 | Train Loss: 0.4061825 Vali Loss: 0.2159183 Test Loss: 0.2734840
Validation loss decreased (0.216697 --> 0.215918).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 10.632222414016724
Epoch: 7, Steps: 61 | Train Loss: 0.4053711 Vali Loss: 0.2161015 Test Loss: 0.2733111
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 10.227211952209473
Epoch: 8, Steps: 61 | Train Loss: 0.4048609 Vali Loss: 0.2151552 Test Loss: 0.2731323
Validation loss decreased (0.215918 --> 0.215155).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 10.23962664604187
Epoch: 9, Steps: 61 | Train Loss: 0.4038350 Vali Loss: 0.2155578 Test Loss: 0.2730172
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 10.074292421340942
Epoch: 10, Steps: 61 | Train Loss: 0.4030671 Vali Loss: 0.2139386 Test Loss: 0.2728570
Validation loss decreased (0.215155 --> 0.213939).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 9.660552978515625
Epoch: 11, Steps: 61 | Train Loss: 0.4033876 Vali Loss: 0.2137410 Test Loss: 0.2729205
Validation loss decreased (0.213939 --> 0.213741).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 9.588762044906616
Epoch: 12, Steps: 61 | Train Loss: 0.4029576 Vali Loss: 0.2132525 Test Loss: 0.2728085
Validation loss decreased (0.213741 --> 0.213252).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 9.94987177848816
Epoch: 13, Steps: 61 | Train Loss: 0.4014161 Vali Loss: 0.2131612 Test Loss: 0.2726058
Validation loss decreased (0.213252 --> 0.213161).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 10.301518440246582
Epoch: 14, Steps: 61 | Train Loss: 0.4022334 Vali Loss: 0.2132508 Test Loss: 0.2727737
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 10.33826494216919
Epoch: 15, Steps: 61 | Train Loss: 0.4026914 Vali Loss: 0.2134959 Test Loss: 0.2726845
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 10.526939630508423
Epoch: 16, Steps: 61 | Train Loss: 0.4022837 Vali Loss: 0.2128194 Test Loss: 0.2727471
Validation loss decreased (0.213161 --> 0.212819).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 9.814814329147339
Epoch: 17, Steps: 61 | Train Loss: 0.4016130 Vali Loss: 0.2137960 Test Loss: 0.2725188
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 10.06783127784729
Epoch: 18, Steps: 61 | Train Loss: 0.4020027 Vali Loss: 0.2128648 Test Loss: 0.2726940
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 10.136497020721436
Epoch: 19, Steps: 61 | Train Loss: 0.4019766 Vali Loss: 0.2129334 Test Loss: 0.2724611
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.2724328637123108, mae:0.3371771275997162, rse:0.4206404685974121, corr:[0.27427107 0.2764435  0.27577588 0.27440155 0.27350876 0.27319574
 0.27295542 0.27218816 0.27131274 0.27021447 0.26889086 0.26718733
 0.26555035 0.26436993 0.26347992 0.26295722 0.26247272 0.26183292
 0.2609377  0.25996548 0.25904053 0.25804463 0.25679538 0.2550453
 0.25308096 0.2512506  0.24971537 0.24833755 0.24706556 0.24584112
 0.24453695 0.2430592  0.24141103 0.24000551 0.23888794 0.23777208
 0.23657405 0.23542598 0.23463853 0.23393264 0.23325832 0.2325684
 0.23182373 0.2310272  0.23044546 0.22976576 0.22868276 0.2268486
 0.22455938 0.2225504  0.22134522 0.22021785 0.21911561 0.21775484
 0.21582797 0.21391596 0.21212657 0.2102628  0.20856151 0.20750147
 0.20721109 0.20701097 0.20681657 0.20672105 0.20608392 0.2056047
 0.20519288 0.20468959 0.20411733 0.20361532 0.20301671 0.20247203
 0.20166665 0.2003842  0.1989597  0.19725816 0.19628683 0.19593933
 0.19594812 0.1954067  0.19544643 0.19587947 0.1956483  0.19472355
 0.19382627 0.19414072 0.19518998 0.19579512 0.19447732 0.19271271
 0.1919591  0.1923668  0.19305952 0.19230524 0.19094685 0.19273682]
