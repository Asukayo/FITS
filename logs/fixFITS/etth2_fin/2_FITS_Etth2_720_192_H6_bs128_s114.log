Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=196, out_features=248, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  87105536.0
params:  48856.0
Trainable parameters:  48856
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 4.1922056674957275
Epoch: 1, Steps: 30 | Train Loss: 0.6319960 Vali Loss: 0.5210809 Test Loss: 0.4694287
Validation loss decreased (inf --> 0.521081).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 5.32241153717041
Epoch: 2, Steps: 30 | Train Loss: 0.5315300 Vali Loss: 0.4681338 Test Loss: 0.4333831
Validation loss decreased (0.521081 --> 0.468134).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 4.358721971511841
Epoch: 3, Steps: 30 | Train Loss: 0.4695879 Vali Loss: 0.4304520 Test Loss: 0.4117274
Validation loss decreased (0.468134 --> 0.430452).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 4.4196295738220215
Epoch: 4, Steps: 30 | Train Loss: 0.4292100 Vali Loss: 0.4104716 Test Loss: 0.3993438
Validation loss decreased (0.430452 --> 0.410472).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 5.115646123886108
Epoch: 5, Steps: 30 | Train Loss: 0.4009620 Vali Loss: 0.3977436 Test Loss: 0.3920494
Validation loss decreased (0.410472 --> 0.397744).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 5.736469268798828
Epoch: 6, Steps: 30 | Train Loss: 0.3802115 Vali Loss: 0.3863212 Test Loss: 0.3876875
Validation loss decreased (0.397744 --> 0.386321).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 4.26165509223938
Epoch: 7, Steps: 30 | Train Loss: 0.3634106 Vali Loss: 0.3814069 Test Loss: 0.3850128
Validation loss decreased (0.386321 --> 0.381407).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 5.257834434509277
Epoch: 8, Steps: 30 | Train Loss: 0.3495528 Vali Loss: 0.3733232 Test Loss: 0.3831397
Validation loss decreased (0.381407 --> 0.373323).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 5.109482288360596
Epoch: 9, Steps: 30 | Train Loss: 0.3384802 Vali Loss: 0.3718108 Test Loss: 0.3820089
Validation loss decreased (0.373323 --> 0.371811).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 5.2350006103515625
Epoch: 10, Steps: 30 | Train Loss: 0.3287499 Vali Loss: 0.3675409 Test Loss: 0.3812769
Validation loss decreased (0.371811 --> 0.367541).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 5.4891533851623535
Epoch: 11, Steps: 30 | Train Loss: 0.3195089 Vali Loss: 0.3662044 Test Loss: 0.3806332
Validation loss decreased (0.367541 --> 0.366204).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 5.722556114196777
Epoch: 12, Steps: 30 | Train Loss: 0.3125293 Vali Loss: 0.3617811 Test Loss: 0.3801167
Validation loss decreased (0.366204 --> 0.361781).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 5.643871784210205
Epoch: 13, Steps: 30 | Train Loss: 0.3056239 Vali Loss: 0.3641203 Test Loss: 0.3797908
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 5.334720611572266
Epoch: 14, Steps: 30 | Train Loss: 0.2987112 Vali Loss: 0.3621846 Test Loss: 0.3793187
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 5.302920341491699
Epoch: 15, Steps: 30 | Train Loss: 0.2931779 Vali Loss: 0.3605711 Test Loss: 0.3791382
Validation loss decreased (0.361781 --> 0.360571).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 4.883211612701416
Epoch: 16, Steps: 30 | Train Loss: 0.2872829 Vali Loss: 0.3583120 Test Loss: 0.3788708
Validation loss decreased (0.360571 --> 0.358312).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 5.343577861785889
Epoch: 17, Steps: 30 | Train Loss: 0.2825563 Vali Loss: 0.3572315 Test Loss: 0.3786177
Validation loss decreased (0.358312 --> 0.357232).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 5.00957727432251
Epoch: 18, Steps: 30 | Train Loss: 0.2787606 Vali Loss: 0.3556252 Test Loss: 0.3783566
Validation loss decreased (0.357232 --> 0.355625).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 4.719561815261841
Epoch: 19, Steps: 30 | Train Loss: 0.2741983 Vali Loss: 0.3546827 Test Loss: 0.3781960
Validation loss decreased (0.355625 --> 0.354683).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.938013076782227
Epoch: 20, Steps: 30 | Train Loss: 0.2706460 Vali Loss: 0.3556709 Test Loss: 0.3778863
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 4.945298194885254
Epoch: 21, Steps: 30 | Train Loss: 0.2668878 Vali Loss: 0.3544883 Test Loss: 0.3777090
Validation loss decreased (0.354683 --> 0.354488).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 4.561812162399292
Epoch: 22, Steps: 30 | Train Loss: 0.2633152 Vali Loss: 0.3511226 Test Loss: 0.3774835
Validation loss decreased (0.354488 --> 0.351123).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 4.3593902587890625
Epoch: 23, Steps: 30 | Train Loss: 0.2608519 Vali Loss: 0.3510952 Test Loss: 0.3772873
Validation loss decreased (0.351123 --> 0.351095).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 4.13166356086731
Epoch: 24, Steps: 30 | Train Loss: 0.2580585 Vali Loss: 0.3511462 Test Loss: 0.3771360
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 4.359836101531982
Epoch: 25, Steps: 30 | Train Loss: 0.2557912 Vali Loss: 0.3503644 Test Loss: 0.3769297
Validation loss decreased (0.351095 --> 0.350364).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 4.175247430801392
Epoch: 26, Steps: 30 | Train Loss: 0.2531473 Vali Loss: 0.3487434 Test Loss: 0.3767671
Validation loss decreased (0.350364 --> 0.348743).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 5.33756160736084
Epoch: 27, Steps: 30 | Train Loss: 0.2506311 Vali Loss: 0.3473869 Test Loss: 0.3765294
Validation loss decreased (0.348743 --> 0.347387).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 4.299336671829224
Epoch: 28, Steps: 30 | Train Loss: 0.2485012 Vali Loss: 0.3485134 Test Loss: 0.3763461
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 4.547551870346069
Epoch: 29, Steps: 30 | Train Loss: 0.2466003 Vali Loss: 0.3471653 Test Loss: 0.3761976
Validation loss decreased (0.347387 --> 0.347165).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 5.123324394226074
Epoch: 30, Steps: 30 | Train Loss: 0.2444102 Vali Loss: 0.3474039 Test Loss: 0.3760988
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 4.9741051197052
Epoch: 31, Steps: 30 | Train Loss: 0.2422109 Vali Loss: 0.3464447 Test Loss: 0.3759146
Validation loss decreased (0.347165 --> 0.346445).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 4.95579719543457
Epoch: 32, Steps: 30 | Train Loss: 0.2407796 Vali Loss: 0.3459466 Test Loss: 0.3757941
Validation loss decreased (0.346445 --> 0.345947).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 4.983243227005005
Epoch: 33, Steps: 30 | Train Loss: 0.2393094 Vali Loss: 0.3459909 Test Loss: 0.3756381
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 5.136181592941284
Epoch: 34, Steps: 30 | Train Loss: 0.2375419 Vali Loss: 0.3449045 Test Loss: 0.3754938
Validation loss decreased (0.345947 --> 0.344905).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 4.940417528152466
Epoch: 35, Steps: 30 | Train Loss: 0.2362728 Vali Loss: 0.3450987 Test Loss: 0.3753411
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 4.704060316085815
Epoch: 36, Steps: 30 | Train Loss: 0.2353679 Vali Loss: 0.3443122 Test Loss: 0.3752148
Validation loss decreased (0.344905 --> 0.344312).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 4.8808088302612305
Epoch: 37, Steps: 30 | Train Loss: 0.2335289 Vali Loss: 0.3438583 Test Loss: 0.3751189
Validation loss decreased (0.344312 --> 0.343858).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 5.223098278045654
Epoch: 38, Steps: 30 | Train Loss: 0.2329359 Vali Loss: 0.3433798 Test Loss: 0.3750229
Validation loss decreased (0.343858 --> 0.343380).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 5.3593361377716064
Epoch: 39, Steps: 30 | Train Loss: 0.2314998 Vali Loss: 0.3422644 Test Loss: 0.3749007
Validation loss decreased (0.343380 --> 0.342264).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 5.569631814956665
Epoch: 40, Steps: 30 | Train Loss: 0.2301667 Vali Loss: 0.3432458 Test Loss: 0.3747894
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 5.295145273208618
Epoch: 41, Steps: 30 | Train Loss: 0.2293066 Vali Loss: 0.3432300 Test Loss: 0.3747056
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 4.701030731201172
Epoch: 42, Steps: 30 | Train Loss: 0.2281967 Vali Loss: 0.3436039 Test Loss: 0.3746239
EarlyStopping counter: 3 out of 3
Early stopping
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=196, out_features=248, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  87105536.0
params:  48856.0
Trainable parameters:  48856
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 5.499601125717163
Epoch: 1, Steps: 30 | Train Loss: 0.5691107 Vali Loss: 0.3211774 Test Loss: 0.3618914
Validation loss decreased (inf --> 0.321177).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 5.4131598472595215
Epoch: 2, Steps: 30 | Train Loss: 0.5476272 Vali Loss: 0.3095617 Test Loss: 0.3551700
Validation loss decreased (0.321177 --> 0.309562).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 5.763029098510742
Epoch: 3, Steps: 30 | Train Loss: 0.5333991 Vali Loss: 0.3019756 Test Loss: 0.3519018
Validation loss decreased (0.309562 --> 0.301976).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 5.547317028045654
Epoch: 4, Steps: 30 | Train Loss: 0.5276371 Vali Loss: 0.2964206 Test Loss: 0.3504118
Validation loss decreased (0.301976 --> 0.296421).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 5.50681734085083
Epoch: 5, Steps: 30 | Train Loss: 0.5219727 Vali Loss: 0.2940994 Test Loss: 0.3500874
Validation loss decreased (0.296421 --> 0.294099).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 5.689701557159424
Epoch: 6, Steps: 30 | Train Loss: 0.5175393 Vali Loss: 0.2931502 Test Loss: 0.3498499
Validation loss decreased (0.294099 --> 0.293150).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 5.412316560745239
Epoch: 7, Steps: 30 | Train Loss: 0.5170007 Vali Loss: 0.2895225 Test Loss: 0.3501057
Validation loss decreased (0.293150 --> 0.289522).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 5.451668739318848
Epoch: 8, Steps: 30 | Train Loss: 0.5159912 Vali Loss: 0.2893012 Test Loss: 0.3503478
Validation loss decreased (0.289522 --> 0.289301).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 5.4157068729400635
Epoch: 9, Steps: 30 | Train Loss: 0.5141510 Vali Loss: 0.2875619 Test Loss: 0.3503427
Validation loss decreased (0.289301 --> 0.287562).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 5.605430364608765
Epoch: 10, Steps: 30 | Train Loss: 0.5138298 Vali Loss: 0.2881314 Test Loss: 0.3506143
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 5.348168611526489
Epoch: 11, Steps: 30 | Train Loss: 0.5116855 Vali Loss: 0.2859645 Test Loss: 0.3508132
Validation loss decreased (0.287562 --> 0.285964).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 5.499131917953491
Epoch: 12, Steps: 30 | Train Loss: 0.5128181 Vali Loss: 0.2861628 Test Loss: 0.3510503
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 5.815692901611328
Epoch: 13, Steps: 30 | Train Loss: 0.5125110 Vali Loss: 0.2866332 Test Loss: 0.3512132
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 5.4954705238342285
Epoch: 14, Steps: 30 | Train Loss: 0.5124558 Vali Loss: 0.2851217 Test Loss: 0.3511679
Validation loss decreased (0.285964 --> 0.285122).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 5.437528133392334
Epoch: 15, Steps: 30 | Train Loss: 0.5113046 Vali Loss: 0.2858931 Test Loss: 0.3512785
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 4.808608055114746
Epoch: 16, Steps: 30 | Train Loss: 0.5120147 Vali Loss: 0.2856022 Test Loss: 0.3513943
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 5.5785791873931885
Epoch: 17, Steps: 30 | Train Loss: 0.5121206 Vali Loss: 0.2835768 Test Loss: 0.3515472
Validation loss decreased (0.285122 --> 0.283577).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 4.5950257778167725
Epoch: 18, Steps: 30 | Train Loss: 0.5098630 Vali Loss: 0.2842773 Test Loss: 0.3514988
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 4.741158485412598
Epoch: 19, Steps: 30 | Train Loss: 0.5104153 Vali Loss: 0.2844069 Test Loss: 0.3516457
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.510393381118774
Epoch: 20, Steps: 30 | Train Loss: 0.5112309 Vali Loss: 0.2850232 Test Loss: 0.3516917
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.3306450843811035, mae:0.37425798177719116, rse:0.46112844347953796, corr:[0.26558778 0.26880106 0.26726824 0.26844785 0.26845044 0.26711643
 0.2671067  0.26726484 0.26619428 0.26479363 0.2639397  0.26280218
 0.2611875  0.2598934  0.25924197 0.25887713 0.25839266 0.25785142
 0.25711724 0.25587496 0.2544732  0.25329396 0.2520331  0.2503454
 0.24870671 0.24728015 0.24552138 0.24344425 0.24206713 0.24138719
 0.24027099 0.23838475 0.23696832 0.23631291 0.23522626 0.23345709
 0.23206483 0.23157693 0.23115322 0.2302098  0.22914927 0.22836362
 0.22789043 0.22740719 0.22636907 0.22498949 0.22395971 0.22282664
 0.22080094 0.21842    0.2168404  0.21580505 0.21444654 0.21240842
 0.21043383 0.20918149 0.20744517 0.20507617 0.2035906  0.20268276
 0.20156114 0.20060438 0.20085445 0.2013716  0.20090023 0.20033395
 0.19984272 0.19912817 0.19841395 0.19778132 0.196855   0.19586205
 0.19510897 0.19434087 0.1928956  0.19105749 0.19032323 0.19016446
 0.18936181 0.18799005 0.18767549 0.1875406  0.18693729 0.18663652
 0.18689553 0.18712418 0.18665555 0.18587075 0.18492673 0.18431875
 0.18409033 0.18377107 0.18340342 0.18273939 0.18241    0.18245876
 0.18212274 0.18126398 0.18039943 0.179596   0.17860025 0.17720689
 0.17612691 0.1754276  0.17521119 0.17466055 0.17376502 0.17360315
 0.17366211 0.17341997 0.17245603 0.17175429 0.17133917 0.17127813
 0.17107584 0.17055644 0.16954519 0.16763565 0.16614284 0.16529037
 0.16437732 0.16284963 0.16186403 0.16102868 0.15925379 0.15762001
 0.15764038 0.15752676 0.15581565 0.15391612 0.1536902  0.15333253
 0.1517779  0.15061064 0.15086663 0.15093713 0.14990897 0.1493829
 0.14923841 0.1480403  0.14687517 0.14705414 0.14714395 0.14533354
 0.14311944 0.14236711 0.14135145 0.13919385 0.13780665 0.13749318
 0.13655512 0.13482614 0.13501005 0.1352818  0.1333428  0.13150255
 0.13252155 0.1333005  0.13194661 0.13131973 0.13193694 0.13239188
 0.13199645 0.131892   0.13188879 0.13116227 0.13117497 0.13129172
 0.12973441 0.12687019 0.12638272 0.12671426 0.12518507 0.12244078
 0.12174672 0.12078688 0.11854012 0.11826939 0.11881886 0.11759602
 0.11531416 0.11566157 0.11686105 0.11582392 0.11467142 0.11636601
 0.11639384 0.11442162 0.11655138 0.11667144 0.1141598  0.12551375]
