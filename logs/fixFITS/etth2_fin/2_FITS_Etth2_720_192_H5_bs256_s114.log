Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=512, c_out=7, checkpoints='./checkpoints/', cut_freq=165, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=165, out_features=209, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  123594240.0
params:  34694.0
Trainable parameters:  34694
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.950284719467163
Epoch: 1, Steps: 15 | Train Loss: 0.6910751 Vali Loss: 0.5802646 Test Loss: 0.5643932
Validation loss decreased (inf --> 0.580265).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.098065137863159
Epoch: 2, Steps: 15 | Train Loss: 0.6241544 Vali Loss: 0.5339380 Test Loss: 0.5360119
Validation loss decreased (0.580265 --> 0.533938).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.9820995330810547
Epoch: 3, Steps: 15 | Train Loss: 0.5759868 Vali Loss: 0.5068268 Test Loss: 0.5136850
Validation loss decreased (0.533938 --> 0.506827).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.1558749675750732
Epoch: 4, Steps: 15 | Train Loss: 0.5384182 Vali Loss: 0.4860801 Test Loss: 0.4961680
Validation loss decreased (0.506827 --> 0.486080).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.1544859409332275
Epoch: 5, Steps: 15 | Train Loss: 0.5093849 Vali Loss: 0.4679304 Test Loss: 0.4824111
Validation loss decreased (0.486080 --> 0.467930).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.0378763675689697
Epoch: 6, Steps: 15 | Train Loss: 0.4858072 Vali Loss: 0.4546627 Test Loss: 0.4717029
Validation loss decreased (0.467930 --> 0.454663).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.2462267875671387
Epoch: 7, Steps: 15 | Train Loss: 0.4665063 Vali Loss: 0.4443823 Test Loss: 0.4634059
Validation loss decreased (0.454663 --> 0.444382).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.8890819549560547
Epoch: 8, Steps: 15 | Train Loss: 0.4499544 Vali Loss: 0.4360010 Test Loss: 0.4569196
Validation loss decreased (0.444382 --> 0.436001).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.8468539714813232
Epoch: 9, Steps: 15 | Train Loss: 0.4373653 Vali Loss: 0.4256043 Test Loss: 0.4515750
Validation loss decreased (0.436001 --> 0.425604).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.9091877937316895
Epoch: 10, Steps: 15 | Train Loss: 0.4246702 Vali Loss: 0.4190302 Test Loss: 0.4473235
Validation loss decreased (0.425604 --> 0.419030).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.0567758083343506
Epoch: 11, Steps: 15 | Train Loss: 0.4145092 Vali Loss: 0.4166020 Test Loss: 0.4439557
Validation loss decreased (0.419030 --> 0.416602).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.9983136653900146
Epoch: 12, Steps: 15 | Train Loss: 0.4061193 Vali Loss: 0.4094872 Test Loss: 0.4411944
Validation loss decreased (0.416602 --> 0.409487).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.8576698303222656
Epoch: 13, Steps: 15 | Train Loss: 0.3975440 Vali Loss: 0.4071422 Test Loss: 0.4388269
Validation loss decreased (0.409487 --> 0.407142).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.8293375968933105
Epoch: 14, Steps: 15 | Train Loss: 0.3915200 Vali Loss: 0.4048992 Test Loss: 0.4369948
Validation loss decreased (0.407142 --> 0.404899).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.7632639408111572
Epoch: 15, Steps: 15 | Train Loss: 0.3856606 Vali Loss: 0.4017119 Test Loss: 0.4354316
Validation loss decreased (0.404899 --> 0.401712).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.8249764442443848
Epoch: 16, Steps: 15 | Train Loss: 0.3798398 Vali Loss: 0.3990380 Test Loss: 0.4341184
Validation loss decreased (0.401712 --> 0.399038).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.9030046463012695
Epoch: 17, Steps: 15 | Train Loss: 0.3752063 Vali Loss: 0.3965255 Test Loss: 0.4329530
Validation loss decreased (0.399038 --> 0.396526).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.9207570552825928
Epoch: 18, Steps: 15 | Train Loss: 0.3704392 Vali Loss: 0.3951622 Test Loss: 0.4320658
Validation loss decreased (0.396526 --> 0.395162).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.797551155090332
Epoch: 19, Steps: 15 | Train Loss: 0.3659361 Vali Loss: 0.3927800 Test Loss: 0.4312527
Validation loss decreased (0.395162 --> 0.392780).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.7901151180267334
Epoch: 20, Steps: 15 | Train Loss: 0.3620564 Vali Loss: 0.3916581 Test Loss: 0.4305771
Validation loss decreased (0.392780 --> 0.391658).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.8660480976104736
Epoch: 21, Steps: 15 | Train Loss: 0.3589361 Vali Loss: 0.3896602 Test Loss: 0.4299717
Validation loss decreased (0.391658 --> 0.389660).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.8028957843780518
Epoch: 22, Steps: 15 | Train Loss: 0.3557526 Vali Loss: 0.3897681 Test Loss: 0.4294734
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.8243720531463623
Epoch: 23, Steps: 15 | Train Loss: 0.3536866 Vali Loss: 0.3881293 Test Loss: 0.4290122
Validation loss decreased (0.389660 --> 0.388129).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.742107629776001
Epoch: 24, Steps: 15 | Train Loss: 0.3500092 Vali Loss: 0.3882678 Test Loss: 0.4286137
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.9165985584259033
Epoch: 25, Steps: 15 | Train Loss: 0.3473833 Vali Loss: 0.3855906 Test Loss: 0.4283080
Validation loss decreased (0.388129 --> 0.385591).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.4373345375061035
Epoch: 26, Steps: 15 | Train Loss: 0.3446778 Vali Loss: 0.3856245 Test Loss: 0.4279883
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.852529287338257
Epoch: 27, Steps: 15 | Train Loss: 0.3425714 Vali Loss: 0.3834880 Test Loss: 0.4277285
Validation loss decreased (0.385591 --> 0.383488).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.272883892059326
Epoch: 28, Steps: 15 | Train Loss: 0.3407810 Vali Loss: 0.3830069 Test Loss: 0.4275092
Validation loss decreased (0.383488 --> 0.383007).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.1634368896484375
Epoch: 29, Steps: 15 | Train Loss: 0.3388252 Vali Loss: 0.3815415 Test Loss: 0.4272937
Validation loss decreased (0.383007 --> 0.381541).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.746502161026001
Epoch: 30, Steps: 15 | Train Loss: 0.3372816 Vali Loss: 0.3818815 Test Loss: 0.4271004
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.8156895637512207
Epoch: 31, Steps: 15 | Train Loss: 0.3354487 Vali Loss: 0.3812231 Test Loss: 0.4269350
Validation loss decreased (0.381541 --> 0.381223).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.8215527534484863
Epoch: 32, Steps: 15 | Train Loss: 0.3338266 Vali Loss: 0.3814588 Test Loss: 0.4268006
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.9668378829956055
Epoch: 33, Steps: 15 | Train Loss: 0.3321011 Vali Loss: 0.3795116 Test Loss: 0.4266230
Validation loss decreased (0.381223 --> 0.379512).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 2.8777217864990234
Epoch: 34, Steps: 15 | Train Loss: 0.3301945 Vali Loss: 0.3813733 Test Loss: 0.4264959
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.9451634883880615
Epoch: 35, Steps: 15 | Train Loss: 0.3298018 Vali Loss: 0.3803902 Test Loss: 0.4264017
EarlyStopping counter: 2 out of 3
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.8153977394104004
Epoch: 36, Steps: 15 | Train Loss: 0.3281011 Vali Loss: 0.3773715 Test Loss: 0.4262985
Validation loss decreased (0.379512 --> 0.377371).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.6926627159118652
Epoch: 37, Steps: 15 | Train Loss: 0.3269832 Vali Loss: 0.3785630 Test Loss: 0.4262142
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.862673759460449
Epoch: 38, Steps: 15 | Train Loss: 0.3253636 Vali Loss: 0.3784103 Test Loss: 0.4261189
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.8588051795959473
Epoch: 39, Steps: 15 | Train Loss: 0.3250428 Vali Loss: 0.3769002 Test Loss: 0.4260455
Validation loss decreased (0.377371 --> 0.376900).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.799325942993164
Epoch: 40, Steps: 15 | Train Loss: 0.3238755 Vali Loss: 0.3765574 Test Loss: 0.4259718
Validation loss decreased (0.376900 --> 0.376557).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 3.0132768154144287
Epoch: 41, Steps: 15 | Train Loss: 0.3226797 Vali Loss: 0.3768210 Test Loss: 0.4259187
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.6974353790283203
Epoch: 42, Steps: 15 | Train Loss: 0.3217725 Vali Loss: 0.3774721 Test Loss: 0.4258611
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 2.765821695327759
Epoch: 43, Steps: 15 | Train Loss: 0.3208298 Vali Loss: 0.3767142 Test Loss: 0.4258045
EarlyStopping counter: 3 out of 3
Early stopping
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=165, out_features=209, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  123594240.0
params:  34694.0
Trainable parameters:  34694
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.909960985183716
Epoch: 1, Steps: 15 | Train Loss: 0.6017987 Vali Loss: 0.3567989 Test Loss: 0.4140263
Validation loss decreased (inf --> 0.356799).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.5005083084106445
Epoch: 2, Steps: 15 | Train Loss: 0.5843758 Vali Loss: 0.3438089 Test Loss: 0.4064898
Validation loss decreased (0.356799 --> 0.343809).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.198190212249756
Epoch: 3, Steps: 15 | Train Loss: 0.5712539 Vali Loss: 0.3339772 Test Loss: 0.4012253
Validation loss decreased (0.343809 --> 0.333977).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.5767836570739746
Epoch: 4, Steps: 15 | Train Loss: 0.5622568 Vali Loss: 0.3282574 Test Loss: 0.3975703
Validation loss decreased (0.333977 --> 0.328257).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.6421384811401367
Epoch: 5, Steps: 15 | Train Loss: 0.5531236 Vali Loss: 0.3230488 Test Loss: 0.3948188
Validation loss decreased (0.328257 --> 0.323049).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.350257158279419
Epoch: 6, Steps: 15 | Train Loss: 0.5482246 Vali Loss: 0.3195904 Test Loss: 0.3929380
Validation loss decreased (0.323049 --> 0.319590).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.418813705444336
Epoch: 7, Steps: 15 | Train Loss: 0.5441294 Vali Loss: 0.3158605 Test Loss: 0.3915592
Validation loss decreased (0.319590 --> 0.315860).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.622036933898926
Epoch: 8, Steps: 15 | Train Loss: 0.5404499 Vali Loss: 0.3125575 Test Loss: 0.3904523
Validation loss decreased (0.315860 --> 0.312558).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.6013381481170654
Epoch: 9, Steps: 15 | Train Loss: 0.5382417 Vali Loss: 0.3097364 Test Loss: 0.3895551
Validation loss decreased (0.312558 --> 0.309736).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.456874132156372
Epoch: 10, Steps: 15 | Train Loss: 0.5358504 Vali Loss: 0.3067421 Test Loss: 0.3890493
Validation loss decreased (0.309736 --> 0.306742).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.6243579387664795
Epoch: 11, Steps: 15 | Train Loss: 0.5328905 Vali Loss: 0.3071171 Test Loss: 0.3885107
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.7264182567596436
Epoch: 12, Steps: 15 | Train Loss: 0.5307248 Vali Loss: 0.3054065 Test Loss: 0.3881043
Validation loss decreased (0.306742 --> 0.305407).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.6202902793884277
Epoch: 13, Steps: 15 | Train Loss: 0.5290254 Vali Loss: 0.3034149 Test Loss: 0.3878239
Validation loss decreased (0.305407 --> 0.303415).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.7819972038269043
Epoch: 14, Steps: 15 | Train Loss: 0.5288627 Vali Loss: 0.3038942 Test Loss: 0.3875849
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.490048408508301
Epoch: 15, Steps: 15 | Train Loss: 0.5285543 Vali Loss: 0.3004085 Test Loss: 0.3874709
Validation loss decreased (0.303415 --> 0.300408).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.290187358856201
Epoch: 16, Steps: 15 | Train Loss: 0.5257064 Vali Loss: 0.3009781 Test Loss: 0.3873223
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.958606719970703
Epoch: 17, Steps: 15 | Train Loss: 0.5256105 Vali Loss: 0.3007961 Test Loss: 0.3871727
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.7770297527313232
Epoch: 18, Steps: 15 | Train Loss: 0.5243950 Vali Loss: 0.2980959 Test Loss: 0.3870918
Validation loss decreased (0.300408 --> 0.298096).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.8464691638946533
Epoch: 19, Steps: 15 | Train Loss: 0.5237732 Vali Loss: 0.2994049 Test Loss: 0.3870262
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.7170212268829346
Epoch: 20, Steps: 15 | Train Loss: 0.5236506 Vali Loss: 0.2988992 Test Loss: 0.3869833
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.672468900680542
Epoch: 21, Steps: 15 | Train Loss: 0.5239800 Vali Loss: 0.2959649 Test Loss: 0.3869765
Validation loss decreased (0.298096 --> 0.295965).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.211531162261963
Epoch: 22, Steps: 15 | Train Loss: 0.5208353 Vali Loss: 0.2986600 Test Loss: 0.3869329
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.3192615509033203
Epoch: 23, Steps: 15 | Train Loss: 0.5223130 Vali Loss: 0.2970441 Test Loss: 0.3869427
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.7045812606811523
Epoch: 24, Steps: 15 | Train Loss: 0.5216388 Vali Loss: 0.2968605 Test Loss: 0.3869170
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.3284686207771301, mae:0.37469953298568726, rse:0.4596082270145416, corr:[0.26377675 0.27037466 0.268501   0.2680169  0.26923853 0.26933354
 0.2681648  0.26747844 0.2672016  0.2664364  0.2650788  0.26359165
 0.26243228 0.26155192 0.2606576  0.25984484 0.25918686 0.25863126
 0.2577513  0.25640833 0.2549861  0.2537969  0.2525184  0.25077912
 0.24892257 0.24731937 0.2459616  0.24435121 0.24261667 0.24112481
 0.24012211 0.23898555 0.23768544 0.23637222 0.23532625 0.23438276
 0.23325427 0.23206957 0.23104872 0.23025976 0.22961107 0.22895268
 0.22818446 0.22730981 0.22634618 0.2253397  0.2242126  0.22259495
 0.22061618 0.21870172 0.21718404 0.215946   0.21481802 0.21316545
 0.21081136 0.20886867 0.20742399 0.20575407 0.20397112 0.20267439
 0.20226152 0.20194197 0.2015104  0.20125143 0.20101959 0.20074762
 0.1998953  0.19883296 0.19830664 0.19804186 0.19719441 0.19593492
 0.19486131 0.19406751 0.19289449 0.19112927 0.1900476  0.18987659
 0.1895975  0.18840623 0.18746622 0.18711443 0.18693775 0.18638788
 0.18561983 0.18532176 0.18531911 0.18510981 0.18438557 0.18383093
 0.18364023 0.18325052 0.18286222 0.18249574 0.18235345 0.18212833
 0.18128078 0.18015827 0.17943418 0.17896539 0.17809336 0.17672303
 0.17583874 0.17548561 0.17519079 0.17429592 0.17333037 0.17332092
 0.17339455 0.17290355 0.17177674 0.17101724 0.17065382 0.17041151
 0.16964796 0.16861042 0.16805848 0.16750568 0.16653821 0.16489018
 0.16331479 0.16187851 0.16063744 0.15944839 0.15837532 0.15752976
 0.15664229 0.15532564 0.15430903 0.15393397 0.15367696 0.15255758
 0.1512755  0.15064481 0.15047273 0.14995843 0.14878234 0.14784166
 0.14753479 0.14731543 0.14676853 0.14602007 0.14539146 0.14430007
 0.14215194 0.1397619  0.13807677 0.13709638 0.13619232 0.13516593
 0.13453455 0.13374773 0.13309257 0.13227805 0.13152204 0.13110442
 0.1311968  0.13090062 0.13022247 0.13013323 0.13030751 0.13059953
 0.13016197 0.12901966 0.12832281 0.1284437  0.12877092 0.1278271
 0.12604985 0.12436373 0.12379735 0.12318039 0.12208913 0.12013678
 0.11862595 0.11734056 0.11630823 0.11563065 0.11429225 0.1131971
 0.11227973 0.1118724  0.11224049 0.11241148 0.11050644 0.10869805
 0.10860112 0.10777842 0.10471842 0.10160241 0.10667747 0.1132469 ]
