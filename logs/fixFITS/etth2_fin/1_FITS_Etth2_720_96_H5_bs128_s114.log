Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=165, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=165, out_features=187, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  55292160.0
params:  31042.0
Trainable parameters:  31042
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 5.990447759628296
Epoch: 1, Steps: 30 | Train Loss: 0.6625396 Vali Loss: 0.3289418 Test Loss: 0.3321380
Validation loss decreased (inf --> 0.328942).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 5.923131704330444
Epoch: 2, Steps: 30 | Train Loss: 0.5086639 Vali Loss: 0.2808061 Test Loss: 0.2996632
Validation loss decreased (0.328942 --> 0.280806).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 5.49130916595459
Epoch: 3, Steps: 30 | Train Loss: 0.4781654 Vali Loss: 0.2641088 Test Loss: 0.2899031
Validation loss decreased (0.280806 --> 0.264109).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 5.6344733238220215
Epoch: 4, Steps: 30 | Train Loss: 0.4628216 Vali Loss: 0.2553265 Test Loss: 0.2853164
Validation loss decreased (0.264109 --> 0.255326).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 6.0034499168396
Epoch: 5, Steps: 30 | Train Loss: 0.4504471 Vali Loss: 0.2501869 Test Loss: 0.2830353
Validation loss decreased (0.255326 --> 0.250187).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 6.00341010093689
Epoch: 6, Steps: 30 | Train Loss: 0.4452790 Vali Loss: 0.2450394 Test Loss: 0.2814359
Validation loss decreased (0.250187 --> 0.245039).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 5.746965169906616
Epoch: 7, Steps: 30 | Train Loss: 0.4393172 Vali Loss: 0.2407267 Test Loss: 0.2805024
Validation loss decreased (0.245039 --> 0.240727).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 5.6051576137542725
Epoch: 8, Steps: 30 | Train Loss: 0.4349660 Vali Loss: 0.2380535 Test Loss: 0.2797049
Validation loss decreased (0.240727 --> 0.238053).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 5.547462224960327
Epoch: 9, Steps: 30 | Train Loss: 0.4293906 Vali Loss: 0.2374676 Test Loss: 0.2790940
Validation loss decreased (0.238053 --> 0.237468).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 5.581508159637451
Epoch: 10, Steps: 30 | Train Loss: 0.4294435 Vali Loss: 0.2352577 Test Loss: 0.2786951
Validation loss decreased (0.237468 --> 0.235258).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 5.899736404418945
Epoch: 11, Steps: 30 | Train Loss: 0.4265033 Vali Loss: 0.2326995 Test Loss: 0.2783422
Validation loss decreased (0.235258 --> 0.232700).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 6.078310012817383
Epoch: 12, Steps: 30 | Train Loss: 0.4241739 Vali Loss: 0.2317078 Test Loss: 0.2779564
Validation loss decreased (0.232700 --> 0.231708).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 5.766418218612671
Epoch: 13, Steps: 30 | Train Loss: 0.4226909 Vali Loss: 0.2310818 Test Loss: 0.2775707
Validation loss decreased (0.231708 --> 0.231082).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 5.639458179473877
Epoch: 14, Steps: 30 | Train Loss: 0.4198145 Vali Loss: 0.2286085 Test Loss: 0.2773843
Validation loss decreased (0.231082 --> 0.228609).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 4.975151777267456
Epoch: 15, Steps: 30 | Train Loss: 0.4182533 Vali Loss: 0.2276165 Test Loss: 0.2772639
Validation loss decreased (0.228609 --> 0.227616).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 4.659379720687866
Epoch: 16, Steps: 30 | Train Loss: 0.4167574 Vali Loss: 0.2274952 Test Loss: 0.2770045
Validation loss decreased (0.227616 --> 0.227495).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 4.754096031188965
Epoch: 17, Steps: 30 | Train Loss: 0.4188966 Vali Loss: 0.2288107 Test Loss: 0.2768523
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 4.824230909347534
Epoch: 18, Steps: 30 | Train Loss: 0.4159767 Vali Loss: 0.2258526 Test Loss: 0.2768003
Validation loss decreased (0.227495 --> 0.225853).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 4.572996139526367
Epoch: 19, Steps: 30 | Train Loss: 0.4138652 Vali Loss: 0.2252457 Test Loss: 0.2765115
Validation loss decreased (0.225853 --> 0.225246).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.668350458145142
Epoch: 20, Steps: 30 | Train Loss: 0.4142586 Vali Loss: 0.2250034 Test Loss: 0.2763800
Validation loss decreased (0.225246 --> 0.225003).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 4.421095609664917
Epoch: 21, Steps: 30 | Train Loss: 0.4154755 Vali Loss: 0.2241334 Test Loss: 0.2762824
Validation loss decreased (0.225003 --> 0.224133).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.623101234436035
Epoch: 22, Steps: 30 | Train Loss: 0.4142313 Vali Loss: 0.2234271 Test Loss: 0.2762288
Validation loss decreased (0.224133 --> 0.223427).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.4728200435638428
Epoch: 23, Steps: 30 | Train Loss: 0.4126701 Vali Loss: 0.2235183 Test Loss: 0.2761239
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 4.677244186401367
Epoch: 24, Steps: 30 | Train Loss: 0.4123625 Vali Loss: 0.2228815 Test Loss: 0.2760322
Validation loss decreased (0.223427 --> 0.222882).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 5.082948684692383
Epoch: 25, Steps: 30 | Train Loss: 0.4130889 Vali Loss: 0.2224002 Test Loss: 0.2760067
Validation loss decreased (0.222882 --> 0.222400).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 5.385366916656494
Epoch: 26, Steps: 30 | Train Loss: 0.4097554 Vali Loss: 0.2225735 Test Loss: 0.2758960
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 5.054820537567139
Epoch: 27, Steps: 30 | Train Loss: 0.4113002 Vali Loss: 0.2227292 Test Loss: 0.2758805
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 4.927002429962158
Epoch: 28, Steps: 30 | Train Loss: 0.4109259 Vali Loss: 0.2213484 Test Loss: 0.2758335
Validation loss decreased (0.222400 --> 0.221348).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 5.03010106086731
Epoch: 29, Steps: 30 | Train Loss: 0.4114549 Vali Loss: 0.2229945 Test Loss: 0.2757549
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 5.0116496086120605
Epoch: 30, Steps: 30 | Train Loss: 0.4107317 Vali Loss: 0.2220365 Test Loss: 0.2757204
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 4.929494619369507
Epoch: 31, Steps: 30 | Train Loss: 0.4121242 Vali Loss: 0.2214278 Test Loss: 0.2755995
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.27362382411956787, mae:0.33950841426849365, rse:0.4215588867664337, corr:[0.27050623 0.27675322 0.2750203  0.2741944  0.2748861  0.27460867
 0.27304974 0.27216193 0.27156344 0.27043316 0.26872393 0.26719588
 0.26602185 0.26503155 0.26409674 0.26339516 0.26287404 0.26232344
 0.2613626  0.26005438 0.25877655 0.25772277 0.25643906 0.25464144
 0.25272068 0.2511563  0.24990039 0.2484733  0.24686262 0.24532177
 0.24405986 0.24283466 0.24151672 0.24022622 0.23900853 0.23791222
 0.23682956 0.23575968 0.2348171  0.23396835 0.23312184 0.23227766
 0.23152012 0.23088612 0.23027955 0.22947411 0.22828637 0.22654963
 0.22452709 0.22268985 0.22136776 0.22020772 0.2191855  0.21784484
 0.21597147 0.21429698 0.21269685 0.21089321 0.20920774 0.20823221
 0.20794564 0.20754993 0.20707819 0.20706756 0.20712842 0.20721363
 0.20663731 0.20552093 0.20467411 0.20435424 0.20394135 0.20321855
 0.20228346 0.20129108 0.20029825 0.19870591 0.19743194 0.19679607
 0.19670169 0.19594635 0.19523123 0.19471593 0.19434224 0.19421549
 0.19384952 0.19354935 0.19357227 0.19387433 0.19276974 0.19126725
 0.19074789 0.19091694 0.19009031 0.18745042 0.1874094  0.18945085]
