Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=165, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=165, out_features=209, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  61797120.0
params:  34694.0
Trainable parameters:  34694
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 4.9711973667144775
Epoch: 1, Steps: 30 | Train Loss: 0.6590896 Vali Loss: 0.5397043 Test Loss: 0.4823817
Validation loss decreased (inf --> 0.539704).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 5.094455242156982
Epoch: 2, Steps: 30 | Train Loss: 0.5580420 Vali Loss: 0.4845076 Test Loss: 0.4453785
Validation loss decreased (0.539704 --> 0.484508).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 4.789459943771362
Epoch: 3, Steps: 30 | Train Loss: 0.4949078 Vali Loss: 0.4499181 Test Loss: 0.4214270
Validation loss decreased (0.484508 --> 0.449918).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 5.229740142822266
Epoch: 4, Steps: 30 | Train Loss: 0.4513379 Vali Loss: 0.4264225 Test Loss: 0.4070904
Validation loss decreased (0.449918 --> 0.426423).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 5.0172953605651855
Epoch: 5, Steps: 30 | Train Loss: 0.4208075 Vali Loss: 0.4145695 Test Loss: 0.3978681
Validation loss decreased (0.426423 --> 0.414570).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 5.172864198684692
Epoch: 6, Steps: 30 | Train Loss: 0.3978363 Vali Loss: 0.4034350 Test Loss: 0.3919354
Validation loss decreased (0.414570 --> 0.403435).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 4.973302602767944
Epoch: 7, Steps: 30 | Train Loss: 0.3788284 Vali Loss: 0.3969368 Test Loss: 0.3881528
Validation loss decreased (0.403435 --> 0.396937).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 4.9260008335113525
Epoch: 8, Steps: 30 | Train Loss: 0.3644475 Vali Loss: 0.3907953 Test Loss: 0.3854731
Validation loss decreased (0.396937 --> 0.390795).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.744231462478638
Epoch: 9, Steps: 30 | Train Loss: 0.3519371 Vali Loss: 0.3837277 Test Loss: 0.3836348
Validation loss decreased (0.390795 --> 0.383728).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 4.736074686050415
Epoch: 10, Steps: 30 | Train Loss: 0.3410396 Vali Loss: 0.3803508 Test Loss: 0.3823316
Validation loss decreased (0.383728 --> 0.380351).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 4.922427177429199
Epoch: 11, Steps: 30 | Train Loss: 0.3323636 Vali Loss: 0.3781269 Test Loss: 0.3812833
Validation loss decreased (0.380351 --> 0.378127).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 4.946894884109497
Epoch: 12, Steps: 30 | Train Loss: 0.3233662 Vali Loss: 0.3751044 Test Loss: 0.3805309
Validation loss decreased (0.378127 --> 0.375104).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 5.325606346130371
Epoch: 13, Steps: 30 | Train Loss: 0.3163218 Vali Loss: 0.3737901 Test Loss: 0.3799110
Validation loss decreased (0.375104 --> 0.373790).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 5.0136847496032715
Epoch: 14, Steps: 30 | Train Loss: 0.3095577 Vali Loss: 0.3709668 Test Loss: 0.3793743
Validation loss decreased (0.373790 --> 0.370967).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 4.826029062271118
Epoch: 15, Steps: 30 | Train Loss: 0.3029879 Vali Loss: 0.3687816 Test Loss: 0.3789626
Validation loss decreased (0.370967 --> 0.368782).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 4.633059024810791
Epoch: 16, Steps: 30 | Train Loss: 0.2979361 Vali Loss: 0.3673348 Test Loss: 0.3786462
Validation loss decreased (0.368782 --> 0.367335).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 4.5076165199279785
Epoch: 17, Steps: 30 | Train Loss: 0.2928203 Vali Loss: 0.3653459 Test Loss: 0.3782613
Validation loss decreased (0.367335 --> 0.365346).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 4.483247995376587
Epoch: 18, Steps: 30 | Train Loss: 0.2884051 Vali Loss: 0.3652232 Test Loss: 0.3780417
Validation loss decreased (0.365346 --> 0.365223).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 4.6308441162109375
Epoch: 19, Steps: 30 | Train Loss: 0.2839130 Vali Loss: 0.3624103 Test Loss: 0.3777787
Validation loss decreased (0.365223 --> 0.362410).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.784247159957886
Epoch: 20, Steps: 30 | Train Loss: 0.2801049 Vali Loss: 0.3633218 Test Loss: 0.3775427
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.37864089012146
Epoch: 21, Steps: 30 | Train Loss: 0.2762553 Vali Loss: 0.3604431 Test Loss: 0.3773045
Validation loss decreased (0.362410 --> 0.360443).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 4.966069936752319
Epoch: 22, Steps: 30 | Train Loss: 0.2727359 Vali Loss: 0.3608353 Test Loss: 0.3771430
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 4.7177574634552
Epoch: 23, Steps: 30 | Train Loss: 0.2699395 Vali Loss: 0.3602566 Test Loss: 0.3768652
Validation loss decreased (0.360443 --> 0.360257).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 4.877843856811523
Epoch: 24, Steps: 30 | Train Loss: 0.2672121 Vali Loss: 0.3585631 Test Loss: 0.3766665
Validation loss decreased (0.360257 --> 0.358563).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 4.7584147453308105
Epoch: 25, Steps: 30 | Train Loss: 0.2641459 Vali Loss: 0.3579454 Test Loss: 0.3765309
Validation loss decreased (0.358563 --> 0.357945).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 4.68206262588501
Epoch: 26, Steps: 30 | Train Loss: 0.2617173 Vali Loss: 0.3591896 Test Loss: 0.3763245
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 4.783444166183472
Epoch: 27, Steps: 30 | Train Loss: 0.2591176 Vali Loss: 0.3580387 Test Loss: 0.3761609
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 4.783077716827393
Epoch: 28, Steps: 30 | Train Loss: 0.2573933 Vali Loss: 0.3570008 Test Loss: 0.3760679
Validation loss decreased (0.357945 --> 0.357001).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 4.75257420539856
Epoch: 29, Steps: 30 | Train Loss: 0.2548624 Vali Loss: 0.3543431 Test Loss: 0.3758473
Validation loss decreased (0.357001 --> 0.354343).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 5.0293591022491455
Epoch: 30, Steps: 30 | Train Loss: 0.2525312 Vali Loss: 0.3556295 Test Loss: 0.3757349
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 5.098711013793945
Epoch: 31, Steps: 30 | Train Loss: 0.2511678 Vali Loss: 0.3544358 Test Loss: 0.3755863
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 5.0688135623931885
Epoch: 32, Steps: 30 | Train Loss: 0.2494278 Vali Loss: 0.3539977 Test Loss: 0.3754486
Validation loss decreased (0.354343 --> 0.353998).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 4.957793235778809
Epoch: 33, Steps: 30 | Train Loss: 0.2482991 Vali Loss: 0.3543814 Test Loss: 0.3753407
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 4.696460008621216
Epoch: 34, Steps: 30 | Train Loss: 0.2461417 Vali Loss: 0.3530493 Test Loss: 0.3752414
Validation loss decreased (0.353998 --> 0.353049).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 5.005934238433838
Epoch: 35, Steps: 30 | Train Loss: 0.2449214 Vali Loss: 0.3516595 Test Loss: 0.3750920
Validation loss decreased (0.353049 --> 0.351659).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 5.129049777984619
Epoch: 36, Steps: 30 | Train Loss: 0.2435902 Vali Loss: 0.3524278 Test Loss: 0.3749910
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 4.741794586181641
Epoch: 37, Steps: 30 | Train Loss: 0.2424098 Vali Loss: 0.3514198 Test Loss: 0.3748601
Validation loss decreased (0.351659 --> 0.351420).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 4.625930547714233
Epoch: 38, Steps: 30 | Train Loss: 0.2407566 Vali Loss: 0.3514566 Test Loss: 0.3747483
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 5.006832838058472
Epoch: 39, Steps: 30 | Train Loss: 0.2403087 Vali Loss: 0.3505020 Test Loss: 0.3746814
Validation loss decreased (0.351420 --> 0.350502).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 4.795088052749634
Epoch: 40, Steps: 30 | Train Loss: 0.2388512 Vali Loss: 0.3504715 Test Loss: 0.3746051
Validation loss decreased (0.350502 --> 0.350471).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 5.11643123626709
Epoch: 41, Steps: 30 | Train Loss: 0.2377528 Vali Loss: 0.3504432 Test Loss: 0.3745221
Validation loss decreased (0.350471 --> 0.350443).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 4.795766592025757
Epoch: 42, Steps: 30 | Train Loss: 0.2371188 Vali Loss: 0.3512608 Test Loss: 0.3744262
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 4.761904716491699
Epoch: 43, Steps: 30 | Train Loss: 0.2359388 Vali Loss: 0.3490052 Test Loss: 0.3743455
Validation loss decreased (0.350443 --> 0.349005).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 4.195249795913696
Epoch: 44, Steps: 30 | Train Loss: 0.2354958 Vali Loss: 0.3503509 Test Loss: 0.3742760
EarlyStopping counter: 1 out of 3
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 4.329198122024536
Epoch: 45, Steps: 30 | Train Loss: 0.2341690 Vali Loss: 0.3485680 Test Loss: 0.3741628
Validation loss decreased (0.349005 --> 0.348568).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 3.6829726696014404
Epoch: 46, Steps: 30 | Train Loss: 0.2334835 Vali Loss: 0.3476176 Test Loss: 0.3741049
Validation loss decreased (0.348568 --> 0.347618).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 3.870417356491089
Epoch: 47, Steps: 30 | Train Loss: 0.2329640 Vali Loss: 0.3471492 Test Loss: 0.3740449
Validation loss decreased (0.347618 --> 0.347149).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 3.818885087966919
Epoch: 48, Steps: 30 | Train Loss: 0.2320336 Vali Loss: 0.3484602 Test Loss: 0.3739910
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 5.062084197998047
Epoch: 49, Steps: 30 | Train Loss: 0.2314729 Vali Loss: 0.3493917 Test Loss: 0.3739357
EarlyStopping counter: 2 out of 3
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 5.005547523498535
Epoch: 50, Steps: 30 | Train Loss: 0.2312365 Vali Loss: 0.3469025 Test Loss: 0.3738586
Validation loss decreased (0.347149 --> 0.346902).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=165, out_features=209, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  61797120.0
params:  34694.0
Trainable parameters:  34694
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 5.239989757537842
Epoch: 1, Steps: 30 | Train Loss: 0.5717335 Vali Loss: 0.3256814 Test Loss: 0.3613585
Validation loss decreased (inf --> 0.325681).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.876410484313965
Epoch: 2, Steps: 30 | Train Loss: 0.5510492 Vali Loss: 0.3122801 Test Loss: 0.3549506
Validation loss decreased (0.325681 --> 0.312280).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 5.1903910636901855
Epoch: 3, Steps: 30 | Train Loss: 0.5367514 Vali Loss: 0.3047433 Test Loss: 0.3519359
Validation loss decreased (0.312280 --> 0.304743).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 5.086668014526367
Epoch: 4, Steps: 30 | Train Loss: 0.5283051 Vali Loss: 0.3005579 Test Loss: 0.3505361
Validation loss decreased (0.304743 --> 0.300558).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 5.173696756362915
Epoch: 5, Steps: 30 | Train Loss: 0.5254034 Vali Loss: 0.2958798 Test Loss: 0.3500331
Validation loss decreased (0.300558 --> 0.295880).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 5.434863567352295
Epoch: 6, Steps: 30 | Train Loss: 0.5229814 Vali Loss: 0.2953878 Test Loss: 0.3499809
Validation loss decreased (0.295880 --> 0.295388).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 5.224581718444824
Epoch: 7, Steps: 30 | Train Loss: 0.5186597 Vali Loss: 0.2923099 Test Loss: 0.3500789
Validation loss decreased (0.295388 --> 0.292310).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 5.295259952545166
Epoch: 8, Steps: 30 | Train Loss: 0.5184973 Vali Loss: 0.2915016 Test Loss: 0.3503985
Validation loss decreased (0.292310 --> 0.291502).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 5.01334547996521
Epoch: 9, Steps: 30 | Train Loss: 0.5169289 Vali Loss: 0.2909250 Test Loss: 0.3505557
Validation loss decreased (0.291502 --> 0.290925).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 4.898739814758301
Epoch: 10, Steps: 30 | Train Loss: 0.5161997 Vali Loss: 0.2892271 Test Loss: 0.3507851
Validation loss decreased (0.290925 --> 0.289227).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 5.0716872215271
Epoch: 11, Steps: 30 | Train Loss: 0.5154925 Vali Loss: 0.2892402 Test Loss: 0.3510084
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 5.099243640899658
Epoch: 12, Steps: 30 | Train Loss: 0.5145298 Vali Loss: 0.2889940 Test Loss: 0.3511931
Validation loss decreased (0.289227 --> 0.288994).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 5.376932859420776
Epoch: 13, Steps: 30 | Train Loss: 0.5136078 Vali Loss: 0.2884546 Test Loss: 0.3513378
Validation loss decreased (0.288994 --> 0.288455).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 5.295808553695679
Epoch: 14, Steps: 30 | Train Loss: 0.5139986 Vali Loss: 0.2870371 Test Loss: 0.3513845
Validation loss decreased (0.288455 --> 0.287037).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 5.2708024978637695
Epoch: 15, Steps: 30 | Train Loss: 0.5118571 Vali Loss: 0.2875085 Test Loss: 0.3515335
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 4.897021770477295
Epoch: 16, Steps: 30 | Train Loss: 0.5141731 Vali Loss: 0.2871472 Test Loss: 0.3516169
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 5.0339014530181885
Epoch: 17, Steps: 30 | Train Loss: 0.5109481 Vali Loss: 0.2861010 Test Loss: 0.3517682
Validation loss decreased (0.287037 --> 0.286101).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 4.657118320465088
Epoch: 18, Steps: 30 | Train Loss: 0.5126822 Vali Loss: 0.2862011 Test Loss: 0.3517396
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 4.913609981536865
Epoch: 19, Steps: 30 | Train Loss: 0.5115047 Vali Loss: 0.2859577 Test Loss: 0.3518387
Validation loss decreased (0.286101 --> 0.285958).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.801555395126343
Epoch: 20, Steps: 30 | Train Loss: 0.5109074 Vali Loss: 0.2865198 Test Loss: 0.3518354
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 5.3699023723602295
Epoch: 21, Steps: 30 | Train Loss: 0.5126243 Vali Loss: 0.2856168 Test Loss: 0.3519688
Validation loss decreased (0.285958 --> 0.285617).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 5.352545976638794
Epoch: 22, Steps: 30 | Train Loss: 0.5108067 Vali Loss: 0.2845380 Test Loss: 0.3519511
Validation loss decreased (0.285617 --> 0.284538).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 5.207186460494995
Epoch: 23, Steps: 30 | Train Loss: 0.5118791 Vali Loss: 0.2850043 Test Loss: 0.3520570
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 5.2783215045928955
Epoch: 24, Steps: 30 | Train Loss: 0.5124188 Vali Loss: 0.2831803 Test Loss: 0.3521533
Validation loss decreased (0.284538 --> 0.283180).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 5.011838674545288
Epoch: 25, Steps: 30 | Train Loss: 0.5115842 Vali Loss: 0.2848986 Test Loss: 0.3521219
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 5.038846254348755
Epoch: 26, Steps: 30 | Train Loss: 0.5117708 Vali Loss: 0.2817573 Test Loss: 0.3521816
Validation loss decreased (0.283180 --> 0.281757).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 4.9883623123168945
Epoch: 27, Steps: 30 | Train Loss: 0.5112309 Vali Loss: 0.2846746 Test Loss: 0.3521723
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 5.150128602981567
Epoch: 28, Steps: 30 | Train Loss: 0.5098122 Vali Loss: 0.2842835 Test Loss: 0.3521415
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 4.432592868804932
Epoch: 29, Steps: 30 | Train Loss: 0.5099985 Vali Loss: 0.2840296 Test Loss: 0.3521855
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.33132192492485046, mae:0.3746475279331207, rse:0.4616001546382904, corr:[0.2650598  0.26839566 0.26691142 0.266922   0.2673767  0.26688287
 0.26598403 0.26564    0.26535004 0.2642163  0.2626637  0.2613405
 0.26040027 0.25955936 0.25859582 0.25801095 0.25776204 0.2573825
 0.25629985 0.25495785 0.25388655 0.25292206 0.25149262 0.24952774
 0.24762747 0.2460309  0.24448697 0.24280109 0.24138652 0.24032444
 0.23926905 0.23775056 0.2362474  0.23510088 0.2340385  0.23274639
 0.23147726 0.23058274 0.22992495 0.22905843 0.2282189  0.2277414
 0.22736607 0.22652759 0.22535634 0.22427262 0.22327451 0.22165452
 0.2194848  0.21751092 0.21615927 0.21484365 0.21326856 0.21130078
 0.20904987 0.20735537 0.20589626 0.20410757 0.20251049 0.20162153
 0.20130228 0.20065793 0.20002858 0.1999155  0.19965152 0.19910505
 0.19824927 0.19770499 0.19766939 0.19722381 0.19585855 0.19451757
 0.1939575  0.19357088 0.19237778 0.19044632 0.18939005 0.18930572
 0.18906343 0.18802567 0.18757936 0.18752636 0.186987   0.18591541
 0.18517958 0.18532702 0.18535443 0.18461835 0.18354556 0.18332988
 0.18365209 0.18327816 0.18267843 0.18229175 0.18223508 0.18191966
 0.18101986 0.1801158  0.17957027 0.1787905  0.17753725 0.17631544
 0.17584856 0.17530389 0.17435114 0.17335674 0.1731259  0.17365223
 0.17315271 0.17181833 0.17071064 0.17069435 0.17049737 0.16979519
 0.16896373 0.16860895 0.16851597 0.16743623 0.16576715 0.16414073
 0.16303663 0.16158651 0.15993108 0.15867914 0.15796018 0.15722403
 0.15611356 0.15473703 0.15389466 0.15336262 0.15263456 0.15151551
 0.15094706 0.15080006 0.15021753 0.14925094 0.1484813  0.14825857
 0.14781411 0.14686589 0.14632764 0.14631145 0.14590229 0.144231
 0.14194752 0.14050834 0.13953482 0.1379669  0.13626398 0.13571063
 0.13615829 0.13518538 0.13330632 0.13213564 0.13228229 0.13223515
 0.13146918 0.13073501 0.13112603 0.1320105  0.13126096 0.13005702
 0.12995394 0.13057426 0.13049296 0.12969476 0.12981774 0.13011946
 0.12895612 0.1260489  0.12440995 0.12474973 0.12503137 0.12259318
 0.11966219 0.11859354 0.11889237 0.11815324 0.11550925 0.11450817
 0.11526239 0.11521284 0.11437798 0.11497738 0.11575828 0.11467447
 0.11247993 0.11266579 0.11570937 0.11474817 0.11329916 0.12502255]
