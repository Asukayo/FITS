Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=165, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=165, out_features=209, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  15449280.0
params:  34694.0
Trainable parameters:  34694
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4292828
	speed: 0.1434s/iter; left time: 846.4839s
Epoch: 1 cost time: 17.12639856338501
Epoch: 1, Steps: 120 | Train Loss: 0.5519581 Vali Loss: 0.4340125 Test Loss: 0.4023212
Validation loss decreased (inf --> 0.434012).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3432052
	speed: 0.3548s/iter; left time: 2050.9610s
Epoch: 2 cost time: 17.179660081863403
Epoch: 2, Steps: 120 | Train Loss: 0.3917105 Vali Loss: 0.3856692 Test Loss: 0.3760929
Validation loss decreased (0.434012 --> 0.385669).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2859110
	speed: 0.3826s/iter; left time: 2165.9608s
Epoch: 3 cost time: 17.743826389312744
Epoch: 3, Steps: 120 | Train Loss: 0.3250636 Vali Loss: 0.3687416 Test Loss: 0.3683866
Validation loss decreased (0.385669 --> 0.368742).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2657252
	speed: 0.3605s/iter; left time: 1997.5515s
Epoch: 4 cost time: 16.651493072509766
Epoch: 4, Steps: 120 | Train Loss: 0.2838238 Vali Loss: 0.3580047 Test Loss: 0.3651012
Validation loss decreased (0.368742 --> 0.358005).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2599780
	speed: 0.3186s/iter; left time: 1727.3756s
Epoch: 5 cost time: 15.49840235710144
Epoch: 5, Steps: 120 | Train Loss: 0.2534662 Vali Loss: 0.3496770 Test Loss: 0.3625661
Validation loss decreased (0.358005 --> 0.349677).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2563379
	speed: 0.3717s/iter; left time: 1970.1167s
Epoch: 6 cost time: 17.279346704483032
Epoch: 6, Steps: 120 | Train Loss: 0.2308389 Vali Loss: 0.3433529 Test Loss: 0.3602818
Validation loss decreased (0.349677 --> 0.343353).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1614281
	speed: 0.3725s/iter; left time: 1929.9028s
Epoch: 7 cost time: 17.194825887680054
Epoch: 7, Steps: 120 | Train Loss: 0.2135114 Vali Loss: 0.3376296 Test Loss: 0.3584830
Validation loss decreased (0.343353 --> 0.337630).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2012865
	speed: 0.3846s/iter; left time: 1946.4471s
Epoch: 8 cost time: 18.02118468284607
Epoch: 8, Steps: 120 | Train Loss: 0.1994765 Vali Loss: 0.3323186 Test Loss: 0.3562687
Validation loss decreased (0.337630 --> 0.332319).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2310786
	speed: 0.3643s/iter; left time: 1800.2262s
Epoch: 9 cost time: 16.782679319381714
Epoch: 9, Steps: 120 | Train Loss: 0.1877207 Vali Loss: 0.3279262 Test Loss: 0.3546839
Validation loss decreased (0.332319 --> 0.327926).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1958301
	speed: 0.3278s/iter; left time: 1580.0904s
Epoch: 10 cost time: 14.529195308685303
Epoch: 10, Steps: 120 | Train Loss: 0.1779982 Vali Loss: 0.3241400 Test Loss: 0.3528893
Validation loss decreased (0.327926 --> 0.324140).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1285615
	speed: 0.3133s/iter; left time: 1472.7774s
Epoch: 11 cost time: 14.139848709106445
Epoch: 11, Steps: 120 | Train Loss: 0.1704251 Vali Loss: 0.3207003 Test Loss: 0.3518628
Validation loss decreased (0.324140 --> 0.320700).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1577702
	speed: 0.3332s/iter; left time: 1526.2993s
Epoch: 12 cost time: 15.182349443435669
Epoch: 12, Steps: 120 | Train Loss: 0.1640038 Vali Loss: 0.3173066 Test Loss: 0.3506655
Validation loss decreased (0.320700 --> 0.317307).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1211552
	speed: 0.3391s/iter; left time: 1512.6735s
Epoch: 13 cost time: 15.642640113830566
Epoch: 13, Steps: 120 | Train Loss: 0.1588544 Vali Loss: 0.3143899 Test Loss: 0.3498276
Validation loss decreased (0.317307 --> 0.314390).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1497912
	speed: 0.3200s/iter; left time: 1389.0433s
Epoch: 14 cost time: 15.410106420516968
Epoch: 14, Steps: 120 | Train Loss: 0.1542230 Vali Loss: 0.3119336 Test Loss: 0.3488378
Validation loss decreased (0.314390 --> 0.311934).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1513136
	speed: 0.3232s/iter; left time: 1364.2600s
Epoch: 15 cost time: 15.152116775512695
Epoch: 15, Steps: 120 | Train Loss: 0.1507494 Vali Loss: 0.3098587 Test Loss: 0.3483250
Validation loss decreased (0.311934 --> 0.309859).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1333845
	speed: 0.3272s/iter; left time: 1341.7965s
Epoch: 16 cost time: 15.478251218795776
Epoch: 16, Steps: 120 | Train Loss: 0.1476983 Vali Loss: 0.3074228 Test Loss: 0.3478327
Validation loss decreased (0.309859 --> 0.307423).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1416071
	speed: 0.3333s/iter; left time: 1326.9838s
Epoch: 17 cost time: 15.132477760314941
Epoch: 17, Steps: 120 | Train Loss: 0.1442551 Vali Loss: 0.3062104 Test Loss: 0.3474198
Validation loss decreased (0.307423 --> 0.306210).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1854937
	speed: 0.3217s/iter; left time: 1241.9975s
Epoch: 18 cost time: 15.188279390335083
Epoch: 18, Steps: 120 | Train Loss: 0.1424866 Vali Loss: 0.3044008 Test Loss: 0.3470149
Validation loss decreased (0.306210 --> 0.304401).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1154871
	speed: 0.3282s/iter; left time: 1227.8950s
Epoch: 19 cost time: 16.27689814567566
Epoch: 19, Steps: 120 | Train Loss: 0.1407068 Vali Loss: 0.3026367 Test Loss: 0.3469056
Validation loss decreased (0.304401 --> 0.302637).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1642604
	speed: 0.3480s/iter; left time: 1260.1358s
Epoch: 20 cost time: 16.280149221420288
Epoch: 20, Steps: 120 | Train Loss: 0.1389847 Vali Loss: 0.3015139 Test Loss: 0.3468167
Validation loss decreased (0.302637 --> 0.301514).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1324553
	speed: 0.3297s/iter; left time: 1154.1313s
Epoch: 21 cost time: 14.420435905456543
Epoch: 21, Steps: 120 | Train Loss: 0.1374693 Vali Loss: 0.3002676 Test Loss: 0.3466489
Validation loss decreased (0.301514 --> 0.300268).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1305629
	speed: 0.3389s/iter; left time: 1145.8579s
Epoch: 22 cost time: 16.352662801742554
Epoch: 22, Steps: 120 | Train Loss: 0.1361392 Vali Loss: 0.2993863 Test Loss: 0.3464294
Validation loss decreased (0.300268 --> 0.299386).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.0893608
	speed: 0.3492s/iter; left time: 1138.8675s
Epoch: 23 cost time: 16.48503851890564
Epoch: 23, Steps: 120 | Train Loss: 0.1350857 Vali Loss: 0.2987581 Test Loss: 0.3463039
Validation loss decreased (0.299386 --> 0.298758).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1420294
	speed: 0.3344s/iter; left time: 1050.3713s
Epoch: 24 cost time: 14.923322439193726
Epoch: 24, Steps: 120 | Train Loss: 0.1340445 Vali Loss: 0.2977286 Test Loss: 0.3463469
Validation loss decreased (0.298758 --> 0.297729).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1301907
	speed: 0.3651s/iter; left time: 1102.8425s
Epoch: 25 cost time: 17.030016899108887
Epoch: 25, Steps: 120 | Train Loss: 0.1334026 Vali Loss: 0.2968170 Test Loss: 0.3463751
Validation loss decreased (0.297729 --> 0.296817).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.0929917
	speed: 0.3679s/iter; left time: 1067.4001s
Epoch: 26 cost time: 17.385042905807495
Epoch: 26, Steps: 120 | Train Loss: 0.1324730 Vali Loss: 0.2964249 Test Loss: 0.3463233
Validation loss decreased (0.296817 --> 0.296425).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1426251
	speed: 0.3820s/iter; left time: 1062.4808s
Epoch: 27 cost time: 16.882059812545776
Epoch: 27, Steps: 120 | Train Loss: 0.1323390 Vali Loss: 0.2956194 Test Loss: 0.3464409
Validation loss decreased (0.296425 --> 0.295619).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1355691
	speed: 0.3608s/iter; left time: 960.0632s
Epoch: 28 cost time: 16.613741397857666
Epoch: 28, Steps: 120 | Train Loss: 0.1317267 Vali Loss: 0.2950293 Test Loss: 0.3464925
Validation loss decreased (0.295619 --> 0.295029).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1101621
	speed: 0.3921s/iter; left time: 996.3999s
Epoch: 29 cost time: 18.408156156539917
Epoch: 29, Steps: 120 | Train Loss: 0.1310670 Vali Loss: 0.2943911 Test Loss: 0.3465322
Validation loss decreased (0.295029 --> 0.294391).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1607291
	speed: 0.3558s/iter; left time: 861.4180s
Epoch: 30 cost time: 16.851927280426025
Epoch: 30, Steps: 120 | Train Loss: 0.1307824 Vali Loss: 0.2941510 Test Loss: 0.3464313
Validation loss decreased (0.294391 --> 0.294151).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1387507
	speed: 0.3773s/iter; left time: 868.0871s
Epoch: 31 cost time: 18.408220052719116
Epoch: 31, Steps: 120 | Train Loss: 0.1305172 Vali Loss: 0.2938780 Test Loss: 0.3464690
Validation loss decreased (0.294151 --> 0.293878).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1045169
	speed: 0.3716s/iter; left time: 810.3947s
Epoch: 32 cost time: 16.387336492538452
Epoch: 32, Steps: 120 | Train Loss: 0.1295894 Vali Loss: 0.2931573 Test Loss: 0.3465503
Validation loss decreased (0.293878 --> 0.293157).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1398663
	speed: 0.3529s/iter; left time: 727.2878s
Epoch: 33 cost time: 16.335182428359985
Epoch: 33, Steps: 120 | Train Loss: 0.1298090 Vali Loss: 0.2930874 Test Loss: 0.3466431
Validation loss decreased (0.293157 --> 0.293087).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1051564
	speed: 0.3805s/iter; left time: 738.5927s
Epoch: 34 cost time: 17.662081956863403
Epoch: 34, Steps: 120 | Train Loss: 0.1296054 Vali Loss: 0.2927044 Test Loss: 0.3466783
Validation loss decreased (0.293087 --> 0.292704).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1419908
	speed: 0.3540s/iter; left time: 644.5745s
Epoch: 35 cost time: 16.46746826171875
Epoch: 35, Steps: 120 | Train Loss: 0.1291249 Vali Loss: 0.2924015 Test Loss: 0.3467627
Validation loss decreased (0.292704 --> 0.292402).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1504826
	speed: 0.3678s/iter; left time: 625.6732s
Epoch: 36 cost time: 18.04673409461975
Epoch: 36, Steps: 120 | Train Loss: 0.1292901 Vali Loss: 0.2922362 Test Loss: 0.3467648
Validation loss decreased (0.292402 --> 0.292236).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1383864
	speed: 0.3687s/iter; left time: 582.8982s
Epoch: 37 cost time: 16.851154327392578
Epoch: 37, Steps: 120 | Train Loss: 0.1289022 Vali Loss: 0.2920501 Test Loss: 0.3468666
Validation loss decreased (0.292236 --> 0.292050).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1095830
	speed: 0.3429s/iter; left time: 501.0418s
Epoch: 38 cost time: 16.409417867660522
Epoch: 38, Steps: 120 | Train Loss: 0.1290781 Vali Loss: 0.2919312 Test Loss: 0.3468859
Validation loss decreased (0.292050 --> 0.291931).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1179652
	speed: 0.3791s/iter; left time: 508.4369s
Epoch: 39 cost time: 17.59789276123047
Epoch: 39, Steps: 120 | Train Loss: 0.1285455 Vali Loss: 0.2916647 Test Loss: 0.3469244
Validation loss decreased (0.291931 --> 0.291665).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1159483
	speed: 0.3487s/iter; left time: 425.7068s
Epoch: 40 cost time: 16.38020610809326
Epoch: 40, Steps: 120 | Train Loss: 0.1283216 Vali Loss: 0.2915419 Test Loss: 0.3469684
Validation loss decreased (0.291665 --> 0.291542).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1431316
	speed: 0.3613s/iter; left time: 397.7370s
Epoch: 41 cost time: 17.537267923355103
Epoch: 41, Steps: 120 | Train Loss: 0.1284408 Vali Loss: 0.2911558 Test Loss: 0.3470510
Validation loss decreased (0.291542 --> 0.291156).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1339707
	speed: 0.3667s/iter; left time: 359.7698s
Epoch: 42 cost time: 16.25301194190979
Epoch: 42, Steps: 120 | Train Loss: 0.1280198 Vali Loss: 0.2910547 Test Loss: 0.3471014
Validation loss decreased (0.291156 --> 0.291055).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1587948
	speed: 0.3439s/iter; left time: 296.0918s
Epoch: 43 cost time: 15.945504188537598
Epoch: 43, Steps: 120 | Train Loss: 0.1281109 Vali Loss: 0.2909012 Test Loss: 0.3471287
Validation loss decreased (0.291055 --> 0.290901).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1724665
	speed: 0.3752s/iter; left time: 278.0097s
Epoch: 44 cost time: 17.8203444480896
Epoch: 44, Steps: 120 | Train Loss: 0.1282301 Vali Loss: 0.2908067 Test Loss: 0.3472114
Validation loss decreased (0.290901 --> 0.290807).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.0934978
	speed: 0.3572s/iter; left time: 221.7940s
Epoch: 45 cost time: 16.309924840927124
Epoch: 45, Steps: 120 | Train Loss: 0.1278630 Vali Loss: 0.2905042 Test Loss: 0.3472185
Validation loss decreased (0.290807 --> 0.290504).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1529609
	speed: 0.3600s/iter; left time: 180.3684s
Epoch: 46 cost time: 17.661391496658325
Epoch: 46, Steps: 120 | Train Loss: 0.1279308 Vali Loss: 0.2905441 Test Loss: 0.3473423
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1345259
	speed: 0.3722s/iter; left time: 141.8008s
Epoch: 47 cost time: 16.73206639289856
Epoch: 47, Steps: 120 | Train Loss: 0.1278956 Vali Loss: 0.2905400 Test Loss: 0.3473669
EarlyStopping counter: 2 out of 3
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1798829
	speed: 0.3560s/iter; left time: 92.9165s
Epoch: 48 cost time: 16.530479192733765
Epoch: 48, Steps: 120 | Train Loss: 0.1279309 Vali Loss: 0.2902946 Test Loss: 0.3473825
Validation loss decreased (0.290504 --> 0.290295).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.0982850
	speed: 0.3668s/iter; left time: 51.7145s
Epoch: 49 cost time: 17.10852837562561
Epoch: 49, Steps: 120 | Train Loss: 0.1278468 Vali Loss: 0.2902905 Test Loss: 0.3473940
Validation loss decreased (0.290295 --> 0.290290).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1418601
	speed: 0.3463s/iter; left time: 7.2717s
Epoch: 50 cost time: 15.188910484313965
Epoch: 50, Steps: 120 | Train Loss: 0.1277678 Vali Loss: 0.2900941 Test Loss: 0.3474508
Validation loss decreased (0.290290 --> 0.290094).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=165, out_features=209, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  15449280.0
params:  34694.0
Trainable parameters:  34694
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4653235
	speed: 0.1446s/iter; left time: 853.2021s
Epoch: 1 cost time: 17.29941749572754
Epoch: 1, Steps: 120 | Train Loss: 0.5199183 Vali Loss: 0.2852497 Test Loss: 0.3454733
Validation loss decreased (inf --> 0.285250).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3688764
	speed: 0.3338s/iter; left time: 1929.5777s
Epoch: 2 cost time: 14.117737054824829
Epoch: 2, Steps: 120 | Train Loss: 0.5147194 Vali Loss: 0.2838533 Test Loss: 0.3446973
Validation loss decreased (0.285250 --> 0.283853).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3860766
	speed: 0.3577s/iter; left time: 2024.7434s
Epoch: 3 cost time: 16.201841115951538
Epoch: 3, Steps: 120 | Train Loss: 0.5141953 Vali Loss: 0.2821818 Test Loss: 0.3445880
Validation loss decreased (0.283853 --> 0.282182).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.7478958
	speed: 0.3191s/iter; left time: 1768.1908s
Epoch: 4 cost time: 14.383387565612793
Epoch: 4, Steps: 120 | Train Loss: 0.5133357 Vali Loss: 0.2825829 Test Loss: 0.3437648
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.6744916
	speed: 0.3207s/iter; left time: 1738.6993s
Epoch: 5 cost time: 15.12351131439209
Epoch: 5, Steps: 120 | Train Loss: 0.5107211 Vali Loss: 0.2813253 Test Loss: 0.3440723
Validation loss decreased (0.282182 --> 0.281325).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4827997
	speed: 0.3372s/iter; left time: 1787.3858s
Epoch: 6 cost time: 15.580042123794556
Epoch: 6, Steps: 120 | Train Loss: 0.5123082 Vali Loss: 0.2819354 Test Loss: 0.3428019
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.6193908
	speed: 0.3478s/iter; left time: 1801.7039s
Epoch: 7 cost time: 16.115265369415283
Epoch: 7, Steps: 120 | Train Loss: 0.5113534 Vali Loss: 0.2816958 Test Loss: 0.3430367
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4634175
	speed: 0.3500s/iter; left time: 1771.2219s
Epoch: 8 cost time: 16.31474757194519
Epoch: 8, Steps: 120 | Train Loss: 0.5107842 Vali Loss: 0.2809172 Test Loss: 0.3428695
Validation loss decreased (0.281325 --> 0.280917).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2717689
	speed: 0.3590s/iter; left time: 1773.5949s
Epoch: 9 cost time: 17.195032119750977
Epoch: 9, Steps: 120 | Train Loss: 0.5092859 Vali Loss: 0.2797165 Test Loss: 0.3432765
Validation loss decreased (0.280917 --> 0.279716).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.5816548
	speed: 0.3773s/iter; left time: 1819.0900s
Epoch: 10 cost time: 17.069522380828857
Epoch: 10, Steps: 120 | Train Loss: 0.5103112 Vali Loss: 0.2807551 Test Loss: 0.3422971
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.9154127
	speed: 0.3641s/iter; left time: 1711.6076s
Epoch: 11 cost time: 17.36886215209961
Epoch: 11, Steps: 120 | Train Loss: 0.5085655 Vali Loss: 0.2804118 Test Loss: 0.3427079
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4679873
	speed: 0.3946s/iter; left time: 1807.7501s
Epoch: 12 cost time: 17.808847665786743
Epoch: 12, Steps: 120 | Train Loss: 0.5094421 Vali Loss: 0.2795764 Test Loss: 0.3425715
Validation loss decreased (0.279716 --> 0.279576).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4465598
	speed: 0.3680s/iter; left time: 1641.6500s
Epoch: 13 cost time: 17.008559226989746
Epoch: 13, Steps: 120 | Train Loss: 0.5078003 Vali Loss: 0.2803766 Test Loss: 0.3423709
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3900427
	speed: 0.3770s/iter; left time: 1636.5279s
Epoch: 14 cost time: 17.969415187835693
Epoch: 14, Steps: 120 | Train Loss: 0.5093458 Vali Loss: 0.2798527 Test Loss: 0.3424802
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.7339153
	speed: 0.3686s/iter; left time: 1555.7593s
Epoch: 15 cost time: 16.920883893966675
Epoch: 15, Steps: 120 | Train Loss: 0.5092289 Vali Loss: 0.2795931 Test Loss: 0.3426090
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.3327391445636749, mae:0.3750472664833069, rse:0.46258631348609924, corr:[0.26601714 0.26933706 0.26776698 0.26679966 0.2668161  0.26635477
 0.26529628 0.26456138 0.26422992 0.2633452  0.2617547  0.25995523
 0.2585634  0.2577146  0.25700933 0.2565143  0.25621325 0.25583035
 0.2549205  0.2537497  0.25267458 0.2516339  0.25018132 0.2481326
 0.24592942 0.24396223 0.24231853 0.24095434 0.23992716 0.23896031
 0.23764324 0.23578176 0.23423313 0.23330745 0.23249437 0.23114124
 0.2293971  0.22799015 0.2271921  0.2265072  0.22572078 0.22521001
 0.22500366 0.22450201 0.22350435 0.22227438 0.22101842 0.21950555
 0.21760385 0.21546213 0.21341291 0.21147451 0.20985672 0.20824625
 0.20654821 0.20530811 0.20399764 0.20185961 0.19957662 0.1983957
 0.19855288 0.1985548  0.19798905 0.19753948 0.1974292  0.19761647
 0.19710286 0.19591846 0.1950976  0.19488412 0.19453602 0.19374807
 0.19276066 0.19190593 0.19102584 0.18972854 0.18856515 0.1876037
 0.18659534 0.18533422 0.18484676 0.18461059 0.183992   0.18331863
 0.18350254 0.1845775  0.18498272 0.18375714 0.18155985 0.18040898
 0.18070494 0.1810395  0.18105434 0.1809057  0.18102428 0.18088184
 0.17977357 0.1782378  0.17736888 0.1770451  0.17619331 0.17442158
 0.17300291 0.17247652 0.17246424 0.17185943 0.17090179 0.17082162
 0.17100081 0.17067425 0.16938537 0.16827711 0.16782525 0.16788225
 0.16724172 0.16579443 0.16473588 0.16422361 0.16368634 0.16202274
 0.15980057 0.15808588 0.15766875 0.157647   0.15672308 0.15499401
 0.15365991 0.15314397 0.15313502 0.15257584 0.1513265  0.14987291
 0.14921294 0.1488687  0.14790048 0.14674486 0.1465432  0.1474679
 0.14782628 0.14660285 0.14506249 0.14474    0.14529723 0.14471497
 0.14237538 0.14017026 0.13920419 0.13845462 0.13686116 0.13522935
 0.13507806 0.13522074 0.13477476 0.13365741 0.13304947 0.13324903
 0.13347192 0.13293657 0.13269323 0.13377254 0.13448758 0.13413961
 0.13343279 0.13356219 0.13410546 0.13330889 0.13139214 0.12978043
 0.1296659  0.12954931 0.12859806 0.12700659 0.12611732 0.12495972
 0.12311847 0.12103757 0.12039474 0.12086626 0.12008726 0.11936637
 0.12045373 0.1225279  0.12321761 0.12217611 0.12125555 0.12222569
 0.12266837 0.1211618  0.12161526 0.12379118 0.1225102  0.1167955 ]
