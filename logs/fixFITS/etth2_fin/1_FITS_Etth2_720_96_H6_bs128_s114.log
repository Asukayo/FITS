Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=196, out_features=222, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  77973504.0
params:  43734.0
Trainable parameters:  43734
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 5.1652140617370605
Epoch: 1, Steps: 30 | Train Loss: 0.6580547 Vali Loss: 0.3350152 Test Loss: 0.3355670
Validation loss decreased (inf --> 0.335015).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 5.018810033798218
Epoch: 2, Steps: 30 | Train Loss: 0.5110337 Vali Loss: 0.2802790 Test Loss: 0.3017310
Validation loss decreased (0.335015 --> 0.280279).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 5.04789400100708
Epoch: 3, Steps: 30 | Train Loss: 0.4735322 Vali Loss: 0.2626204 Test Loss: 0.2907210
Validation loss decreased (0.280279 --> 0.262620).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 5.2219789028167725
Epoch: 4, Steps: 30 | Train Loss: 0.4550495 Vali Loss: 0.2536662 Test Loss: 0.2854580
Validation loss decreased (0.262620 --> 0.253666).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 5.293018341064453
Epoch: 5, Steps: 30 | Train Loss: 0.4444612 Vali Loss: 0.2458486 Test Loss: 0.2824889
Validation loss decreased (0.253666 --> 0.245849).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 4.972384452819824
Epoch: 6, Steps: 30 | Train Loss: 0.4391261 Vali Loss: 0.2402466 Test Loss: 0.2807529
Validation loss decreased (0.245849 --> 0.240247).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 5.238783359527588
Epoch: 7, Steps: 30 | Train Loss: 0.4337309 Vali Loss: 0.2391254 Test Loss: 0.2796758
Validation loss decreased (0.240247 --> 0.239125).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 5.134259462356567
Epoch: 8, Steps: 30 | Train Loss: 0.4303383 Vali Loss: 0.2348767 Test Loss: 0.2787402
Validation loss decreased (0.239125 --> 0.234877).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.959815263748169
Epoch: 9, Steps: 30 | Train Loss: 0.4275421 Vali Loss: 0.2334797 Test Loss: 0.2782719
Validation loss decreased (0.234877 --> 0.233480).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 4.9861979484558105
Epoch: 10, Steps: 30 | Train Loss: 0.4223169 Vali Loss: 0.2320657 Test Loss: 0.2775211
Validation loss decreased (0.233480 --> 0.232066).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 4.720784664154053
Epoch: 11, Steps: 30 | Train Loss: 0.4211726 Vali Loss: 0.2311807 Test Loss: 0.2773933
Validation loss decreased (0.232066 --> 0.231181).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 4.956892490386963
Epoch: 12, Steps: 30 | Train Loss: 0.4164125 Vali Loss: 0.2282041 Test Loss: 0.2770758
Validation loss decreased (0.231181 --> 0.228204).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 5.057689666748047
Epoch: 13, Steps: 30 | Train Loss: 0.4195058 Vali Loss: 0.2290123 Test Loss: 0.2765805
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 5.073083400726318
Epoch: 14, Steps: 30 | Train Loss: 0.4176448 Vali Loss: 0.2278574 Test Loss: 0.2763300
Validation loss decreased (0.228204 --> 0.227857).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 4.659144878387451
Epoch: 15, Steps: 30 | Train Loss: 0.4185077 Vali Loss: 0.2249058 Test Loss: 0.2760827
Validation loss decreased (0.227857 --> 0.224906).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 5.214728355407715
Epoch: 16, Steps: 30 | Train Loss: 0.4155789 Vali Loss: 0.2257668 Test Loss: 0.2759848
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 5.044877767562866
Epoch: 17, Steps: 30 | Train Loss: 0.4136510 Vali Loss: 0.2238723 Test Loss: 0.2758279
Validation loss decreased (0.224906 --> 0.223872).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 4.950002193450928
Epoch: 18, Steps: 30 | Train Loss: 0.4115566 Vali Loss: 0.2251623 Test Loss: 0.2755866
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 4.790888547897339
Epoch: 19, Steps: 30 | Train Loss: 0.4133539 Vali Loss: 0.2234563 Test Loss: 0.2754784
Validation loss decreased (0.223872 --> 0.223456).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.91714334487915
Epoch: 20, Steps: 30 | Train Loss: 0.4118881 Vali Loss: 0.2239134 Test Loss: 0.2752334
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 5.1036217212677
Epoch: 21, Steps: 30 | Train Loss: 0.4098571 Vali Loss: 0.2216408 Test Loss: 0.2752696
Validation loss decreased (0.223456 --> 0.221641).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 5.331312656402588
Epoch: 22, Steps: 30 | Train Loss: 0.4100504 Vali Loss: 0.2222205 Test Loss: 0.2751927
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 5.417970657348633
Epoch: 23, Steps: 30 | Train Loss: 0.4124786 Vali Loss: 0.2221926 Test Loss: 0.2750823
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 4.353780508041382
Epoch: 24, Steps: 30 | Train Loss: 0.4099341 Vali Loss: 0.2212986 Test Loss: 0.2750485
Validation loss decreased (0.221641 --> 0.221299).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 3.7951090335845947
Epoch: 25, Steps: 30 | Train Loss: 0.4100121 Vali Loss: 0.2210778 Test Loss: 0.2749555
Validation loss decreased (0.221299 --> 0.221078).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.9921083450317383
Epoch: 26, Steps: 30 | Train Loss: 0.4048255 Vali Loss: 0.2210505 Test Loss: 0.2749062
Validation loss decreased (0.221078 --> 0.221051).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 3.9060959815979004
Epoch: 27, Steps: 30 | Train Loss: 0.4090420 Vali Loss: 0.2217607 Test Loss: 0.2748633
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 4.38215970993042
Epoch: 28, Steps: 30 | Train Loss: 0.4056203 Vali Loss: 0.2207694 Test Loss: 0.2747608
Validation loss decreased (0.221051 --> 0.220769).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 5.079733610153198
Epoch: 29, Steps: 30 | Train Loss: 0.4104263 Vali Loss: 0.2196233 Test Loss: 0.2746608
Validation loss decreased (0.220769 --> 0.219623).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 5.200829029083252
Epoch: 30, Steps: 30 | Train Loss: 0.4100896 Vali Loss: 0.2204188 Test Loss: 0.2746654
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 5.165150165557861
Epoch: 31, Steps: 30 | Train Loss: 0.4085649 Vali Loss: 0.2207471 Test Loss: 0.2747080
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 5.1835784912109375
Epoch: 32, Steps: 30 | Train Loss: 0.4061408 Vali Loss: 0.2212042 Test Loss: 0.2746320
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.27245813608169556, mae:0.3385089337825775, rse:0.42065998911857605, corr:[0.27100763 0.27653474 0.27462384 0.27511433 0.2753925  0.2740622
 0.27334782 0.27304232 0.27203953 0.27055293 0.26920822 0.2681796
 0.26699752 0.2654658  0.2643546  0.26408404 0.26364395 0.26271304
 0.26196316 0.26103967 0.2595289  0.25831568 0.25744587 0.25583375
 0.25349835 0.2519493  0.2509034  0.24911642 0.247268   0.24644579
 0.24564825 0.24384432 0.24222606 0.24148135 0.24026915 0.23847349
 0.23755404 0.23719102 0.23591948 0.23440365 0.23398319 0.23380552
 0.23283115 0.23181276 0.23128632 0.23043026 0.22898428 0.22741708
 0.22579288 0.22392944 0.22232111 0.22110438 0.22017114 0.21882904
 0.21699445 0.21528976 0.21343486 0.21171674 0.21045335 0.20929067
 0.20831248 0.20799439 0.2082401  0.20825823 0.20770189 0.20758304
 0.20735879 0.20667012 0.20614468 0.20570561 0.2049222  0.20398784
 0.20280072 0.20146179 0.20056583 0.19951487 0.19857225 0.19798489
 0.19796541 0.19690105 0.19574489 0.19575235 0.19605044 0.19518758
 0.1938999  0.19449387 0.1949142  0.1937605  0.19273989 0.19344775
 0.19198154 0.1896979  0.19112194 0.18972836 0.1860533  0.19236913]
