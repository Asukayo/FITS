Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=165, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=165, out_features=187, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  27646080.0
params:  31042.0
Trainable parameters:  31042
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 8.96022629737854
Epoch: 1, Steps: 61 | Train Loss: 0.5634360 Vali Loss: 0.3910214 Test Loss: 0.3821295
Validation loss decreased (inf --> 0.391021).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 9.16324257850647
Epoch: 2, Steps: 61 | Train Loss: 0.4357283 Vali Loss: 0.3467314 Test Loss: 0.3447379
Validation loss decreased (0.391021 --> 0.346731).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 9.049521684646606
Epoch: 3, Steps: 61 | Train Loss: 0.3709961 Vali Loss: 0.3302768 Test Loss: 0.3313101
Validation loss decreased (0.346731 --> 0.330277).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 9.792181491851807
Epoch: 4, Steps: 61 | Train Loss: 0.3317836 Vali Loss: 0.3248038 Test Loss: 0.3263803
Validation loss decreased (0.330277 --> 0.324804).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 9.229315042495728
Epoch: 5, Steps: 61 | Train Loss: 0.3036656 Vali Loss: 0.3200426 Test Loss: 0.3241850
Validation loss decreased (0.324804 --> 0.320043).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 9.099704027175903
Epoch: 6, Steps: 61 | Train Loss: 0.2819955 Vali Loss: 0.3166209 Test Loss: 0.3224002
Validation loss decreased (0.320043 --> 0.316621).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 9.166428327560425
Epoch: 7, Steps: 61 | Train Loss: 0.2643933 Vali Loss: 0.3149969 Test Loss: 0.3213194
Validation loss decreased (0.316621 --> 0.314997).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 9.863348484039307
Epoch: 8, Steps: 61 | Train Loss: 0.2491084 Vali Loss: 0.3120946 Test Loss: 0.3196982
Validation loss decreased (0.314997 --> 0.312095).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 9.867741346359253
Epoch: 9, Steps: 61 | Train Loss: 0.2360521 Vali Loss: 0.3086858 Test Loss: 0.3182880
Validation loss decreased (0.312095 --> 0.308686).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 8.944514036178589
Epoch: 10, Steps: 61 | Train Loss: 0.2246863 Vali Loss: 0.3041799 Test Loss: 0.3167973
Validation loss decreased (0.308686 --> 0.304180).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 8.67985463142395
Epoch: 11, Steps: 61 | Train Loss: 0.2145901 Vali Loss: 0.3020797 Test Loss: 0.3150182
Validation loss decreased (0.304180 --> 0.302080).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 9.321555852890015
Epoch: 12, Steps: 61 | Train Loss: 0.2056837 Vali Loss: 0.2984931 Test Loss: 0.3133563
Validation loss decreased (0.302080 --> 0.298493).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 9.176723718643188
Epoch: 13, Steps: 61 | Train Loss: 0.1972319 Vali Loss: 0.2968076 Test Loss: 0.3116795
Validation loss decreased (0.298493 --> 0.296808).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 8.482745885848999
Epoch: 14, Steps: 61 | Train Loss: 0.1903310 Vali Loss: 0.2944155 Test Loss: 0.3101807
Validation loss decreased (0.296808 --> 0.294416).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 8.815688848495483
Epoch: 15, Steps: 61 | Train Loss: 0.1837441 Vali Loss: 0.2928692 Test Loss: 0.3085849
Validation loss decreased (0.294416 --> 0.292869).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 6.670944929122925
Epoch: 16, Steps: 61 | Train Loss: 0.1777030 Vali Loss: 0.2896197 Test Loss: 0.3071644
Validation loss decreased (0.292869 --> 0.289620).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 7.322640419006348
Epoch: 17, Steps: 61 | Train Loss: 0.1720488 Vali Loss: 0.2874194 Test Loss: 0.3057692
Validation loss decreased (0.289620 --> 0.287419).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 9.632206678390503
Epoch: 18, Steps: 61 | Train Loss: 0.1672298 Vali Loss: 0.2855202 Test Loss: 0.3043789
Validation loss decreased (0.287419 --> 0.285520).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 9.006551265716553
Epoch: 19, Steps: 61 | Train Loss: 0.1625484 Vali Loss: 0.2832542 Test Loss: 0.3031742
Validation loss decreased (0.285520 --> 0.283254).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 9.453117847442627
Epoch: 20, Steps: 61 | Train Loss: 0.1584976 Vali Loss: 0.2822624 Test Loss: 0.3019344
Validation loss decreased (0.283254 --> 0.282262).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 9.244610786437988
Epoch: 21, Steps: 61 | Train Loss: 0.1547229 Vali Loss: 0.2801126 Test Loss: 0.3009374
Validation loss decreased (0.282262 --> 0.280113).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 9.585256576538086
Epoch: 22, Steps: 61 | Train Loss: 0.1511435 Vali Loss: 0.2784606 Test Loss: 0.2998649
Validation loss decreased (0.280113 --> 0.278461).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 9.008712768554688
Epoch: 23, Steps: 61 | Train Loss: 0.1478978 Vali Loss: 0.2770080 Test Loss: 0.2988882
Validation loss decreased (0.278461 --> 0.277008).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 8.814159154891968
Epoch: 24, Steps: 61 | Train Loss: 0.1448007 Vali Loss: 0.2742545 Test Loss: 0.2979590
Validation loss decreased (0.277008 --> 0.274254).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 8.965266466140747
Epoch: 25, Steps: 61 | Train Loss: 0.1418569 Vali Loss: 0.2742480 Test Loss: 0.2971080
Validation loss decreased (0.274254 --> 0.274248).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 9.422308444976807
Epoch: 26, Steps: 61 | Train Loss: 0.1394044 Vali Loss: 0.2730900 Test Loss: 0.2963215
Validation loss decreased (0.274248 --> 0.273090).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 9.247694969177246
Epoch: 27, Steps: 61 | Train Loss: 0.1369693 Vali Loss: 0.2721343 Test Loss: 0.2954912
Validation loss decreased (0.273090 --> 0.272134).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 8.653953313827515
Epoch: 28, Steps: 61 | Train Loss: 0.1347198 Vali Loss: 0.2707311 Test Loss: 0.2948200
Validation loss decreased (0.272134 --> 0.270731).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 8.615108013153076
Epoch: 29, Steps: 61 | Train Loss: 0.1327720 Vali Loss: 0.2694178 Test Loss: 0.2941443
Validation loss decreased (0.270731 --> 0.269418).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 8.866055011749268
Epoch: 30, Steps: 61 | Train Loss: 0.1307528 Vali Loss: 0.2687477 Test Loss: 0.2934874
Validation loss decreased (0.269418 --> 0.268748).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 9.11331582069397
Epoch: 31, Steps: 61 | Train Loss: 0.1290357 Vali Loss: 0.2672212 Test Loss: 0.2929735
Validation loss decreased (0.268748 --> 0.267221).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 9.150080442428589
Epoch: 32, Steps: 61 | Train Loss: 0.1273286 Vali Loss: 0.2658648 Test Loss: 0.2923492
Validation loss decreased (0.267221 --> 0.265865).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 8.170698165893555
Epoch: 33, Steps: 61 | Train Loss: 0.1257657 Vali Loss: 0.2658347 Test Loss: 0.2918904
Validation loss decreased (0.265865 --> 0.265835).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 8.60893177986145
Epoch: 34, Steps: 61 | Train Loss: 0.1240575 Vali Loss: 0.2641262 Test Loss: 0.2913987
Validation loss decreased (0.265835 --> 0.264126).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 8.654249668121338
Epoch: 35, Steps: 61 | Train Loss: 0.1229474 Vali Loss: 0.2644200 Test Loss: 0.2909470
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 9.24657392501831
Epoch: 36, Steps: 61 | Train Loss: 0.1216279 Vali Loss: 0.2641946 Test Loss: 0.2905600
EarlyStopping counter: 2 out of 3
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 8.616700410842896
Epoch: 37, Steps: 61 | Train Loss: 0.1204012 Vali Loss: 0.2629607 Test Loss: 0.2901249
Validation loss decreased (0.264126 --> 0.262961).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 8.666134357452393
Epoch: 38, Steps: 61 | Train Loss: 0.1191560 Vali Loss: 0.2626723 Test Loss: 0.2897319
Validation loss decreased (0.262961 --> 0.262672).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 8.365418910980225
Epoch: 39, Steps: 61 | Train Loss: 0.1181580 Vali Loss: 0.2622612 Test Loss: 0.2893915
Validation loss decreased (0.262672 --> 0.262261).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 9.228965759277344
Epoch: 40, Steps: 61 | Train Loss: 0.1170056 Vali Loss: 0.2613677 Test Loss: 0.2890174
Validation loss decreased (0.262261 --> 0.261368).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 9.265028715133667
Epoch: 41, Steps: 61 | Train Loss: 0.1163022 Vali Loss: 0.2605128 Test Loss: 0.2887001
Validation loss decreased (0.261368 --> 0.260513).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 7.393762588500977
Epoch: 42, Steps: 61 | Train Loss: 0.1153559 Vali Loss: 0.2592379 Test Loss: 0.2883891
Validation loss decreased (0.260513 --> 0.259238).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 9.259473085403442
Epoch: 43, Steps: 61 | Train Loss: 0.1145679 Vali Loss: 0.2587003 Test Loss: 0.2881188
Validation loss decreased (0.259238 --> 0.258700).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 9.068273305892944
Epoch: 44, Steps: 61 | Train Loss: 0.1135538 Vali Loss: 0.2588750 Test Loss: 0.2878124
EarlyStopping counter: 1 out of 3
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 9.959153175354004
Epoch: 45, Steps: 61 | Train Loss: 0.1129612 Vali Loss: 0.2577583 Test Loss: 0.2875769
Validation loss decreased (0.258700 --> 0.257758).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 9.875147342681885
Epoch: 46, Steps: 61 | Train Loss: 0.1120800 Vali Loss: 0.2580436 Test Loss: 0.2873423
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 8.908994197845459
Epoch: 47, Steps: 61 | Train Loss: 0.1115417 Vali Loss: 0.2585222 Test Loss: 0.2871106
EarlyStopping counter: 2 out of 3
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 8.7187979221344
Epoch: 48, Steps: 61 | Train Loss: 0.1108518 Vali Loss: 0.2572245 Test Loss: 0.2868959
Validation loss decreased (0.257758 --> 0.257225).  Saving model ...
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 9.472080707550049
Epoch: 49, Steps: 61 | Train Loss: 0.1103911 Vali Loss: 0.2570038 Test Loss: 0.2866773
Validation loss decreased (0.257225 --> 0.257004).  Saving model ...
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 9.455433368682861
Epoch: 50, Steps: 61 | Train Loss: 0.1097084 Vali Loss: 0.2574233 Test Loss: 0.2864994
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.0497355408796396e-05
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=165, out_features=187, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  27646080.0
params:  31042.0
Trainable parameters:  31042
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 8.495720863342285
Epoch: 1, Steps: 61 | Train Loss: 0.4328593 Vali Loss: 0.2309211 Test Loss: 0.2735018
Validation loss decreased (inf --> 0.230921).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 8.948307275772095
Epoch: 2, Steps: 61 | Train Loss: 0.4155937 Vali Loss: 0.2235057 Test Loss: 0.2733512
Validation loss decreased (0.230921 --> 0.223506).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 8.999611377716064
Epoch: 3, Steps: 61 | Train Loss: 0.4109477 Vali Loss: 0.2199494 Test Loss: 0.2732532
Validation loss decreased (0.223506 --> 0.219949).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 9.139242172241211
Epoch: 4, Steps: 61 | Train Loss: 0.4085033 Vali Loss: 0.2180166 Test Loss: 0.2732911
Validation loss decreased (0.219949 --> 0.218017).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 9.304813385009766
Epoch: 5, Steps: 61 | Train Loss: 0.4066933 Vali Loss: 0.2168222 Test Loss: 0.2731127
Validation loss decreased (0.218017 --> 0.216822).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 8.729850053787231
Epoch: 6, Steps: 61 | Train Loss: 0.4056046 Vali Loss: 0.2160277 Test Loss: 0.2728294
Validation loss decreased (0.216822 --> 0.216028).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 8.705392599105835
Epoch: 7, Steps: 61 | Train Loss: 0.4046387 Vali Loss: 0.2159644 Test Loss: 0.2727592
Validation loss decreased (0.216028 --> 0.215964).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 8.873847246170044
Epoch: 8, Steps: 61 | Train Loss: 0.4042538 Vali Loss: 0.2150882 Test Loss: 0.2728614
Validation loss decreased (0.215964 --> 0.215088).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 9.365144729614258
Epoch: 9, Steps: 61 | Train Loss: 0.4038299 Vali Loss: 0.2157782 Test Loss: 0.2727833
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 8.941694259643555
Epoch: 10, Steps: 61 | Train Loss: 0.4029236 Vali Loss: 0.2141593 Test Loss: 0.2725691
Validation loss decreased (0.215088 --> 0.214159).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 8.54120421409607
Epoch: 11, Steps: 61 | Train Loss: 0.4029227 Vali Loss: 0.2146586 Test Loss: 0.2726254
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 9.004316091537476
Epoch: 12, Steps: 61 | Train Loss: 0.4008625 Vali Loss: 0.2141705 Test Loss: 0.2724769
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 8.11991262435913
Epoch: 13, Steps: 61 | Train Loss: 0.4015344 Vali Loss: 0.2144665 Test Loss: 0.2723489
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.2722209095954895, mae:0.3372456133365631, rse:0.4204767942428589, corr:[0.27440616 0.2769736  0.27589366 0.27493665 0.27440473 0.27403507
 0.27347687 0.27268448 0.27156743 0.27008912 0.26872778 0.26741758
 0.26598895 0.26455447 0.2632899  0.2627639  0.2628461  0.26284757
 0.26199266 0.2606004  0.25928605 0.2581136  0.25669277 0.25492504
 0.25335562 0.2520747  0.2505416  0.2485524  0.24682735 0.24591368
 0.24527322 0.2440301  0.24210231 0.24039201 0.23910156 0.2380453
 0.23717682 0.23639324 0.23562077 0.23456644 0.23361461 0.23301248
 0.23249097 0.2315318  0.2305051  0.22967122 0.22885598 0.22725756
 0.22513478 0.22341709 0.22239473 0.22086534 0.21906969 0.21752393
 0.21635732 0.2155414  0.21402688 0.21161175 0.20942113 0.20836668
 0.20797497 0.20726956 0.20674892 0.20688882 0.20631038 0.20545861
 0.20508142 0.20549512 0.20566404 0.2044466  0.2021911  0.20109792
 0.20155084 0.20153707 0.2000765  0.19770779 0.19686921 0.19701004
 0.1968484  0.19557628 0.19549234 0.19618894 0.19607507 0.19539346
 0.19481891 0.19472986 0.194731   0.19519132 0.19502105 0.19419585
 0.19269074 0.19167645 0.19215332 0.19079448 0.18803933 0.19118051]
