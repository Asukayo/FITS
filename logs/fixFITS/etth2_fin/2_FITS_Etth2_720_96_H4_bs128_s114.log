Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=134, out_features=151, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  36259328.0
params:  20385.0
Trainable parameters:  20385
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 4.988632917404175
Epoch: 1, Steps: 30 | Train Loss: 0.5986711 Vali Loss: 0.4349870 Test Loss: 0.4265963
Validation loss decreased (inf --> 0.434987).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.299058437347412
Epoch: 2, Steps: 30 | Train Loss: 0.5102952 Vali Loss: 0.3880493 Test Loss: 0.3901857
Validation loss decreased (0.434987 --> 0.388049).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 5.138490200042725
Epoch: 3, Steps: 30 | Train Loss: 0.4537967 Vali Loss: 0.3601741 Test Loss: 0.3674360
Validation loss decreased (0.388049 --> 0.360174).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 5.552957534790039
Epoch: 4, Steps: 30 | Train Loss: 0.4127236 Vali Loss: 0.3434220 Test Loss: 0.3531286
Validation loss decreased (0.360174 --> 0.343422).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 5.769212484359741
Epoch: 5, Steps: 30 | Train Loss: 0.3836619 Vali Loss: 0.3325006 Test Loss: 0.3441495
Validation loss decreased (0.343422 --> 0.332501).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 5.225600004196167
Epoch: 6, Steps: 30 | Train Loss: 0.3614136 Vali Loss: 0.3255627 Test Loss: 0.3383719
Validation loss decreased (0.332501 --> 0.325563).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 5.5340797901153564
Epoch: 7, Steps: 30 | Train Loss: 0.3433943 Vali Loss: 0.3224222 Test Loss: 0.3345426
Validation loss decreased (0.325563 --> 0.322422).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 4.997234582901001
Epoch: 8, Steps: 30 | Train Loss: 0.3283203 Vali Loss: 0.3180788 Test Loss: 0.3321011
Validation loss decreased (0.322422 --> 0.318079).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.75594425201416
Epoch: 9, Steps: 30 | Train Loss: 0.3162905 Vali Loss: 0.3159735 Test Loss: 0.3302528
Validation loss decreased (0.318079 --> 0.315973).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 6.033897876739502
Epoch: 10, Steps: 30 | Train Loss: 0.3058849 Vali Loss: 0.3131589 Test Loss: 0.3287877
Validation loss decreased (0.315973 --> 0.313159).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 8.030977249145508
Epoch: 11, Steps: 30 | Train Loss: 0.2959241 Vali Loss: 0.3149206 Test Loss: 0.3279512
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 6.5639872550964355
Epoch: 12, Steps: 30 | Train Loss: 0.2887671 Vali Loss: 0.3123438 Test Loss: 0.3270920
Validation loss decreased (0.313159 --> 0.312344).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 7.041425704956055
Epoch: 13, Steps: 30 | Train Loss: 0.2815198 Vali Loss: 0.3110636 Test Loss: 0.3265550
Validation loss decreased (0.312344 --> 0.311064).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 7.740455627441406
Epoch: 14, Steps: 30 | Train Loss: 0.2750096 Vali Loss: 0.3104869 Test Loss: 0.3258841
Validation loss decreased (0.311064 --> 0.310487).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 7.982595205307007
Epoch: 15, Steps: 30 | Train Loss: 0.2685597 Vali Loss: 0.3092046 Test Loss: 0.3254857
Validation loss decreased (0.310487 --> 0.309205).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 8.072876214981079
Epoch: 16, Steps: 30 | Train Loss: 0.2628364 Vali Loss: 0.3073016 Test Loss: 0.3248892
Validation loss decreased (0.309205 --> 0.307302).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 8.076883792877197
Epoch: 17, Steps: 30 | Train Loss: 0.2578877 Vali Loss: 0.3083943 Test Loss: 0.3244735
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 7.296370267868042
Epoch: 18, Steps: 30 | Train Loss: 0.2538031 Vali Loss: 0.3068945 Test Loss: 0.3240692
Validation loss decreased (0.307302 --> 0.306894).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 6.95855188369751
Epoch: 19, Steps: 30 | Train Loss: 0.2499030 Vali Loss: 0.3047013 Test Loss: 0.3235925
Validation loss decreased (0.306894 --> 0.304701).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 7.038259744644165
Epoch: 20, Steps: 30 | Train Loss: 0.2458374 Vali Loss: 0.3069294 Test Loss: 0.3232388
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 7.708414316177368
Epoch: 21, Steps: 30 | Train Loss: 0.2419707 Vali Loss: 0.3050594 Test Loss: 0.3227841
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 6.83755898475647
Epoch: 22, Steps: 30 | Train Loss: 0.2382353 Vali Loss: 0.3035374 Test Loss: 0.3223717
Validation loss decreased (0.304701 --> 0.303537).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 6.121400356292725
Epoch: 23, Steps: 30 | Train Loss: 0.2354945 Vali Loss: 0.3025023 Test Loss: 0.3219960
Validation loss decreased (0.303537 --> 0.302502).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 6.2056825160980225
Epoch: 24, Steps: 30 | Train Loss: 0.2326568 Vali Loss: 0.3039466 Test Loss: 0.3217121
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 7.405627012252808
Epoch: 25, Steps: 30 | Train Loss: 0.2293046 Vali Loss: 0.3020612 Test Loss: 0.3213286
Validation loss decreased (0.302502 --> 0.302061).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 7.48128080368042
Epoch: 26, Steps: 30 | Train Loss: 0.2273198 Vali Loss: 0.3023453 Test Loss: 0.3210335
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 7.410322904586792
Epoch: 27, Steps: 30 | Train Loss: 0.2246823 Vali Loss: 0.3014126 Test Loss: 0.3206182
Validation loss decreased (0.302061 --> 0.301413).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 7.245438814163208
Epoch: 28, Steps: 30 | Train Loss: 0.2223040 Vali Loss: 0.3015491 Test Loss: 0.3203294
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 7.119267463684082
Epoch: 29, Steps: 30 | Train Loss: 0.2201831 Vali Loss: 0.3001893 Test Loss: 0.3199969
Validation loss decreased (0.301413 --> 0.300189).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 6.984025955200195
Epoch: 30, Steps: 30 | Train Loss: 0.2181862 Vali Loss: 0.3010413 Test Loss: 0.3197157
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 6.795504331588745
Epoch: 31, Steps: 30 | Train Loss: 0.2165576 Vali Loss: 0.2988888 Test Loss: 0.3193968
Validation loss decreased (0.300189 --> 0.298889).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 6.928863048553467
Epoch: 32, Steps: 30 | Train Loss: 0.2145274 Vali Loss: 0.3003670 Test Loss: 0.3191587
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 7.25903844833374
Epoch: 33, Steps: 30 | Train Loss: 0.2132292 Vali Loss: 0.2999465 Test Loss: 0.3188471
EarlyStopping counter: 2 out of 3
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 7.023285627365112
Epoch: 34, Steps: 30 | Train Loss: 0.2108366 Vali Loss: 0.2976515 Test Loss: 0.3185643
Validation loss decreased (0.298889 --> 0.297651).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 7.344196557998657
Epoch: 35, Steps: 30 | Train Loss: 0.2100573 Vali Loss: 0.2984576 Test Loss: 0.3183351
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 7.898113012313843
Epoch: 36, Steps: 30 | Train Loss: 0.2092006 Vali Loss: 0.2983355 Test Loss: 0.3181179
EarlyStopping counter: 2 out of 3
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 8.168780326843262
Epoch: 37, Steps: 30 | Train Loss: 0.2073988 Vali Loss: 0.2967768 Test Loss: 0.3178772
Validation loss decreased (0.297651 --> 0.296777).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 8.087749004364014
Epoch: 38, Steps: 30 | Train Loss: 0.2067931 Vali Loss: 0.2967207 Test Loss: 0.3176236
Validation loss decreased (0.296777 --> 0.296721).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 7.945340633392334
Epoch: 39, Steps: 30 | Train Loss: 0.2056054 Vali Loss: 0.2966440 Test Loss: 0.3174349
Validation loss decreased (0.296721 --> 0.296644).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 7.535725831985474
Epoch: 40, Steps: 30 | Train Loss: 0.2041620 Vali Loss: 0.2946805 Test Loss: 0.3172693
Validation loss decreased (0.296644 --> 0.294680).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 7.967686414718628
Epoch: 41, Steps: 30 | Train Loss: 0.2031809 Vali Loss: 0.2966661 Test Loss: 0.3170728
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 7.427323341369629
Epoch: 42, Steps: 30 | Train Loss: 0.2023528 Vali Loss: 0.2944742 Test Loss: 0.3169004
Validation loss decreased (0.294680 --> 0.294474).  Saving model ...
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 6.893581390380859
Epoch: 43, Steps: 30 | Train Loss: 0.2015209 Vali Loss: 0.2950037 Test Loss: 0.3167034
EarlyStopping counter: 1 out of 3
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 7.103939771652222
Epoch: 44, Steps: 30 | Train Loss: 0.2004021 Vali Loss: 0.2952883 Test Loss: 0.3165469
EarlyStopping counter: 2 out of 3
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 7.010354280471802
Epoch: 45, Steps: 30 | Train Loss: 0.1991619 Vali Loss: 0.2953668 Test Loss: 0.3163949
EarlyStopping counter: 3 out of 3
Early stopping
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=134, out_features=151, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  36259328.0
params:  20385.0
Trainable parameters:  20385
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 7.464326858520508
Epoch: 1, Steps: 30 | Train Loss: 0.4818671 Vali Loss: 0.2615896 Test Loss: 0.2914048
Validation loss decreased (inf --> 0.261590).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 7.2276294231414795
Epoch: 2, Steps: 30 | Train Loss: 0.4471251 Vali Loss: 0.2444434 Test Loss: 0.2802913
Validation loss decreased (0.261590 --> 0.244443).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 7.4329752922058105
Epoch: 3, Steps: 30 | Train Loss: 0.4315263 Vali Loss: 0.2371081 Test Loss: 0.2759292
Validation loss decreased (0.244443 --> 0.237108).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 7.079995632171631
Epoch: 4, Steps: 30 | Train Loss: 0.4218297 Vali Loss: 0.2305742 Test Loss: 0.2746196
Validation loss decreased (0.237108 --> 0.230574).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 6.96741509437561
Epoch: 5, Steps: 30 | Train Loss: 0.4167495 Vali Loss: 0.2278145 Test Loss: 0.2740188
Validation loss decreased (0.230574 --> 0.227814).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 6.695775032043457
Epoch: 6, Steps: 30 | Train Loss: 0.4150224 Vali Loss: 0.2257942 Test Loss: 0.2741631
Validation loss decreased (0.227814 --> 0.225794).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 5.130315542221069
Epoch: 7, Steps: 30 | Train Loss: 0.4130698 Vali Loss: 0.2236127 Test Loss: 0.2741845
Validation loss decreased (0.225794 --> 0.223613).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 5.08221173286438
Epoch: 8, Steps: 30 | Train Loss: 0.4118872 Vali Loss: 0.2214175 Test Loss: 0.2741208
Validation loss decreased (0.223613 --> 0.221418).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.035887718200684
Epoch: 9, Steps: 30 | Train Loss: 0.4112000 Vali Loss: 0.2231147 Test Loss: 0.2740110
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.967214345932007
Epoch: 10, Steps: 30 | Train Loss: 0.4078106 Vali Loss: 0.2208693 Test Loss: 0.2741542
Validation loss decreased (0.221418 --> 0.220869).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 4.158409118652344
Epoch: 11, Steps: 30 | Train Loss: 0.4095384 Vali Loss: 0.2198336 Test Loss: 0.2741102
Validation loss decreased (0.220869 --> 0.219834).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 4.204416036605835
Epoch: 12, Steps: 30 | Train Loss: 0.4088182 Vali Loss: 0.2208250 Test Loss: 0.2742068
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 5.450402736663818
Epoch: 13, Steps: 30 | Train Loss: 0.4076101 Vali Loss: 0.2194290 Test Loss: 0.2741956
Validation loss decreased (0.219834 --> 0.219429).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 5.1555914878845215
Epoch: 14, Steps: 30 | Train Loss: 0.4059575 Vali Loss: 0.2181764 Test Loss: 0.2739851
Validation loss decreased (0.219429 --> 0.218176).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 5.352221250534058
Epoch: 15, Steps: 30 | Train Loss: 0.4089015 Vali Loss: 0.2184935 Test Loss: 0.2741961
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 5.405078172683716
Epoch: 16, Steps: 30 | Train Loss: 0.4057800 Vali Loss: 0.2175235 Test Loss: 0.2740980
Validation loss decreased (0.218176 --> 0.217523).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 5.567007064819336
Epoch: 17, Steps: 30 | Train Loss: 0.4070682 Vali Loss: 0.2191532 Test Loss: 0.2738701
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 6.397387266159058
Epoch: 18, Steps: 30 | Train Loss: 0.4063879 Vali Loss: 0.2170889 Test Loss: 0.2741905
Validation loss decreased (0.217523 --> 0.217089).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 6.080705642700195
Epoch: 19, Steps: 30 | Train Loss: 0.4063247 Vali Loss: 0.2164144 Test Loss: 0.2741481
Validation loss decreased (0.217089 --> 0.216414).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 5.78427791595459
Epoch: 20, Steps: 30 | Train Loss: 0.4010599 Vali Loss: 0.2169064 Test Loss: 0.2740298
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 6.009075880050659
Epoch: 21, Steps: 30 | Train Loss: 0.4053543 Vali Loss: 0.2164707 Test Loss: 0.2742046
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 5.79394006729126
Epoch: 22, Steps: 30 | Train Loss: 0.4051916 Vali Loss: 0.2163766 Test Loss: 0.2739497
Validation loss decreased (0.216414 --> 0.216377).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 5.723507404327393
Epoch: 23, Steps: 30 | Train Loss: 0.4056749 Vali Loss: 0.2161354 Test Loss: 0.2740342
Validation loss decreased (0.216377 --> 0.216135).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 5.554738283157349
Epoch: 24, Steps: 30 | Train Loss: 0.4030272 Vali Loss: 0.2162897 Test Loss: 0.2740497
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 5.268209218978882
Epoch: 25, Steps: 30 | Train Loss: 0.4040692 Vali Loss: 0.2169729 Test Loss: 0.2740692
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 5.293952703475952
Epoch: 26, Steps: 30 | Train Loss: 0.4025041 Vali Loss: 0.2157460 Test Loss: 0.2740238
Validation loss decreased (0.216135 --> 0.215746).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 5.283892393112183
Epoch: 27, Steps: 30 | Train Loss: 0.4033289 Vali Loss: 0.2155067 Test Loss: 0.2740575
Validation loss decreased (0.215746 --> 0.215507).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 5.381211996078491
Epoch: 28, Steps: 30 | Train Loss: 0.4048537 Vali Loss: 0.2152875 Test Loss: 0.2740181
Validation loss decreased (0.215507 --> 0.215288).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 5.341610431671143
Epoch: 29, Steps: 30 | Train Loss: 0.4028983 Vali Loss: 0.2146684 Test Loss: 0.2739471
Validation loss decreased (0.215288 --> 0.214668).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 4.831898927688599
Epoch: 30, Steps: 30 | Train Loss: 0.4026316 Vali Loss: 0.2155112 Test Loss: 0.2740234
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 5.3184731006622314
Epoch: 31, Steps: 30 | Train Loss: 0.4024711 Vali Loss: 0.2159660 Test Loss: 0.2740093
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 5.331915855407715
Epoch: 32, Steps: 30 | Train Loss: 0.4045654 Vali Loss: 0.2150160 Test Loss: 0.2740055
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.2718697488307953, mae:0.33744022250175476, rse:0.4202055037021637, corr:[0.27377063 0.27616683 0.27556995 0.2744281  0.27388635 0.2736482
 0.27321276 0.272194   0.27119032 0.27011353 0.26888934 0.26732954
 0.26585317 0.26487485 0.2641527  0.26367202 0.26317275 0.26252878
 0.26160866 0.26057515 0.2595848  0.25850254 0.2571364  0.2552757
 0.25329357 0.2515647  0.25021046 0.24897884 0.24776734 0.24654658
 0.24522802 0.24377559 0.24219106 0.24085519 0.23982894 0.23879285
 0.23759556 0.23638414 0.23557936 0.23497309 0.23448135 0.23390153
 0.2330419  0.23189896 0.23096882 0.23018484 0.22929673 0.22775774
 0.22561708 0.22358789 0.22237796 0.22132762 0.220275   0.21876924
 0.21652462 0.21443613 0.21285051 0.21144833 0.2100451  0.20876764
 0.20786865 0.20716812 0.20695247 0.20722567 0.20692891 0.20653997
 0.20601663 0.20545141 0.20495571 0.2044993  0.20378885 0.20312959
 0.20248516 0.20170057 0.20075253 0.19906339 0.19771038 0.196963
 0.19683838 0.19618899 0.19582523 0.19559066 0.19491546 0.19422562
 0.19391185 0.19435535 0.1946515  0.194345   0.19286825 0.19182834
 0.1916387  0.19143878 0.19105865 0.19013561 0.1896231  0.19044769]
