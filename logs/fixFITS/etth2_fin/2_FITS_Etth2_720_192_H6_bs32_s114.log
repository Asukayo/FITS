Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=196, out_features=248, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  21776384.0
params:  48856.0
Trainable parameters:  48856
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5670319
	speed: 0.1600s/iter; left time: 944.2063s
Epoch: 1 cost time: 19.154627561569214
Epoch: 1, Steps: 120 | Train Loss: 0.5264059 Vali Loss: 0.4160642 Test Loss: 0.3940651
Validation loss decreased (inf --> 0.416064).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3750910
	speed: 0.4000s/iter; left time: 2312.6383s
Epoch: 2 cost time: 18.550812005996704
Epoch: 2, Steps: 120 | Train Loss: 0.3742024 Vali Loss: 0.3722141 Test Loss: 0.3732083
Validation loss decreased (0.416064 --> 0.372214).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2632206
	speed: 0.3488s/iter; left time: 1974.4032s
Epoch: 3 cost time: 19.003868103027344
Epoch: 3, Steps: 120 | Train Loss: 0.3124531 Vali Loss: 0.3578935 Test Loss: 0.3676469
Validation loss decreased (0.372214 --> 0.357894).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3048734
	speed: 0.4109s/iter; left time: 2276.5562s
Epoch: 4 cost time: 19.096566677093506
Epoch: 4, Steps: 120 | Train Loss: 0.2739717 Vali Loss: 0.3492072 Test Loss: 0.3650095
Validation loss decreased (0.357894 --> 0.349207).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2268422
	speed: 0.4054s/iter; left time: 2197.5562s
Epoch: 5 cost time: 19.025190353393555
Epoch: 5, Steps: 120 | Train Loss: 0.2442694 Vali Loss: 0.3427898 Test Loss: 0.3627955
Validation loss decreased (0.349207 --> 0.342790).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2219382
	speed: 0.4073s/iter; left time: 2159.2230s
Epoch: 6 cost time: 19.029361486434937
Epoch: 6, Steps: 120 | Train Loss: 0.2230847 Vali Loss: 0.3368559 Test Loss: 0.3604787
Validation loss decreased (0.342790 --> 0.336856).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2119811
	speed: 0.4144s/iter; left time: 2147.0336s
Epoch: 7 cost time: 19.508250951766968
Epoch: 7, Steps: 120 | Train Loss: 0.2047491 Vali Loss: 0.3318371 Test Loss: 0.3583705
Validation loss decreased (0.336856 --> 0.331837).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1339261
	speed: 0.4197s/iter; left time: 2124.2980s
Epoch: 8 cost time: 19.62890338897705
Epoch: 8, Steps: 120 | Train Loss: 0.1911886 Vali Loss: 0.3265580 Test Loss: 0.3567216
Validation loss decreased (0.331837 --> 0.326558).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1355103
	speed: 0.4202s/iter; left time: 2076.2300s
Epoch: 9 cost time: 19.678966283798218
Epoch: 9, Steps: 120 | Train Loss: 0.1794692 Vali Loss: 0.3229126 Test Loss: 0.3547333
Validation loss decreased (0.326558 --> 0.322913).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1644191
	speed: 0.4182s/iter; left time: 2015.9930s
Epoch: 10 cost time: 19.38635563850403
Epoch: 10, Steps: 120 | Train Loss: 0.1706053 Vali Loss: 0.3184071 Test Loss: 0.3531888
Validation loss decreased (0.322913 --> 0.318407).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1978804
	speed: 0.4133s/iter; left time: 1943.0484s
Epoch: 11 cost time: 19.248472929000854
Epoch: 11, Steps: 120 | Train Loss: 0.1633788 Vali Loss: 0.3157804 Test Loss: 0.3518176
Validation loss decreased (0.318407 --> 0.315780).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1402728
	speed: 0.3483s/iter; left time: 1595.5559s
Epoch: 12 cost time: 15.011317253112793
Epoch: 12, Steps: 120 | Train Loss: 0.1566426 Vali Loss: 0.3121355 Test Loss: 0.3508052
Validation loss decreased (0.315780 --> 0.312136).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1270395
	speed: 0.4009s/iter; left time: 1788.2070s
Epoch: 13 cost time: 18.22922372817993
Epoch: 13, Steps: 120 | Train Loss: 0.1520769 Vali Loss: 0.3098919 Test Loss: 0.3498867
Validation loss decreased (0.312136 --> 0.309892).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1653940
	speed: 0.3672s/iter; left time: 1594.0571s
Epoch: 14 cost time: 13.878737688064575
Epoch: 14, Steps: 120 | Train Loss: 0.1474381 Vali Loss: 0.3074386 Test Loss: 0.3492077
Validation loss decreased (0.309892 --> 0.307439).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1177018
	speed: 0.4015s/iter; left time: 1694.5930s
Epoch: 15 cost time: 19.020909309387207
Epoch: 15, Steps: 120 | Train Loss: 0.1442862 Vali Loss: 0.3055503 Test Loss: 0.3486072
Validation loss decreased (0.307439 --> 0.305550).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1616713
	speed: 0.4104s/iter; left time: 1683.1369s
Epoch: 16 cost time: 19.17564082145691
Epoch: 16, Steps: 120 | Train Loss: 0.1411435 Vali Loss: 0.3037500 Test Loss: 0.3481219
Validation loss decreased (0.305550 --> 0.303750).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1231558
	speed: 0.4214s/iter; left time: 1677.4104s
Epoch: 17 cost time: 19.371184825897217
Epoch: 17, Steps: 120 | Train Loss: 0.1387103 Vali Loss: 0.3020699 Test Loss: 0.3478591
Validation loss decreased (0.303750 --> 0.302070).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1513968
	speed: 0.3889s/iter; left time: 1501.4128s
Epoch: 18 cost time: 18.183064937591553
Epoch: 18, Steps: 120 | Train Loss: 0.1367995 Vali Loss: 0.3007612 Test Loss: 0.3474918
Validation loss decreased (0.302070 --> 0.300761).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1457856
	speed: 0.4099s/iter; left time: 1533.5613s
Epoch: 19 cost time: 19.183515071868896
Epoch: 19, Steps: 120 | Train Loss: 0.1347187 Vali Loss: 0.2992899 Test Loss: 0.3473604
Validation loss decreased (0.300761 --> 0.299290).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1231510
	speed: 0.4117s/iter; left time: 1490.9019s
Epoch: 20 cost time: 19.33874773979187
Epoch: 20, Steps: 120 | Train Loss: 0.1332238 Vali Loss: 0.2983009 Test Loss: 0.3471555
Validation loss decreased (0.299290 --> 0.298301).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1848097
	speed: 0.3302s/iter; left time: 1155.9220s
Epoch: 21 cost time: 17.85974144935608
Epoch: 21, Steps: 120 | Train Loss: 0.1318117 Vali Loss: 0.2973945 Test Loss: 0.3469884
Validation loss decreased (0.298301 --> 0.297394).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1949152
	speed: 0.4176s/iter; left time: 1411.9880s
Epoch: 22 cost time: 19.280271530151367
Epoch: 22, Steps: 120 | Train Loss: 0.1304955 Vali Loss: 0.2966855 Test Loss: 0.3468034
Validation loss decreased (0.297394 --> 0.296685).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.0813186
	speed: 0.4135s/iter; left time: 1348.4475s
Epoch: 23 cost time: 18.879831552505493
Epoch: 23, Steps: 120 | Train Loss: 0.1298336 Vali Loss: 0.2958333 Test Loss: 0.3468297
Validation loss decreased (0.296685 --> 0.295833).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1233120
	speed: 0.4006s/iter; left time: 1258.4030s
Epoch: 24 cost time: 19.1047260761261
Epoch: 24, Steps: 120 | Train Loss: 0.1290887 Vali Loss: 0.2951007 Test Loss: 0.3467349
Validation loss decreased (0.295833 --> 0.295101).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1786215
	speed: 0.4035s/iter; left time: 1219.1164s
Epoch: 25 cost time: 18.33885955810547
Epoch: 25, Steps: 120 | Train Loss: 0.1284917 Vali Loss: 0.2945192 Test Loss: 0.3465945
Validation loss decreased (0.295101 --> 0.294519).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.0897430
	speed: 0.3987s/iter; left time: 1156.6505s
Epoch: 26 cost time: 18.704578161239624
Epoch: 26, Steps: 120 | Train Loss: 0.1279060 Vali Loss: 0.2937461 Test Loss: 0.3468554
Validation loss decreased (0.294519 --> 0.293746).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.0989151
	speed: 0.4175s/iter; left time: 1161.0447s
Epoch: 27 cost time: 19.404465913772583
Epoch: 27, Steps: 120 | Train Loss: 0.1272525 Vali Loss: 0.2932788 Test Loss: 0.3466325
Validation loss decreased (0.293746 --> 0.293279).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1223786
	speed: 0.3920s/iter; left time: 1043.1619s
Epoch: 28 cost time: 17.72995138168335
Epoch: 28, Steps: 120 | Train Loss: 0.1266870 Vali Loss: 0.2929063 Test Loss: 0.3466543
Validation loss decreased (0.293279 --> 0.292906).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1153985
	speed: 0.3919s/iter; left time: 995.8736s
Epoch: 29 cost time: 18.101283073425293
Epoch: 29, Steps: 120 | Train Loss: 0.1259330 Vali Loss: 0.2923134 Test Loss: 0.3466869
Validation loss decreased (0.292906 --> 0.292313).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1573246
	speed: 0.4100s/iter; left time: 992.5965s
Epoch: 30 cost time: 19.1794171333313
Epoch: 30, Steps: 120 | Train Loss: 0.1258906 Vali Loss: 0.2919769 Test Loss: 0.3468383
Validation loss decreased (0.292313 --> 0.291977).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1388277
	speed: 0.3983s/iter; left time: 916.3952s
Epoch: 31 cost time: 18.876391649246216
Epoch: 31, Steps: 120 | Train Loss: 0.1256114 Vali Loss: 0.2918015 Test Loss: 0.3467892
Validation loss decreased (0.291977 --> 0.291801).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1172308
	speed: 0.3366s/iter; left time: 734.1414s
Epoch: 32 cost time: 17.606929540634155
Epoch: 32, Steps: 120 | Train Loss: 0.1254422 Vali Loss: 0.2915049 Test Loss: 0.3467645
Validation loss decreased (0.291801 --> 0.291505).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1041727
	speed: 0.3878s/iter; left time: 799.2462s
Epoch: 33 cost time: 18.450542211532593
Epoch: 33, Steps: 120 | Train Loss: 0.1250061 Vali Loss: 0.2912118 Test Loss: 0.3468499
Validation loss decreased (0.291505 --> 0.291212).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1515928
	speed: 0.3992s/iter; left time: 774.8606s
Epoch: 34 cost time: 18.730863332748413
Epoch: 34, Steps: 120 | Train Loss: 0.1244373 Vali Loss: 0.2908961 Test Loss: 0.3468646
Validation loss decreased (0.291212 --> 0.290896).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1588325
	speed: 0.3873s/iter; left time: 705.3170s
Epoch: 35 cost time: 17.637964963912964
Epoch: 35, Steps: 120 | Train Loss: 0.1250444 Vali Loss: 0.2907820 Test Loss: 0.3469141
Validation loss decreased (0.290896 --> 0.290782).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1411754
	speed: 0.3824s/iter; left time: 650.5449s
Epoch: 36 cost time: 18.383021593093872
Epoch: 36, Steps: 120 | Train Loss: 0.1244763 Vali Loss: 0.2905982 Test Loss: 0.3468731
Validation loss decreased (0.290782 --> 0.290598).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1065237
	speed: 0.3912s/iter; left time: 618.4292s
Epoch: 37 cost time: 17.05734658241272
Epoch: 37, Steps: 120 | Train Loss: 0.1243055 Vali Loss: 0.2902581 Test Loss: 0.3470701
Validation loss decreased (0.290598 --> 0.290258).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1250067
	speed: 0.3722s/iter; left time: 543.8487s
Epoch: 38 cost time: 17.44800329208374
Epoch: 38, Steps: 120 | Train Loss: 0.1243162 Vali Loss: 0.2901061 Test Loss: 0.3470218
Validation loss decreased (0.290258 --> 0.290106).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1349941
	speed: 0.3834s/iter; left time: 514.1786s
Epoch: 39 cost time: 17.827153205871582
Epoch: 39, Steps: 120 | Train Loss: 0.1245149 Vali Loss: 0.2900158 Test Loss: 0.3470182
Validation loss decreased (0.290106 --> 0.290016).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1216756
	speed: 0.3720s/iter; left time: 454.1740s
Epoch: 40 cost time: 17.405149221420288
Epoch: 40, Steps: 120 | Train Loss: 0.1242031 Vali Loss: 0.2898012 Test Loss: 0.3470750
Validation loss decreased (0.290016 --> 0.289801).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1518037
	speed: 0.3906s/iter; left time: 430.0756s
Epoch: 41 cost time: 18.048311710357666
Epoch: 41, Steps: 120 | Train Loss: 0.1240259 Vali Loss: 0.2893574 Test Loss: 0.3471610
Validation loss decreased (0.289801 --> 0.289357).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1220394
	speed: 0.3715s/iter; left time: 364.4075s
Epoch: 42 cost time: 17.01179313659668
Epoch: 42, Steps: 120 | Train Loss: 0.1240696 Vali Loss: 0.2895806 Test Loss: 0.3470959
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1323796
	speed: 0.3659s/iter; left time: 315.0228s
Epoch: 43 cost time: 17.253424167633057
Epoch: 43, Steps: 120 | Train Loss: 0.1234602 Vali Loss: 0.2894565 Test Loss: 0.3471697
EarlyStopping counter: 2 out of 3
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1800616
	speed: 0.3763s/iter; left time: 278.8520s
Epoch: 44 cost time: 17.07537579536438
Epoch: 44, Steps: 120 | Train Loss: 0.1236637 Vali Loss: 0.2893060 Test Loss: 0.3471920
Validation loss decreased (0.289357 --> 0.289306).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.1500902
	speed: 0.3612s/iter; left time: 224.3318s
Epoch: 45 cost time: 17.251800537109375
Epoch: 45, Steps: 120 | Train Loss: 0.1236949 Vali Loss: 0.2892342 Test Loss: 0.3471698
Validation loss decreased (0.289306 --> 0.289234).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.0965060
	speed: 0.3727s/iter; left time: 186.7467s
Epoch: 46 cost time: 17.311567544937134
Epoch: 46, Steps: 120 | Train Loss: 0.1235492 Vali Loss: 0.2891126 Test Loss: 0.3472583
Validation loss decreased (0.289234 --> 0.289113).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1113065
	speed: 0.3639s/iter; left time: 138.6553s
Epoch: 47 cost time: 17.05096697807312
Epoch: 47, Steps: 120 | Train Loss: 0.1237724 Vali Loss: 0.2891023 Test Loss: 0.3472564
Validation loss decreased (0.289113 --> 0.289102).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1680937
	speed: 0.3788s/iter; left time: 98.8619s
Epoch: 48 cost time: 17.715248584747314
Epoch: 48, Steps: 120 | Train Loss: 0.1230779 Vali Loss: 0.2890180 Test Loss: 0.3472911
Validation loss decreased (0.289102 --> 0.289018).  Saving model ...
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1188074
	speed: 0.3724s/iter; left time: 52.5146s
Epoch: 49 cost time: 16.98402190208435
Epoch: 49, Steps: 120 | Train Loss: 0.1236571 Vali Loss: 0.2889166 Test Loss: 0.3472971
Validation loss decreased (0.289018 --> 0.288917).  Saving model ...
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1330756
	speed: 0.3816s/iter; left time: 8.0145s
Epoch: 50 cost time: 17.647215127944946
Epoch: 50, Steps: 120 | Train Loss: 0.1232657 Vali Loss: 0.2889698 Test Loss: 0.3472942
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.0497355408796396e-05
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=196, out_features=248, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  21776384.0
params:  48856.0
Trainable parameters:  48856
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5379001
	speed: 0.1543s/iter; left time: 910.6083s
Epoch: 1 cost time: 18.24834442138672
Epoch: 1, Steps: 120 | Train Loss: 0.5178309 Vali Loss: 0.2855599 Test Loss: 0.3449128
Validation loss decreased (inf --> 0.285560).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4097751
	speed: 0.3596s/iter; left time: 2079.0888s
Epoch: 2 cost time: 16.7578182220459
Epoch: 2, Steps: 120 | Train Loss: 0.5137172 Vali Loss: 0.2824933 Test Loss: 0.3439687
Validation loss decreased (0.285560 --> 0.282493).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2404675
	speed: 0.3446s/iter; left time: 1951.0156s
Epoch: 3 cost time: 13.593419075012207
Epoch: 3, Steps: 120 | Train Loss: 0.5122044 Vali Loss: 0.2821812 Test Loss: 0.3441136
Validation loss decreased (0.282493 --> 0.282181).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3817472
	speed: 0.3378s/iter; left time: 1871.8449s
Epoch: 4 cost time: 16.80963897705078
Epoch: 4, Steps: 120 | Train Loss: 0.5117582 Vali Loss: 0.2820233 Test Loss: 0.3435689
Validation loss decreased (0.282181 --> 0.282023).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.5198029
	speed: 0.3848s/iter; left time: 2086.1264s
Epoch: 5 cost time: 18.37304377555847
Epoch: 5, Steps: 120 | Train Loss: 0.5110835 Vali Loss: 0.2810367 Test Loss: 0.3430728
Validation loss decreased (0.282023 --> 0.281037).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5245305
	speed: 0.3776s/iter; left time: 2001.4770s
Epoch: 6 cost time: 17.602278470993042
Epoch: 6, Steps: 120 | Train Loss: 0.5096671 Vali Loss: 0.2811212 Test Loss: 0.3429262
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.7421552
	speed: 0.3548s/iter; left time: 1838.3571s
Epoch: 7 cost time: 18.0447518825531
Epoch: 7, Steps: 120 | Train Loss: 0.5086337 Vali Loss: 0.2803193 Test Loss: 0.3429052
Validation loss decreased (0.281037 --> 0.280319).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.5290626
	speed: 0.3780s/iter; left time: 1912.9639s
Epoch: 8 cost time: 17.2358136177063
Epoch: 8, Steps: 120 | Train Loss: 0.5095344 Vali Loss: 0.2800157 Test Loss: 0.3425776
Validation loss decreased (0.280319 --> 0.280016).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3454459
	speed: 0.3678s/iter; left time: 1817.2557s
Epoch: 9 cost time: 16.981019258499146
Epoch: 9, Steps: 120 | Train Loss: 0.5092584 Vali Loss: 0.2801701 Test Loss: 0.3422231
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.5426562
	speed: 0.3811s/iter; left time: 1837.0672s
Epoch: 10 cost time: 17.573928594589233
Epoch: 10, Steps: 120 | Train Loss: 0.5082440 Vali Loss: 0.2801152 Test Loss: 0.3422529
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.5283564
	speed: 0.3744s/iter; left time: 1759.8991s
Epoch: 11 cost time: 17.200339555740356
Epoch: 11, Steps: 120 | Train Loss: 0.5085498 Vali Loss: 0.2799934 Test Loss: 0.3420583
Validation loss decreased (0.280016 --> 0.279993).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4913905
	speed: 0.3838s/iter; left time: 1758.3768s
Epoch: 12 cost time: 17.867581605911255
Epoch: 12, Steps: 120 | Train Loss: 0.5087560 Vali Loss: 0.2800361 Test Loss: 0.3419403
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.7493762
	speed: 0.3823s/iter; left time: 1705.5385s
Epoch: 13 cost time: 17.608093976974487
Epoch: 13, Steps: 120 | Train Loss: 0.5075288 Vali Loss: 0.2794291 Test Loss: 0.3421869
Validation loss decreased (0.279993 --> 0.279429).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.7527904
	speed: 0.3828s/iter; left time: 1661.5684s
Epoch: 14 cost time: 17.747844696044922
Epoch: 14, Steps: 120 | Train Loss: 0.5072424 Vali Loss: 0.2794649 Test Loss: 0.3421151
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4403981
	speed: 0.3816s/iter; left time: 1610.5930s
Epoch: 15 cost time: 17.741721153259277
Epoch: 15, Steps: 120 | Train Loss: 0.5075082 Vali Loss: 0.2794763 Test Loss: 0.3419355
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.6952764
	speed: 0.3475s/iter; left time: 1425.1537s
Epoch: 16 cost time: 18.116962432861328
Epoch: 16, Steps: 120 | Train Loss: 0.5063858 Vali Loss: 0.2791063 Test Loss: 0.3419284
Validation loss decreased (0.279429 --> 0.279106).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.6451327
	speed: 0.4252s/iter; left time: 1692.7949s
Epoch: 17 cost time: 19.476035118103027
Epoch: 17, Steps: 120 | Train Loss: 0.5072720 Vali Loss: 0.2788295 Test Loss: 0.3420465
Validation loss decreased (0.279106 --> 0.278830).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.3993720
	speed: 0.3969s/iter; left time: 1532.4986s
Epoch: 18 cost time: 18.20005965232849
Epoch: 18, Steps: 120 | Train Loss: 0.5058590 Vali Loss: 0.2791731 Test Loss: 0.3418827
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.5811532
	speed: 0.4173s/iter; left time: 1561.0800s
Epoch: 19 cost time: 19.965240955352783
Epoch: 19, Steps: 120 | Train Loss: 0.5065903 Vali Loss: 0.2790532 Test Loss: 0.3418748
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4623040
	speed: 0.4087s/iter; left time: 1479.8252s
Epoch: 20 cost time: 18.29751205444336
Epoch: 20, Steps: 120 | Train Loss: 0.5064280 Vali Loss: 0.2788937 Test Loss: 0.3416888
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.33196043968200684, mae:0.3745401203632355, rse:0.46204471588134766, corr:[0.26602888 0.26893947 0.26751474 0.2676194  0.26703897 0.26600072
 0.26592    0.26558664 0.26423562 0.2628442  0.26200452 0.26064435
 0.25871348 0.25728014 0.2568965  0.2568812  0.2565878  0.25626752
 0.25571495 0.25446883 0.252852   0.251667   0.25064364 0.24891524
 0.24677499 0.24500515 0.24322607 0.24074087 0.23875009 0.23815891
 0.23783234 0.2364188  0.23493756 0.23405245 0.2327588  0.23096517
 0.23010564 0.23000202 0.22887756 0.22687036 0.2259376  0.22605987
 0.22573379 0.22481397 0.2240654  0.22326969 0.22199239 0.22042581
 0.21889403 0.21705411 0.2149619  0.21340816 0.21245426 0.21056615
 0.20771319 0.20574237 0.20451659 0.202968   0.20144711 0.20028628
 0.19941385 0.19885051 0.1990386  0.19938663 0.19897516 0.1984174
 0.19761135 0.19635391 0.19531673 0.19499223 0.19478787 0.19401014
 0.19280277 0.19189477 0.19121037 0.19026682 0.18961856 0.1889673
 0.18777344 0.18658048 0.18687715 0.18728714 0.18639527 0.1850772
 0.1844375  0.1841302  0.18362848 0.1839078  0.18474056 0.1847819
 0.18329923 0.18190013 0.18227158 0.18271612 0.18200172 0.18100381
 0.18057539 0.18002558 0.1785374  0.17656167 0.1751483  0.17441118
 0.17387612 0.17256841 0.17116383 0.17066106 0.17131689 0.17219967
 0.1717953  0.1709067  0.1701874  0.1697286  0.16905813 0.16896354
 0.1689468  0.16813128 0.1668692  0.1655674  0.16444103 0.16304515
 0.16211298 0.16163668 0.16100942 0.15961862 0.15799104 0.15662321
 0.15533625 0.15410204 0.15376739 0.15365474 0.15281478 0.15128745
 0.15031968 0.14988974 0.14963746 0.1496646  0.14938153 0.14846854
 0.14745633 0.14701931 0.14683652 0.14636543 0.14614178 0.1457028
 0.14399426 0.14210656 0.14118846 0.14006361 0.13752587 0.13528998
 0.13528268 0.13529383 0.1347056  0.1345883  0.13500877 0.13437197
 0.1334236  0.13382022 0.13483511 0.13493128 0.13426922 0.13469324
 0.13469627 0.13343954 0.13337408 0.13472462 0.13485135 0.13308449
 0.1324152  0.13239217 0.131275   0.12953538 0.12920374 0.12794502
 0.12524976 0.12368152 0.12411608 0.12383378 0.12195282 0.12196907
 0.12228063 0.12075837 0.12022346 0.12166569 0.12113122 0.12066235
 0.12325463 0.12360183 0.12031567 0.12068091 0.12273446 0.11197054]
