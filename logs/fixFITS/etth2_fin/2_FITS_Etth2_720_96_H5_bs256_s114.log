Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=512, c_out=7, checkpoints='./checkpoints/', cut_freq=165, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=165, out_features=187, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  110584320.0
params:  31042.0
Trainable parameters:  31042
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.9225480556488037
Epoch: 1, Steps: 15 | Train Loss: 0.6381727 Vali Loss: 0.4772555 Test Loss: 0.4910902
Validation loss decreased (inf --> 0.477255).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.8262879848480225
Epoch: 2, Steps: 15 | Train Loss: 0.5769718 Vali Loss: 0.4347469 Test Loss: 0.4610330
Validation loss decreased (0.477255 --> 0.434747).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.8775079250335693
Epoch: 3, Steps: 15 | Train Loss: 0.5295692 Vali Loss: 0.4130752 Test Loss: 0.4384516
Validation loss decreased (0.434747 --> 0.413075).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.9880564212799072
Epoch: 4, Steps: 15 | Train Loss: 0.4963983 Vali Loss: 0.3905143 Test Loss: 0.4214218
Validation loss decreased (0.413075 --> 0.390514).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.2775323390960693
Epoch: 5, Steps: 15 | Train Loss: 0.4702568 Vali Loss: 0.3767265 Test Loss: 0.4083277
Validation loss decreased (0.390514 --> 0.376727).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.9874212741851807
Epoch: 6, Steps: 15 | Train Loss: 0.4459163 Vali Loss: 0.3686601 Test Loss: 0.3986801
Validation loss decreased (0.376727 --> 0.368660).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.238211154937744
Epoch: 7, Steps: 15 | Train Loss: 0.4296353 Vali Loss: 0.3583086 Test Loss: 0.3911481
Validation loss decreased (0.368660 --> 0.358309).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.3121278285980225
Epoch: 8, Steps: 15 | Train Loss: 0.4148803 Vali Loss: 0.3519725 Test Loss: 0.3854529
Validation loss decreased (0.358309 --> 0.351972).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.1564011573791504
Epoch: 9, Steps: 15 | Train Loss: 0.4008002 Vali Loss: 0.3479187 Test Loss: 0.3809158
Validation loss decreased (0.351972 --> 0.347919).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.2464616298675537
Epoch: 10, Steps: 15 | Train Loss: 0.3907121 Vali Loss: 0.3455629 Test Loss: 0.3774956
Validation loss decreased (0.347919 --> 0.345563).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.1254611015319824
Epoch: 11, Steps: 15 | Train Loss: 0.3803103 Vali Loss: 0.3415055 Test Loss: 0.3748479
Validation loss decreased (0.345563 --> 0.341506).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.054293155670166
Epoch: 12, Steps: 15 | Train Loss: 0.3722829 Vali Loss: 0.3397209 Test Loss: 0.3726547
Validation loss decreased (0.341506 --> 0.339721).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.2304184436798096
Epoch: 13, Steps: 15 | Train Loss: 0.3651840 Vali Loss: 0.3386514 Test Loss: 0.3709216
Validation loss decreased (0.339721 --> 0.338651).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.150787115097046
Epoch: 14, Steps: 15 | Train Loss: 0.3578387 Vali Loss: 0.3376625 Test Loss: 0.3695510
Validation loss decreased (0.338651 --> 0.337662).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.9402403831481934
Epoch: 15, Steps: 15 | Train Loss: 0.3518265 Vali Loss: 0.3343881 Test Loss: 0.3684413
Validation loss decreased (0.337662 --> 0.334388).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.3068480491638184
Epoch: 16, Steps: 15 | Train Loss: 0.3470715 Vali Loss: 0.3352027 Test Loss: 0.3675485
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.940702438354492
Epoch: 17, Steps: 15 | Train Loss: 0.3421810 Vali Loss: 0.3324416 Test Loss: 0.3667215
Validation loss decreased (0.334388 --> 0.332442).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.89359712600708
Epoch: 18, Steps: 15 | Train Loss: 0.3376536 Vali Loss: 0.3309469 Test Loss: 0.3660546
Validation loss decreased (0.332442 --> 0.330947).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.930912733078003
Epoch: 19, Steps: 15 | Train Loss: 0.3347769 Vali Loss: 0.3318840 Test Loss: 0.3655293
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.9746828079223633
Epoch: 20, Steps: 15 | Train Loss: 0.3292086 Vali Loss: 0.3310058 Test Loss: 0.3650993
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.978170394897461
Epoch: 21, Steps: 15 | Train Loss: 0.3273967 Vali Loss: 0.3316110 Test Loss: 0.3647157
EarlyStopping counter: 3 out of 3
Early stopping
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=165, out_features=187, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  110584320.0
params:  31042.0
Trainable parameters:  31042
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.4304890632629395
Epoch: 1, Steps: 15 | Train Loss: 0.5279804 Vali Loss: 0.3005617 Test Loss: 0.3384204
Validation loss decreased (inf --> 0.300562).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.5436179637908936
Epoch: 2, Steps: 15 | Train Loss: 0.4961045 Vali Loss: 0.2831549 Test Loss: 0.3229837
Validation loss decreased (0.300562 --> 0.283155).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.4143800735473633
Epoch: 3, Steps: 15 | Train Loss: 0.4761513 Vali Loss: 0.2709388 Test Loss: 0.3137110
Validation loss decreased (0.283155 --> 0.270939).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.4654998779296875
Epoch: 4, Steps: 15 | Train Loss: 0.4585438 Vali Loss: 0.2613271 Test Loss: 0.3076471
Validation loss decreased (0.270939 --> 0.261327).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.477111339569092
Epoch: 5, Steps: 15 | Train Loss: 0.4507351 Vali Loss: 0.2554848 Test Loss: 0.3036074
Validation loss decreased (0.261327 --> 0.255485).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.405884265899658
Epoch: 6, Steps: 15 | Train Loss: 0.4460416 Vali Loss: 0.2512048 Test Loss: 0.3007855
Validation loss decreased (0.255485 --> 0.251205).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.476283073425293
Epoch: 7, Steps: 15 | Train Loss: 0.4416706 Vali Loss: 0.2475530 Test Loss: 0.2989620
Validation loss decreased (0.251205 --> 0.247553).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.4446489810943604
Epoch: 8, Steps: 15 | Train Loss: 0.4350823 Vali Loss: 0.2432123 Test Loss: 0.2976980
Validation loss decreased (0.247553 --> 0.243212).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.7753069400787354
Epoch: 9, Steps: 15 | Train Loss: 0.4328178 Vali Loss: 0.2422771 Test Loss: 0.2965262
Validation loss decreased (0.243212 --> 0.242277).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.1168806552886963
Epoch: 10, Steps: 15 | Train Loss: 0.4297538 Vali Loss: 0.2385657 Test Loss: 0.2957204
Validation loss decreased (0.242277 --> 0.238566).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.9442875385284424
Epoch: 11, Steps: 15 | Train Loss: 0.4277749 Vali Loss: 0.2367499 Test Loss: 0.2950394
Validation loss decreased (0.238566 --> 0.236750).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.0999271869659424
Epoch: 12, Steps: 15 | Train Loss: 0.4257902 Vali Loss: 0.2377237 Test Loss: 0.2946144
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.1237599849700928
Epoch: 13, Steps: 15 | Train Loss: 0.4248128 Vali Loss: 0.2360355 Test Loss: 0.2941692
Validation loss decreased (0.236750 --> 0.236036).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.9789063930511475
Epoch: 14, Steps: 15 | Train Loss: 0.4231824 Vali Loss: 0.2343779 Test Loss: 0.2937548
Validation loss decreased (0.236036 --> 0.234378).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.9697530269622803
Epoch: 15, Steps: 15 | Train Loss: 0.4214617 Vali Loss: 0.2325764 Test Loss: 0.2935580
Validation loss decreased (0.234378 --> 0.232576).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.9983437061309814
Epoch: 16, Steps: 15 | Train Loss: 0.4177855 Vali Loss: 0.2309323 Test Loss: 0.2933915
Validation loss decreased (0.232576 --> 0.230932).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.0415940284729004
Epoch: 17, Steps: 15 | Train Loss: 0.4180447 Vali Loss: 0.2305940 Test Loss: 0.2930311
Validation loss decreased (0.230932 --> 0.230594).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.826117753982544
Epoch: 18, Steps: 15 | Train Loss: 0.4206615 Vali Loss: 0.2316987 Test Loss: 0.2927293
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 3.1090593338012695
Epoch: 19, Steps: 15 | Train Loss: 0.4184909 Vali Loss: 0.2316907 Test Loss: 0.2925793
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.794886350631714
Epoch: 20, Steps: 15 | Train Loss: 0.4181479 Vali Loss: 0.2292624 Test Loss: 0.2924923
Validation loss decreased (0.230594 --> 0.229262).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.174189329147339
Epoch: 21, Steps: 15 | Train Loss: 0.4160227 Vali Loss: 0.2283305 Test Loss: 0.2922895
Validation loss decreased (0.229262 --> 0.228330).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.1761374473571777
Epoch: 22, Steps: 15 | Train Loss: 0.4162947 Vali Loss: 0.2277216 Test Loss: 0.2922130
Validation loss decreased (0.228330 --> 0.227722).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.047848701477051
Epoch: 23, Steps: 15 | Train Loss: 0.4137737 Vali Loss: 0.2298717 Test Loss: 0.2920302
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.9944205284118652
Epoch: 24, Steps: 15 | Train Loss: 0.4153366 Vali Loss: 0.2290577 Test Loss: 0.2919142
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 3.148953914642334
Epoch: 25, Steps: 15 | Train Loss: 0.4163032 Vali Loss: 0.2275687 Test Loss: 0.2918062
Validation loss decreased (0.227722 --> 0.227569).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.073575735092163
Epoch: 26, Steps: 15 | Train Loss: 0.4142332 Vali Loss: 0.2274394 Test Loss: 0.2917905
Validation loss decreased (0.227569 --> 0.227439).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.9206459522247314
Epoch: 27, Steps: 15 | Train Loss: 0.4118293 Vali Loss: 0.2259258 Test Loss: 0.2916902
Validation loss decreased (0.227439 --> 0.225926).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.1183552742004395
Epoch: 28, Steps: 15 | Train Loss: 0.4155157 Vali Loss: 0.2263071 Test Loss: 0.2915777
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.8294875621795654
Epoch: 29, Steps: 15 | Train Loss: 0.4120233 Vali Loss: 0.2277385 Test Loss: 0.2914716
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 3.022151470184326
Epoch: 30, Steps: 15 | Train Loss: 0.4119333 Vali Loss: 0.2273613 Test Loss: 0.2914715
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.27134770154953003, mae:0.3394573926925659, rse:0.41980186104774475, corr:[0.27252233 0.2775303  0.2760927  0.2756542  0.2757511  0.27492216
 0.2737891  0.2731665  0.27244648 0.27112934 0.2697055  0.2683082
 0.26688656 0.26565233 0.26475504 0.26419398 0.26362976 0.26302013
 0.26220322 0.26109505 0.25987414 0.25867304 0.2573919  0.25568146
 0.25374988 0.25202614 0.25066328 0.24931215 0.24795699 0.24664642
 0.24534486 0.24393097 0.24247448 0.2413239  0.24020585 0.23888366
 0.23756865 0.23654653 0.23582289 0.23496397 0.23409128 0.23354289
 0.23317885 0.23243257 0.23140775 0.2304715  0.22977708 0.22846805
 0.22626138 0.22404754 0.22279032 0.22182867 0.22081546 0.21935147
 0.2174559  0.21601827 0.21449645 0.2123757  0.21037221 0.20940074
 0.20922504 0.20868567 0.2081573  0.20850332 0.20868026 0.2084198
 0.2075017  0.20674269 0.20676899 0.20679224 0.20582956 0.20459384
 0.2039593  0.20359328 0.20267595 0.20070568 0.19956084 0.19926919
 0.19890636 0.19739734 0.19693033 0.1974611  0.19712567 0.19588944
 0.19508386 0.19586995 0.19657162 0.19601215 0.19409855 0.1935341
 0.19388768 0.19265488 0.19029506 0.18859318 0.18839447 0.18345982]
