Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_336', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=336, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_336_FITS_ETTh2_ftM_sl720_ll48_pl336_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=134, out_features=196, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  11766272.0
params:  26460.0
Trainable parameters:  26460
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5066626
	speed: 0.1084s/iter; left time: 628.7968s
Epoch: 1 cost time: 12.885819435119629
Epoch: 1, Steps: 118 | Train Loss: 0.5989012 Vali Loss: 0.5286500 Test Loss: 0.4080141
Validation loss decreased (inf --> 0.528650).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4675792
	speed: 0.2699s/iter; left time: 1533.8010s
Epoch: 2 cost time: 12.584692001342773
Epoch: 2, Steps: 118 | Train Loss: 0.4361695 Vali Loss: 0.4728939 Test Loss: 0.3853675
Validation loss decreased (0.528650 --> 0.472894).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3384261
	speed: 0.2658s/iter; left time: 1479.1792s
Epoch: 3 cost time: 13.103423833847046
Epoch: 3, Steps: 118 | Train Loss: 0.3725884 Vali Loss: 0.4469683 Test Loss: 0.3795410
Validation loss decreased (0.472894 --> 0.446968).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3257452
	speed: 0.2649s/iter; left time: 1442.7871s
Epoch: 4 cost time: 12.644060611724854
Epoch: 4, Steps: 118 | Train Loss: 0.3346577 Vali Loss: 0.4353347 Test Loss: 0.3767434
Validation loss decreased (0.446968 --> 0.435335).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2932463
	speed: 0.3189s/iter; left time: 1699.5396s
Epoch: 5 cost time: 15.015573263168335
Epoch: 5, Steps: 118 | Train Loss: 0.3090331 Vali Loss: 0.4268773 Test Loss: 0.3747022
Validation loss decreased (0.435335 --> 0.426877).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2717617
	speed: 0.3161s/iter; left time: 1646.9581s
Epoch: 6 cost time: 14.765057802200317
Epoch: 6, Steps: 118 | Train Loss: 0.2902523 Vali Loss: 0.4206438 Test Loss: 0.3726254
Validation loss decreased (0.426877 --> 0.420644).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3210993
	speed: 0.3208s/iter; left time: 1633.8216s
Epoch: 7 cost time: 14.269289255142212
Epoch: 7, Steps: 118 | Train Loss: 0.2755717 Vali Loss: 0.4158182 Test Loss: 0.3711616
Validation loss decreased (0.420644 --> 0.415818).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2900869
	speed: 0.2666s/iter; left time: 1326.3694s
Epoch: 8 cost time: 13.809707164764404
Epoch: 8, Steps: 118 | Train Loss: 0.2639796 Vali Loss: 0.4103644 Test Loss: 0.3695239
Validation loss decreased (0.415818 --> 0.410364).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2259889
	speed: 0.2911s/iter; left time: 1413.7530s
Epoch: 9 cost time: 13.926487445831299
Epoch: 9, Steps: 118 | Train Loss: 0.2544337 Vali Loss: 0.4072991 Test Loss: 0.3685696
Validation loss decreased (0.410364 --> 0.407299).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2601448
	speed: 0.3058s/iter; left time: 1449.1316s
Epoch: 10 cost time: 14.46188998222351
Epoch: 10, Steps: 118 | Train Loss: 0.2477445 Vali Loss: 0.4045123 Test Loss: 0.3676871
Validation loss decreased (0.407299 --> 0.404512).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2381609
	speed: 0.2873s/iter; left time: 1327.8093s
Epoch: 11 cost time: 14.263538360595703
Epoch: 11, Steps: 118 | Train Loss: 0.2415764 Vali Loss: 0.4004886 Test Loss: 0.3666632
Validation loss decreased (0.404512 --> 0.400489).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2107759
	speed: 0.2952s/iter; left time: 1329.5092s
Epoch: 12 cost time: 14.096293687820435
Epoch: 12, Steps: 118 | Train Loss: 0.2376208 Vali Loss: 0.3998483 Test Loss: 0.3659922
Validation loss decreased (0.400489 --> 0.399848).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2169646
	speed: 0.2904s/iter; left time: 1273.5361s
Epoch: 13 cost time: 14.110042572021484
Epoch: 13, Steps: 118 | Train Loss: 0.2339032 Vali Loss: 0.3977891 Test Loss: 0.3655969
Validation loss decreased (0.399848 --> 0.397789).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1986113
	speed: 0.2590s/iter; left time: 1105.1331s
Epoch: 14 cost time: 10.0205717086792
Epoch: 14, Steps: 118 | Train Loss: 0.2311355 Vali Loss: 0.3951802 Test Loss: 0.3652711
Validation loss decreased (0.397789 --> 0.395180).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3454649
	speed: 0.2370s/iter; left time: 983.4877s
Epoch: 15 cost time: 13.623878479003906
Epoch: 15, Steps: 118 | Train Loss: 0.2291134 Vali Loss: 0.3939266 Test Loss: 0.3649964
Validation loss decreased (0.395180 --> 0.393927).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2022797
	speed: 0.3022s/iter; left time: 1218.2232s
Epoch: 16 cost time: 14.595020532608032
Epoch: 16, Steps: 118 | Train Loss: 0.2269399 Vali Loss: 0.3932898 Test Loss: 0.3646418
Validation loss decreased (0.393927 --> 0.393290).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1871372
	speed: 0.3037s/iter; left time: 1188.1883s
Epoch: 17 cost time: 14.74490737915039
Epoch: 17, Steps: 118 | Train Loss: 0.2252871 Vali Loss: 0.3918898 Test Loss: 0.3645964
Validation loss decreased (0.393290 --> 0.391890).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2729655
	speed: 0.3039s/iter; left time: 1153.2793s
Epoch: 18 cost time: 14.060276508331299
Epoch: 18, Steps: 118 | Train Loss: 0.2240935 Vali Loss: 0.3889145 Test Loss: 0.3645017
Validation loss decreased (0.391890 --> 0.388914).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2547304
	speed: 0.2900s/iter; left time: 1066.2580s
Epoch: 19 cost time: 14.077765226364136
Epoch: 19, Steps: 118 | Train Loss: 0.2231406 Vali Loss: 0.3916318 Test Loss: 0.3645104
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2400695
	speed: 0.2855s/iter; left time: 1015.9977s
Epoch: 20 cost time: 14.363069295883179
Epoch: 20, Steps: 118 | Train Loss: 0.2215754 Vali Loss: 0.3911691 Test Loss: 0.3643044
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1923820
	speed: 0.2933s/iter; left time: 1009.1299s
Epoch: 21 cost time: 14.063885688781738
Epoch: 21, Steps: 118 | Train Loss: 0.2202173 Vali Loss: 0.3897161 Test Loss: 0.3643356
EarlyStopping counter: 3 out of 3
Early stopping
train 7585
val 2545
test 2545
Model(
  (freq_upsampler): Linear(in_features=134, out_features=196, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  11766272.0
params:  26460.0
Trainable parameters:  26460
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.6167635
	speed: 0.1144s/iter; left time: 663.5021s
Epoch: 1 cost time: 13.516926765441895
Epoch: 1, Steps: 118 | Train Loss: 0.6221885 Vali Loss: 0.3838281 Test Loss: 0.3611068
Validation loss decreased (inf --> 0.383828).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5483344
	speed: 0.2938s/iter; left time: 1669.7490s
Epoch: 2 cost time: 13.928726434707642
Epoch: 2, Steps: 118 | Train Loss: 0.6165799 Vali Loss: 0.3808939 Test Loss: 0.3605461
Validation loss decreased (0.383828 --> 0.380894).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.7074021
	speed: 0.3083s/iter; left time: 1715.8404s
Epoch: 3 cost time: 15.087373971939087
Epoch: 3, Steps: 118 | Train Loss: 0.6162476 Vali Loss: 0.3794344 Test Loss: 0.3608385
Validation loss decreased (0.380894 --> 0.379434).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.7006880
	speed: 0.3037s/iter; left time: 1654.3406s
Epoch: 4 cost time: 15.009278059005737
Epoch: 4, Steps: 118 | Train Loss: 0.6152058 Vali Loss: 0.3792077 Test Loss: 0.3606403
Validation loss decreased (0.379434 --> 0.379208).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4079227
	speed: 0.2999s/iter; left time: 1598.0691s
Epoch: 5 cost time: 14.20940375328064
Epoch: 5, Steps: 118 | Train Loss: 0.6137728 Vali Loss: 0.3780092 Test Loss: 0.3601728
Validation loss decreased (0.379208 --> 0.378009).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.6701263
	speed: 0.2984s/iter; left time: 1554.9074s
Epoch: 6 cost time: 14.060794830322266
Epoch: 6, Steps: 118 | Train Loss: 0.6152730 Vali Loss: 0.3789227 Test Loss: 0.3599563
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.7990359
	speed: 0.2927s/iter; left time: 1490.8628s
Epoch: 7 cost time: 14.648613929748535
Epoch: 7, Steps: 118 | Train Loss: 0.6123199 Vali Loss: 0.3772396 Test Loss: 0.3600165
Validation loss decreased (0.378009 --> 0.377240).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.7703991
	speed: 0.2931s/iter; left time: 1458.0820s
Epoch: 8 cost time: 13.83055067062378
Epoch: 8, Steps: 118 | Train Loss: 0.6130380 Vali Loss: 0.3768246 Test Loss: 0.3597044
Validation loss decreased (0.377240 --> 0.376825).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.5931584
	speed: 0.2881s/iter; left time: 1399.2191s
Epoch: 9 cost time: 13.008178234100342
Epoch: 9, Steps: 118 | Train Loss: 0.6138298 Vali Loss: 0.3779144 Test Loss: 0.3597562
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.6501082
	speed: 0.2898s/iter; left time: 1373.3400s
Epoch: 10 cost time: 13.760844230651855
Epoch: 10, Steps: 118 | Train Loss: 0.6133754 Vali Loss: 0.3750050 Test Loss: 0.3596291
Validation loss decreased (0.376825 --> 0.375005).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.5071027
	speed: 0.3067s/iter; left time: 1417.1870s
Epoch: 11 cost time: 14.821851968765259
Epoch: 11, Steps: 118 | Train Loss: 0.6134936 Vali Loss: 0.3759993 Test Loss: 0.3596706
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.5177062
	speed: 0.3024s/iter; left time: 1361.7757s
Epoch: 12 cost time: 14.289915800094604
Epoch: 12, Steps: 118 | Train Loss: 0.6124293 Vali Loss: 0.3754034 Test Loss: 0.3595914
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.5467756
	speed: 0.2954s/iter; left time: 1295.3867s
Epoch: 13 cost time: 13.78848147392273
Epoch: 13, Steps: 118 | Train Loss: 0.6115981 Vali Loss: 0.3761108 Test Loss: 0.3595615
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_336_FITS_ETTh2_ftM_sl720_ll48_pl336_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.35493117570877075, mae:0.3959639370441437, rse:0.4763340353965759, corr:[0.26227024 0.26538956 0.26419827 0.26264802 0.2622569  0.2623286
 0.26166332 0.26024672 0.2592319  0.2585126  0.25755784 0.25589603
 0.25427988 0.25317025 0.25262532 0.25226367 0.25156558 0.25048202
 0.2494377  0.24869065 0.24801868 0.24703349 0.24549793 0.24380802
 0.24240811 0.24146703 0.24062757 0.23963766 0.23857121 0.23757914
 0.2366622  0.2357018  0.23467235 0.23374689 0.23294671 0.23213185
 0.23119733 0.2304072  0.22988293 0.22942403 0.22875215 0.22763024
 0.22614618 0.22480054 0.22389919 0.22328088 0.22244948 0.22104223
 0.21928927 0.21765926 0.21620433 0.21470214 0.21329439 0.21189494
 0.21029222 0.20871812 0.20712154 0.20533575 0.20364408 0.20239168
 0.20176283 0.20149633 0.20140786 0.20137808 0.20087515 0.20026384
 0.19949739 0.19881597 0.19824831 0.19789444 0.19743648 0.19689779
 0.19627225 0.19560899 0.19484766 0.19365947 0.19228038 0.19090606
 0.18992282 0.18935391 0.1893911  0.18929894 0.18869625 0.18786645
 0.1873328  0.18718058 0.18697198 0.18632306 0.18521908 0.18423837
 0.18399227 0.18440801 0.18537985 0.18612112 0.18604827 0.18515092
 0.18393512 0.18292208 0.18240179 0.18199831 0.18153995 0.18088123
 0.1803689  0.17984433 0.17958835 0.17947465 0.17957793 0.1796694
 0.17920306 0.17831668 0.17707999 0.17606546 0.17537154 0.17531183
 0.17557515 0.17576762 0.175698   0.17503555 0.1740803  0.17288198
 0.17167374 0.17056523 0.16971754 0.16902715 0.16812092 0.16698782
 0.16562389 0.16441728 0.16371426 0.16345677 0.16334915 0.1628147
 0.16186625 0.16066983 0.15971456 0.15924211 0.15903914 0.15898636
 0.15896294 0.15898891 0.15903315 0.15859099 0.15729791 0.1552092
 0.15293828 0.15148635 0.1510492  0.15104546 0.15056777 0.14938127
 0.14786023 0.14646888 0.14585717 0.14580892 0.14577305 0.14532554
 0.14461705 0.14377238 0.14289884 0.14208415 0.14125107 0.14093082
 0.1412162  0.14186269 0.14244147 0.14251576 0.14202592 0.1409002
 0.13955736 0.13807316 0.13661948 0.1352298  0.13405639 0.13279441
 0.13164225 0.13042122 0.12957498 0.1292868  0.12908982 0.12872253
 0.12794542 0.12701383 0.12636538 0.12618369 0.1258366  0.12542509
 0.12508963 0.12510228 0.12586543 0.12699659 0.12800962 0.12789398
 0.12674974 0.12539533 0.12440026 0.12403972 0.12372073 0.12299772
 0.12222364 0.12191508 0.12249765 0.12338336 0.12377425 0.1233143
 0.12246767 0.12222039 0.1225322  0.12306067 0.12309465 0.12263831
 0.12205301 0.12200166 0.12258074 0.12318984 0.12332988 0.12270167
 0.12168442 0.12066706 0.11974397 0.1190901  0.11846009 0.11829755
 0.11828448 0.11875091 0.11926529 0.11949652 0.11918422 0.11820685
 0.11687315 0.11595244 0.1157596  0.11650731 0.11724886 0.11742213
 0.11683532 0.11625717 0.1163984  0.11735947 0.11829936 0.11818109
 0.11683892 0.115243   0.11472098 0.11581431 0.11725707 0.11772725
 0.11738266 0.11683229 0.11692559 0.11752647 0.1180408  0.11821489
 0.11807673 0.11873689 0.12026463 0.12265635 0.12428584 0.12487999
 0.12440755 0.12395083 0.12431302 0.12520355 0.12659064 0.12747468
 0.12765689 0.1271132  0.12663382 0.12649177 0.12628642 0.12590042
 0.12534387 0.12489571 0.1249694  0.12506059 0.1255602  0.12571383
 0.12561737 0.12549943 0.12575088 0.12653208 0.1274497  0.12785485
 0.12743737 0.12681718 0.12641428 0.1264306  0.12677893 0.12684684
 0.12620988 0.12503242 0.12374747 0.12291408 0.1223602  0.12171626
 0.12138951 0.12138438 0.12139748 0.12070905 0.11950994 0.11837338
 0.11777028 0.11844121 0.11955385 0.1202922  0.11967598 0.11924083
 0.11929664 0.12041155 0.12175194 0.12262209 0.12267616 0.12197059
 0.1210411  0.11945932 0.11784656 0.1166202  0.11647485 0.11733389
 0.11823042 0.11813774 0.11671788 0.11595382 0.11667099 0.1183681
 0.11876646 0.11783377 0.11735688 0.11825284 0.11934657 0.11877356
 0.11636595 0.11444999 0.11533656 0.11755257 0.11759245 0.11115157]
