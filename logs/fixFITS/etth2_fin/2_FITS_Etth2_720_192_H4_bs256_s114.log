Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=512, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=134, out_features=169, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  81163264.0
params:  22815.0
Trainable parameters:  22815
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.70314359664917
Epoch: 1, Steps: 15 | Train Loss: 0.6676556 Vali Loss: 0.5567914 Test Loss: 0.5612438
Validation loss decreased (inf --> 0.556791).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.5129032135009766
Epoch: 2, Steps: 15 | Train Loss: 0.6068747 Vali Loss: 0.5207028 Test Loss: 0.5359601
Validation loss decreased (0.556791 --> 0.520703).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.6065874099731445
Epoch: 3, Steps: 15 | Train Loss: 0.5606100 Vali Loss: 0.4944949 Test Loss: 0.5153816
Validation loss decreased (0.520703 --> 0.494495).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.5634360313415527
Epoch: 4, Steps: 15 | Train Loss: 0.5255757 Vali Loss: 0.4716430 Test Loss: 0.4987859
Validation loss decreased (0.494495 --> 0.471643).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.6192190647125244
Epoch: 5, Steps: 15 | Train Loss: 0.4981533 Vali Loss: 0.4564406 Test Loss: 0.4859253
Validation loss decreased (0.471643 --> 0.456441).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.5596210956573486
Epoch: 6, Steps: 15 | Train Loss: 0.4760870 Vali Loss: 0.4419409 Test Loss: 0.4755619
Validation loss decreased (0.456441 --> 0.441941).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.6363847255706787
Epoch: 7, Steps: 15 | Train Loss: 0.4572871 Vali Loss: 0.4331883 Test Loss: 0.4673469
Validation loss decreased (0.441941 --> 0.433188).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.685293197631836
Epoch: 8, Steps: 15 | Train Loss: 0.4414688 Vali Loss: 0.4249516 Test Loss: 0.4606698
Validation loss decreased (0.433188 --> 0.424952).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.8114969730377197
Epoch: 9, Steps: 15 | Train Loss: 0.4275014 Vali Loss: 0.4170477 Test Loss: 0.4552781
Validation loss decreased (0.424952 --> 0.417048).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.6956753730773926
Epoch: 10, Steps: 15 | Train Loss: 0.4153743 Vali Loss: 0.4122091 Test Loss: 0.4508983
Validation loss decreased (0.417048 --> 0.412209).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.5439534187316895
Epoch: 11, Steps: 15 | Train Loss: 0.4064201 Vali Loss: 0.4064689 Test Loss: 0.4472989
Validation loss decreased (0.412209 --> 0.406469).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.577630043029785
Epoch: 12, Steps: 15 | Train Loss: 0.3979998 Vali Loss: 0.4021655 Test Loss: 0.4443441
Validation loss decreased (0.406469 --> 0.402165).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.7324111461639404
Epoch: 13, Steps: 15 | Train Loss: 0.3898357 Vali Loss: 0.3971730 Test Loss: 0.4419167
Validation loss decreased (0.402165 --> 0.397173).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.6521952152252197
Epoch: 14, Steps: 15 | Train Loss: 0.3835065 Vali Loss: 0.3958548 Test Loss: 0.4399039
Validation loss decreased (0.397173 --> 0.395855).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.6690261363983154
Epoch: 15, Steps: 15 | Train Loss: 0.3765976 Vali Loss: 0.3924292 Test Loss: 0.4382019
Validation loss decreased (0.395855 --> 0.392429).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.7488057613372803
Epoch: 16, Steps: 15 | Train Loss: 0.3720406 Vali Loss: 0.3885437 Test Loss: 0.4367990
Validation loss decreased (0.392429 --> 0.388544).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.8416411876678467
Epoch: 17, Steps: 15 | Train Loss: 0.3666769 Vali Loss: 0.3875994 Test Loss: 0.4355716
Validation loss decreased (0.388544 --> 0.387599).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.816007137298584
Epoch: 18, Steps: 15 | Train Loss: 0.3621068 Vali Loss: 0.3860861 Test Loss: 0.4345635
Validation loss decreased (0.387599 --> 0.386086).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.777578115463257
Epoch: 19, Steps: 15 | Train Loss: 0.3582500 Vali Loss: 0.3828951 Test Loss: 0.4337146
Validation loss decreased (0.386086 --> 0.382895).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.6657276153564453
Epoch: 20, Steps: 15 | Train Loss: 0.3549248 Vali Loss: 0.3813828 Test Loss: 0.4329762
Validation loss decreased (0.382895 --> 0.381383).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.9131088256835938
Epoch: 21, Steps: 15 | Train Loss: 0.3509361 Vali Loss: 0.3809698 Test Loss: 0.4323353
Validation loss decreased (0.381383 --> 0.380970).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.9559521675109863
Epoch: 22, Steps: 15 | Train Loss: 0.3470512 Vali Loss: 0.3783147 Test Loss: 0.4317966
Validation loss decreased (0.380970 --> 0.378315).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.7346816062927246
Epoch: 23, Steps: 15 | Train Loss: 0.3448615 Vali Loss: 0.3772604 Test Loss: 0.4313055
Validation loss decreased (0.378315 --> 0.377260).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.7154221534729004
Epoch: 24, Steps: 15 | Train Loss: 0.3423429 Vali Loss: 0.3780327 Test Loss: 0.4309088
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.7824387550354004
Epoch: 25, Steps: 15 | Train Loss: 0.3387229 Vali Loss: 0.3744784 Test Loss: 0.4305364
Validation loss decreased (0.377260 --> 0.374478).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.9143455028533936
Epoch: 26, Steps: 15 | Train Loss: 0.3372535 Vali Loss: 0.3759649 Test Loss: 0.4302254
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.7303569316864014
Epoch: 27, Steps: 15 | Train Loss: 0.3356783 Vali Loss: 0.3721679 Test Loss: 0.4299420
Validation loss decreased (0.374478 --> 0.372168).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.562213897705078
Epoch: 28, Steps: 15 | Train Loss: 0.3331733 Vali Loss: 0.3742728 Test Loss: 0.4297020
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.9331138134002686
Epoch: 29, Steps: 15 | Train Loss: 0.3320072 Vali Loss: 0.3722027 Test Loss: 0.4294592
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.6809909343719482
Epoch: 30, Steps: 15 | Train Loss: 0.3296717 Vali Loss: 0.3723583 Test Loss: 0.4292847
EarlyStopping counter: 3 out of 3
Early stopping
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=134, out_features=169, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  81163264.0
params:  22815.0
Trainable parameters:  22815
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.787248373031616
Epoch: 1, Steps: 15 | Train Loss: 0.5991544 Vali Loss: 0.3533015 Test Loss: 0.4169056
Validation loss decreased (inf --> 0.353301).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.004783868789673
Epoch: 2, Steps: 15 | Train Loss: 0.5788107 Vali Loss: 0.3389798 Test Loss: 0.4087640
Validation loss decreased (0.353301 --> 0.338980).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.9050581455230713
Epoch: 3, Steps: 15 | Train Loss: 0.5670453 Vali Loss: 0.3303813 Test Loss: 0.4033047
Validation loss decreased (0.338980 --> 0.330381).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 2.9073939323425293
Epoch: 4, Steps: 15 | Train Loss: 0.5567576 Vali Loss: 0.3225754 Test Loss: 0.3995524
Validation loss decreased (0.330381 --> 0.322575).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.625941753387451
Epoch: 5, Steps: 15 | Train Loss: 0.5524734 Vali Loss: 0.3187447 Test Loss: 0.3967229
Validation loss decreased (0.322575 --> 0.318745).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.8226447105407715
Epoch: 6, Steps: 15 | Train Loss: 0.5457528 Vali Loss: 0.3157791 Test Loss: 0.3946203
Validation loss decreased (0.318745 --> 0.315779).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.848660469055176
Epoch: 7, Steps: 15 | Train Loss: 0.5423854 Vali Loss: 0.3133201 Test Loss: 0.3931105
Validation loss decreased (0.315779 --> 0.313320).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.7434468269348145
Epoch: 8, Steps: 15 | Train Loss: 0.5374919 Vali Loss: 0.3100224 Test Loss: 0.3920110
Validation loss decreased (0.313320 --> 0.310022).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.813136577606201
Epoch: 9, Steps: 15 | Train Loss: 0.5361082 Vali Loss: 0.3088994 Test Loss: 0.3911550
Validation loss decreased (0.310022 --> 0.308899).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.6948318481445312
Epoch: 10, Steps: 15 | Train Loss: 0.5325675 Vali Loss: 0.3048971 Test Loss: 0.3905886
Validation loss decreased (0.308899 --> 0.304897).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.6569643020629883
Epoch: 11, Steps: 15 | Train Loss: 0.5308938 Vali Loss: 0.3032265 Test Loss: 0.3900089
Validation loss decreased (0.304897 --> 0.303227).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.7650351524353027
Epoch: 12, Steps: 15 | Train Loss: 0.5287675 Vali Loss: 0.3025357 Test Loss: 0.3896919
Validation loss decreased (0.303227 --> 0.302536).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.553250551223755
Epoch: 13, Steps: 15 | Train Loss: 0.5285756 Vali Loss: 0.3012080 Test Loss: 0.3892790
Validation loss decreased (0.302536 --> 0.301208).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 2.713610887527466
Epoch: 14, Steps: 15 | Train Loss: 0.5264652 Vali Loss: 0.3004416 Test Loss: 0.3890787
Validation loss decreased (0.301208 --> 0.300442).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.770303726196289
Epoch: 15, Steps: 15 | Train Loss: 0.5261025 Vali Loss: 0.2991803 Test Loss: 0.3890022
Validation loss decreased (0.300442 --> 0.299180).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.933600664138794
Epoch: 16, Steps: 15 | Train Loss: 0.5256193 Vali Loss: 0.2987727 Test Loss: 0.3888343
Validation loss decreased (0.299180 --> 0.298773).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.8651185035705566
Epoch: 17, Steps: 15 | Train Loss: 0.5226957 Vali Loss: 0.2973457 Test Loss: 0.3886782
Validation loss decreased (0.298773 --> 0.297346).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.8910210132598877
Epoch: 18, Steps: 15 | Train Loss: 0.5239292 Vali Loss: 0.2979112 Test Loss: 0.3886437
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.8643691539764404
Epoch: 19, Steps: 15 | Train Loss: 0.5219041 Vali Loss: 0.2956461 Test Loss: 0.3885996
Validation loss decreased (0.297346 --> 0.295646).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.5932812690734863
Epoch: 20, Steps: 15 | Train Loss: 0.5227643 Vali Loss: 0.2954325 Test Loss: 0.3885343
Validation loss decreased (0.295646 --> 0.295433).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.826423406600952
Epoch: 21, Steps: 15 | Train Loss: 0.5220725 Vali Loss: 0.2954608 Test Loss: 0.3884817
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.719917058944702
Epoch: 22, Steps: 15 | Train Loss: 0.5214543 Vali Loss: 0.2952278 Test Loss: 0.3884659
Validation loss decreased (0.295433 --> 0.295228).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.863187313079834
Epoch: 23, Steps: 15 | Train Loss: 0.5212195 Vali Loss: 0.2950909 Test Loss: 0.3884536
Validation loss decreased (0.295228 --> 0.295091).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 2.955271005630493
Epoch: 24, Steps: 15 | Train Loss: 0.5190620 Vali Loss: 0.2940649 Test Loss: 0.3884555
Validation loss decreased (0.295091 --> 0.294065).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.798778772354126
Epoch: 25, Steps: 15 | Train Loss: 0.5202550 Vali Loss: 0.2941045 Test Loss: 0.3884312
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 2.7847487926483154
Epoch: 26, Steps: 15 | Train Loss: 0.5194490 Vali Loss: 0.2938265 Test Loss: 0.3884459
Validation loss decreased (0.294065 --> 0.293826).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.9538562297821045
Epoch: 27, Steps: 15 | Train Loss: 0.5210519 Vali Loss: 0.2932268 Test Loss: 0.3884293
Validation loss decreased (0.293826 --> 0.293227).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.9309239387512207
Epoch: 28, Steps: 15 | Train Loss: 0.5206230 Vali Loss: 0.2926044 Test Loss: 0.3884150
Validation loss decreased (0.293227 --> 0.292604).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.7955660820007324
Epoch: 29, Steps: 15 | Train Loss: 0.5193791 Vali Loss: 0.2923501 Test Loss: 0.3884601
Validation loss decreased (0.292604 --> 0.292350).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.7383623123168945
Epoch: 30, Steps: 15 | Train Loss: 0.5177621 Vali Loss: 0.2920546 Test Loss: 0.3885121
Validation loss decreased (0.292350 --> 0.292055).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 2.78513765335083
Epoch: 31, Steps: 15 | Train Loss: 0.5186819 Vali Loss: 0.2926162 Test Loss: 0.3884751
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 2.905247926712036
Epoch: 32, Steps: 15 | Train Loss: 0.5200512 Vali Loss: 0.2918390 Test Loss: 0.3884596
Validation loss decreased (0.292055 --> 0.291839).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 2.93424391746521
Epoch: 33, Steps: 15 | Train Loss: 0.5158535 Vali Loss: 0.2925441 Test Loss: 0.3884914
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 3.054929494857788
Epoch: 34, Steps: 15 | Train Loss: 0.5190958 Vali Loss: 0.2921891 Test Loss: 0.3884844
EarlyStopping counter: 2 out of 3
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 2.9701614379882812
Epoch: 35, Steps: 15 | Train Loss: 0.5164285 Vali Loss: 0.2909982 Test Loss: 0.3885164
Validation loss decreased (0.291839 --> 0.290998).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 2.8720922470092773
Epoch: 36, Steps: 15 | Train Loss: 0.5181748 Vali Loss: 0.2901286 Test Loss: 0.3885248
Validation loss decreased (0.290998 --> 0.290129).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 2.8254146575927734
Epoch: 37, Steps: 15 | Train Loss: 0.5179338 Vali Loss: 0.2918555 Test Loss: 0.3885547
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 2.8264381885528564
Epoch: 38, Steps: 15 | Train Loss: 0.5178386 Vali Loss: 0.2899473 Test Loss: 0.3885545
Validation loss decreased (0.290129 --> 0.289947).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 2.822474718093872
Epoch: 39, Steps: 15 | Train Loss: 0.5159891 Vali Loss: 0.2903666 Test Loss: 0.3885573
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 2.757685899734497
Epoch: 40, Steps: 15 | Train Loss: 0.5168129 Vali Loss: 0.2895768 Test Loss: 0.3885485
Validation loss decreased (0.289947 --> 0.289577).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 2.771615743637085
Epoch: 41, Steps: 15 | Train Loss: 0.5172089 Vali Loss: 0.2902011 Test Loss: 0.3885678
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 2.8021974563598633
Epoch: 42, Steps: 15 | Train Loss: 0.5168952 Vali Loss: 0.2911747 Test Loss: 0.3885610
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 3.0687055587768555
Epoch: 43, Steps: 15 | Train Loss: 0.5167604 Vali Loss: 0.2923903 Test Loss: 0.3885465
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.32963505387306213, mae:0.37440332770347595, rse:0.4604235887527466, corr:[0.26326385 0.26899144 0.2686881  0.26693392 0.2671052  0.2679785
 0.2680531  0.26691008 0.26563534 0.2646561  0.2637214  0.26259103
 0.26141855 0.260433   0.25966707 0.25913152 0.25864774 0.2578988
 0.25676116 0.25559524 0.2544673  0.25333473 0.25191498 0.25004902
 0.24821837 0.2466319  0.24537873 0.24421784 0.2429151  0.24142517
 0.23994714 0.23843911 0.2372662  0.23621066 0.23523153 0.23404568
 0.23269884 0.23166412 0.23110594 0.23064901 0.23003404 0.22913885
 0.2279951  0.22686584 0.22591068 0.2249585  0.22376601 0.22215067
 0.22032282 0.21862656 0.21716724 0.21569006 0.21425289 0.21273969
 0.21079625 0.20882541 0.20704669 0.20544994 0.20428099 0.20334013
 0.20260559 0.20184626 0.20138885 0.20134479 0.20116195 0.20076598
 0.19998673 0.19912075 0.19853969 0.19819851 0.19758981 0.19658035
 0.19527751 0.19407235 0.19310194 0.19204788 0.191019   0.19000791
 0.18917881 0.18848893 0.18830371 0.1879886  0.18733764 0.1866469
 0.1863304  0.18641815 0.18628518 0.18571486 0.18484826 0.18429323
 0.18412566 0.18381312 0.18343475 0.18292798 0.18252462 0.18231238
 0.18194477 0.1811581  0.17998393 0.1787974  0.17802116 0.17752147
 0.17703094 0.1760476  0.1750368  0.17446834 0.17449825 0.1747363
 0.174085   0.17277959 0.17151596 0.17107767 0.17099893 0.17084989
 0.17023586 0.16933458 0.1686966  0.16804624 0.16706814 0.16530296
 0.16332614 0.16168949 0.16093618 0.16049656 0.15947507 0.15786786
 0.15645112 0.15557764 0.15521398 0.15466838 0.15373236 0.15240958
 0.15144885 0.15100847 0.1506991  0.15018766 0.14935319 0.14859478
 0.1481133  0.14771049 0.14710325 0.1461622  0.14521469 0.14424595
 0.14279538 0.14080508 0.13854697 0.13670158 0.13578108 0.13555151
 0.13531527 0.13400213 0.13260254 0.13186547 0.1318101  0.13156939
 0.13099448 0.13026822 0.13011575 0.13088883 0.13127534 0.13080014
 0.12963158 0.12874365 0.12902093 0.12985456 0.1300228  0.1283305
 0.12581323 0.12401923 0.12405672 0.1243186  0.12344927 0.12071235
 0.11792854 0.11629402 0.11601671 0.115924   0.11424454 0.11227258
 0.11132482 0.11179969 0.11253648 0.11235885 0.11082605 0.10986561
 0.109756   0.10814024 0.10568959 0.10495575 0.11092259 0.11761221]
