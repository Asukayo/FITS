Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=196, out_features=248, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  21776384.0
params:  48856.0
Trainable parameters:  48856
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.8009974
	speed: 0.0809s/iter; left time: 477.5446s
Epoch: 1 cost time: 9.763792037963867
Epoch: 1, Steps: 120 | Train Loss: 0.6568913 Vali Loss: 0.3418101 Test Loss: 0.3567490
Validation loss decreased (inf --> 0.341810).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5412872
	speed: 0.2979s/iter; left time: 1722.0463s
Epoch: 2 cost time: 14.678727626800537
Epoch: 2, Steps: 120 | Train Loss: 0.5553017 Vali Loss: 0.3131883 Test Loss: 0.3480439
Validation loss decreased (0.341810 --> 0.313188).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5288292
	speed: 0.3242s/iter; left time: 1835.0975s
Epoch: 3 cost time: 14.877310276031494
Epoch: 3, Steps: 120 | Train Loss: 0.5383246 Vali Loss: 0.3041884 Test Loss: 0.3455519
Validation loss decreased (0.313188 --> 0.304188).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.7159979
	speed: 0.3234s/iter; left time: 1791.8959s
Epoch: 4 cost time: 15.269442796707153
Epoch: 4, Steps: 120 | Train Loss: 0.5318156 Vali Loss: 0.2987692 Test Loss: 0.3452446
Validation loss decreased (0.304188 --> 0.298769).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.6323233
	speed: 0.3299s/iter; left time: 1788.5073s
Epoch: 5 cost time: 15.832732915878296
Epoch: 5, Steps: 120 | Train Loss: 0.5237587 Vali Loss: 0.2957695 Test Loss: 0.3445622
Validation loss decreased (0.298769 --> 0.295769).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5572317
	speed: 0.3348s/iter; left time: 1774.5621s
Epoch: 6 cost time: 15.509337663650513
Epoch: 6, Steps: 120 | Train Loss: 0.5238407 Vali Loss: 0.2931689 Test Loss: 0.3438218
Validation loss decreased (0.295769 --> 0.293169).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.5360379
	speed: 0.3378s/iter; left time: 1749.8930s
Epoch: 7 cost time: 15.347740650177002
Epoch: 7, Steps: 120 | Train Loss: 0.5192940 Vali Loss: 0.2912267 Test Loss: 0.3434455
Validation loss decreased (0.293169 --> 0.291227).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3147058
	speed: 0.3322s/iter; left time: 1681.4949s
Epoch: 8 cost time: 14.954841613769531
Epoch: 8, Steps: 120 | Train Loss: 0.5186211 Vali Loss: 0.2888267 Test Loss: 0.3437844
Validation loss decreased (0.291227 --> 0.288827).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3744878
	speed: 0.3030s/iter; left time: 1497.3138s
Epoch: 9 cost time: 13.565903902053833
Epoch: 9, Steps: 120 | Train Loss: 0.5151412 Vali Loss: 0.2886520 Test Loss: 0.3431536
Validation loss decreased (0.288827 --> 0.288652).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.4533656
	speed: 0.2954s/iter; left time: 1424.2962s
Epoch: 10 cost time: 11.661320209503174
Epoch: 10, Steps: 120 | Train Loss: 0.5154742 Vali Loss: 0.2865303 Test Loss: 0.3433141
Validation loss decreased (0.288652 --> 0.286530).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.6640986
	speed: 0.2311s/iter; left time: 1086.6277s
Epoch: 11 cost time: 11.160844564437866
Epoch: 11, Steps: 120 | Train Loss: 0.5158670 Vali Loss: 0.2870224 Test Loss: 0.3426238
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4566416
	speed: 0.2692s/iter; left time: 1233.2278s
Epoch: 12 cost time: 16.202710390090942
Epoch: 12, Steps: 120 | Train Loss: 0.5123492 Vali Loss: 0.2851394 Test Loss: 0.3428369
Validation loss decreased (0.286530 --> 0.285139).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3885032
	speed: 0.4029s/iter; left time: 1797.1590s
Epoch: 13 cost time: 18.853477239608765
Epoch: 13, Steps: 120 | Train Loss: 0.5142105 Vali Loss: 0.2853588 Test Loss: 0.3425291
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.6084829
	speed: 0.3925s/iter; left time: 1703.8743s
Epoch: 14 cost time: 18.117466926574707
Epoch: 14, Steps: 120 | Train Loss: 0.5118759 Vali Loss: 0.2842909 Test Loss: 0.3426897
Validation loss decreased (0.285139 --> 0.284291).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3927608
	speed: 0.4127s/iter; left time: 1741.8543s
Epoch: 15 cost time: 19.536329746246338
Epoch: 15, Steps: 120 | Train Loss: 0.5130510 Vali Loss: 0.2842175 Test Loss: 0.3424708
Validation loss decreased (0.284291 --> 0.284218).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.6172267
	speed: 0.3983s/iter; left time: 1633.2474s
Epoch: 16 cost time: 17.929338693618774
Epoch: 16, Steps: 120 | Train Loss: 0.5116831 Vali Loss: 0.2838941 Test Loss: 0.3423291
Validation loss decreased (0.284218 --> 0.283894).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4340409
	speed: 0.3984s/iter; left time: 1585.9869s
Epoch: 17 cost time: 18.465078592300415
Epoch: 17, Steps: 120 | Train Loss: 0.5113813 Vali Loss: 0.2832923 Test Loss: 0.3424361
Validation loss decreased (0.283894 --> 0.283292).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.5571169
	speed: 0.3908s/iter; left time: 1508.7799s
Epoch: 18 cost time: 18.092790603637695
Epoch: 18, Steps: 120 | Train Loss: 0.5119331 Vali Loss: 0.2832651 Test Loss: 0.3422880
Validation loss decreased (0.283292 --> 0.283265).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.5633731
	speed: 0.3381s/iter; left time: 1264.9703s
Epoch: 19 cost time: 13.639799356460571
Epoch: 19, Steps: 120 | Train Loss: 0.5103159 Vali Loss: 0.2827250 Test Loss: 0.3423368
Validation loss decreased (0.283265 --> 0.282725).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4768650
	speed: 0.2842s/iter; left time: 1029.0839s
Epoch: 20 cost time: 9.361677408218384
Epoch: 20, Steps: 120 | Train Loss: 0.5099357 Vali Loss: 0.2826807 Test Loss: 0.3423696
Validation loss decreased (0.282725 --> 0.282681).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.7629833
	speed: 0.2909s/iter; left time: 1018.2887s
Epoch: 21 cost time: 13.69796347618103
Epoch: 21, Steps: 120 | Train Loss: 0.5090491 Vali Loss: 0.2826096 Test Loss: 0.3422025
Validation loss decreased (0.282681 --> 0.282610).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.8277074
	speed: 0.3689s/iter; left time: 1247.4141s
Epoch: 22 cost time: 18.3739116191864
Epoch: 22, Steps: 120 | Train Loss: 0.5078854 Vali Loss: 0.2826175 Test Loss: 0.3420868
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2871530
	speed: 0.3869s/iter; left time: 1261.6888s
Epoch: 23 cost time: 17.90102529525757
Epoch: 23, Steps: 120 | Train Loss: 0.5089347 Vali Loss: 0.2822270 Test Loss: 0.3421487
Validation loss decreased (0.282610 --> 0.282227).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.4832579
	speed: 0.3958s/iter; left time: 1243.1041s
Epoch: 24 cost time: 18.23555088043213
Epoch: 24, Steps: 120 | Train Loss: 0.5090702 Vali Loss: 0.2821158 Test Loss: 0.3420611
Validation loss decreased (0.282227 --> 0.282116).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.7399361
	speed: 0.3874s/iter; left time: 1170.4584s
Epoch: 25 cost time: 17.876317262649536
Epoch: 25, Steps: 120 | Train Loss: 0.5095380 Vali Loss: 0.2821680 Test Loss: 0.3418720
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3355157
	speed: 0.3899s/iter; left time: 1131.0041s
Epoch: 26 cost time: 18.327242612838745
Epoch: 26, Steps: 120 | Train Loss: 0.5094230 Vali Loss: 0.2816139 Test Loss: 0.3421027
Validation loss decreased (0.282116 --> 0.281614).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3583503
	speed: 0.3953s/iter; left time: 1099.3812s
Epoch: 27 cost time: 17.77750062942505
Epoch: 27, Steps: 120 | Train Loss: 0.5088163 Vali Loss: 0.2815935 Test Loss: 0.3418995
Validation loss decreased (0.281614 --> 0.281593).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.5045837
	speed: 0.3907s/iter; left time: 1039.7303s
Epoch: 28 cost time: 18.692546129226685
Epoch: 28, Steps: 120 | Train Loss: 0.5081036 Vali Loss: 0.2816018 Test Loss: 0.3418860
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4675658
	speed: 0.3919s/iter; left time: 995.7224s
Epoch: 29 cost time: 17.684952974319458
Epoch: 29, Steps: 120 | Train Loss: 0.5063537 Vali Loss: 0.2813132 Test Loss: 0.3419074
Validation loss decreased (0.281593 --> 0.281313).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.6482998
	speed: 0.3827s/iter; left time: 926.5345s
Epoch: 30 cost time: 18.321103811264038
Epoch: 30, Steps: 120 | Train Loss: 0.5076919 Vali Loss: 0.2811922 Test Loss: 0.3419811
Validation loss decreased (0.281313 --> 0.281192).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.5779265
	speed: 0.3863s/iter; left time: 888.8267s
Epoch: 31 cost time: 17.571235179901123
Epoch: 31, Steps: 120 | Train Loss: 0.5077480 Vali Loss: 0.2812713 Test Loss: 0.3418377
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.4732560
	speed: 0.3875s/iter; left time: 845.1905s
Epoch: 32 cost time: 17.93907904624939
Epoch: 32, Steps: 120 | Train Loss: 0.5081643 Vali Loss: 0.2812174 Test Loss: 0.3418033
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.4037862
	speed: 0.3815s/iter; left time: 786.3059s
Epoch: 33 cost time: 17.410793781280518
Epoch: 33, Steps: 120 | Train Loss: 0.5070973 Vali Loss: 0.2811240 Test Loss: 0.3418487
Validation loss decreased (0.281192 --> 0.281124).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.6326599
	speed: 0.3433s/iter; left time: 666.3101s
Epoch: 34 cost time: 13.743511199951172
Epoch: 34, Steps: 120 | Train Loss: 0.5053331 Vali Loss: 0.2810481 Test Loss: 0.3418328
Validation loss decreased (0.281124 --> 0.281048).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.6675606
	speed: 0.3609s/iter; left time: 657.2014s
Epoch: 35 cost time: 17.306076526641846
Epoch: 35, Steps: 120 | Train Loss: 0.5090126 Vali Loss: 0.2810787 Test Loss: 0.3418261
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.5931083
	speed: 0.3352s/iter; left time: 570.1198s
Epoch: 36 cost time: 16.79361629486084
Epoch: 36, Steps: 120 | Train Loss: 0.5072073 Vali Loss: 0.2810162 Test Loss: 0.3417245
Validation loss decreased (0.281048 --> 0.281016).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.4235338
	speed: 0.3980s/iter; left time: 629.2406s
Epoch: 37 cost time: 18.082082271575928
Epoch: 37, Steps: 120 | Train Loss: 0.5069309 Vali Loss: 0.2807968 Test Loss: 0.3418339
Validation loss decreased (0.281016 --> 0.280797).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.5061734
	speed: 0.3420s/iter; left time: 499.6831s
Epoch: 38 cost time: 14.716620922088623
Epoch: 38, Steps: 120 | Train Loss: 0.5076357 Vali Loss: 0.2808055 Test Loss: 0.3417599
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.5549549
	speed: 0.3324s/iter; left time: 445.7586s
Epoch: 39 cost time: 18.886330604553223
Epoch: 39, Steps: 120 | Train Loss: 0.5089350 Vali Loss: 0.2808206 Test Loss: 0.3417293
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.4956670
	speed: 0.3976s/iter; left time: 485.4227s
Epoch: 40 cost time: 18.055431604385376
Epoch: 40, Steps: 120 | Train Loss: 0.5080127 Vali Loss: 0.2807106 Test Loss: 0.3417746
Validation loss decreased (0.280797 --> 0.280711).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.6320981
	speed: 0.3969s/iter; left time: 437.0360s
Epoch: 41 cost time: 18.537714958190918
Epoch: 41, Steps: 120 | Train Loss: 0.5075285 Vali Loss: 0.2803538 Test Loss: 0.3417853
Validation loss decreased (0.280711 --> 0.280354).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.4948644
	speed: 0.3753s/iter; left time: 368.1386s
Epoch: 42 cost time: 15.139581441879272
Epoch: 42, Steps: 120 | Train Loss: 0.5081044 Vali Loss: 0.2806503 Test Loss: 0.3416938
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.5288423
	speed: 0.2486s/iter; left time: 214.0832s
Epoch: 43 cost time: 12.110669612884521
Epoch: 43, Steps: 120 | Train Loss: 0.5055284 Vali Loss: 0.2806112 Test Loss: 0.3417383
EarlyStopping counter: 2 out of 3
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.7730054
	speed: 0.3512s/iter; left time: 260.2163s
Epoch: 44 cost time: 17.342296361923218
Epoch: 44, Steps: 120 | Train Loss: 0.5067521 Vali Loss: 0.2805243 Test Loss: 0.3417296
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.33139657974243164, mae:0.37433674931526184, rse:0.46165212988853455, corr:[0.26345932 0.2670203  0.26558605 0.26691586 0.26638672 0.2651218
 0.2651345  0.264964   0.26382637 0.26270533 0.26185605 0.26055363
 0.25902557 0.25779918 0.25720567 0.25694224 0.25649554 0.25591528
 0.2551066  0.25393718 0.252557   0.2515136  0.25056538 0.24887082
 0.24664304 0.24485502 0.24346296 0.24165209 0.2399296  0.23885006
 0.23785196 0.23631452 0.23520626 0.23441754 0.23286192 0.23109744
 0.230475   0.23023081 0.228915   0.22752732 0.22737741 0.2273521
 0.22634181 0.22517797 0.22439967 0.22319905 0.22159114 0.22029829
 0.21900156 0.21700731 0.2149819  0.21365508 0.21242234 0.21032675
 0.2081468  0.20677474 0.20501132 0.20280215 0.20169193 0.20118038
 0.20019749 0.19927204 0.1993828  0.19947988 0.1986587  0.19826135
 0.19813313 0.1972176  0.19620758 0.19609757 0.19580217 0.1942464
 0.19269107 0.19243677 0.19197479 0.1900274  0.18867885 0.18870635
 0.18837705 0.18701829 0.18658397 0.18658935 0.1858681  0.18523924
 0.18556118 0.18580382 0.18493764 0.18421964 0.18417859 0.18393315
 0.18305956 0.1825148  0.18266597 0.18217869 0.18164754 0.18204273
 0.18209958 0.18062368 0.17892009 0.17817232 0.17737754 0.17578703
 0.174891   0.17476122 0.17426433 0.17299686 0.17232905 0.17270441
 0.17246634 0.17172058 0.17090437 0.17025785 0.16957787 0.16959932
 0.16960093 0.16881588 0.16794473 0.16713792 0.16599506 0.164361
 0.16335502 0.16234167 0.16040802 0.15837151 0.15771729 0.15747483
 0.15611932 0.15459375 0.15449026 0.15426065 0.15292154 0.15180084
 0.15171576 0.15090725 0.14947142 0.14945085 0.15013802 0.149631
 0.14854261 0.14832169 0.14808817 0.14684616 0.14605162 0.14579363
 0.14421327 0.14180209 0.1403271  0.13935722 0.1378267  0.13686238
 0.1369853  0.13575962 0.13415313 0.1342412  0.13491194 0.13368759
 0.13262509 0.1336953  0.13458921 0.13347125 0.13225625 0.13311283
 0.13339897 0.13232554 0.13246311 0.13312668 0.13233007 0.13114618
 0.13124862 0.12979428 0.12693845 0.12619787 0.12751311 0.12573037
 0.12259253 0.12216517 0.12222024 0.11976828 0.11784882 0.11954919
 0.11946543 0.11712502 0.11839639 0.12127531 0.11963457 0.1185901
 0.12103159 0.12002632 0.1184788  0.12251545 0.12282029 0.11969163]
