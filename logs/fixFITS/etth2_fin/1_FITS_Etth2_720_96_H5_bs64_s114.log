Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=165, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=165, out_features=187, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  27646080.0
params:  31042.0
Trainable parameters:  31042
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 8.947015285491943
Epoch: 1, Steps: 61 | Train Loss: 0.5913543 Vali Loss: 0.2821825 Test Loss: 0.3014628
Validation loss decreased (inf --> 0.282182).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 8.37249493598938
Epoch: 2, Steps: 61 | Train Loss: 0.4727132 Vali Loss: 0.2543749 Test Loss: 0.2856125
Validation loss decreased (0.282182 --> 0.254375).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 7.941981554031372
Epoch: 3, Steps: 61 | Train Loss: 0.4489599 Vali Loss: 0.2442016 Test Loss: 0.2812668
Validation loss decreased (0.254375 --> 0.244202).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 6.177490472793579
Epoch: 4, Steps: 61 | Train Loss: 0.4372198 Vali Loss: 0.2382888 Test Loss: 0.2792611
Validation loss decreased (0.244202 --> 0.238289).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 6.386011362075806
Epoch: 5, Steps: 61 | Train Loss: 0.4288043 Vali Loss: 0.2325621 Test Loss: 0.2778274
Validation loss decreased (0.238289 --> 0.232562).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 6.3751325607299805
Epoch: 6, Steps: 61 | Train Loss: 0.4249574 Vali Loss: 0.2293847 Test Loss: 0.2770664
Validation loss decreased (0.232562 --> 0.229385).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 6.748592376708984
Epoch: 7, Steps: 61 | Train Loss: 0.4217121 Vali Loss: 0.2281233 Test Loss: 0.2765731
Validation loss decreased (0.229385 --> 0.228123).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 8.082256555557251
Epoch: 8, Steps: 61 | Train Loss: 0.4190598 Vali Loss: 0.2260083 Test Loss: 0.2759010
Validation loss decreased (0.228123 --> 0.226008).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 7.979820013046265
Epoch: 9, Steps: 61 | Train Loss: 0.4164141 Vali Loss: 0.2254997 Test Loss: 0.2754786
Validation loss decreased (0.226008 --> 0.225500).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 7.883863687515259
Epoch: 10, Steps: 61 | Train Loss: 0.4141693 Vali Loss: 0.2223397 Test Loss: 0.2751387
Validation loss decreased (0.225500 --> 0.222340).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 6.1221959590911865
Epoch: 11, Steps: 61 | Train Loss: 0.4132493 Vali Loss: 0.2213418 Test Loss: 0.2749100
Validation loss decreased (0.222340 --> 0.221342).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 5.5698935985565186
Epoch: 12, Steps: 61 | Train Loss: 0.4114981 Vali Loss: 0.2201831 Test Loss: 0.2746305
Validation loss decreased (0.221342 --> 0.220183).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 5.778424024581909
Epoch: 13, Steps: 61 | Train Loss: 0.4102891 Vali Loss: 0.2200432 Test Loss: 0.2742212
Validation loss decreased (0.220183 --> 0.220043).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 5.95936131477356
Epoch: 14, Steps: 61 | Train Loss: 0.4101568 Vali Loss: 0.2194353 Test Loss: 0.2741161
Validation loss decreased (0.220043 --> 0.219435).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 8.160604000091553
Epoch: 15, Steps: 61 | Train Loss: 0.4095822 Vali Loss: 0.2202876 Test Loss: 0.2738987
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 8.19067668914795
Epoch: 16, Steps: 61 | Train Loss: 0.4089812 Vali Loss: 0.2193460 Test Loss: 0.2737840
Validation loss decreased (0.219435 --> 0.219346).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 8.25884461402893
Epoch: 17, Steps: 61 | Train Loss: 0.4070116 Vali Loss: 0.2187085 Test Loss: 0.2735897
Validation loss decreased (0.219346 --> 0.218708).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 8.034560441970825
Epoch: 18, Steps: 61 | Train Loss: 0.4077978 Vali Loss: 0.2183474 Test Loss: 0.2734727
Validation loss decreased (0.218708 --> 0.218347).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 8.56229281425476
Epoch: 19, Steps: 61 | Train Loss: 0.4070104 Vali Loss: 0.2170435 Test Loss: 0.2734448
Validation loss decreased (0.218347 --> 0.217043).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 7.785728931427002
Epoch: 20, Steps: 61 | Train Loss: 0.4071698 Vali Loss: 0.2181560 Test Loss: 0.2734605
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 8.928503274917603
Epoch: 21, Steps: 61 | Train Loss: 0.4067772 Vali Loss: 0.2172196 Test Loss: 0.2732127
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 8.992710828781128
Epoch: 22, Steps: 61 | Train Loss: 0.4061873 Vali Loss: 0.2171874 Test Loss: 0.2731952
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.27284201979637146, mae:0.3381553292274475, rse:0.42095622420310974, corr:[0.27054852 0.27623472 0.27457142 0.27409774 0.27467632 0.2742203
 0.27287522 0.27205545 0.2713999  0.27017704 0.26852855 0.26698792
 0.26577845 0.26486266 0.2640209  0.26344356 0.2630984  0.26269382
 0.2616701  0.26030457 0.25907207 0.25802577 0.25654194 0.2544959
 0.25266656 0.2516032  0.2505848  0.24896939 0.24705173 0.2455164
 0.2444266  0.24316542 0.24169125 0.2404544  0.23943798 0.2382763
 0.23683324 0.23559687 0.23499742 0.23456024 0.23386139 0.23295467
 0.23213673 0.23137848 0.23056531 0.22954766 0.22828674 0.22654332
 0.22452742 0.22285907 0.22191924 0.22100276 0.21978225 0.2180289
 0.21608005 0.21482748 0.21365066 0.211795   0.20962016 0.20816156
 0.2075945  0.20712171 0.20682684 0.20699178 0.20684126 0.20663129
 0.20634739 0.20603052 0.20556003 0.20474292 0.20359935 0.20272551
 0.20197529 0.20092362 0.19983743 0.19845454 0.19725686 0.19600733
 0.19541529 0.19549915 0.19636129 0.19619995 0.19470723 0.19384694
 0.19411688 0.19434127 0.19382674 0.19381191 0.19358365 0.19248517
 0.19092058 0.19086412 0.1920645  0.19020388 0.18780245 0.19228165]
