Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=196, out_features=222, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  38986752.0
params:  43734.0
Trainable parameters:  43734
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 7.321159601211548
Epoch: 1, Steps: 61 | Train Loss: 0.5475246 Vali Loss: 0.3884942 Test Loss: 0.3826737
Validation loss decreased (inf --> 0.388494).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 7.18164849281311
Epoch: 2, Steps: 61 | Train Loss: 0.4226359 Vali Loss: 0.3375756 Test Loss: 0.3478466
Validation loss decreased (0.388494 --> 0.337576).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 7.240423202514648
Epoch: 3, Steps: 61 | Train Loss: 0.3612738 Vali Loss: 0.3223671 Test Loss: 0.3369028
Validation loss decreased (0.337576 --> 0.322367).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 6.9671571254730225
Epoch: 4, Steps: 61 | Train Loss: 0.3243973 Vali Loss: 0.3174089 Test Loss: 0.3331976
Validation loss decreased (0.322367 --> 0.317409).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 7.38939642906189
Epoch: 5, Steps: 61 | Train Loss: 0.2977336 Vali Loss: 0.3144380 Test Loss: 0.3312860
Validation loss decreased (0.317409 --> 0.314438).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 7.361031532287598
Epoch: 6, Steps: 61 | Train Loss: 0.2761965 Vali Loss: 0.3107733 Test Loss: 0.3292876
Validation loss decreased (0.314438 --> 0.310773).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 7.423734188079834
Epoch: 7, Steps: 61 | Train Loss: 0.2586079 Vali Loss: 0.3080987 Test Loss: 0.3280731
Validation loss decreased (0.310773 --> 0.308099).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 7.9309539794921875
Epoch: 8, Steps: 61 | Train Loss: 0.2438606 Vali Loss: 0.3053064 Test Loss: 0.3263333
Validation loss decreased (0.308099 --> 0.305306).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 7.536860466003418
Epoch: 9, Steps: 61 | Train Loss: 0.2305788 Vali Loss: 0.3051359 Test Loss: 0.3244267
Validation loss decreased (0.305306 --> 0.305136).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 7.254563570022583
Epoch: 10, Steps: 61 | Train Loss: 0.2190649 Vali Loss: 0.3007593 Test Loss: 0.3224695
Validation loss decreased (0.305136 --> 0.300759).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 7.343315601348877
Epoch: 11, Steps: 61 | Train Loss: 0.2088715 Vali Loss: 0.2977470 Test Loss: 0.3206625
Validation loss decreased (0.300759 --> 0.297747).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 7.6080803871154785
Epoch: 12, Steps: 61 | Train Loss: 0.1999550 Vali Loss: 0.2951589 Test Loss: 0.3190029
Validation loss decreased (0.297747 --> 0.295159).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 7.430799722671509
Epoch: 13, Steps: 61 | Train Loss: 0.1916907 Vali Loss: 0.2921478 Test Loss: 0.3169509
Validation loss decreased (0.295159 --> 0.292148).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 7.272756338119507
Epoch: 14, Steps: 61 | Train Loss: 0.1840969 Vali Loss: 0.2901726 Test Loss: 0.3152334
Validation loss decreased (0.292148 --> 0.290173).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 7.593727350234985
Epoch: 15, Steps: 61 | Train Loss: 0.1776324 Vali Loss: 0.2871624 Test Loss: 0.3135063
Validation loss decreased (0.290173 --> 0.287162).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 7.695836544036865
Epoch: 16, Steps: 61 | Train Loss: 0.1714576 Vali Loss: 0.2856914 Test Loss: 0.3119121
Validation loss decreased (0.287162 --> 0.285691).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 7.656461715698242
Epoch: 17, Steps: 61 | Train Loss: 0.1660007 Vali Loss: 0.2845884 Test Loss: 0.3104421
Validation loss decreased (0.285691 --> 0.284588).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 7.063119888305664
Epoch: 18, Steps: 61 | Train Loss: 0.1610253 Vali Loss: 0.2804615 Test Loss: 0.3089955
Validation loss decreased (0.284588 --> 0.280461).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 8.144283056259155
Epoch: 19, Steps: 61 | Train Loss: 0.1562393 Vali Loss: 0.2803798 Test Loss: 0.3076534
Validation loss decreased (0.280461 --> 0.280380).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 8.282324075698853
Epoch: 20, Steps: 61 | Train Loss: 0.1522556 Vali Loss: 0.2779406 Test Loss: 0.3062218
Validation loss decreased (0.280380 --> 0.277941).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 7.542998552322388
Epoch: 21, Steps: 61 | Train Loss: 0.1483115 Vali Loss: 0.2757632 Test Loss: 0.3051279
Validation loss decreased (0.277941 --> 0.275763).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 7.7513580322265625
Epoch: 22, Steps: 61 | Train Loss: 0.1448702 Vali Loss: 0.2743711 Test Loss: 0.3040085
Validation loss decreased (0.275763 --> 0.274371).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 7.674503326416016
Epoch: 23, Steps: 61 | Train Loss: 0.1415400 Vali Loss: 0.2737406 Test Loss: 0.3029683
Validation loss decreased (0.274371 --> 0.273741).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 7.325403690338135
Epoch: 24, Steps: 61 | Train Loss: 0.1384746 Vali Loss: 0.2721662 Test Loss: 0.3020442
Validation loss decreased (0.273741 --> 0.272166).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 7.797218084335327
Epoch: 25, Steps: 61 | Train Loss: 0.1357561 Vali Loss: 0.2699207 Test Loss: 0.3010862
Validation loss decreased (0.272166 --> 0.269921).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 7.338351011276245
Epoch: 26, Steps: 61 | Train Loss: 0.1331293 Vali Loss: 0.2691009 Test Loss: 0.3002518
Validation loss decreased (0.269921 --> 0.269101).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 7.793877840042114
Epoch: 27, Steps: 61 | Train Loss: 0.1306225 Vali Loss: 0.2671021 Test Loss: 0.2993640
Validation loss decreased (0.269101 --> 0.267102).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 8.022031307220459
Epoch: 28, Steps: 61 | Train Loss: 0.1284918 Vali Loss: 0.2668066 Test Loss: 0.2985939
Validation loss decreased (0.267102 --> 0.266807).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 7.356260776519775
Epoch: 29, Steps: 61 | Train Loss: 0.1264239 Vali Loss: 0.2662243 Test Loss: 0.2979073
Validation loss decreased (0.266807 --> 0.266224).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 7.40924596786499
Epoch: 30, Steps: 61 | Train Loss: 0.1244895 Vali Loss: 0.2649834 Test Loss: 0.2973499
Validation loss decreased (0.266224 --> 0.264983).  Saving model ...
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 7.688522577285767
Epoch: 31, Steps: 61 | Train Loss: 0.1225126 Vali Loss: 0.2643328 Test Loss: 0.2966312
Validation loss decreased (0.264983 --> 0.264333).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 8.355129718780518
Epoch: 32, Steps: 61 | Train Loss: 0.1209067 Vali Loss: 0.2634298 Test Loss: 0.2960531
Validation loss decreased (0.264333 --> 0.263430).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 7.529622793197632
Epoch: 33, Steps: 61 | Train Loss: 0.1194092 Vali Loss: 0.2614475 Test Loss: 0.2954645
Validation loss decreased (0.263430 --> 0.261448).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 7.38941216468811
Epoch: 34, Steps: 61 | Train Loss: 0.1177821 Vali Loss: 0.2612364 Test Loss: 0.2949933
Validation loss decreased (0.261448 --> 0.261236).  Saving model ...
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 7.9052345752716064
Epoch: 35, Steps: 61 | Train Loss: 0.1165029 Vali Loss: 0.2614172 Test Loss: 0.2945169
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 8.276765823364258
Epoch: 36, Steps: 61 | Train Loss: 0.1150784 Vali Loss: 0.2610137 Test Loss: 0.2940596
Validation loss decreased (0.261236 --> 0.261014).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 7.86754846572876
Epoch: 37, Steps: 61 | Train Loss: 0.1140233 Vali Loss: 0.2591961 Test Loss: 0.2936089
Validation loss decreased (0.261014 --> 0.259196).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 7.84079384803772
Epoch: 38, Steps: 61 | Train Loss: 0.1128985 Vali Loss: 0.2591535 Test Loss: 0.2931374
Validation loss decreased (0.259196 --> 0.259154).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 7.631529808044434
Epoch: 39, Steps: 61 | Train Loss: 0.1117895 Vali Loss: 0.2585349 Test Loss: 0.2928276
Validation loss decreased (0.259154 --> 0.258535).  Saving model ...
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 7.468907356262207
Epoch: 40, Steps: 61 | Train Loss: 0.1106692 Vali Loss: 0.2576826 Test Loss: 0.2924471
Validation loss decreased (0.258535 --> 0.257683).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 7.862968921661377
Epoch: 41, Steps: 61 | Train Loss: 0.1098542 Vali Loss: 0.2573799 Test Loss: 0.2920977
Validation loss decreased (0.257683 --> 0.257380).  Saving model ...
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 7.591952085494995
Epoch: 42, Steps: 61 | Train Loss: 0.1090285 Vali Loss: 0.2575324 Test Loss: 0.2917781
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 7.565993547439575
Epoch: 43, Steps: 61 | Train Loss: 0.1082125 Vali Loss: 0.2556356 Test Loss: 0.2914267
Validation loss decreased (0.257380 --> 0.255636).  Saving model ...
Updating learning rate to 5.799111065000278e-05
Epoch: 44 cost time: 7.433897495269775
Epoch: 44, Steps: 61 | Train Loss: 0.1072671 Vali Loss: 0.2547775 Test Loss: 0.2911541
Validation loss decreased (0.255636 --> 0.254777).  Saving model ...
Updating learning rate to 5.509155511750264e-05
Epoch: 45 cost time: 7.424161672592163
Epoch: 45, Steps: 61 | Train Loss: 0.1066312 Vali Loss: 0.2560013 Test Loss: 0.2908806
EarlyStopping counter: 1 out of 3
Updating learning rate to 5.2336977361627504e-05
Epoch: 46 cost time: 7.9852564334869385
Epoch: 46, Steps: 61 | Train Loss: 0.1059114 Vali Loss: 0.2546861 Test Loss: 0.2906248
Validation loss decreased (0.254777 --> 0.254686).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
Epoch: 47 cost time: 8.060729742050171
Epoch: 47, Steps: 61 | Train Loss: 0.1050282 Vali Loss: 0.2537436 Test Loss: 0.2903626
Validation loss decreased (0.254686 --> 0.253744).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
Epoch: 48 cost time: 7.643815279006958
Epoch: 48, Steps: 61 | Train Loss: 0.1046644 Vali Loss: 0.2542467 Test Loss: 0.2901272
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.487241596542538e-05
Epoch: 49 cost time: 7.153633117675781
Epoch: 49, Steps: 61 | Train Loss: 0.1040391 Vali Loss: 0.2543717 Test Loss: 0.2899465
EarlyStopping counter: 2 out of 3
Updating learning rate to 4.26287951671541e-05
Epoch: 50 cost time: 6.991486072540283
Epoch: 50, Steps: 61 | Train Loss: 0.1035358 Vali Loss: 0.2534482 Test Loss: 0.2897521
Validation loss decreased (0.253744 --> 0.253448).  Saving model ...
Updating learning rate to 4.0497355408796396e-05
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=196, out_features=222, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  38986752.0
params:  43734.0
Trainable parameters:  43734
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 8.1741623878479
Epoch: 1, Steps: 61 | Train Loss: 0.4287475 Vali Loss: 0.2259923 Test Loss: 0.2734635
Validation loss decreased (inf --> 0.225992).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 7.4647438526153564
Epoch: 2, Steps: 61 | Train Loss: 0.4115802 Vali Loss: 0.2201598 Test Loss: 0.2729523
Validation loss decreased (0.225992 --> 0.220160).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 8.744242906570435
Epoch: 3, Steps: 61 | Train Loss: 0.4076747 Vali Loss: 0.2188908 Test Loss: 0.2729195
Validation loss decreased (0.220160 --> 0.218891).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 9.279889822006226
Epoch: 4, Steps: 61 | Train Loss: 0.4058343 Vali Loss: 0.2166524 Test Loss: 0.2725663
Validation loss decreased (0.218891 --> 0.216652).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 9.072818517684937
Epoch: 5, Steps: 61 | Train Loss: 0.4040626 Vali Loss: 0.2163086 Test Loss: 0.2724164
Validation loss decreased (0.216652 --> 0.216309).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 8.509275197982788
Epoch: 6, Steps: 61 | Train Loss: 0.4035289 Vali Loss: 0.2143878 Test Loss: 0.2721695
Validation loss decreased (0.216309 --> 0.214388).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 8.412896871566772
Epoch: 7, Steps: 61 | Train Loss: 0.4022042 Vali Loss: 0.2143355 Test Loss: 0.2723417
Validation loss decreased (0.214388 --> 0.214335).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 7.71647834777832
Epoch: 8, Steps: 61 | Train Loss: 0.4017610 Vali Loss: 0.2145433 Test Loss: 0.2721750
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 8.067455768585205
Epoch: 9, Steps: 61 | Train Loss: 0.4012494 Vali Loss: 0.2143734 Test Loss: 0.2720878
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 8.5113365650177
Epoch: 10, Steps: 61 | Train Loss: 0.4012806 Vali Loss: 0.2134976 Test Loss: 0.2719615
Validation loss decreased (0.214335 --> 0.213498).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 7.551960706710815
Epoch: 11, Steps: 61 | Train Loss: 0.4010132 Vali Loss: 0.2125768 Test Loss: 0.2718735
Validation loss decreased (0.213498 --> 0.212577).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 7.503046989440918
Epoch: 12, Steps: 61 | Train Loss: 0.4002119 Vali Loss: 0.2127524 Test Loss: 0.2718385
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 7.619726896286011
Epoch: 13, Steps: 61 | Train Loss: 0.4007104 Vali Loss: 0.2134476 Test Loss: 0.2719625
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 7.618069648742676
Epoch: 14, Steps: 61 | Train Loss: 0.4001905 Vali Loss: 0.2134846 Test Loss: 0.2717853
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.271530419588089, mae:0.3366657793521881, rse:0.4199432134628296, corr:[0.2745062  0.27694148 0.27554524 0.27553114 0.2751528  0.27387196
 0.27318767 0.27287707 0.2720668  0.2707704  0.26962218 0.26822037
 0.26655623 0.26519236 0.26437983 0.26388326 0.26324162 0.26273277
 0.26216525 0.26101598 0.25961533 0.25868633 0.25784254 0.25601602
 0.2536063  0.25188947 0.25086367 0.2494721  0.24778186 0.24654545
 0.2457134  0.24463601 0.24302526 0.24142435 0.2398301  0.2385235
 0.23777097 0.23713043 0.23610601 0.23481855 0.23387262 0.23323178
 0.23273166 0.23202454 0.2309997  0.22967571 0.22841617 0.22687006
 0.22484255 0.22283883 0.22143412 0.21988066 0.21885222 0.21805413
 0.21645936 0.21461406 0.2129313  0.21149796 0.21007419 0.20861375
 0.20782225 0.207774   0.20801786 0.20801868 0.2071818  0.20665863
 0.20630476 0.20587678 0.20551375 0.20483652 0.20386492 0.20324509
 0.20245416 0.20147932 0.201079   0.20020127 0.1987503  0.19755422
 0.19772503 0.19709696 0.19604336 0.19608201 0.19678508 0.1961472
 0.19451502 0.19527027 0.19661762 0.19546194 0.19351068 0.194902
 0.19514829 0.19209357 0.1923093  0.19401093 0.19143407 0.19302718]
