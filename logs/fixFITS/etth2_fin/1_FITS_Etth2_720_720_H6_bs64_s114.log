Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=128, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_720', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=720, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_720_FITS_ETTh2_ftM_sl720_ll48_pl720_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7201
val 2161
test 2161
Model(
  (freq_upsampler): Linear(in_features=196, out_features=392, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  68841472.0
params:  77224.0
Trainable parameters:  77224
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 8.597168207168579
Epoch: 1, Steps: 56 | Train Loss: 1.0296828 Vali Loss: 0.7782894 Test Loss: 0.4328576
Validation loss decreased (inf --> 0.778289).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 8.902269124984741
Epoch: 2, Steps: 56 | Train Loss: 0.8919047 Vali Loss: 0.7351656 Test Loss: 0.4079538
Validation loss decreased (0.778289 --> 0.735166).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 9.051347017288208
Epoch: 3, Steps: 56 | Train Loss: 0.8614753 Vali Loss: 0.7121031 Test Loss: 0.3987614
Validation loss decreased (0.735166 --> 0.712103).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 8.667386054992676
Epoch: 4, Steps: 56 | Train Loss: 0.8467456 Vali Loss: 0.6996101 Test Loss: 0.3936287
Validation loss decreased (0.712103 --> 0.699610).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 7.427340269088745
Epoch: 5, Steps: 56 | Train Loss: 0.8371202 Vali Loss: 0.6896808 Test Loss: 0.3902935
Validation loss decreased (0.699610 --> 0.689681).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 7.4005842208862305
Epoch: 6, Steps: 56 | Train Loss: 0.8307197 Vali Loss: 0.6818236 Test Loss: 0.3878268
Validation loss decreased (0.689681 --> 0.681824).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 8.710063219070435
Epoch: 7, Steps: 56 | Train Loss: 0.8252515 Vali Loss: 0.6773739 Test Loss: 0.3859622
Validation loss decreased (0.681824 --> 0.677374).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 9.638701677322388
Epoch: 8, Steps: 56 | Train Loss: 0.8212751 Vali Loss: 0.6703005 Test Loss: 0.3845450
Validation loss decreased (0.677374 --> 0.670300).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 9.541026830673218
Epoch: 9, Steps: 56 | Train Loss: 0.8190138 Vali Loss: 0.6705328 Test Loss: 0.3834407
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 8.73999834060669
Epoch: 10, Steps: 56 | Train Loss: 0.8172098 Vali Loss: 0.6685493 Test Loss: 0.3825229
Validation loss decreased (0.670300 --> 0.668549).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 7.500797748565674
Epoch: 11, Steps: 56 | Train Loss: 0.8150936 Vali Loss: 0.6630638 Test Loss: 0.3818029
Validation loss decreased (0.668549 --> 0.663064).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 9.323204517364502
Epoch: 12, Steps: 56 | Train Loss: 0.8137941 Vali Loss: 0.6641574 Test Loss: 0.3812601
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 8.476954936981201
Epoch: 13, Steps: 56 | Train Loss: 0.8120270 Vali Loss: 0.6618186 Test Loss: 0.3808402
Validation loss decreased (0.663064 --> 0.661819).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 9.179948806762695
Epoch: 14, Steps: 56 | Train Loss: 0.8080105 Vali Loss: 0.6578904 Test Loss: 0.3804918
Validation loss decreased (0.661819 --> 0.657890).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 8.696529626846313
Epoch: 15, Steps: 56 | Train Loss: 0.8095738 Vali Loss: 0.6608676 Test Loss: 0.3801260
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 9.173193454742432
Epoch: 16, Steps: 56 | Train Loss: 0.8089327 Vali Loss: 0.6569721 Test Loss: 0.3799200
Validation loss decreased (0.657890 --> 0.656972).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 8.533791542053223
Epoch: 17, Steps: 56 | Train Loss: 0.8079794 Vali Loss: 0.6612662 Test Loss: 0.3797158
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 8.897776365280151
Epoch: 18, Steps: 56 | Train Loss: 0.8066197 Vali Loss: 0.6591544 Test Loss: 0.3795724
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 8.850160360336304
Epoch: 19, Steps: 56 | Train Loss: 0.8058878 Vali Loss: 0.6571280 Test Loss: 0.3793824
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_720_FITS_ETTh2_ftM_sl720_ll48_pl720_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
mse:0.3785128891468048, mae:0.42411091923713684, rse:0.49175193905830383, corr:[ 2.15094849e-01  2.20525876e-01  2.17434824e-01  2.17915684e-01
  2.18837798e-01  2.17272684e-01  2.16432095e-01  2.16521606e-01
  2.15295136e-01  2.13539764e-01  2.12437332e-01  2.11304754e-01
  2.09799767e-01  2.08579957e-01  2.07694069e-01  2.06668049e-01
  2.05778494e-01  2.05117494e-01  2.04556555e-01  2.03671113e-01
  2.02654064e-01  2.01787889e-01  2.00428143e-01  1.99100465e-01
  1.97875455e-01  1.97047248e-01  1.96127951e-01  1.95237696e-01
  1.94551781e-01  1.94012448e-01  1.93449855e-01  1.92629084e-01
  1.91883326e-01  1.90970287e-01  1.89931348e-01  1.88864186e-01
  1.88019723e-01  1.87537625e-01  1.86752409e-01  1.85656905e-01
  1.84683532e-01  1.84162900e-01  1.83785841e-01  1.83053464e-01
  1.82057440e-01  1.81633890e-01  1.81180894e-01  1.79823905e-01
  1.78143159e-01  1.76959127e-01  1.76218241e-01  1.75668865e-01
  1.75116137e-01  1.74476489e-01  1.74177930e-01  1.74079910e-01
  1.73453122e-01  1.72518060e-01  1.72043219e-01  1.71881050e-01
  1.71301156e-01  1.70755625e-01  1.71127290e-01  1.71566725e-01
  1.71224266e-01  1.70886859e-01  1.71220362e-01  1.71705440e-01
  1.71567097e-01  1.71058670e-01  1.70660168e-01  1.70380816e-01
  1.70163527e-01  1.69876575e-01  1.69358253e-01  1.68846950e-01
  1.68928787e-01  1.69254944e-01  1.68973729e-01  1.68441802e-01
  1.68250307e-01  1.68187723e-01  1.67788535e-01  1.67468399e-01
  1.67787641e-01  1.68129817e-01  1.67882368e-01  1.67513028e-01
  1.67816177e-01  1.68165699e-01  1.67832598e-01  1.67610943e-01
  1.68094590e-01  1.68544188e-01  1.68429002e-01  1.68123379e-01
  1.68164253e-01  1.68158293e-01  1.67869359e-01  1.67783976e-01
  1.67931452e-01  1.67612657e-01  1.67015016e-01  1.66776106e-01
  1.66813374e-01  1.66516587e-01  1.66250646e-01  1.66383758e-01
  1.66584313e-01  1.66381940e-01  1.66031122e-01  1.65626526e-01
  1.65128291e-01  1.64874151e-01  1.65222988e-01  1.65617689e-01
  1.65108442e-01  1.64215088e-01  1.64108172e-01  1.64197952e-01
  1.63251981e-01  1.61926702e-01  1.61315411e-01  1.61050886e-01
  1.60438687e-01  1.59990177e-01  1.60031542e-01  1.59927085e-01
  1.59158036e-01  1.58154100e-01  1.57687932e-01  1.57520205e-01
  1.57188579e-01  1.56516820e-01  1.55681387e-01  1.54962003e-01
  1.54671326e-01  1.54667050e-01  1.54014096e-01  1.53216943e-01
  1.53264984e-01  1.53700128e-01  1.53119653e-01  1.51522756e-01
  1.50291651e-01  1.49874061e-01  1.49159640e-01  1.48196355e-01
  1.47964343e-01  1.48153052e-01  1.47731543e-01  1.47108480e-01
  1.47070587e-01  1.46834165e-01  1.45739391e-01  1.44592896e-01
  1.44393638e-01  1.44660309e-01  1.44396156e-01  1.43664986e-01
  1.43239483e-01  1.43537924e-01  1.43965676e-01  1.44135460e-01
  1.44283831e-01  1.44452259e-01  1.44439861e-01  1.43942133e-01
  1.43321365e-01  1.42837971e-01  1.42575771e-01  1.42210484e-01
  1.41735449e-01  1.41443953e-01  1.41283408e-01  1.40812322e-01
  1.39908612e-01  1.38981164e-01  1.38365343e-01  1.38254836e-01
  1.38256475e-01  1.37981236e-01  1.37356877e-01  1.36834085e-01
  1.37168735e-01  1.38015002e-01  1.38303503e-01  1.38236627e-01
  1.38437480e-01  1.38922751e-01  1.39175430e-01  1.38981521e-01
  1.38835683e-01  1.38988450e-01  1.39256984e-01  1.39620736e-01
  1.39901951e-01  1.39790803e-01  1.39662847e-01  1.39688194e-01
  1.39710844e-01  1.39400333e-01  1.39121845e-01  1.39061958e-01
  1.39142781e-01  1.39002651e-01  1.38746843e-01  1.38917670e-01
  1.39510930e-01  1.40230924e-01  1.40686318e-01  1.40830934e-01
  1.40780941e-01  1.40903100e-01  1.41029045e-01  1.40577167e-01
  1.39667258e-01  1.39139473e-01  1.39310479e-01  1.39338702e-01
  1.38765886e-01  1.38339162e-01  1.38275534e-01  1.38351649e-01
  1.38326883e-01  1.38426527e-01  1.38598025e-01  1.38760462e-01
  1.39196962e-01  1.39620885e-01  1.39703169e-01  1.39841199e-01
  1.40410602e-01  1.40791163e-01  1.40599489e-01  1.40805483e-01
  1.41902551e-01  1.42781600e-01  1.42713875e-01  1.42618716e-01
  1.43216372e-01  1.43675402e-01  1.43663228e-01  1.43886730e-01
  1.44517049e-01  1.44930288e-01  1.44810423e-01  1.44629061e-01
  1.44830465e-01  1.45450339e-01  1.46303043e-01  1.46934196e-01
  1.47000805e-01  1.47273660e-01  1.48252308e-01  1.48974687e-01
  1.48662150e-01  1.48633659e-01  1.49746686e-01  1.50679469e-01
  1.50473386e-01  1.50719613e-01  1.52247295e-01  1.53554142e-01
  1.53766319e-01  1.53785899e-01  1.54352561e-01  1.54677659e-01
  1.54764459e-01  1.55559137e-01  1.56568855e-01  1.56515792e-01
  1.55712992e-01  1.55827105e-01  1.57064050e-01  1.57992601e-01
  1.57915935e-01  1.57984287e-01  1.58790514e-01  1.59774214e-01
  1.60327539e-01  1.60540327e-01  1.60762936e-01  1.61142424e-01
  1.61602318e-01  1.62330121e-01  1.63202181e-01  1.63661778e-01
  1.63529664e-01  1.63156599e-01  1.63073644e-01  1.63257346e-01
  1.63204536e-01  1.62871093e-01  1.62686825e-01  1.62736818e-01
  1.62849143e-01  1.63181260e-01  1.63815856e-01  1.64352745e-01
  1.64405495e-01  1.64523005e-01  1.65216818e-01  1.66167945e-01
  1.66797996e-01  1.67067498e-01  1.67066455e-01  1.67034999e-01
  1.66991189e-01  1.67292044e-01  1.67974949e-01  1.68303087e-01
  1.67920619e-01  1.67247653e-01  1.67110026e-01  1.67384073e-01
  1.67678043e-01  1.67631999e-01  1.67190239e-01  1.66582063e-01
  1.66124970e-01  1.66141778e-01  1.66283891e-01  1.66328371e-01
  1.66193813e-01  1.66105494e-01  1.66553929e-01  1.67290837e-01
  1.67913496e-01  1.67837784e-01  1.67384967e-01  1.67692885e-01
  1.68774471e-01  1.69739470e-01  1.70019045e-01  1.69922769e-01
  1.70052111e-01  1.70349821e-01  1.70250684e-01  1.69857576e-01
  1.69789821e-01  1.69799015e-01  1.69589341e-01  1.69267938e-01
  1.69151723e-01  1.69208586e-01  1.69212848e-01  1.69572547e-01
  1.70066729e-01  1.70375541e-01  1.70228407e-01  1.69975609e-01
  1.70383483e-01  1.71456262e-01  1.72353461e-01  1.72788441e-01
  1.72997698e-01  1.73278898e-01  1.73354849e-01  1.73511520e-01
  1.74121648e-01  1.74650088e-01  1.74332544e-01  1.73712090e-01
  1.73930407e-01  1.74855545e-01  1.75578743e-01  1.75773427e-01
  1.75581276e-01  1.75335288e-01  1.74952045e-01  1.74883425e-01
  1.75121665e-01  1.75350323e-01  1.75610766e-01  1.76150292e-01
  1.76473200e-01  1.75851852e-01  1.75022095e-01  1.74948215e-01
  1.75491974e-01  1.75624594e-01  1.75277904e-01  1.75133526e-01
  1.75334617e-01  1.75452128e-01  1.75188765e-01  1.74765199e-01
  1.74809471e-01  1.75470933e-01  1.76170796e-01  1.76388100e-01
  1.76368341e-01  1.76595956e-01  1.76965803e-01  1.77162677e-01
  1.77326620e-01  1.77138731e-01  1.76988870e-01  1.76953584e-01
  1.76799640e-01  1.76337183e-01  1.75689757e-01  1.75378546e-01
  1.75604567e-01  1.76009327e-01  1.75998166e-01  1.75814167e-01
  1.75595954e-01  1.75307900e-01  1.74695775e-01  1.74184203e-01
  1.74213365e-01  1.74406111e-01  1.74423277e-01  1.74328163e-01
  1.74171597e-01  1.73840895e-01  1.73488900e-01  1.73126727e-01
  1.72525823e-01  1.72067270e-01  1.71800703e-01  1.71253175e-01
  1.70225561e-01  1.69203341e-01  1.68493852e-01  1.67679891e-01
  1.66906923e-01  1.66375369e-01  1.65741235e-01  1.64830402e-01
  1.63869411e-01  1.63422853e-01  1.63381204e-01  1.63129181e-01
  1.62850708e-01  1.62540540e-01  1.61839336e-01  1.61029562e-01
  1.60393402e-01  1.60072044e-01  1.59606829e-01  1.59313321e-01
  1.59036815e-01  1.58598006e-01  1.57979622e-01  1.57848075e-01
  1.57905027e-01  1.57494783e-01  1.56846553e-01  1.56563118e-01
  1.56186685e-01  1.55620188e-01  1.55371621e-01  1.55487493e-01
  1.55350491e-01  1.54802531e-01  1.54764578e-01  1.55182704e-01
  1.54936045e-01  1.54334277e-01  1.54678732e-01  1.55422583e-01
  1.54931039e-01  1.53924733e-01  1.53610900e-01  1.53542787e-01
  1.53032959e-01  1.52320832e-01  1.52276441e-01  1.52281165e-01
  1.51693597e-01  1.51021570e-01  1.50930420e-01  1.50758460e-01
  1.50222898e-01  1.50179192e-01  1.50504008e-01  1.50225729e-01
  1.49161920e-01  1.48318425e-01  1.48087785e-01  1.47814810e-01
  1.47203848e-01  1.46245822e-01  1.45359784e-01  1.44776985e-01
  1.44533828e-01  1.44167915e-01  1.43618241e-01  1.42806694e-01
  1.41950861e-01  1.41434729e-01  1.41464174e-01  1.41635031e-01
  1.41191855e-01  1.40350565e-01  1.39601946e-01  1.39187366e-01
  1.38983682e-01  1.38521388e-01  1.37502223e-01  1.35894284e-01
  1.34264126e-01  1.33312732e-01  1.32723123e-01  1.32139936e-01
  1.31879106e-01  1.32003859e-01  1.31650299e-01  1.30760297e-01
  1.30000100e-01  1.29689962e-01  1.29175305e-01  1.27877638e-01
  1.26687646e-01  1.26423076e-01  1.26631245e-01  1.26385048e-01
  1.25946239e-01  1.25679597e-01  1.24951951e-01  1.23828627e-01
  1.23046279e-01  1.22780584e-01  1.22139223e-01  1.20773695e-01
  1.19226098e-01  1.18326701e-01  1.18053712e-01  1.17490813e-01
  1.16347402e-01  1.14802442e-01  1.13761514e-01  1.13271832e-01
  1.12397984e-01  1.10837027e-01  1.09608047e-01  1.09071031e-01
  1.08037777e-01  1.06203534e-01  1.05113372e-01  1.05031706e-01
  1.04510494e-01  1.03173874e-01  1.01911515e-01  1.01569973e-01
  1.01187840e-01  9.98345241e-02  9.85184237e-02  9.76463929e-02
  9.68088508e-02  9.53644067e-02  9.36381295e-02  9.24486518e-02
  9.22280177e-02  9.22194570e-02  9.12776366e-02  8.95366743e-02
  8.87901485e-02  8.89582112e-02  8.87896419e-02  8.77720043e-02
  8.72272179e-02  8.74957070e-02  8.71410817e-02  8.55455175e-02
  8.46740454e-02  8.50778744e-02  8.51566792e-02  8.41195658e-02
  8.29858482e-02  8.23763087e-02  8.13574493e-02  7.96150118e-02
  7.79998377e-02  7.71976486e-02  7.63965100e-02  7.51056299e-02
  7.37360790e-02  7.27666095e-02  7.24252611e-02  7.22266659e-02
  7.15250149e-02  7.04227015e-02  6.95787668e-02  6.92993924e-02
  6.88446686e-02  6.82450235e-02  6.78331107e-02  6.72194213e-02
  6.62642196e-02  6.56662956e-02  6.59770891e-02  6.63327426e-02
  6.53275922e-02  6.35989830e-02  6.23290576e-02  6.14761859e-02
  6.01752698e-02  5.87753765e-02  5.78002185e-02  5.73148578e-02
  5.63983396e-02  5.52198365e-02  5.38102202e-02  5.22085018e-02
  5.06042913e-02  4.94833477e-02  4.87947613e-02  4.81898971e-02
  4.80630584e-02  4.80467975e-02  4.75484021e-02  4.70048264e-02
  4.74238247e-02  4.85777408e-02  4.86533567e-02  4.78247292e-02
  4.73290496e-02  4.74564731e-02  4.69972119e-02  4.61483747e-02
  4.52545621e-02  4.42602336e-02  4.32346202e-02  4.24538553e-02
  4.20467146e-02  4.20389064e-02  4.19567898e-02  4.13983390e-02
  4.02680486e-02  3.92777808e-02  3.90867069e-02  3.96700315e-02
  3.98033150e-02  3.92869189e-02  3.90803777e-02  3.88808697e-02
  3.80149074e-02  3.78259271e-02  3.80953103e-02  3.69286612e-02
  3.49102579e-02  3.46387029e-02  3.56614664e-02  3.54597569e-02
  3.33934911e-02  3.19413915e-02  3.18934284e-02  3.10106818e-02
  2.92138457e-02  2.82533765e-02  2.87208334e-02  2.88911071e-02
  2.79100072e-02  2.72006337e-02  2.76261363e-02  2.81949807e-02
  2.77226325e-02  2.67732050e-02  2.65979879e-02  2.74062175e-02
  2.85605565e-02  2.85958089e-02  2.76392736e-02  2.74571143e-02
  2.81745866e-02  2.84476411e-02  2.74629816e-02  2.65432596e-02
  2.62865443e-02  2.58976128e-02  2.50138007e-02  2.41184104e-02
  2.40772832e-02  2.37641353e-02  2.33112667e-02  2.24196482e-02
  2.23025549e-02  2.29852479e-02  2.35105064e-02  2.28512790e-02
  2.16162149e-02  2.10992955e-02  2.20909361e-02  2.24260595e-02
  2.17662845e-02  2.24701557e-02  2.40050815e-02  2.26468779e-02
  1.98194850e-02  1.93244945e-02  2.07758322e-02  1.99149568e-02
  1.67083666e-02  1.44792423e-02  1.42050488e-02  1.29557522e-02
  1.07133649e-02  9.34061594e-03  9.84247215e-03  9.81156249e-03
  8.63141660e-03  7.73925474e-03  8.04767199e-03  8.87137372e-03
  7.75525393e-03  4.64709708e-03  4.40460443e-03  6.48197159e-03
  5.05096139e-03  1.38969423e-04 -5.55567036e-04  2.49459664e-03
 -2.05312995e-03 -1.00778788e-02 -4.78915032e-03  1.88840309e-03]
