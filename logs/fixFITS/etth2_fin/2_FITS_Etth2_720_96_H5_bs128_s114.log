Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=256, c_out=7, checkpoints='./checkpoints/', cut_freq=165, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=165, out_features=187, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  55292160.0
params:  31042.0
Trainable parameters:  31042
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 4.619337320327759
Epoch: 1, Steps: 30 | Train Loss: 0.6090276 Vali Loss: 0.4380198 Test Loss: 0.4179078
Validation loss decreased (inf --> 0.438020).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.9794697761535645
Epoch: 2, Steps: 30 | Train Loss: 0.5143141 Vali Loss: 0.3905046 Test Loss: 0.3802211
Validation loss decreased (0.438020 --> 0.390505).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 4.899419069290161
Epoch: 3, Steps: 30 | Train Loss: 0.4572762 Vali Loss: 0.3638718 Test Loss: 0.3581043
Validation loss decreased (0.390505 --> 0.363872).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 4.834849834442139
Epoch: 4, Steps: 30 | Train Loss: 0.4169297 Vali Loss: 0.3492191 Test Loss: 0.3450435
Validation loss decreased (0.363872 --> 0.349219).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 4.618855237960815
Epoch: 5, Steps: 30 | Train Loss: 0.3859357 Vali Loss: 0.3405201 Test Loss: 0.3374085
Validation loss decreased (0.349219 --> 0.340520).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 4.457141160964966
Epoch: 6, Steps: 30 | Train Loss: 0.3636718 Vali Loss: 0.3347105 Test Loss: 0.3330947
Validation loss decreased (0.340520 --> 0.334711).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 4.623861312866211
Epoch: 7, Steps: 30 | Train Loss: 0.3475315 Vali Loss: 0.3296973 Test Loss: 0.3303769
Validation loss decreased (0.334711 --> 0.329697).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 4.586400032043457
Epoch: 8, Steps: 30 | Train Loss: 0.3321298 Vali Loss: 0.3280751 Test Loss: 0.3287846
Validation loss decreased (0.329697 --> 0.328075).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.627815246582031
Epoch: 9, Steps: 30 | Train Loss: 0.3192175 Vali Loss: 0.3273752 Test Loss: 0.3277042
Validation loss decreased (0.328075 --> 0.327375).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 4.590162515640259
Epoch: 10, Steps: 30 | Train Loss: 0.3105212 Vali Loss: 0.3263708 Test Loss: 0.3270017
Validation loss decreased (0.327375 --> 0.326371).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 4.198863744735718
Epoch: 11, Steps: 30 | Train Loss: 0.3004783 Vali Loss: 0.3224891 Test Loss: 0.3263291
Validation loss decreased (0.326371 --> 0.322489).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 4.719482183456421
Epoch: 12, Steps: 30 | Train Loss: 0.2925820 Vali Loss: 0.3236787 Test Loss: 0.3259592
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 4.885560035705566
Epoch: 13, Steps: 30 | Train Loss: 0.2859026 Vali Loss: 0.3216704 Test Loss: 0.3254506
Validation loss decreased (0.322489 --> 0.321670).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 4.398298263549805
Epoch: 14, Steps: 30 | Train Loss: 0.2781690 Vali Loss: 0.3201415 Test Loss: 0.3250702
Validation loss decreased (0.321670 --> 0.320141).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 4.349402904510498
Epoch: 15, Steps: 30 | Train Loss: 0.2723819 Vali Loss: 0.3185025 Test Loss: 0.3246295
Validation loss decreased (0.320141 --> 0.318502).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 4.5243518352508545
Epoch: 16, Steps: 30 | Train Loss: 0.2673904 Vali Loss: 0.3174332 Test Loss: 0.3242913
Validation loss decreased (0.318502 --> 0.317433).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 4.519347906112671
Epoch: 17, Steps: 30 | Train Loss: 0.2622341 Vali Loss: 0.3195206 Test Loss: 0.3238556
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 4.3445868492126465
Epoch: 18, Steps: 30 | Train Loss: 0.2575751 Vali Loss: 0.3169964 Test Loss: 0.3235935
Validation loss decreased (0.317433 --> 0.316996).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 4.707714557647705
Epoch: 19, Steps: 30 | Train Loss: 0.2534469 Vali Loss: 0.3139823 Test Loss: 0.3230889
Validation loss decreased (0.316996 --> 0.313982).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 4.779006481170654
Epoch: 20, Steps: 30 | Train Loss: 0.2497895 Vali Loss: 0.3143001 Test Loss: 0.3226372
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 4.695863246917725
Epoch: 21, Steps: 30 | Train Loss: 0.2468079 Vali Loss: 0.3136625 Test Loss: 0.3222264
Validation loss decreased (0.313982 --> 0.313663).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 4.706173658370972
Epoch: 22, Steps: 30 | Train Loss: 0.2423857 Vali Loss: 0.3120703 Test Loss: 0.3218764
Validation loss decreased (0.313663 --> 0.312070).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 4.611375331878662
Epoch: 23, Steps: 30 | Train Loss: 0.2392226 Vali Loss: 0.3110651 Test Loss: 0.3215739
Validation loss decreased (0.312070 --> 0.311065).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 4.317255020141602
Epoch: 24, Steps: 30 | Train Loss: 0.2361080 Vali Loss: 0.3102724 Test Loss: 0.3211196
Validation loss decreased (0.311065 --> 0.310272).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 4.5939271450042725
Epoch: 25, Steps: 30 | Train Loss: 0.2342442 Vali Loss: 0.3113752 Test Loss: 0.3208366
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 4.418592214584351
Epoch: 26, Steps: 30 | Train Loss: 0.2307435 Vali Loss: 0.3104629 Test Loss: 0.3204701
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 4.593153953552246
Epoch: 27, Steps: 30 | Train Loss: 0.2289160 Vali Loss: 0.3092197 Test Loss: 0.3200580
Validation loss decreased (0.310272 --> 0.309220).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 4.458053350448608
Epoch: 28, Steps: 30 | Train Loss: 0.2260468 Vali Loss: 0.3075210 Test Loss: 0.3197824
Validation loss decreased (0.309220 --> 0.307521).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 4.9294445514678955
Epoch: 29, Steps: 30 | Train Loss: 0.2238869 Vali Loss: 0.3097292 Test Loss: 0.3194519
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 4.948222637176514
Epoch: 30, Steps: 30 | Train Loss: 0.2221309 Vali Loss: 0.3080339 Test Loss: 0.3191105
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00011296777049628277
Epoch: 31 cost time: 4.77598237991333
Epoch: 31, Steps: 30 | Train Loss: 0.2205564 Vali Loss: 0.3071231 Test Loss: 0.3188090
Validation loss decreased (0.307521 --> 0.307123).  Saving model ...
Updating learning rate to 0.00010731938197146864
Epoch: 32 cost time: 4.616231441497803
Epoch: 32, Steps: 30 | Train Loss: 0.2188148 Vali Loss: 0.3059182 Test Loss: 0.3185073
Validation loss decreased (0.307123 --> 0.305918).  Saving model ...
Updating learning rate to 0.00010195341287289519
Epoch: 33 cost time: 4.289299488067627
Epoch: 33, Steps: 30 | Train Loss: 0.2169820 Vali Loss: 0.3054304 Test Loss: 0.3182125
Validation loss decreased (0.305918 --> 0.305430).  Saving model ...
Updating learning rate to 9.685574222925044e-05
Epoch: 34 cost time: 4.3785014152526855
Epoch: 34, Steps: 30 | Train Loss: 0.2154383 Vali Loss: 0.3058796 Test Loss: 0.3179064
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.201295511778792e-05
Epoch: 35 cost time: 4.540579080581665
Epoch: 35, Steps: 30 | Train Loss: 0.2140176 Vali Loss: 0.3039573 Test Loss: 0.3176440
Validation loss decreased (0.305430 --> 0.303957).  Saving model ...
Updating learning rate to 8.74123073618985e-05
Epoch: 36 cost time: 4.559253454208374
Epoch: 36, Steps: 30 | Train Loss: 0.2126297 Vali Loss: 0.3039555 Test Loss: 0.3173685
Validation loss decreased (0.303957 --> 0.303955).  Saving model ...
Updating learning rate to 8.304169199380359e-05
Epoch: 37 cost time: 4.4802703857421875
Epoch: 37, Steps: 30 | Train Loss: 0.2104526 Vali Loss: 0.3039325 Test Loss: 0.3171341
Validation loss decreased (0.303955 --> 0.303932).  Saving model ...
Updating learning rate to 7.88896073941134e-05
Epoch: 38 cost time: 4.943409204483032
Epoch: 38, Steps: 30 | Train Loss: 0.2100986 Vali Loss: 0.3033475 Test Loss: 0.3168896
Validation loss decreased (0.303932 --> 0.303347).  Saving model ...
Updating learning rate to 7.494512702440772e-05
Epoch: 39 cost time: 5.0057337284088135
Epoch: 39, Steps: 30 | Train Loss: 0.2084422 Vali Loss: 0.3037347 Test Loss: 0.3166727
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.119787067318733e-05
Epoch: 40 cost time: 4.854015350341797
Epoch: 40, Steps: 30 | Train Loss: 0.2074126 Vali Loss: 0.3014873 Test Loss: 0.3164590
Validation loss decreased (0.303347 --> 0.301487).  Saving model ...
Updating learning rate to 6.763797713952796e-05
Epoch: 41 cost time: 4.287701845169067
Epoch: 41, Steps: 30 | Train Loss: 0.2068055 Vali Loss: 0.3017102 Test Loss: 0.3162911
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.425607828255156e-05
Epoch: 42 cost time: 3.980330467224121
Epoch: 42, Steps: 30 | Train Loss: 0.2055866 Vali Loss: 0.3033757 Test Loss: 0.3160774
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.104327436842398e-05
Epoch: 43 cost time: 3.777127981185913
Epoch: 43, Steps: 30 | Train Loss: 0.2044286 Vali Loss: 0.3015206 Test Loss: 0.3158872
EarlyStopping counter: 3 out of 3
Early stopping
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=165, out_features=187, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  55292160.0
params:  31042.0
Trainable parameters:  31042
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.826193332672119
Epoch: 1, Steps: 30 | Train Loss: 0.4897529 Vali Loss: 0.2669512 Test Loss: 0.2905337
Validation loss decreased (inf --> 0.266951).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.2049171924591064
Epoch: 2, Steps: 30 | Train Loss: 0.4526598 Vali Loss: 0.2474831 Test Loss: 0.2796458
Validation loss decreased (0.266951 --> 0.247483).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 5.392099618911743
Epoch: 3, Steps: 30 | Train Loss: 0.4367657 Vali Loss: 0.2410150 Test Loss: 0.2755755
Validation loss decreased (0.247483 --> 0.241015).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 5.8012025356292725
Epoch: 4, Steps: 30 | Train Loss: 0.4245902 Vali Loss: 0.2335443 Test Loss: 0.2743173
Validation loss decreased (0.241015 --> 0.233544).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 5.687335014343262
Epoch: 5, Steps: 30 | Train Loss: 0.4208313 Vali Loss: 0.2317013 Test Loss: 0.2738582
Validation loss decreased (0.233544 --> 0.231701).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 5.330939769744873
Epoch: 6, Steps: 30 | Train Loss: 0.4159866 Vali Loss: 0.2278432 Test Loss: 0.2737347
Validation loss decreased (0.231701 --> 0.227843).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 4.952876091003418
Epoch: 7, Steps: 30 | Train Loss: 0.4135331 Vali Loss: 0.2277103 Test Loss: 0.2737635
Validation loss decreased (0.227843 --> 0.227710).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 4.737319469451904
Epoch: 8, Steps: 30 | Train Loss: 0.4115107 Vali Loss: 0.2238521 Test Loss: 0.2736944
Validation loss decreased (0.227710 --> 0.223852).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 5.166022300720215
Epoch: 9, Steps: 30 | Train Loss: 0.4118329 Vali Loss: 0.2230411 Test Loss: 0.2736114
Validation loss decreased (0.223852 --> 0.223041).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 5.282156467437744
Epoch: 10, Steps: 30 | Train Loss: 0.4098757 Vali Loss: 0.2224456 Test Loss: 0.2737136
Validation loss decreased (0.223041 --> 0.222446).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 5.283239364624023
Epoch: 11, Steps: 30 | Train Loss: 0.4084368 Vali Loss: 0.2230464 Test Loss: 0.2736904
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 5.393984317779541
Epoch: 12, Steps: 30 | Train Loss: 0.4087335 Vali Loss: 0.2209695 Test Loss: 0.2735622
Validation loss decreased (0.222446 --> 0.220970).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 5.35931134223938
Epoch: 13, Steps: 30 | Train Loss: 0.4057257 Vali Loss: 0.2206601 Test Loss: 0.2736481
Validation loss decreased (0.220970 --> 0.220660).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 5.128590106964111
Epoch: 14, Steps: 30 | Train Loss: 0.4059932 Vali Loss: 0.2189106 Test Loss: 0.2736031
Validation loss decreased (0.220660 --> 0.218911).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 5.035356760025024
Epoch: 15, Steps: 30 | Train Loss: 0.4045676 Vali Loss: 0.2193244 Test Loss: 0.2734766
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 4.998092889785767
Epoch: 16, Steps: 30 | Train Loss: 0.4052668 Vali Loss: 0.2187213 Test Loss: 0.2735413
Validation loss decreased (0.218911 --> 0.218721).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 4.94157600402832
Epoch: 17, Steps: 30 | Train Loss: 0.4053443 Vali Loss: 0.2189240 Test Loss: 0.2735600
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 4.8920228481292725
Epoch: 18, Steps: 30 | Train Loss: 0.4066209 Vali Loss: 0.2197785 Test Loss: 0.2735496
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 5.304322957992554
Epoch: 19, Steps: 30 | Train Loss: 0.4056506 Vali Loss: 0.2181151 Test Loss: 0.2735573
Validation loss decreased (0.218721 --> 0.218115).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 5.0290000438690186
Epoch: 20, Steps: 30 | Train Loss: 0.4060668 Vali Loss: 0.2184752 Test Loss: 0.2736215
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 5.163454294204712
Epoch: 21, Steps: 30 | Train Loss: 0.4034501 Vali Loss: 0.2188600 Test Loss: 0.2736067
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 4.938007593154907
Epoch: 22, Steps: 30 | Train Loss: 0.4049209 Vali Loss: 0.2171665 Test Loss: 0.2736013
Validation loss decreased (0.218115 --> 0.217166).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 4.882780075073242
Epoch: 23, Steps: 30 | Train Loss: 0.4041761 Vali Loss: 0.2170835 Test Loss: 0.2735704
Validation loss decreased (0.217166 --> 0.217084).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 5.110286712646484
Epoch: 24, Steps: 30 | Train Loss: 0.4019357 Vali Loss: 0.2167500 Test Loss: 0.2735518
Validation loss decreased (0.217084 --> 0.216750).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 4.983161449432373
Epoch: 25, Steps: 30 | Train Loss: 0.4040333 Vali Loss: 0.2175283 Test Loss: 0.2736993
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 4.880753517150879
Epoch: 26, Steps: 30 | Train Loss: 0.4038340 Vali Loss: 0.2166887 Test Loss: 0.2735502
Validation loss decreased (0.216750 --> 0.216689).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 5.202333688735962
Epoch: 27, Steps: 30 | Train Loss: 0.4035146 Vali Loss: 0.2179887 Test Loss: 0.2735753
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 5.537672996520996
Epoch: 28, Steps: 30 | Train Loss: 0.4020148 Vali Loss: 0.2169636 Test Loss: 0.2735778
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 5.152651309967041
Epoch: 29, Steps: 30 | Train Loss: 0.4018646 Vali Loss: 0.2168671 Test Loss: 0.2735658
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.2714484632015228, mae:0.3374875485897064, rse:0.4198797941207886, corr:[0.2733492  0.27622437 0.27526152 0.27498865 0.27463606 0.27380604
 0.2729514  0.27236226 0.27169505 0.27045384 0.2689986  0.26747248
 0.26615512 0.2652356  0.26439807 0.26384708 0.26350468 0.2631419
 0.2621643  0.26076353 0.25960606 0.25875178 0.25759387 0.25568658
 0.2536584  0.2521223  0.25081375 0.2492278  0.24765314 0.24659334
 0.24574563 0.24443439 0.2425766  0.24102125 0.23987493 0.23881762
 0.2377585  0.23677549 0.23600371 0.2350642  0.23417687 0.2335715
 0.23312585 0.2322608  0.23126316 0.23048237 0.22992142 0.22857873
 0.22627598 0.22388904 0.22233197 0.2209175  0.21979477 0.21872361
 0.21720561 0.21558987 0.21358806 0.21137166 0.20972423 0.20895617
 0.2084992  0.20763612 0.20716594 0.20762411 0.20741002 0.20672914
 0.2060787  0.20587718 0.20575881 0.20508443 0.20382535 0.20301029
 0.2025185  0.20154941 0.20030269 0.19893493 0.19847307 0.19803943
 0.19736728 0.19618504 0.19616747 0.19626781 0.19535598 0.19457287
 0.19454671 0.19472326 0.19429637 0.19419663 0.19387531 0.19318311
 0.19191141 0.19117205 0.19165365 0.18999334 0.1873735  0.19028161]
