Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=134, out_features=169, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  10145408.0
params:  22815.0
Trainable parameters:  22815
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4272721
	speed: 0.1432s/iter; left time: 844.9956s
Epoch: 1 cost time: 16.99932312965393
Epoch: 1, Steps: 120 | Train Loss: 0.6638564 Vali Loss: 0.3430128 Test Loss: 0.3620042
Validation loss decreased (inf --> 0.343013).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4229705
	speed: 0.3660s/iter; left time: 2115.7184s
Epoch: 2 cost time: 16.898913621902466
Epoch: 2, Steps: 120 | Train Loss: 0.5601688 Vali Loss: 0.3132571 Test Loss: 0.3502630
Validation loss decreased (0.343013 --> 0.313257).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.6033375
	speed: 0.3512s/iter; left time: 1988.0006s
Epoch: 3 cost time: 15.937690019607544
Epoch: 3, Steps: 120 | Train Loss: 0.5405878 Vali Loss: 0.3044356 Test Loss: 0.3472162
Validation loss decreased (0.313257 --> 0.304436).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.6096574
	speed: 0.3049s/iter; left time: 1689.5164s
Epoch: 4 cost time: 13.80686068534851
Epoch: 4, Steps: 120 | Train Loss: 0.5333563 Vali Loss: 0.2984376 Test Loss: 0.3462596
Validation loss decreased (0.304436 --> 0.298438).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.7157336
	speed: 0.3079s/iter; left time: 1669.0231s
Epoch: 5 cost time: 14.585826635360718
Epoch: 5, Steps: 120 | Train Loss: 0.5261143 Vali Loss: 0.2950754 Test Loss: 0.3460862
Validation loss decreased (0.298438 --> 0.295075).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3817994
	speed: 0.3014s/iter; left time: 1597.9728s
Epoch: 6 cost time: 14.01030969619751
Epoch: 6, Steps: 120 | Train Loss: 0.5248640 Vali Loss: 0.2933856 Test Loss: 0.3449737
Validation loss decreased (0.295075 --> 0.293386).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4328285
	speed: 0.2985s/iter; left time: 1546.4174s
Epoch: 7 cost time: 13.667598485946655
Epoch: 7, Steps: 120 | Train Loss: 0.5218396 Vali Loss: 0.2916332 Test Loss: 0.3449370
Validation loss decreased (0.293386 --> 0.291633).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3969496
	speed: 0.3039s/iter; left time: 1538.0114s
Epoch: 8 cost time: 14.479471445083618
Epoch: 8, Steps: 120 | Train Loss: 0.5210210 Vali Loss: 0.2881068 Test Loss: 0.3452766
Validation loss decreased (0.291633 --> 0.288107).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4891567
	speed: 0.3007s/iter; left time: 1485.8215s
Epoch: 9 cost time: 13.96052074432373
Epoch: 9, Steps: 120 | Train Loss: 0.5179720 Vali Loss: 0.2882540 Test Loss: 0.3445003
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.6587587
	speed: 0.2919s/iter; left time: 1407.0231s
Epoch: 10 cost time: 13.834987878799438
Epoch: 10, Steps: 120 | Train Loss: 0.5181983 Vali Loss: 0.2876600 Test Loss: 0.3442048
Validation loss decreased (0.288107 --> 0.287660).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.5577913
	speed: 0.2926s/iter; left time: 1375.7077s
Epoch: 11 cost time: 13.675243616104126
Epoch: 11, Steps: 120 | Train Loss: 0.5151860 Vali Loss: 0.2864750 Test Loss: 0.3441336
Validation loss decreased (0.287660 --> 0.286475).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.8760329
	speed: 0.3107s/iter; left time: 1423.2348s
Epoch: 12 cost time: 15.106425285339355
Epoch: 12, Steps: 120 | Train Loss: 0.5160799 Vali Loss: 0.2858556 Test Loss: 0.3439327
Validation loss decreased (0.286475 --> 0.285856).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.5463832
	speed: 0.3451s/iter; left time: 1539.7058s
Epoch: 13 cost time: 15.83630895614624
Epoch: 13, Steps: 120 | Train Loss: 0.5129921 Vali Loss: 0.2850187 Test Loss: 0.3438402
Validation loss decreased (0.285856 --> 0.285019).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4670305
	speed: 0.3333s/iter; left time: 1446.9043s
Epoch: 14 cost time: 15.681361198425293
Epoch: 14, Steps: 120 | Train Loss: 0.5137372 Vali Loss: 0.2844978 Test Loss: 0.3438418
Validation loss decreased (0.285019 --> 0.284498).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3891587
	speed: 0.3130s/iter; left time: 1320.9682s
Epoch: 15 cost time: 13.960036516189575
Epoch: 15, Steps: 120 | Train Loss: 0.5125534 Vali Loss: 0.2844175 Test Loss: 0.3434713
Validation loss decreased (0.284498 --> 0.284417).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.5813812
	speed: 0.3072s/iter; left time: 1259.7760s
Epoch: 16 cost time: 14.277114868164062
Epoch: 16, Steps: 120 | Train Loss: 0.5147233 Vali Loss: 0.2841192 Test Loss: 0.3435542
Validation loss decreased (0.284417 --> 0.284119).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4139520
	speed: 0.2972s/iter; left time: 1183.3111s
Epoch: 17 cost time: 14.17956280708313
Epoch: 17, Steps: 120 | Train Loss: 0.5125672 Vali Loss: 0.2835848 Test Loss: 0.3432679
Validation loss decreased (0.284119 --> 0.283585).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.4637063
	speed: 0.3002s/iter; left time: 1159.2396s
Epoch: 18 cost time: 13.934224605560303
Epoch: 18, Steps: 120 | Train Loss: 0.5136601 Vali Loss: 0.2834729 Test Loss: 0.3433110
Validation loss decreased (0.283585 --> 0.283473).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.5129240
	speed: 0.3014s/iter; left time: 1127.4517s
Epoch: 19 cost time: 14.121610164642334
Epoch: 19, Steps: 120 | Train Loss: 0.5124302 Vali Loss: 0.2833746 Test Loss: 0.3432732
Validation loss decreased (0.283473 --> 0.283375).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.4811388
	speed: 0.2770s/iter; left time: 1003.1855s
Epoch: 20 cost time: 13.053335428237915
Epoch: 20, Steps: 120 | Train Loss: 0.5123330 Vali Loss: 0.2835024 Test Loss: 0.3429904
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.4127027
	speed: 0.2145s/iter; left time: 750.9367s
Epoch: 21 cost time: 9.295250654220581
Epoch: 21, Steps: 120 | Train Loss: 0.5115079 Vali Loss: 0.2830548 Test Loss: 0.3430694
Validation loss decreased (0.283375 --> 0.283055).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.5330846
	speed: 0.2195s/iter; left time: 742.2025s
Epoch: 22 cost time: 11.762784481048584
Epoch: 22, Steps: 120 | Train Loss: 0.5112997 Vali Loss: 0.2828760 Test Loss: 0.3431702
Validation loss decreased (0.283055 --> 0.282876).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.4115292
	speed: 0.2767s/iter; left time: 902.1925s
Epoch: 23 cost time: 13.233153581619263
Epoch: 23, Steps: 120 | Train Loss: 0.5097906 Vali Loss: 0.2823664 Test Loss: 0.3430543
Validation loss decreased (0.282876 --> 0.282366).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.6915269
	speed: 0.2891s/iter; left time: 908.0806s
Epoch: 24 cost time: 14.310547590255737
Epoch: 24, Steps: 120 | Train Loss: 0.5097996 Vali Loss: 0.2824476 Test Loss: 0.3431191
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.3345997
	speed: 0.3232s/iter; left time: 976.4685s
Epoch: 25 cost time: 13.953160524368286
Epoch: 25, Steps: 120 | Train Loss: 0.5089971 Vali Loss: 0.2822670 Test Loss: 0.3429913
Validation loss decreased (0.282366 --> 0.282267).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.5686229
	speed: 0.2929s/iter; left time: 849.6604s
Epoch: 26 cost time: 14.190705299377441
Epoch: 26, Steps: 120 | Train Loss: 0.5090674 Vali Loss: 0.2821486 Test Loss: 0.3429227
Validation loss decreased (0.282267 --> 0.282149).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.3743937
	speed: 0.3275s/iter; left time: 910.7932s
Epoch: 27 cost time: 15.41891360282898
Epoch: 27, Steps: 120 | Train Loss: 0.5097085 Vali Loss: 0.2819779 Test Loss: 0.3429640
Validation loss decreased (0.282149 --> 0.281978).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.4223887
	speed: 0.3146s/iter; left time: 837.1160s
Epoch: 28 cost time: 14.981473922729492
Epoch: 28, Steps: 120 | Train Loss: 0.5117855 Vali Loss: 0.2822577 Test Loss: 0.3427648
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4930301
	speed: 0.3134s/iter; left time: 796.4723s
Epoch: 29 cost time: 14.87333869934082
Epoch: 29, Steps: 120 | Train Loss: 0.5104638 Vali Loss: 0.2820482 Test Loss: 0.3428342
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.6094823
	speed: 0.3208s/iter; left time: 776.6344s
Epoch: 30 cost time: 15.188811540603638
Epoch: 30, Steps: 120 | Train Loss: 0.5098805 Vali Loss: 0.2817834 Test Loss: 0.3429317
Validation loss decreased (0.281978 --> 0.281783).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.6958206
	speed: 0.3130s/iter; left time: 720.2443s
Epoch: 31 cost time: 14.52619194984436
Epoch: 31, Steps: 120 | Train Loss: 0.5109465 Vali Loss: 0.2814665 Test Loss: 0.3429388
Validation loss decreased (0.281783 --> 0.281466).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.5610982
	speed: 0.3197s/iter; left time: 697.1689s
Epoch: 32 cost time: 15.280828714370728
Epoch: 32, Steps: 120 | Train Loss: 0.5092680 Vali Loss: 0.2815816 Test Loss: 0.3429187
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.5032843
	speed: 0.3170s/iter; left time: 653.3906s
Epoch: 33 cost time: 14.81929898262024
Epoch: 33, Steps: 120 | Train Loss: 0.5094977 Vali Loss: 0.2815478 Test Loss: 0.3429512
EarlyStopping counter: 2 out of 3
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.5137383
	speed: 0.3164s/iter; left time: 614.2036s
Epoch: 34 cost time: 14.906833410263062
Epoch: 34, Steps: 120 | Train Loss: 0.5092478 Vali Loss: 0.2814648 Test Loss: 0.3428701
Validation loss decreased (0.281466 --> 0.281465).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.4057327
	speed: 0.3179s/iter; left time: 578.8551s
Epoch: 35 cost time: 14.802712678909302
Epoch: 35, Steps: 120 | Train Loss: 0.5109168 Vali Loss: 0.2814103 Test Loss: 0.3429207
Validation loss decreased (0.281465 --> 0.281410).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.5023741
	speed: 0.3455s/iter; left time: 587.6921s
Epoch: 36 cost time: 16.134294033050537
Epoch: 36, Steps: 120 | Train Loss: 0.5111309 Vali Loss: 0.2812824 Test Loss: 0.3429450
Validation loss decreased (0.281410 --> 0.281282).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.3680967
	speed: 0.3579s/iter; left time: 565.9132s
Epoch: 37 cost time: 16.68423843383789
Epoch: 37, Steps: 120 | Train Loss: 0.5105760 Vali Loss: 0.2814911 Test Loss: 0.3428009
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4546600
	speed: 0.3451s/iter; left time: 504.2026s
Epoch: 38 cost time: 15.132734060287476
Epoch: 38, Steps: 120 | Train Loss: 0.5091463 Vali Loss: 0.2813886 Test Loss: 0.3428250
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.4586191
	speed: 0.3124s/iter; left time: 418.8786s
Epoch: 39 cost time: 15.041237831115723
Epoch: 39, Steps: 120 | Train Loss: 0.5091587 Vali Loss: 0.2809783 Test Loss: 0.3428500
Validation loss decreased (0.281282 --> 0.280978).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.6380515
	speed: 0.3172s/iter; left time: 387.3010s
Epoch: 40 cost time: 14.837660551071167
Epoch: 40, Steps: 120 | Train Loss: 0.5087172 Vali Loss: 0.2811382 Test Loss: 0.3428333
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.3875503
	speed: 0.3212s/iter; left time: 353.6633s
Epoch: 41 cost time: 15.295567035675049
Epoch: 41, Steps: 120 | Train Loss: 0.5109831 Vali Loss: 0.2811747 Test Loss: 0.3427684
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.7064258
	speed: 0.3177s/iter; left time: 311.6991s
Epoch: 42 cost time: 14.252007722854614
Epoch: 42, Steps: 120 | Train Loss: 0.5094794 Vali Loss: 0.2811793 Test Loss: 0.3427792
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.33228030800819397, mae:0.37488695979118347, rse:0.46226727962493896, corr:[0.2625008  0.26750368 0.2664009  0.26524115 0.2652303  0.2656088
 0.26518327 0.2641231  0.26322556 0.26223478 0.2610043  0.2594391
 0.25818565 0.25745478 0.25695905 0.25659227 0.25600573 0.25517902
 0.25416225 0.25311217 0.25204903 0.25084823 0.2494008  0.24764352
 0.24580602 0.24403934 0.24249053 0.24110733 0.23983026 0.23847853
 0.2370836  0.23560381 0.2343164  0.2331753  0.23208056 0.23080522
 0.22957806 0.22883566 0.22856113 0.22814618 0.2272973  0.22615004
 0.2250122  0.2241451  0.22343624 0.22240858 0.2208286  0.21886063
 0.21702011 0.21558152 0.21432148 0.2127269  0.21098754 0.20928971
 0.20741601 0.20557886 0.20379275 0.2020627  0.2008223  0.20008694
 0.19974178 0.19920596 0.19862573 0.19824705 0.19782579 0.19754642
 0.19706286 0.19630815 0.19552682 0.19494012 0.19440225 0.19374195
 0.19265585 0.1912586  0.1898767  0.18860085 0.18776608 0.18715915
 0.18658672 0.18584582 0.1855797  0.1854503  0.18514392 0.18463074
 0.18420352 0.1841456  0.1841971  0.1840907  0.18353517 0.18283841
 0.18229376 0.18188703 0.18188724 0.18177822 0.18121706 0.18029541
 0.17932422 0.178592   0.17793772 0.17691    0.17551419 0.17416614
 0.17354022 0.17333074 0.17325254 0.17282705 0.17213175 0.1717112
 0.17122316 0.17068501 0.1699062  0.16921245 0.16858995 0.16841924
 0.16833563 0.1677888  0.16675003 0.16530691 0.16407642 0.16292262
 0.16168104 0.1599214  0.1581552  0.15692735 0.15628237 0.15589945
 0.15533532 0.15419331 0.15302116 0.15228678 0.15206593 0.15147787
 0.15035817 0.14908051 0.14835271 0.1484127  0.14844482 0.14778265
 0.14655359 0.14563717 0.14563729 0.14590591 0.14541554 0.14363912
 0.14112693 0.13924514 0.13831557 0.13753311 0.13615021 0.13451768
 0.13379057 0.13381582 0.1343164  0.13411438 0.13291617 0.13150354
 0.131318   0.13210545 0.1326684  0.13240676 0.13132586 0.13081275
 0.13116926 0.13152313 0.13123696 0.13049231 0.13022026 0.13008884
 0.12947989 0.1277103  0.12585533 0.12484092 0.12513909 0.12482602
 0.12286779 0.11952196 0.11727225 0.11783532 0.11904861 0.11889983
 0.11688337 0.11545318 0.11698274 0.11999742 0.12037551 0.11789948
 0.1159778  0.11748693 0.12096671 0.12091719 0.11825821 0.12320299]
