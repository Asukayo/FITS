Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=512, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=196, out_features=222, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  155947008.0
params:  43734.0
Trainable parameters:  43734
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.5963807106018066
Epoch: 1, Steps: 15 | Train Loss: 0.6219251 Vali Loss: 0.4859800 Test Loss: 0.4937473
Validation loss decreased (inf --> 0.485980).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.2420291900634766
Epoch: 2, Steps: 15 | Train Loss: 0.5592845 Vali Loss: 0.4414147 Test Loss: 0.4608290
Validation loss decreased (0.485980 --> 0.441415).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.420867919921875
Epoch: 3, Steps: 15 | Train Loss: 0.5143624 Vali Loss: 0.4066525 Test Loss: 0.4369243
Validation loss decreased (0.441415 --> 0.406653).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.5708906650543213
Epoch: 4, Steps: 15 | Train Loss: 0.4795028 Vali Loss: 0.3838703 Test Loss: 0.4200761
Validation loss decreased (0.406653 --> 0.383870).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.3418657779693604
Epoch: 5, Steps: 15 | Train Loss: 0.4535459 Vali Loss: 0.3697737 Test Loss: 0.4074295
Validation loss decreased (0.383870 --> 0.369774).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.266951560974121
Epoch: 6, Steps: 15 | Train Loss: 0.4310321 Vali Loss: 0.3563694 Test Loss: 0.3983133
Validation loss decreased (0.369774 --> 0.356369).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.082144021987915
Epoch: 7, Steps: 15 | Train Loss: 0.4143690 Vali Loss: 0.3502875 Test Loss: 0.3916979
Validation loss decreased (0.356369 --> 0.350288).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.163602113723755
Epoch: 8, Steps: 15 | Train Loss: 0.3992529 Vali Loss: 0.3419157 Test Loss: 0.3867172
Validation loss decreased (0.350288 --> 0.341916).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.12277889251709
Epoch: 9, Steps: 15 | Train Loss: 0.3891863 Vali Loss: 0.3388686 Test Loss: 0.3829300
Validation loss decreased (0.341916 --> 0.338869).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.2264652252197266
Epoch: 10, Steps: 15 | Train Loss: 0.3775765 Vali Loss: 0.3336406 Test Loss: 0.3801016
Validation loss decreased (0.338869 --> 0.333641).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.201817512512207
Epoch: 11, Steps: 15 | Train Loss: 0.3691594 Vali Loss: 0.3340153 Test Loss: 0.3779763
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.129610300064087
Epoch: 12, Steps: 15 | Train Loss: 0.3610139 Vali Loss: 0.3294609 Test Loss: 0.3762464
Validation loss decreased (0.333641 --> 0.329461).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.0817761421203613
Epoch: 13, Steps: 15 | Train Loss: 0.3539090 Vali Loss: 0.3295862 Test Loss: 0.3750792
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.300504207611084
Epoch: 14, Steps: 15 | Train Loss: 0.3486700 Vali Loss: 0.3290663 Test Loss: 0.3739644
Validation loss decreased (0.329461 --> 0.329066).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.2718405723571777
Epoch: 15, Steps: 15 | Train Loss: 0.3440626 Vali Loss: 0.3254254 Test Loss: 0.3732029
Validation loss decreased (0.329066 --> 0.325425).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.3624181747436523
Epoch: 16, Steps: 15 | Train Loss: 0.3382328 Vali Loss: 0.3242637 Test Loss: 0.3725134
Validation loss decreased (0.325425 --> 0.324264).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.120654582977295
Epoch: 17, Steps: 15 | Train Loss: 0.3345486 Vali Loss: 0.3249595 Test Loss: 0.3720527
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.128843069076538
Epoch: 18, Steps: 15 | Train Loss: 0.3286406 Vali Loss: 0.3259552 Test Loss: 0.3715657
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 3.1282711029052734
Epoch: 19, Steps: 15 | Train Loss: 0.3259328 Vali Loss: 0.3230564 Test Loss: 0.3711593
Validation loss decreased (0.324264 --> 0.323056).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.0983173847198486
Epoch: 20, Steps: 15 | Train Loss: 0.3214362 Vali Loss: 0.3243818 Test Loss: 0.3708079
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.0213193893432617
Epoch: 21, Steps: 15 | Train Loss: 0.3185416 Vali Loss: 0.3230945 Test Loss: 0.3705857
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.8404698371887207
Epoch: 22, Steps: 15 | Train Loss: 0.3155367 Vali Loss: 0.3208187 Test Loss: 0.3703331
Validation loss decreased (0.323056 --> 0.320819).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.253319501876831
Epoch: 23, Steps: 15 | Train Loss: 0.3132208 Vali Loss: 0.3237408 Test Loss: 0.3701306
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.103792905807495
Epoch: 24, Steps: 15 | Train Loss: 0.3098105 Vali Loss: 0.3209576 Test Loss: 0.3699798
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.9739325046539307
Epoch: 25, Steps: 15 | Train Loss: 0.3083403 Vali Loss: 0.3226371 Test Loss: 0.3697889
EarlyStopping counter: 3 out of 3
Early stopping
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=196, out_features=222, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  155947008.0
params:  43734.0
Trainable parameters:  43734
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.522493600845337
Epoch: 1, Steps: 15 | Train Loss: 0.5199997 Vali Loss: 0.2935885 Test Loss: 0.3429496
Validation loss decreased (inf --> 0.293588).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.533257007598877
Epoch: 2, Steps: 15 | Train Loss: 0.4922362 Vali Loss: 0.2743537 Test Loss: 0.3265729
Validation loss decreased (0.293588 --> 0.274354).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.372920513153076
Epoch: 3, Steps: 15 | Train Loss: 0.4697291 Vali Loss: 0.2640646 Test Loss: 0.3160901
Validation loss decreased (0.274354 --> 0.264065).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.347442626953125
Epoch: 4, Steps: 15 | Train Loss: 0.4572200 Vali Loss: 0.2562743 Test Loss: 0.3089306
Validation loss decreased (0.264065 --> 0.256274).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 2.781811237335205
Epoch: 5, Steps: 15 | Train Loss: 0.4420925 Vali Loss: 0.2501122 Test Loss: 0.3041283
Validation loss decreased (0.256274 --> 0.250112).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.939232110977173
Epoch: 6, Steps: 15 | Train Loss: 0.4398071 Vali Loss: 0.2458485 Test Loss: 0.3007854
Validation loss decreased (0.250112 --> 0.245849).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 2.769073724746704
Epoch: 7, Steps: 15 | Train Loss: 0.4336981 Vali Loss: 0.2412672 Test Loss: 0.2984662
Validation loss decreased (0.245849 --> 0.241267).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.845780372619629
Epoch: 8, Steps: 15 | Train Loss: 0.4263409 Vali Loss: 0.2373776 Test Loss: 0.2966245
Validation loss decreased (0.241267 --> 0.237378).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 2.722989320755005
Epoch: 9, Steps: 15 | Train Loss: 0.4241305 Vali Loss: 0.2368109 Test Loss: 0.2953767
Validation loss decreased (0.237378 --> 0.236811).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.195842742919922
Epoch: 10, Steps: 15 | Train Loss: 0.4243199 Vali Loss: 0.2341487 Test Loss: 0.2944187
Validation loss decreased (0.236811 --> 0.234149).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 2.706916332244873
Epoch: 11, Steps: 15 | Train Loss: 0.4199376 Vali Loss: 0.2328810 Test Loss: 0.2937292
Validation loss decreased (0.234149 --> 0.232881).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.490536689758301
Epoch: 12, Steps: 15 | Train Loss: 0.4182949 Vali Loss: 0.2300949 Test Loss: 0.2930342
Validation loss decreased (0.232881 --> 0.230095).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 2.1151440143585205
Epoch: 13, Steps: 15 | Train Loss: 0.4175592 Vali Loss: 0.2326902 Test Loss: 0.2927382
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 1.6502914428710938
Epoch: 14, Steps: 15 | Train Loss: 0.4162901 Vali Loss: 0.2317910 Test Loss: 0.2924015
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.2128093242645264
Epoch: 15, Steps: 15 | Train Loss: 0.4158954 Vali Loss: 0.2289228 Test Loss: 0.2919275
Validation loss decreased (0.230095 --> 0.228923).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 2.210439443588257
Epoch: 16, Steps: 15 | Train Loss: 0.4149157 Vali Loss: 0.2294623 Test Loss: 0.2917339
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.750450372695923
Epoch: 17, Steps: 15 | Train Loss: 0.4125709 Vali Loss: 0.2266861 Test Loss: 0.2914836
Validation loss decreased (0.228923 --> 0.226686).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.9880740642547607
Epoch: 18, Steps: 15 | Train Loss: 0.4116927 Vali Loss: 0.2259649 Test Loss: 0.2912822
Validation loss decreased (0.226686 --> 0.225965).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 3.288203477859497
Epoch: 19, Steps: 15 | Train Loss: 0.4107808 Vali Loss: 0.2250476 Test Loss: 0.2911705
Validation loss decreased (0.225965 --> 0.225048).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.354774236679077
Epoch: 20, Steps: 15 | Train Loss: 0.4123473 Vali Loss: 0.2252591 Test Loss: 0.2909843
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.3424625396728516
Epoch: 21, Steps: 15 | Train Loss: 0.4114273 Vali Loss: 0.2263047 Test Loss: 0.2908572
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.288928270339966
Epoch: 22, Steps: 15 | Train Loss: 0.4103642 Vali Loss: 0.2249616 Test Loss: 0.2906801
Validation loss decreased (0.225048 --> 0.224962).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.7018613815307617
Epoch: 23, Steps: 15 | Train Loss: 0.4094323 Vali Loss: 0.2245597 Test Loss: 0.2906295
Validation loss decreased (0.224962 --> 0.224560).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.378910779953003
Epoch: 24, Steps: 15 | Train Loss: 0.4081712 Vali Loss: 0.2245819 Test Loss: 0.2905754
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.5081980228424072
Epoch: 25, Steps: 15 | Train Loss: 0.4099211 Vali Loss: 0.2250828 Test Loss: 0.2904561
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.074483633041382
Epoch: 26, Steps: 15 | Train Loss: 0.4076696 Vali Loss: 0.2226762 Test Loss: 0.2904068
Validation loss decreased (0.224560 --> 0.222676).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 3.430844783782959
Epoch: 27, Steps: 15 | Train Loss: 0.4071498 Vali Loss: 0.2234383 Test Loss: 0.2902642
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.8991236686706543
Epoch: 28, Steps: 15 | Train Loss: 0.4090406 Vali Loss: 0.2235883 Test Loss: 0.2902766
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 2.8320090770721436
Epoch: 29, Steps: 15 | Train Loss: 0.4053372 Vali Loss: 0.2232951 Test Loss: 0.2901699
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.27063676714897156, mae:0.3384510576725006, rse:0.41925159096717834, corr:[0.27305165 0.27717382 0.27575913 0.27643564 0.27593535 0.27459517
 0.2741823  0.2736717  0.27267006 0.27147746 0.2702616  0.26884198
 0.267444   0.2661362  0.2650008  0.26446342 0.26404345 0.263419
 0.26267514 0.2616081  0.2602804  0.2592112  0.25825176 0.2565002
 0.2542439  0.25258726 0.25137392 0.24985214 0.24842435 0.24741842
 0.24617127 0.24449995 0.24309993 0.24221598 0.24093707 0.23942208
 0.23848084 0.23777583 0.23664041 0.23538192 0.2347717  0.23443006
 0.23388761 0.23306248 0.23204531 0.23096375 0.23021075 0.2290414
 0.2269484  0.2249207  0.22376123 0.22236255 0.2211104  0.22013825
 0.218638   0.21671367 0.21470533 0.21314594 0.21175332 0.21006134
 0.20893145 0.20879303 0.20896322 0.20881192 0.2083088  0.20857376
 0.20846173 0.20748517 0.20674641 0.20628397 0.2054851  0.20476338
 0.20391753 0.2028496  0.20217715 0.20112073 0.19998172 0.19888912
 0.19865274 0.19798137 0.1975332  0.19747081 0.19723485 0.19663984
 0.19579588 0.1962106  0.19637929 0.19558385 0.19423178 0.19424146
 0.19315127 0.19111818 0.19141859 0.18973657 0.18678528 0.18808171]
