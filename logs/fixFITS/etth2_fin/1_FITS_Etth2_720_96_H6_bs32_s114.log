Args in experiment:
Namespace(H_order=6, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=196, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=196, out_features=222, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  19493376.0
params:  43734.0
Trainable parameters:  43734
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5357843
	speed: 0.1537s/iter; left time: 922.6046s
Epoch: 1 cost time: 18.750123500823975
Epoch: 1, Steps: 122 | Train Loss: 0.5354035 Vali Loss: 0.2531644 Test Loss: 0.2862293
Validation loss decreased (inf --> 0.253164).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5587469
	speed: 0.4106s/iter; left time: 2413.9567s
Epoch: 2 cost time: 18.4068124294281
Epoch: 2, Steps: 122 | Train Loss: 0.4419020 Vali Loss: 0.2367080 Test Loss: 0.2774167
Validation loss decreased (0.253164 --> 0.236708).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3266742
	speed: 0.4009s/iter; left time: 2307.8345s
Epoch: 3 cost time: 19.334559440612793
Epoch: 3, Steps: 122 | Train Loss: 0.4270494 Vali Loss: 0.2291535 Test Loss: 0.2756381
Validation loss decreased (0.236708 --> 0.229154).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4633127
	speed: 0.3567s/iter; left time: 2010.0144s
Epoch: 4 cost time: 14.77695107460022
Epoch: 4, Steps: 122 | Train Loss: 0.4199086 Vali Loss: 0.2247715 Test Loss: 0.2741787
Validation loss decreased (0.229154 --> 0.224772).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3131726
	speed: 0.3041s/iter; left time: 1676.7071s
Epoch: 5 cost time: 13.293521165847778
Epoch: 5, Steps: 122 | Train Loss: 0.4152443 Vali Loss: 0.2226158 Test Loss: 0.2733624
Validation loss decreased (0.224772 --> 0.222616).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3885490
	speed: 0.3629s/iter; left time: 1956.3661s
Epoch: 6 cost time: 19.081308603286743
Epoch: 6, Steps: 122 | Train Loss: 0.4123906 Vali Loss: 0.2195907 Test Loss: 0.2725640
Validation loss decreased (0.222616 --> 0.219591).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3429758
	speed: 0.3968s/iter; left time: 2090.6373s
Epoch: 7 cost time: 18.42005753517151
Epoch: 7, Steps: 122 | Train Loss: 0.4102481 Vali Loss: 0.2188933 Test Loss: 0.2723332
Validation loss decreased (0.219591 --> 0.218893).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3042996
	speed: 0.4047s/iter; left time: 2083.2401s
Epoch: 8 cost time: 18.575113534927368
Epoch: 8, Steps: 122 | Train Loss: 0.4075626 Vali Loss: 0.2175360 Test Loss: 0.2717526
Validation loss decreased (0.218893 --> 0.217536).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4557617
	speed: 0.3958s/iter; left time: 1988.8044s
Epoch: 9 cost time: 18.09852409362793
Epoch: 9, Steps: 122 | Train Loss: 0.4074766 Vali Loss: 0.2165830 Test Loss: 0.2721184
Validation loss decreased (0.217536 --> 0.216583).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.6384857
	speed: 0.4107s/iter; left time: 2013.5733s
Epoch: 10 cost time: 19.22280716896057
Epoch: 10, Steps: 122 | Train Loss: 0.4061956 Vali Loss: 0.2159136 Test Loss: 0.2713387
Validation loss decreased (0.216583 --> 0.215914).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3863299
	speed: 0.3710s/iter; left time: 1773.6776s
Epoch: 11 cost time: 15.771371603012085
Epoch: 11, Steps: 122 | Train Loss: 0.4051741 Vali Loss: 0.2159683 Test Loss: 0.2713774
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.5535829
	speed: 0.3302s/iter; left time: 1538.3356s
Epoch: 12 cost time: 15.344115734100342
Epoch: 12, Steps: 122 | Train Loss: 0.4048525 Vali Loss: 0.2155452 Test Loss: 0.2712317
Validation loss decreased (0.215914 --> 0.215545).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4807661
	speed: 0.3249s/iter; left time: 1474.0162s
Epoch: 13 cost time: 14.39719295501709
Epoch: 13, Steps: 122 | Train Loss: 0.4040547 Vali Loss: 0.2147528 Test Loss: 0.2708613
Validation loss decreased (0.215545 --> 0.214753).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3059168
	speed: 0.3312s/iter; left time: 1462.2245s
Epoch: 14 cost time: 17.054393768310547
Epoch: 14, Steps: 122 | Train Loss: 0.4033556 Vali Loss: 0.2140813 Test Loss: 0.2710805
Validation loss decreased (0.214753 --> 0.214081).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.6099905
	speed: 0.3680s/iter; left time: 1579.8508s
Epoch: 15 cost time: 16.90026831626892
Epoch: 15, Steps: 122 | Train Loss: 0.4032259 Vali Loss: 0.2142575 Test Loss: 0.2710586
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3650050
	speed: 0.3297s/iter; left time: 1375.3372s
Epoch: 16 cost time: 14.226004600524902
Epoch: 16, Steps: 122 | Train Loss: 0.4023974 Vali Loss: 0.2143333 Test Loss: 0.2709072
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.4542734
	speed: 0.3276s/iter; left time: 1326.4684s
Epoch: 17 cost time: 15.358236074447632
Epoch: 17, Steps: 122 | Train Loss: 0.4020217 Vali Loss: 0.2138981 Test Loss: 0.2707543
Validation loss decreased (0.214081 --> 0.213898).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.5509959
	speed: 0.3224s/iter; left time: 1266.0015s
Epoch: 18 cost time: 15.155434608459473
Epoch: 18, Steps: 122 | Train Loss: 0.4015830 Vali Loss: 0.2141091 Test Loss: 0.2707587
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3733695
	speed: 0.3690s/iter; left time: 1404.0051s
Epoch: 19 cost time: 18.442035913467407
Epoch: 19, Steps: 122 | Train Loss: 0.4017355 Vali Loss: 0.2143417 Test Loss: 0.2706622
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3864444
	speed: 0.3954s/iter; left time: 1456.3932s
Epoch: 20 cost time: 17.973838567733765
Epoch: 20, Steps: 122 | Train Loss: 0.4002569 Vali Loss: 0.2139822 Test Loss: 0.2708315
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.2714591324329376, mae:0.33663564920425415, rse:0.41988804936408997, corr:[0.27166623 0.27570453 0.27382004 0.27477652 0.27453196 0.27291653
 0.27244776 0.2723561  0.2712891  0.2699282  0.26891524 0.26767176
 0.2661827  0.26492247 0.26432726 0.26390886 0.26333278 0.26288766
 0.2623293  0.26114497 0.259732   0.25883284 0.25780383 0.2558768
 0.2535963  0.25191087 0.2504776  0.24892959 0.24793771 0.24719742
 0.24575393 0.24384646 0.24251907 0.24151768 0.23992781 0.23845656
 0.23769574 0.23678617 0.23552808 0.23483217 0.23451707 0.23374233
 0.23291577 0.23245914 0.23150118 0.2299257  0.22906798 0.22826253
 0.22584002 0.22266982 0.22120258 0.2206424  0.21956399 0.21803877
 0.21658736 0.21502322 0.21268506 0.2106694  0.20948736 0.20819706
 0.2074399  0.20800593 0.20848446 0.20762976 0.206446   0.20670639
 0.20674478 0.20581487 0.20550212 0.20557708 0.20461103 0.2035532
 0.20327269 0.20261945 0.20120229 0.19987498 0.19965513 0.1992436
 0.19863436 0.19763367 0.19678888 0.19646804 0.19709459 0.19724324
 0.19568944 0.19528218 0.19649214 0.19630003 0.19457376 0.19547513
 0.19570428 0.19268224 0.19280618 0.19441141 0.19039877 0.19409262]
