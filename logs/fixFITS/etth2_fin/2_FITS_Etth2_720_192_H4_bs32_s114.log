Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=134, out_features=169, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  10145408.0
params:  22815.0
Trainable parameters:  22815
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3523605
	speed: 0.1776s/iter; left time: 1047.7621s
Epoch: 1 cost time: 21.29213261604309
Epoch: 1, Steps: 120 | Train Loss: 0.5373254 Vali Loss: 0.4217278 Test Loss: 0.4035399
Validation loss decreased (inf --> 0.421728).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2412297
	speed: 0.4523s/iter; left time: 2614.9818s
Epoch: 2 cost time: 20.967529296875
Epoch: 2, Steps: 120 | Train Loss: 0.3829619 Vali Loss: 0.3752038 Test Loss: 0.3750899
Validation loss decreased (0.421728 --> 0.375204).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3396385
	speed: 0.4300s/iter; left time: 2434.0051s
Epoch: 3 cost time: 19.356775999069214
Epoch: 3, Steps: 120 | Train Loss: 0.3181525 Vali Loss: 0.3593630 Test Loss: 0.3676594
Validation loss decreased (0.375204 --> 0.359363).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3128794
	speed: 0.4222s/iter; left time: 2339.4777s
Epoch: 4 cost time: 19.738567113876343
Epoch: 4, Steps: 120 | Train Loss: 0.2785596 Vali Loss: 0.3493878 Test Loss: 0.3644935
Validation loss decreased (0.359363 --> 0.349388).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2863790
	speed: 0.4128s/iter; left time: 2237.6810s
Epoch: 5 cost time: 18.00702404975891
Epoch: 5, Steps: 120 | Train Loss: 0.2497758 Vali Loss: 0.3427948 Test Loss: 0.3622361
Validation loss decreased (0.349388 --> 0.342795).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1783848
	speed: 0.3737s/iter; left time: 1981.1813s
Epoch: 6 cost time: 18.216102361679077
Epoch: 6, Steps: 120 | Train Loss: 0.2287065 Vali Loss: 0.3373016 Test Loss: 0.3600017
Validation loss decreased (0.342795 --> 0.337302).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1906247
	speed: 0.4124s/iter; left time: 2136.8349s
Epoch: 7 cost time: 18.951277256011963
Epoch: 7, Steps: 120 | Train Loss: 0.2111225 Vali Loss: 0.3322895 Test Loss: 0.3579584
Validation loss decreased (0.337302 --> 0.332290).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1644823
	speed: 0.4114s/iter; left time: 2082.1953s
Epoch: 8 cost time: 18.86443257331848
Epoch: 8, Steps: 120 | Train Loss: 0.1976445 Vali Loss: 0.3270778 Test Loss: 0.3566183
Validation loss decreased (0.332290 --> 0.327078).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1764168
	speed: 0.4125s/iter; left time: 2038.2016s
Epoch: 9 cost time: 19.295878171920776
Epoch: 9, Steps: 120 | Train Loss: 0.1861282 Vali Loss: 0.3232310 Test Loss: 0.3546203
Validation loss decreased (0.327078 --> 0.323231).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2056543
	speed: 0.4426s/iter; left time: 2133.9623s
Epoch: 10 cost time: 20.184808254241943
Epoch: 10, Steps: 120 | Train Loss: 0.1775793 Vali Loss: 0.3199342 Test Loss: 0.3531780
Validation loss decreased (0.323231 --> 0.319934).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1858406
	speed: 0.3785s/iter; left time: 1779.5157s
Epoch: 11 cost time: 18.1103732585907
Epoch: 11, Steps: 120 | Train Loss: 0.1698462 Vali Loss: 0.3164661 Test Loss: 0.3520931
Validation loss decreased (0.319934 --> 0.316466).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2422069
	speed: 0.4264s/iter; left time: 1953.3747s
Epoch: 12 cost time: 18.916827917099
Epoch: 12, Steps: 120 | Train Loss: 0.1641882 Vali Loss: 0.3134975 Test Loss: 0.3510457
Validation loss decreased (0.316466 --> 0.313497).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1621547
	speed: 0.3822s/iter; left time: 1704.9543s
Epoch: 13 cost time: 15.14832329750061
Epoch: 13, Steps: 120 | Train Loss: 0.1585434 Vali Loss: 0.3108977 Test Loss: 0.3502411
Validation loss decreased (0.313497 --> 0.310898).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1461290
	speed: 0.4266s/iter; left time: 1851.7184s
Epoch: 14 cost time: 19.924480676651
Epoch: 14, Steps: 120 | Train Loss: 0.1547402 Vali Loss: 0.3085485 Test Loss: 0.3496166
Validation loss decreased (0.310898 --> 0.308548).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1204352
	speed: 0.4249s/iter; left time: 1793.3111s
Epoch: 15 cost time: 19.707733154296875
Epoch: 15, Steps: 120 | Train Loss: 0.1510885 Vali Loss: 0.3068187 Test Loss: 0.3490238
Validation loss decreased (0.308548 --> 0.306819).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1571821
	speed: 0.4212s/iter; left time: 1727.4992s
Epoch: 16 cost time: 19.82235050201416
Epoch: 16, Steps: 120 | Train Loss: 0.1487651 Vali Loss: 0.3049665 Test Loss: 0.3485273
Validation loss decreased (0.306819 --> 0.304967).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1208181
	speed: 0.4258s/iter; left time: 1695.0217s
Epoch: 17 cost time: 19.940145254135132
Epoch: 17, Steps: 120 | Train Loss: 0.1459226 Vali Loss: 0.3031115 Test Loss: 0.3481798
Validation loss decreased (0.304967 --> 0.303112).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1318965
	speed: 0.4217s/iter; left time: 1628.3031s
Epoch: 18 cost time: 19.750231981277466
Epoch: 18, Steps: 120 | Train Loss: 0.1442012 Vali Loss: 0.3019741 Test Loss: 0.3479023
Validation loss decreased (0.303112 --> 0.301974).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1398665
	speed: 0.4361s/iter; left time: 1631.4623s
Epoch: 19 cost time: 20.77749514579773
Epoch: 19, Steps: 120 | Train Loss: 0.1422463 Vali Loss: 0.3007397 Test Loss: 0.3477238
Validation loss decreased (0.301974 --> 0.300740).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1388805
	speed: 0.4324s/iter; left time: 1565.7796s
Epoch: 20 cost time: 20.21316695213318
Epoch: 20, Steps: 120 | Train Loss: 0.1407481 Vali Loss: 0.2998806 Test Loss: 0.3474174
Validation loss decreased (0.300740 --> 0.299881).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1208042
	speed: 0.4002s/iter; left time: 1401.1463s
Epoch: 21 cost time: 18.181798696517944
Epoch: 21, Steps: 120 | Train Loss: 0.1393708 Vali Loss: 0.2988311 Test Loss: 0.3473724
Validation loss decreased (0.299881 --> 0.298831).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1395731
	speed: 0.3312s/iter; left time: 1119.7870s
Epoch: 22 cost time: 13.803282022476196
Epoch: 22, Steps: 120 | Train Loss: 0.1382893 Vali Loss: 0.2979777 Test Loss: 0.3474650
Validation loss decreased (0.298831 --> 0.297978).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1169465
	speed: 0.2497s/iter; left time: 814.3337s
Epoch: 23 cost time: 12.036982297897339
Epoch: 23, Steps: 120 | Train Loss: 0.1370741 Vali Loss: 0.2967867 Test Loss: 0.3472661
Validation loss decreased (0.297978 --> 0.296787).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1730278
	speed: 0.2887s/iter; left time: 906.9286s
Epoch: 24 cost time: 13.987466812133789
Epoch: 24, Steps: 120 | Train Loss: 0.1363011 Vali Loss: 0.2962908 Test Loss: 0.3473541
Validation loss decreased (0.296787 --> 0.296291).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.0996891
	speed: 0.2845s/iter; left time: 859.4323s
Epoch: 25 cost time: 13.139666318893433
Epoch: 25, Steps: 120 | Train Loss: 0.1354695 Vali Loss: 0.2956305 Test Loss: 0.3473004
Validation loss decreased (0.296291 --> 0.295630).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1441904
	speed: 0.2485s/iter; left time: 720.9875s
Epoch: 26 cost time: 11.28720498085022
Epoch: 26, Steps: 120 | Train Loss: 0.1349000 Vali Loss: 0.2950245 Test Loss: 0.3472459
Validation loss decreased (0.295630 --> 0.295024).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1045133
	speed: 0.2806s/iter; left time: 780.4217s
Epoch: 27 cost time: 12.94794225692749
Epoch: 27, Steps: 120 | Train Loss: 0.1345408 Vali Loss: 0.2944171 Test Loss: 0.3473113
Validation loss decreased (0.295024 --> 0.294417).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1167235
	speed: 0.2672s/iter; left time: 711.1284s
Epoch: 28 cost time: 12.645581483840942
Epoch: 28, Steps: 120 | Train Loss: 0.1345542 Vali Loss: 0.2942677 Test Loss: 0.3471888
Validation loss decreased (0.294417 --> 0.294268).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1320030
	speed: 0.2647s/iter; left time: 672.7171s
Epoch: 29 cost time: 12.58348274230957
Epoch: 29, Steps: 120 | Train Loss: 0.1338865 Vali Loss: 0.2938262 Test Loss: 0.3473008
Validation loss decreased (0.294268 --> 0.293826).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1548994
	speed: 0.2660s/iter; left time: 644.0886s
Epoch: 30 cost time: 12.445268630981445
Epoch: 30, Steps: 120 | Train Loss: 0.1334452 Vali Loss: 0.2933038 Test Loss: 0.3474512
Validation loss decreased (0.293826 --> 0.293304).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.1705104
	speed: 0.2826s/iter; left time: 650.2966s
Epoch: 31 cost time: 12.812487840652466
Epoch: 31, Steps: 120 | Train Loss: 0.1333702 Vali Loss: 0.2927213 Test Loss: 0.3474589
Validation loss decreased (0.293304 --> 0.292721).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.1440709
	speed: 0.2807s/iter; left time: 612.2700s
Epoch: 32 cost time: 13.048338413238525
Epoch: 32, Steps: 120 | Train Loss: 0.1327895 Vali Loss: 0.2925265 Test Loss: 0.3475137
Validation loss decreased (0.292721 --> 0.292527).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1309013
	speed: 0.2665s/iter; left time: 549.1998s
Epoch: 33 cost time: 13.055238008499146
Epoch: 33, Steps: 120 | Train Loss: 0.1326307 Vali Loss: 0.2923908 Test Loss: 0.3475960
Validation loss decreased (0.292527 --> 0.292391).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.1314956
	speed: 0.2461s/iter; left time: 477.6436s
Epoch: 34 cost time: 10.59874677658081
Epoch: 34, Steps: 120 | Train Loss: 0.1323678 Vali Loss: 0.2920907 Test Loss: 0.3475731
Validation loss decreased (0.292391 --> 0.292091).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.1120662
	speed: 0.2780s/iter; left time: 506.1787s
Epoch: 35 cost time: 13.335027694702148
Epoch: 35, Steps: 120 | Train Loss: 0.1325546 Vali Loss: 0.2918589 Test Loss: 0.3476788
Validation loss decreased (0.292091 --> 0.291859).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.1331414
	speed: 0.2475s/iter; left time: 421.0500s
Epoch: 36 cost time: 11.405280590057373
Epoch: 36, Steps: 120 | Train Loss: 0.1324479 Vali Loss: 0.2915982 Test Loss: 0.3477217
Validation loss decreased (0.291859 --> 0.291598).  Saving model ...
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.1005388
	speed: 0.2392s/iter; left time: 378.1057s
Epoch: 37 cost time: 11.173813819885254
Epoch: 37, Steps: 120 | Train Loss: 0.1321909 Vali Loss: 0.2916319 Test Loss: 0.3477208
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.1207755
	speed: 0.2314s/iter; left time: 338.0948s
Epoch: 38 cost time: 10.974492073059082
Epoch: 38, Steps: 120 | Train Loss: 0.1317524 Vali Loss: 0.2913614 Test Loss: 0.3477661
Validation loss decreased (0.291598 --> 0.291361).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.1229936
	speed: 0.2239s/iter; left time: 300.3092s
Epoch: 39 cost time: 10.971138954162598
Epoch: 39, Steps: 120 | Train Loss: 0.1316730 Vali Loss: 0.2908553 Test Loss: 0.3478695
Validation loss decreased (0.291361 --> 0.290855).  Saving model ...
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.1583937
	speed: 0.2585s/iter; left time: 315.6194s
Epoch: 40 cost time: 12.235085725784302
Epoch: 40, Steps: 120 | Train Loss: 0.1314972 Vali Loss: 0.2909458 Test Loss: 0.3478745
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.1035545
	speed: 0.2563s/iter; left time: 282.1993s
Epoch: 41 cost time: 12.455230951309204
Epoch: 41, Steps: 120 | Train Loss: 0.1318933 Vali Loss: 0.2908729 Test Loss: 0.3478691
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.1728376
	speed: 0.2693s/iter; left time: 264.1619s
Epoch: 42 cost time: 12.784473180770874
Epoch: 42, Steps: 120 | Train Loss: 0.1314868 Vali Loss: 0.2907867 Test Loss: 0.3479195
Validation loss decreased (0.290855 --> 0.290787).  Saving model ...
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.1475194
	speed: 0.2729s/iter; left time: 234.9599s
Epoch: 43 cost time: 12.604406595230103
Epoch: 43, Steps: 120 | Train Loss: 0.1315710 Vali Loss: 0.2907428 Test Loss: 0.3479343
Validation loss decreased (0.290787 --> 0.290743).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.1720730
	speed: 0.2599s/iter; left time: 192.5990s
Epoch: 44 cost time: 11.712589263916016
Epoch: 44, Steps: 120 | Train Loss: 0.1314284 Vali Loss: 0.2906007 Test Loss: 0.3479681
Validation loss decreased (0.290743 --> 0.290601).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.0990714
	speed: 0.2811s/iter; left time: 174.5420s
Epoch: 45 cost time: 12.979643821716309
Epoch: 45, Steps: 120 | Train Loss: 0.1312663 Vali Loss: 0.2905847 Test Loss: 0.3480234
Validation loss decreased (0.290601 --> 0.290585).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.1441305
	speed: 0.2792s/iter; left time: 139.9006s
Epoch: 46 cost time: 12.514208555221558
Epoch: 46, Steps: 120 | Train Loss: 0.1312420 Vali Loss: 0.2904461 Test Loss: 0.3480517
Validation loss decreased (0.290585 --> 0.290446).  Saving model ...
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.1350202
	speed: 0.2717s/iter; left time: 103.5240s
Epoch: 47 cost time: 13.241824626922607
Epoch: 47, Steps: 120 | Train Loss: 0.1310389 Vali Loss: 0.2899717 Test Loss: 0.3481357
Validation loss decreased (0.290446 --> 0.289972).  Saving model ...
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.1168433
	speed: 0.2801s/iter; left time: 73.1154s
Epoch: 48 cost time: 12.910533666610718
Epoch: 48, Steps: 120 | Train Loss: 0.1311055 Vali Loss: 0.2902588 Test Loss: 0.3481785
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.487241596542538e-05
	iters: 100, epoch: 49 | loss: 0.1350790
	speed: 0.2792s/iter; left time: 39.3640s
Epoch: 49 cost time: 13.339506387710571
Epoch: 49, Steps: 120 | Train Loss: 0.1306420 Vali Loss: 0.2901178 Test Loss: 0.3481705
EarlyStopping counter: 2 out of 3
Updating learning rate to 4.26287951671541e-05
	iters: 100, epoch: 50 | loss: 0.1131748
	speed: 0.2826s/iter; left time: 5.9348s
Epoch: 50 cost time: 13.182800769805908
Epoch: 50, Steps: 120 | Train Loss: 0.1309470 Vali Loss: 0.2900656 Test Loss: 0.3481774
EarlyStopping counter: 3 out of 3
Early stopping
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=134, out_features=169, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  10145408.0
params:  22815.0
Trainable parameters:  22815
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4957003
	speed: 0.1090s/iter; left time: 643.0157s
Epoch: 1 cost time: 13.114603281021118
Epoch: 1, Steps: 120 | Train Loss: 0.5192605 Vali Loss: 0.2842010 Test Loss: 0.3467797
Validation loss decreased (inf --> 0.284201).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6023638
	speed: 0.2890s/iter; left time: 1670.7817s
Epoch: 2 cost time: 13.438794136047363
Epoch: 2, Steps: 120 | Train Loss: 0.5149595 Vali Loss: 0.2839082 Test Loss: 0.3453789
Validation loss decreased (0.284201 --> 0.283908).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4760589
	speed: 0.2715s/iter; left time: 1537.2284s
Epoch: 3 cost time: 11.070513486862183
Epoch: 3, Steps: 120 | Train Loss: 0.5146506 Vali Loss: 0.2828127 Test Loss: 0.3447439
Validation loss decreased (0.283908 --> 0.282813).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3909675
	speed: 0.2735s/iter; left time: 1515.6751s
Epoch: 4 cost time: 13.121840238571167
Epoch: 4, Steps: 120 | Train Loss: 0.5128347 Vali Loss: 0.2824256 Test Loss: 0.3442273
Validation loss decreased (0.282813 --> 0.282426).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3475240
	speed: 0.2904s/iter; left time: 1574.3782s
Epoch: 5 cost time: 13.2379469871521
Epoch: 5, Steps: 120 | Train Loss: 0.5111293 Vali Loss: 0.2815222 Test Loss: 0.3438301
Validation loss decreased (0.282426 --> 0.281522).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5118231
	speed: 0.2892s/iter; left time: 1533.2043s
Epoch: 6 cost time: 13.91380524635315
Epoch: 6, Steps: 120 | Train Loss: 0.5128637 Vali Loss: 0.2820828 Test Loss: 0.3435463
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.5565563
	speed: 0.2901s/iter; left time: 1502.9428s
Epoch: 7 cost time: 13.253377437591553
Epoch: 7, Steps: 120 | Train Loss: 0.5111752 Vali Loss: 0.2814900 Test Loss: 0.3435373
Validation loss decreased (0.281522 --> 0.281490).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.5494078
	speed: 0.2468s/iter; left time: 1249.1694s
Epoch: 8 cost time: 14.171924352645874
Epoch: 8, Steps: 120 | Train Loss: 0.5112294 Vali Loss: 0.2800558 Test Loss: 0.3438521
Validation loss decreased (0.281490 --> 0.280056).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.5129365
	speed: 0.3052s/iter; left time: 1508.1409s
Epoch: 9 cost time: 14.045764684677124
Epoch: 9, Steps: 120 | Train Loss: 0.5110466 Vali Loss: 0.2804384 Test Loss: 0.3431374
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.5077917
	speed: 0.2985s/iter; left time: 1439.1310s
Epoch: 10 cost time: 13.617934465408325
Epoch: 10, Steps: 120 | Train Loss: 0.5093052 Vali Loss: 0.2803530 Test Loss: 0.3434594
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.4134398
	speed: 0.2914s/iter; left time: 1369.7747s
Epoch: 11 cost time: 14.660876750946045
Epoch: 11, Steps: 120 | Train Loss: 0.5098821 Vali Loss: 0.2804937 Test Loss: 0.3430729
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.33356669545173645, mae:0.3756193220615387, rse:0.4631612002849579, corr:[0.26640803 0.26911122 0.2688669  0.26757985 0.2669497  0.26681057
 0.2663585  0.26531368 0.2642506  0.26316628 0.26192597 0.26036644
 0.2589031  0.25787032 0.25725743 0.25707138 0.25690365 0.25628224
 0.2550768  0.25366643 0.252291   0.25103152 0.24966836 0.24798366
 0.24620473 0.24443531 0.24279432 0.24124433 0.23967403 0.2379464
 0.23624799 0.23470613 0.2336918  0.23297147 0.23218246 0.23079869
 0.22893499 0.22739615 0.22669823 0.22646755 0.22626193 0.22583446
 0.22512996 0.22433911 0.22351089 0.22233106 0.2206351  0.21858247
 0.21667928 0.21522614 0.21396182 0.21228878 0.21038058 0.20851994
 0.20661524 0.20482953 0.20301759 0.20111935 0.19971521 0.19899888
 0.19883585 0.19852197 0.19808608 0.19776188 0.19741726 0.19727014
 0.19682114 0.19583003 0.19457397 0.19351438 0.19273561 0.19214018
 0.19129461 0.19013229 0.1889204  0.1878633  0.18740037 0.18720508
 0.18682098 0.18594438 0.18538171 0.184933   0.18433817 0.18354562
 0.18291469 0.18291429 0.18334338 0.18373722 0.18340823 0.18236087
 0.18101169 0.17991263 0.17982097 0.18021724 0.18032251 0.17967355
 0.17842926 0.17721532 0.1763037  0.17535776 0.1740597  0.1724301
 0.1711748  0.1704357  0.17042094 0.17072949 0.17099302 0.17116056
 0.17067568 0.1698089  0.1687025  0.16781309 0.16698997 0.16653302
 0.16616952 0.16557261 0.16476443 0.16362268 0.16256285 0.16148826
 0.16048495 0.15925422 0.15807322 0.15704817 0.15605113 0.15507907
 0.15417883 0.15311565 0.15218407 0.15147986 0.15102409 0.150224
 0.14920397 0.1482819  0.1478214  0.147786   0.14741167 0.14631349
 0.14476928 0.14365236 0.14360087 0.14401701 0.14390321 0.1424675
 0.13982531 0.13734695 0.13584457 0.13515325 0.13468932 0.13422182
 0.13401996 0.13352783 0.13302141 0.13214086 0.13090375 0.12978318
 0.1297123  0.1303463  0.13076681 0.13058119 0.12965961 0.12922522
 0.12963884 0.1302987  0.13065696 0.13064636 0.13082217 0.13070878
 0.12997332 0.1281435  0.12618065 0.12477925 0.12460966 0.12437866
 0.12330922 0.12106094 0.11921217 0.11912017 0.11939911 0.11926339
 0.11845216 0.11861543 0.12118944 0.12455644 0.12509932 0.12254495
 0.11972976 0.11982778 0.12303504 0.12433652 0.12186576 0.12102836]
