Args in experiment:
Namespace(H_order=5, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=165, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=1, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Model(
  (freq_upsampler): Linear(in_features=165, out_features=209, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  15449280.0
params:  34694.0
Trainable parameters:  34694
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5110397
	speed: 0.1061s/iter; left time: 626.0871s
Epoch: 1 cost time: 13.029196500778198
Epoch: 1, Steps: 120 | Train Loss: 0.6682859 Vali Loss: 0.3474798 Test Loss: 0.3579246
Validation loss decreased (inf --> 0.347480).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5133520
	speed: 0.3473s/iter; left time: 2007.4546s
Epoch: 2 cost time: 16.38565993309021
Epoch: 2, Steps: 120 | Train Loss: 0.5600376 Vali Loss: 0.3159339 Test Loss: 0.3482817
Validation loss decreased (0.347480 --> 0.315934).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.6787659
	speed: 0.3440s/iter; left time: 1947.3182s
Epoch: 3 cost time: 16.271263360977173
Epoch: 3, Steps: 120 | Train Loss: 0.5424197 Vali Loss: 0.3074122 Test Loss: 0.3458066
Validation loss decreased (0.315934 --> 0.307412).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.5798877
	speed: 0.3602s/iter; left time: 1995.9081s
Epoch: 4 cost time: 16.72416353225708
Epoch: 4, Steps: 120 | Train Loss: 0.5338460 Vali Loss: 0.3005308 Test Loss: 0.3453412
Validation loss decreased (0.307412 --> 0.300531).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.5537847
	speed: 0.3303s/iter; left time: 1790.4117s
Epoch: 5 cost time: 15.410107135772705
Epoch: 5, Steps: 120 | Train Loss: 0.5265102 Vali Loss: 0.2964509 Test Loss: 0.3449280
Validation loss decreased (0.300531 --> 0.296451).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.7187752
	speed: 0.2759s/iter; left time: 1462.7457s
Epoch: 6 cost time: 9.685370445251465
Epoch: 6, Steps: 120 | Train Loss: 0.5241383 Vali Loss: 0.2939467 Test Loss: 0.3446860
Validation loss decreased (0.296451 --> 0.293947).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3494210
	speed: 0.1117s/iter; left time: 578.7855s
Epoch: 7 cost time: 5.053679466247559
Epoch: 7, Steps: 120 | Train Loss: 0.5234300 Vali Loss: 0.2915967 Test Loss: 0.3441063
Validation loss decreased (0.293947 --> 0.291597).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.5357591
	speed: 0.3040s/iter; left time: 1538.3361s
Epoch: 8 cost time: 14.557950973510742
Epoch: 8, Steps: 120 | Train Loss: 0.5214781 Vali Loss: 0.2901188 Test Loss: 0.3439954
Validation loss decreased (0.291597 --> 0.290119).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.7143494
	speed: 0.2973s/iter; left time: 1469.0864s
Epoch: 9 cost time: 14.190277099609375
Epoch: 9, Steps: 120 | Train Loss: 0.5191120 Vali Loss: 0.2886205 Test Loss: 0.3439032
Validation loss decreased (0.290119 --> 0.288621).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.6201203
	speed: 0.3079s/iter; left time: 1484.4388s
Epoch: 10 cost time: 14.42433214187622
Epoch: 10, Steps: 120 | Train Loss: 0.5167755 Vali Loss: 0.2885301 Test Loss: 0.3432799
Validation loss decreased (0.288621 --> 0.288530).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3335523
	speed: 0.3047s/iter; left time: 1432.1907s
Epoch: 11 cost time: 13.729337930679321
Epoch: 11, Steps: 120 | Train Loss: 0.5170107 Vali Loss: 0.2876107 Test Loss: 0.3432344
Validation loss decreased (0.288530 --> 0.287611).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.5047801
	speed: 0.2812s/iter; left time: 1288.3720s
Epoch: 12 cost time: 13.34674882888794
Epoch: 12, Steps: 120 | Train Loss: 0.5153496 Vali Loss: 0.2867066 Test Loss: 0.3430046
Validation loss decreased (0.287611 --> 0.286707).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3664792
	speed: 0.2896s/iter; left time: 1291.9760s
Epoch: 13 cost time: 13.509078979492188
Epoch: 13, Steps: 120 | Train Loss: 0.5157344 Vali Loss: 0.2859411 Test Loss: 0.3431894
Validation loss decreased (0.286707 --> 0.285941).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4942105
	speed: 0.2990s/iter; left time: 1298.0041s
Epoch: 14 cost time: 14.34424638748169
Epoch: 14, Steps: 120 | Train Loss: 0.5144024 Vali Loss: 0.2857639 Test Loss: 0.3429937
Validation loss decreased (0.285941 --> 0.285764).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.5175375
	speed: 0.2927s/iter; left time: 1235.4432s
Epoch: 15 cost time: 13.200842380523682
Epoch: 15, Steps: 120 | Train Loss: 0.5148036 Vali Loss: 0.2854677 Test Loss: 0.3428662
Validation loss decreased (0.285764 --> 0.285468).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4319582
	speed: 0.2754s/iter; left time: 1129.4494s
Epoch: 16 cost time: 12.877589464187622
Epoch: 16, Steps: 120 | Train Loss: 0.5149121 Vali Loss: 0.2846475 Test Loss: 0.3427093
Validation loss decreased (0.285468 --> 0.284647).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.5077390
	speed: 0.2756s/iter; left time: 1096.9790s
Epoch: 17 cost time: 12.91104006767273
Epoch: 17, Steps: 120 | Train Loss: 0.5109900 Vali Loss: 0.2846864 Test Loss: 0.3426495
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.7219379
	speed: 0.2738s/iter; left time: 1057.2400s
Epoch: 18 cost time: 13.116339445114136
Epoch: 18, Steps: 120 | Train Loss: 0.5127695 Vali Loss: 0.2843177 Test Loss: 0.3426107
Validation loss decreased (0.284647 --> 0.284318).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.4207472
	speed: 0.2711s/iter; left time: 1014.2645s
Epoch: 19 cost time: 12.160910367965698
Epoch: 19, Steps: 120 | Train Loss: 0.5131708 Vali Loss: 0.2836857 Test Loss: 0.3427838
Validation loss decreased (0.284318 --> 0.283686).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.6276799
	speed: 0.2232s/iter; left time: 808.3774s
Epoch: 20 cost time: 11.274872303009033
Epoch: 20, Steps: 120 | Train Loss: 0.5124833 Vali Loss: 0.2835905 Test Loss: 0.3428389
Validation loss decreased (0.283686 --> 0.283591).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.5075628
	speed: 0.3075s/iter; left time: 1076.4407s
Epoch: 21 cost time: 13.65086054801941
Epoch: 21, Steps: 120 | Train Loss: 0.5118452 Vali Loss: 0.2832075 Test Loss: 0.3426016
Validation loss decreased (0.283591 --> 0.283207).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.4915879
	speed: 0.2924s/iter; left time: 988.6614s
Epoch: 22 cost time: 13.691800355911255
Epoch: 22, Steps: 120 | Train Loss: 0.5110131 Vali Loss: 0.2833256 Test Loss: 0.3424805
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.3040010
	speed: 0.2842s/iter; left time: 926.6749s
Epoch: 23 cost time: 13.702739477157593
Epoch: 23, Steps: 120 | Train Loss: 0.5108451 Vali Loss: 0.2833325 Test Loss: 0.3422982
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.5443442
	speed: 0.2800s/iter; left time: 879.5008s
Epoch: 24 cost time: 13.392094135284424
Epoch: 24, Steps: 120 | Train Loss: 0.5100092 Vali Loss: 0.2828802 Test Loss: 0.3423720
Validation loss decreased (0.283207 --> 0.282880).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.4866767
	speed: 0.2855s/iter; left time: 862.4957s
Epoch: 25 cost time: 13.696086645126343
Epoch: 25, Steps: 120 | Train Loss: 0.5107223 Vali Loss: 0.2827142 Test Loss: 0.3424617
Validation loss decreased (0.282880 --> 0.282714).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.3278920
	speed: 0.2984s/iter; left time: 865.6055s
Epoch: 26 cost time: 13.444815397262573
Epoch: 26, Steps: 120 | Train Loss: 0.5094064 Vali Loss: 0.2827772 Test Loss: 0.3423848
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.5749927
	speed: 0.2823s/iter; left time: 785.2038s
Epoch: 27 cost time: 13.602320194244385
Epoch: 27, Steps: 120 | Train Loss: 0.5113715 Vali Loss: 0.2824351 Test Loss: 0.3424005
Validation loss decreased (0.282714 --> 0.282435).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.5292928
	speed: 0.2980s/iter; left time: 792.9336s
Epoch: 28 cost time: 14.217352628707886
Epoch: 28, Steps: 120 | Train Loss: 0.5108893 Vali Loss: 0.2822208 Test Loss: 0.3424444
Validation loss decreased (0.282435 --> 0.282221).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.4118737
	speed: 0.2937s/iter; left time: 746.3796s
Epoch: 29 cost time: 13.485501289367676
Epoch: 29, Steps: 120 | Train Loss: 0.5097645 Vali Loss: 0.2820249 Test Loss: 0.3423990
Validation loss decreased (0.282221 --> 0.282025).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.6388955
	speed: 0.2940s/iter; left time: 711.8786s
Epoch: 30 cost time: 13.720027446746826
Epoch: 30, Steps: 120 | Train Loss: 0.5102490 Vali Loss: 0.2821210 Test Loss: 0.3423008
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.5392557
	speed: 0.2890s/iter; left time: 664.8923s
Epoch: 31 cost time: 14.082835912704468
Epoch: 31, Steps: 120 | Train Loss: 0.5106326 Vali Loss: 0.2822112 Test Loss: 0.3422060
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.3876268
	speed: 0.2219s/iter; left time: 483.8572s
Epoch: 32 cost time: 10.276814937591553
Epoch: 32, Steps: 120 | Train Loss: 0.5077733 Vali Loss: 0.2817289 Test Loss: 0.3422455
Validation loss decreased (0.282025 --> 0.281729).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.5653912
	speed: 0.2556s/iter; left time: 526.6911s
Epoch: 33 cost time: 13.411530494689941
Epoch: 33, Steps: 120 | Train Loss: 0.5099369 Vali Loss: 0.2819223 Test Loss: 0.3423235
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.3900522
	speed: 0.2783s/iter; left time: 540.1174s
Epoch: 34 cost time: 12.905364513397217
Epoch: 34, Steps: 120 | Train Loss: 0.5100816 Vali Loss: 0.2817970 Test Loss: 0.3422543
EarlyStopping counter: 2 out of 3
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.5582306
	speed: 0.3047s/iter; left time: 554.8120s
Epoch: 35 cost time: 14.566911697387695
Epoch: 35, Steps: 120 | Train Loss: 0.5087961 Vali Loss: 0.2817166 Test Loss: 0.3422565
Validation loss decreased (0.281729 --> 0.281717).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.6181740
	speed: 0.2892s/iter; left time: 491.9084s
Epoch: 36 cost time: 13.530045986175537
Epoch: 36, Steps: 120 | Train Loss: 0.5103518 Vali Loss: 0.2817703 Test Loss: 0.3421847
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.5566509
	speed: 0.3129s/iter; left time: 494.7462s
Epoch: 37 cost time: 14.580326795578003
Epoch: 37, Steps: 120 | Train Loss: 0.5093133 Vali Loss: 0.2817354 Test Loss: 0.3421800
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.4145943
	speed: 0.3143s/iter; left time: 459.2078s
Epoch: 38 cost time: 15.250199794769287
Epoch: 38, Steps: 120 | Train Loss: 0.5108463 Vali Loss: 0.2817650 Test Loss: 0.3421545
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_192_FITS_ETTh2_ftM_sl720_ll48_pl192_H5_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.33210963010787964, mae:0.3748248219490051, rse:0.462148517370224, corr:[0.2624576  0.26737478 0.26554078 0.26548964 0.2660707  0.26530847
 0.26433474 0.2639351  0.2636643  0.26251364 0.26092005 0.2593707
 0.2583529  0.25773665 0.25710177 0.25657898 0.25630847 0.25591794
 0.25484622 0.25335643 0.2519585  0.2508241  0.24948885 0.24764691
 0.24575636 0.24426359 0.24296243 0.24140239 0.23970293 0.23827255
 0.23713495 0.23564722 0.23402052 0.23281023 0.23222332 0.23159328
 0.2303638  0.22899602 0.22816294 0.2276706  0.2270058  0.22611131
 0.22528546 0.22460689 0.22380584 0.22267373 0.22132792 0.21978863
 0.21806484 0.21613026 0.21428157 0.2128296  0.21165523 0.2099025
 0.20741847 0.20557521 0.20459463 0.20329152 0.20137393 0.19967587
 0.19912715 0.19909249 0.19901057 0.19876225 0.19825746 0.19788189
 0.19733824 0.19668534 0.19620343 0.19565187 0.19461423 0.19346526
 0.1927103  0.19218352 0.19116278 0.18936586 0.18799134 0.18745786
 0.18710184 0.18632156 0.18615389 0.18643114 0.18628465 0.18532225
 0.18430713 0.18422298 0.18465471 0.18461987 0.18379451 0.1831065
 0.18285632 0.18231246 0.18155012 0.18089235 0.18081732 0.18085016
 0.18012212 0.1788133  0.17785162 0.17744018 0.1768857  0.1756026
 0.17426832 0.17334397 0.17301248 0.17270613 0.17235324 0.17232268
 0.17192371 0.17109348 0.17006698 0.16960035 0.16936508 0.16913395
 0.16856705 0.16792451 0.16744134 0.16632226 0.16445939 0.16234455
 0.16114037 0.16050635 0.15967934 0.15817283 0.15651716 0.15550502
 0.15503225 0.15428555 0.15341027 0.15266252 0.1520234  0.15097092
 0.15004325 0.14961234 0.14942771 0.14914955 0.14872053 0.14849442
 0.14817233 0.14728315 0.14615838 0.14532791 0.14484124 0.14383906
 0.14200148 0.14036931 0.13928936 0.13800149 0.13610567 0.1345936
 0.13460234 0.13472918 0.13410436 0.13267677 0.13167167 0.13155004
 0.13178724 0.13146025 0.13107145 0.13143086 0.13155127 0.13129388
 0.13096714 0.13102694 0.13130085 0.13107722 0.13062501 0.1298648
 0.12869555 0.12660223 0.12488168 0.12432456 0.12458602 0.12331916
 0.12083725 0.11894307 0.1189969  0.11928324 0.1173262  0.11555272
 0.11615237 0.11770831 0.11789784 0.11738762 0.11779173 0.11892304
 0.1183029  0.1169776  0.11964663 0.12261955 0.1206494  0.12129839]
