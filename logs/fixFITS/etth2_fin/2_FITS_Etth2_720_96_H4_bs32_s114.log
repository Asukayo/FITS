Args in experiment:
Namespace(H_order=4, ab=2, activation='gelu', aug_data_size=1, aug_method='NA', aug_rate=0.5, base_T=24, batch_size=64, c_out=7, checkpoints='./checkpoints/', cut_freq=134, d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', data_size=1, dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=6, groups=1, hidden_size=1, in_batch_augmentation=False, in_dataset_augmentation=False, individual=False, is_training=1, itr=1, kernel=5, label_len=48, learning_rate=0.0005, levels=3, loss='mse', lradj='type3', model='FITS', model_id='ETTh2_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/', seed=114, seq_len=720, stacks=1, target='OT', test_flop=False, test_time_train=False, testset_div=2, train_epochs=50, train_mode=2, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:6
>>>>>>>start training : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H4_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=134, out_features=151, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  9064832.0
params:  20385.0
Trainable parameters:  20385
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4661577
	speed: 0.1628s/iter; left time: 977.0145s
Epoch: 1 cost time: 19.729387760162354
Epoch: 1, Steps: 122 | Train Loss: 0.4990201 Vali Loss: 0.3442852 Test Loss: 0.3546031
Validation loss decreased (inf --> 0.344285).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3009380
	speed: 0.4239s/iter; left time: 2492.3308s
Epoch: 2 cost time: 19.034263372421265
Epoch: 2, Steps: 122 | Train Loss: 0.3513303 Vali Loss: 0.3121219 Test Loss: 0.3266709
Validation loss decreased (0.344285 --> 0.312122).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2847999
	speed: 0.4389s/iter; left time: 2526.6104s
Epoch: 3 cost time: 22.276644229888916
Epoch: 3, Steps: 122 | Train Loss: 0.2867088 Vali Loss: 0.3026063 Test Loss: 0.3186323
Validation loss decreased (0.312122 --> 0.302606).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2046347
	speed: 0.4842s/iter; left time: 2728.4927s
Epoch: 4 cost time: 22.505067110061646
Epoch: 4, Steps: 122 | Train Loss: 0.2462474 Vali Loss: 0.2969279 Test Loss: 0.3149452
Validation loss decreased (0.302606 --> 0.296928).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2013393
	speed: 0.4584s/iter; left time: 2527.0271s
Epoch: 5 cost time: 19.765034675598145
Epoch: 5, Steps: 122 | Train Loss: 0.2161340 Vali Loss: 0.2919777 Test Loss: 0.3110256
Validation loss decreased (0.296928 --> 0.291978).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2246654
	speed: 0.4345s/iter; left time: 2342.5346s
Epoch: 6 cost time: 20.064831495285034
Epoch: 6, Steps: 122 | Train Loss: 0.1926518 Vali Loss: 0.2864392 Test Loss: 0.3074183
Validation loss decreased (0.291978 --> 0.286439).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1583650
	speed: 0.4322s/iter; left time: 2277.1074s
Epoch: 7 cost time: 19.853281259536743
Epoch: 7, Steps: 122 | Train Loss: 0.1740001 Vali Loss: 0.2800763 Test Loss: 0.3037637
Validation loss decreased (0.286439 --> 0.280076).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1798270
	speed: 0.4358s/iter; left time: 2243.2582s
Epoch: 8 cost time: 20.163950204849243
Epoch: 8, Steps: 122 | Train Loss: 0.1586745 Vali Loss: 0.2756382 Test Loss: 0.3003230
Validation loss decreased (0.280076 --> 0.275638).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1582226
	speed: 0.4324s/iter; left time: 2172.8170s
Epoch: 9 cost time: 20.28273057937622
Epoch: 9, Steps: 122 | Train Loss: 0.1459329 Vali Loss: 0.2707473 Test Loss: 0.2970881
Validation loss decreased (0.275638 --> 0.270747).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1313677
	speed: 0.4353s/iter; left time: 2134.1134s
Epoch: 10 cost time: 19.9826877117157
Epoch: 10, Steps: 122 | Train Loss: 0.1353378 Vali Loss: 0.2651340 Test Loss: 0.2941623
Validation loss decreased (0.270747 --> 0.265134).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1270188
	speed: 0.4353s/iter; left time: 2081.1067s
Epoch: 11 cost time: 20.355656385421753
Epoch: 11, Steps: 122 | Train Loss: 0.1265160 Vali Loss: 0.2620299 Test Loss: 0.2914370
Validation loss decreased (0.265134 --> 0.262030).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1108973
	speed: 0.4690s/iter; left time: 2185.1781s
Epoch: 12 cost time: 20.945693969726562
Epoch: 12, Steps: 122 | Train Loss: 0.1191107 Vali Loss: 0.2580027 Test Loss: 0.2890943
Validation loss decreased (0.262030 --> 0.258003).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.0987001
	speed: 0.4844s/iter; left time: 2197.5360s
Epoch: 13 cost time: 22.393523693084717
Epoch: 13, Steps: 122 | Train Loss: 0.1128046 Vali Loss: 0.2540063 Test Loss: 0.2870857
Validation loss decreased (0.258003 --> 0.254006).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1146372
	speed: 0.4275s/iter; left time: 1887.5409s
Epoch: 14 cost time: 19.162382125854492
Epoch: 14, Steps: 122 | Train Loss: 0.1073783 Vali Loss: 0.2513686 Test Loss: 0.2855816
Validation loss decreased (0.254006 --> 0.251369).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1175887
	speed: 0.4172s/iter; left time: 1791.2435s
Epoch: 15 cost time: 19.075668573379517
Epoch: 15, Steps: 122 | Train Loss: 0.1028870 Vali Loss: 0.2487668 Test Loss: 0.2841646
Validation loss decreased (0.251369 --> 0.248767).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.0898074
	speed: 0.4215s/iter; left time: 1758.2666s
Epoch: 16 cost time: 19.505735158920288
Epoch: 16, Steps: 122 | Train Loss: 0.0989658 Vali Loss: 0.2454236 Test Loss: 0.2826069
Validation loss decreased (0.248767 --> 0.245424).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.0863352
	speed: 0.4199s/iter; left time: 1700.0884s
Epoch: 17 cost time: 19.543878078460693
Epoch: 17, Steps: 122 | Train Loss: 0.0954724 Vali Loss: 0.2442340 Test Loss: 0.2815908
Validation loss decreased (0.245424 --> 0.244234).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.0841986
	speed: 0.4087s/iter; left time: 1604.8217s
Epoch: 18 cost time: 19.102407217025757
Epoch: 18, Steps: 122 | Train Loss: 0.0928049 Vali Loss: 0.2423810 Test Loss: 0.2809075
Validation loss decreased (0.244234 --> 0.242381).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.0981202
	speed: 0.4198s/iter; left time: 1597.2309s
Epoch: 19 cost time: 19.492136240005493
Epoch: 19, Steps: 122 | Train Loss: 0.0903633 Vali Loss: 0.2409939 Test Loss: 0.2799998
Validation loss decreased (0.242381 --> 0.240994).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.0906098
	speed: 0.4314s/iter; left time: 1588.9899s
Epoch: 20 cost time: 20.913263082504272
Epoch: 20, Steps: 122 | Train Loss: 0.0881361 Vali Loss: 0.2390935 Test Loss: 0.2790562
Validation loss decreased (0.240994 --> 0.239093).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.0877902
	speed: 0.4603s/iter; left time: 1639.0146s
Epoch: 21 cost time: 21.04537796974182
Epoch: 21, Steps: 122 | Train Loss: 0.0863433 Vali Loss: 0.2374842 Test Loss: 0.2786495
Validation loss decreased (0.239093 --> 0.237484).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.0806374
	speed: 0.4623s/iter; left time: 1589.8401s
Epoch: 22 cost time: 20.85042119026184
Epoch: 22, Steps: 122 | Train Loss: 0.0846401 Vali Loss: 0.2370577 Test Loss: 0.2782794
Validation loss decreased (0.237484 --> 0.237058).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.0778555
	speed: 0.4151s/iter; left time: 1376.8035s
Epoch: 23 cost time: 18.75420379638672
Epoch: 23, Steps: 122 | Train Loss: 0.0831375 Vali Loss: 0.2350758 Test Loss: 0.2777497
Validation loss decreased (0.237058 --> 0.235076).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1067059
	speed: 0.4168s/iter; left time: 1331.7075s
Epoch: 24 cost time: 19.425745248794556
Epoch: 24, Steps: 122 | Train Loss: 0.0820825 Vali Loss: 0.2340753 Test Loss: 0.2773992
Validation loss decreased (0.235076 --> 0.234075).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.0791955
	speed: 0.4135s/iter; left time: 1270.6429s
Epoch: 25 cost time: 18.92052125930786
Epoch: 25, Steps: 122 | Train Loss: 0.0808789 Vali Loss: 0.2339898 Test Loss: 0.2771509
Validation loss decreased (0.234075 --> 0.233990).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.0650490
	speed: 0.3817s/iter; left time: 1126.3330s
Epoch: 26 cost time: 16.158915519714355
Epoch: 26, Steps: 122 | Train Loss: 0.0800172 Vali Loss: 0.2328754 Test Loss: 0.2768948
Validation loss decreased (0.233990 --> 0.232875).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1014394
	speed: 0.3662s/iter; left time: 1036.0718s
Epoch: 27 cost time: 18.334086179733276
Epoch: 27, Steps: 122 | Train Loss: 0.0791107 Vali Loss: 0.2317826 Test Loss: 0.2766432
Validation loss decreased (0.232875 --> 0.231783).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.0929869
	speed: 0.4177s/iter; left time: 1130.7609s
Epoch: 28 cost time: 19.43462824821472
Epoch: 28, Steps: 122 | Train Loss: 0.0784219 Vali Loss: 0.2314264 Test Loss: 0.2765841
Validation loss decreased (0.231783 --> 0.231426).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.0868236
	speed: 0.4336s/iter; left time: 1120.9098s
Epoch: 29 cost time: 20.799699068069458
Epoch: 29, Steps: 122 | Train Loss: 0.0777649 Vali Loss: 0.2304163 Test Loss: 0.2765370
Validation loss decreased (0.231426 --> 0.230416).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.0526180
	speed: 0.4463s/iter; left time: 1099.1590s
Epoch: 30 cost time: 20.72876763343811
Epoch: 30, Steps: 122 | Train Loss: 0.0772393 Vali Loss: 0.2301130 Test Loss: 0.2763741
Validation loss decreased (0.230416 --> 0.230113).  Saving model ...
Updating learning rate to 0.00011296777049628277
	iters: 100, epoch: 31 | loss: 0.0681865
	speed: 0.4651s/iter; left time: 1088.7332s
Epoch: 31 cost time: 21.07563853263855
Epoch: 31, Steps: 122 | Train Loss: 0.0766723 Vali Loss: 0.2294421 Test Loss: 0.2762826
Validation loss decreased (0.230113 --> 0.229442).  Saving model ...
Updating learning rate to 0.00010731938197146864
	iters: 100, epoch: 32 | loss: 0.0844450
	speed: 0.4073s/iter; left time: 903.6991s
Epoch: 32 cost time: 19.062346696853638
Epoch: 32, Steps: 122 | Train Loss: 0.0762057 Vali Loss: 0.2285113 Test Loss: 0.2762836
Validation loss decreased (0.229442 --> 0.228511).  Saving model ...
Updating learning rate to 0.00010195341287289519
	iters: 100, epoch: 33 | loss: 0.1068246
	speed: 0.4111s/iter; left time: 862.1267s
Epoch: 33 cost time: 18.866483449935913
Epoch: 33, Steps: 122 | Train Loss: 0.0758297 Vali Loss: 0.2282237 Test Loss: 0.2762105
Validation loss decreased (0.228511 --> 0.228224).  Saving model ...
Updating learning rate to 9.685574222925044e-05
	iters: 100, epoch: 34 | loss: 0.0922527
	speed: 0.4139s/iter; left time: 817.3680s
Epoch: 34 cost time: 18.864869594573975
Epoch: 34, Steps: 122 | Train Loss: 0.0754842 Vali Loss: 0.2279713 Test Loss: 0.2761259
Validation loss decreased (0.228224 --> 0.227971).  Saving model ...
Updating learning rate to 9.201295511778792e-05
	iters: 100, epoch: 35 | loss: 0.0751352
	speed: 0.4098s/iter; left time: 759.3358s
Epoch: 35 cost time: 19.085307359695435
Epoch: 35, Steps: 122 | Train Loss: 0.0751313 Vali Loss: 0.2275573 Test Loss: 0.2761495
Validation loss decreased (0.227971 --> 0.227557).  Saving model ...
Updating learning rate to 8.74123073618985e-05
	iters: 100, epoch: 36 | loss: 0.0784620
	speed: 0.4198s/iter; left time: 726.6634s
Epoch: 36 cost time: 19.272392988204956
Epoch: 36, Steps: 122 | Train Loss: 0.0747398 Vali Loss: 0.2278378 Test Loss: 0.2761380
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.304169199380359e-05
	iters: 100, epoch: 37 | loss: 0.0673002
	speed: 0.4253s/iter; left time: 684.2403s
Epoch: 37 cost time: 19.604411840438843
Epoch: 37, Steps: 122 | Train Loss: 0.0744477 Vali Loss: 0.2274553 Test Loss: 0.2761296
Validation loss decreased (0.227557 --> 0.227455).  Saving model ...
Updating learning rate to 7.88896073941134e-05
	iters: 100, epoch: 38 | loss: 0.0755602
	speed: 0.4375s/iter; left time: 650.5969s
Epoch: 38 cost time: 21.797561168670654
Epoch: 38, Steps: 122 | Train Loss: 0.0743604 Vali Loss: 0.2266979 Test Loss: 0.2762749
Validation loss decreased (0.227455 --> 0.226698).  Saving model ...
Updating learning rate to 7.494512702440772e-05
	iters: 100, epoch: 39 | loss: 0.0622481
	speed: 0.4665s/iter; left time: 636.7410s
Epoch: 39 cost time: 21.503419399261475
Epoch: 39, Steps: 122 | Train Loss: 0.0741116 Vali Loss: 0.2271297 Test Loss: 0.2762613
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.119787067318733e-05
	iters: 100, epoch: 40 | loss: 0.0832581
	speed: 0.4630s/iter; left time: 575.5206s
Epoch: 40 cost time: 21.307478189468384
Epoch: 40, Steps: 122 | Train Loss: 0.0739339 Vali Loss: 0.2265298 Test Loss: 0.2763197
Validation loss decreased (0.226698 --> 0.226530).  Saving model ...
Updating learning rate to 6.763797713952796e-05
	iters: 100, epoch: 41 | loss: 0.0598890
	speed: 0.4174s/iter; left time: 467.8992s
Epoch: 41 cost time: 18.937260389328003
Epoch: 41, Steps: 122 | Train Loss: 0.0736627 Vali Loss: 0.2264460 Test Loss: 0.2762743
Validation loss decreased (0.226530 --> 0.226446).  Saving model ...
Updating learning rate to 6.425607828255156e-05
	iters: 100, epoch: 42 | loss: 0.0613263
	speed: 0.4116s/iter; left time: 411.2203s
Epoch: 42 cost time: 19.417298555374146
Epoch: 42, Steps: 122 | Train Loss: 0.0734555 Vali Loss: 0.2265882 Test Loss: 0.2763533
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.104327436842398e-05
	iters: 100, epoch: 43 | loss: 0.0650392
	speed: 0.4125s/iter; left time: 361.7703s
Epoch: 43 cost time: 18.85651683807373
Epoch: 43, Steps: 122 | Train Loss: 0.0735022 Vali Loss: 0.2258306 Test Loss: 0.2763784
Validation loss decreased (0.226446 --> 0.225831).  Saving model ...
Updating learning rate to 5.799111065000278e-05
	iters: 100, epoch: 44 | loss: 0.0707678
	speed: 0.4086s/iter; left time: 308.4858s
Epoch: 44 cost time: 18.26746439933777
Epoch: 44, Steps: 122 | Train Loss: 0.0733348 Vali Loss: 0.2257412 Test Loss: 0.2763942
Validation loss decreased (0.225831 --> 0.225741).  Saving model ...
Updating learning rate to 5.509155511750264e-05
	iters: 100, epoch: 45 | loss: 0.0738185
	speed: 0.4164s/iter; left time: 263.5662s
Epoch: 45 cost time: 19.340500831604004
Epoch: 45, Steps: 122 | Train Loss: 0.0732104 Vali Loss: 0.2245872 Test Loss: 0.2763979
Validation loss decreased (0.225741 --> 0.224587).  Saving model ...
Updating learning rate to 5.2336977361627504e-05
	iters: 100, epoch: 46 | loss: 0.0621729
	speed: 0.4121s/iter; left time: 210.5637s
Epoch: 46 cost time: 18.989649057388306
Epoch: 46, Steps: 122 | Train Loss: 0.0731050 Vali Loss: 0.2248866 Test Loss: 0.2764052
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.9720128493546124e-05
	iters: 100, epoch: 47 | loss: 0.0461104
	speed: 0.4390s/iter; left time: 170.7672s
Epoch: 47 cost time: 21.395007371902466
Epoch: 47, Steps: 122 | Train Loss: 0.0730531 Vali Loss: 0.2253074 Test Loss: 0.2764632
EarlyStopping counter: 2 out of 3
Updating learning rate to 4.7234122068868816e-05
	iters: 100, epoch: 48 | loss: 0.0737446
	speed: 0.4388s/iter; left time: 117.1679s
Epoch: 48 cost time: 20.09189510345459
Epoch: 48, Steps: 122 | Train Loss: 0.0729734 Vali Loss: 0.2250240 Test Loss: 0.2764942
EarlyStopping counter: 3 out of 3
Early stopping
train 7825
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=134, out_features=151, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  9064832.0
params:  20385.0
Trainable parameters:  20385
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2232831
	speed: 0.1614s/iter; left time: 968.3670s
Epoch: 1 cost time: 19.625731229782104
Epoch: 1, Steps: 122 | Train Loss: 0.4130465 Vali Loss: 0.2154934 Test Loss: 0.2756584
Validation loss decreased (inf --> 0.215493).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3670932
	speed: 0.4213s/iter; left time: 2476.6377s
Epoch: 2 cost time: 19.412514209747314
Epoch: 2, Steps: 122 | Train Loss: 0.4090201 Vali Loss: 0.2161074 Test Loss: 0.2738928
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3406797
	speed: 0.4169s/iter; left time: 2399.9198s
Epoch: 3 cost time: 19.34201741218567
Epoch: 3, Steps: 122 | Train Loss: 0.4075399 Vali Loss: 0.2165634 Test Loss: 0.2735458
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2493648
	speed: 0.4159s/iter; left time: 2343.3966s
Epoch: 4 cost time: 18.938421964645386
Epoch: 4, Steps: 122 | Train Loss: 0.4063855 Vali Loss: 0.2135603 Test Loss: 0.2727806
Validation loss decreased (0.215493 --> 0.213560).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.5628694
	speed: 0.4070s/iter; left time: 2243.7310s
Epoch: 5 cost time: 17.962146759033203
Epoch: 5, Steps: 122 | Train Loss: 0.4049081 Vali Loss: 0.2147758 Test Loss: 0.2725472
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2411009
	speed: 0.4363s/iter; left time: 2351.9887s
Epoch: 6 cost time: 20.754085302352905
Epoch: 6, Steps: 122 | Train Loss: 0.4044957 Vali Loss: 0.2130169 Test Loss: 0.2720875
Validation loss decreased (0.213560 --> 0.213017).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.5399538
	speed: 0.4324s/iter; left time: 2278.3447s
Epoch: 7 cost time: 19.505491971969604
Epoch: 7, Steps: 122 | Train Loss: 0.4043102 Vali Loss: 0.2140550 Test Loss: 0.2725954
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3776020
	speed: 0.4718s/iter; left time: 2428.5929s
Epoch: 8 cost time: 21.634850025177002
Epoch: 8, Steps: 122 | Train Loss: 0.4027938 Vali Loss: 0.2127330 Test Loss: 0.2723513
Validation loss decreased (0.213017 --> 0.212733).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3998545
	speed: 0.4607s/iter; left time: 2315.2162s
Epoch: 9 cost time: 20.489990234375
Epoch: 9, Steps: 122 | Train Loss: 0.4034794 Vali Loss: 0.2125279 Test Loss: 0.2719238
Validation loss decreased (0.212733 --> 0.212528).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.6148544
	speed: 0.4296s/iter; left time: 2106.5123s
Epoch: 10 cost time: 18.898503065109253
Epoch: 10, Steps: 122 | Train Loss: 0.4029636 Vali Loss: 0.2143527 Test Loss: 0.2717395
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3693067
	speed: 0.4212s/iter; left time: 2013.7375s
Epoch: 11 cost time: 19.98873782157898
Epoch: 11, Steps: 122 | Train Loss: 0.4028816 Vali Loss: 0.2126918 Test Loss: 0.2716790
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3928918
	speed: 0.4251s/iter; left time: 1980.3355s
Epoch: 12 cost time: 19.567203283309937
Epoch: 12, Steps: 122 | Train Loss: 0.4024971 Vali Loss: 0.2117952 Test Loss: 0.2715154
Validation loss decreased (0.212528 --> 0.211795).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4472438
	speed: 0.4158s/iter; left time: 1886.5737s
Epoch: 13 cost time: 19.71990442276001
Epoch: 13, Steps: 122 | Train Loss: 0.4013451 Vali Loss: 0.2133346 Test Loss: 0.2714640
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3359752
	speed: 0.4316s/iter; left time: 1905.4024s
Epoch: 14 cost time: 19.433829069137573
Epoch: 14, Steps: 122 | Train Loss: 0.4019968 Vali Loss: 0.2132711 Test Loss: 0.2716530
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.5440896
	speed: 0.4281s/iter; left time: 1837.9075s
Epoch: 15 cost time: 19.880624532699585
Epoch: 15, Steps: 122 | Train Loss: 0.4017350 Vali Loss: 0.2123394 Test Loss: 0.2715091
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_720_96_FITS_ETTh2_ftM_sl720_ll48_pl96_H4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.27243250608444214, mae:0.33682382106781006, rse:0.4206402003765106, corr:[0.2737606  0.27622005 0.27561235 0.27417925 0.27336046 0.27313507
 0.27272385 0.2717601  0.27074015 0.26953596 0.26813206 0.2663655
 0.26476178 0.26376414 0.2632163  0.26299465 0.26255772 0.2617682
 0.26077846 0.25995973 0.2593436  0.2584755  0.25694656 0.25466335
 0.2521823  0.25015292 0.24876322 0.24761163 0.24639021 0.245051
 0.24372272 0.24250285 0.24127117 0.24011976 0.23897664 0.23771222
 0.23650804 0.23565249 0.2352731  0.23482727 0.2341312  0.2331984
 0.23209852 0.23095684 0.23006272 0.22917117 0.22801177 0.2262982
 0.2242323  0.22230825 0.22091533 0.21959768 0.21854982 0.21754408
 0.21608663 0.21437277 0.21235436 0.2100891  0.20816629 0.20715107
 0.20703419 0.20700654 0.20684148 0.20656374 0.20571472 0.20507352
 0.20459965 0.20417419 0.20384988 0.20376481 0.20376995 0.203869
 0.20351717 0.20227924 0.20049313 0.1983843  0.1972711  0.19710802
 0.1972824  0.19668585 0.19634828 0.19642009 0.1961768  0.19549112
 0.19478165 0.19508627 0.19624496 0.19726893 0.19648695 0.19477178
 0.19359584 0.19396646 0.19546108 0.19563429 0.19380979 0.19275497]
